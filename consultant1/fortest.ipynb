{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "%pip install -q nest_asyncio xmltodict faiss-cpu==1.7.4 langchain==0.1.7 openai==1.12.0 tiktoken==0.6.0 langchain_community==0.0.20 langchain-openai==0.0.6 unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader\n",
    "\n",
    "ipynblinklist = [\"https://colab.research.google.com/drive/15ksFMFXYWiFWGNwm2w7E5BuQY43pxswn?usp=sharing\"]\n",
    "\n",
    "ul=loader.UniversalLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipynblinklist = [\"https://colab.research.google.com/drive/1qKaqDCCKGqSO9KBaz69gO5a2RuflJLrw?usp=sharing#scrollTo=aX_dms8m1jzG\"]\n",
    "\n",
    "docs=ul.load_ipynb(ipynblinklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**content** - *это выбор из какой базы будет использоваться текст для анализа*\n",
      "\n",
      "\n",
      "\n",
      "**temperature** - *это значение чем меньше (ближе, либо равно нулю) чем точнее к контексту, чем ближе к 1 тем больше фантазии*\n",
      "\n",
      "\n",
      "\n",
      "**num_fragment** - *это количество отрезков документа которые отбираются по ключевым фразам и передаются в модель для анализа (сейчас 5 так как при нынешней нарезке влезает в модель по количеству токенов в среднем около 3000, но может варьироваться)*\n",
      "\n",
      "\n",
      "\n",
      "**system_prompt** - это роль модели и какие то глобальные установки\n",
      "\n",
      "\n",
      "\n",
      "**instructions** - *это описание задачи что нужно сделать над отобранным контекстом по ключевым фразам*\n",
      "\n",
      "\n",
      "\n",
      "**topicphrase** - *это ключевые слова для отбора отрывков текста в нужном смысле для анализа*\n",
      "#B2B или B2C\n",
      "#@title 1. B2B или B2C\n",
      "\n",
      "model = \"gpt-3.5-turbo-1106\" #@param [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-1106\"]\n",
      "\n",
      "content = 'Client +' #@param ['Диалог', 'Client +', 'Manager +']\n",
      "\n",
      "chunk_size = 1024 #@param {type: \"slider\", min: 200, max: 1024, step:8}\n",
      "\n",
      "chunk_overlap = 0 #@param {type: \"slider\", min: 0, max: 256, step:8}\n",
      "\n",
      "temperature = 0 #@param {type: \"slider\", min: 0, max: 1, step:0.1}\n",
      "\n",
      "num_fragment = 6 #@param {type:\"integer\"}\n",
      "\n",
      "system_prompt = \"Вы анализируете текст, в котором клиент обратился в компанию \\\"университет искусственного интеллекта\\\" для покупки курсов обучения по искусственному интеллекту и программированию. Ваша задача точно определить, является ли клиент b2b или b2c. Вы всегда учитываете что \\\"b2c\\\" - это человек который ищет курсы для себя чтобы получить новую работу/ заработать большую зарплату/ улучшить свои навыки или развиться в IT-сфере/ когда человек говорит о личном интересе к нейронным сетям/ когда он хочет создать проект для себя/стажировки/гарантия трудоустройства/смена деятельности/ когда вы понимаете что разговор идет о личных интересах клиента. Вы всегда учитываете что \\\"b2b\\\" - это когда есть фразы в тексте указывающим на то что клиент явно хочет обучить своих сотрудников / создать проект для своей компании / с целью развития услуг / увеличения доходов/ когда предприниматель или руководитель компании обращается в компанию/  когда вы слышите что разговор идет о интересах компании. Вы знаете на 100% что фразы о нейронных сетях/ разработке/ программировании/датасетов/аналитика/анализирования/инстуственном интеллекте/алгоритмы/ создание проектов / разработка игр - НИКОГДА НЕ ОПРЕДЕЛЯЕТ  является ли этот клиент b2b или b2c. Вы всегда пишете не равные проценты дления между b2b и b2c. Вы всегда строго следуете порядку отчета.\" #@param {type:\"string\"}\n",
      "\n",
      "instructions = \"Пожалуйста, давайте подумаем шаг за шагом. #01 Первый порядок отчета: проанализируйте пожалуйста все тексты, далее определите является ли клиент b2b или b2c согласно тому что вы знаете, и напишите только вывод: \\\"b2c: % вероятность, что это b2c\\\"+\\\"b2b: % вероятность, что это b2b\\\" +\\\"подробное описание до 200 символов, объясняющее, почему это b2b или b2c\\\".\" #@param {type:\"string\"}\n",
      "\n",
      "topicphrase = 'проект, себя, развиваться, создать, обучиться, навки, знания, трудоустройство' #@param {type:\"string\"}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "if content == 'Диалог':\n",
      "\n",
      "  content_base = base\n",
      "\n",
      "elif content == 'Client +':\n",
      "\n",
      "  content_base = base1\n",
      "\n",
      "elif content == 'Manager +':\n",
      "\n",
      "  content_base = base2\n",
      "\n",
      "\n",
      "\n",
      "output1 = answer_user_question(system_prompt, content_base, topicphrase,\n",
      "\n",
      "                               instructions, temperature, 1, num_fragment,\n",
      "\n",
      "                               chunk_size, chunk_overlap, model) #ОБЩИЙ\n",
      "\n",
      "\n",
      "\n",
      "print(\"\\nОтвет:\\n\", output1)\n",
      "#@title 3. Отчет итого\n",
      "\n",
      "model = \"gpt-3.5-turbo-1106\" #@param [\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-3.5-turbo-1106\"]\n",
      "\n",
      "temperature = 0 #@param {type: \"slider\", min: 0, max: 1, step:0.1}\n",
      "\n",
      "system_prompt = \"Ты четко следуешь данным тебе инструкциям\" #@param {type:\"string\"}\n",
      "\n",
      "instructions = \"Выдели из текста, что там указано: «b2b» или «b2c»? Ответ дай в формате: b2b или b2c, без дополнительного текста\" #@param {type:\"string\"}\n",
      "\n",
      "answer_1 = \"b2c: 90% вероятность, что это b2c b2b: 10% вероятность, что это b2b Клиент выражает личные желания и потребности, связанные с изменением своей профессиональной деятельности, улучшением дохода и поиском новых возможностей для себя. Он говорит о своих личных переживаниях, усталости от текущей работы, желании сменить сферу деятельности и найти себя на рынке.\" #@param {type:\"string\"}\n",
      "\n",
      "answer_2 = \"\" #@param {type:\"string\"}\n",
      "\n",
      "answer_3 = \"\" #@param {type:\"string\"}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "answers = \" \".join([f\"Анализ №{i+1}. {q}\\n\"  for i, q in enumerate([answer_1, answer_2, answer_3]) if len(q)])\n",
      "\n",
      "\n",
      "\n",
      "output1 = answer_user_question_from_answer(system_prompt, instructions, answers,\n",
      "\n",
      "                               temperature, 1, model)\n",
      "\n",
      "\n",
      "\n",
      "print(\"\\nОтвет:\\n\", output1)\n"
     ]
    }
   ],
   "source": [
    "print(docs[2].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
