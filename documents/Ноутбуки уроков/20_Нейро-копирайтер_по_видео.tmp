[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n\n\u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0435 \u043c\u044b \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0438 \u0432\u0438\u0434\u0435\u043e-\u043b\u0435\u043a\u0446\u0438\u0438 \u0441 \u044e\u0442\u0443\u0431 \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u043d\u0435\u0439\u0440\u043e-\u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u043d\u0442\u0430 \u0438 \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0443 \u043f\u043e \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u043c \u043c\u043e\u043c\u0435\u043d\u0442\u0430\u043c \u0434\u0430\u043d\u043d\u043e\u0439 \u043b\u0435\u043a\u0446\u0438\u0438. \u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430, \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0430\u0443\u0434\u0438\u043e-\u0434\u043e\u0440\u043e\u0436\u043a\u0443 \u0438\u0437 \u0432\u0438\u0434\u0435\u043e, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u0431\u0443\u0434\u0435\u043c \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0438\u0440\u043e\u0432\u0430\u0442\u044c (\u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0438\u0442\u044c \u0432 \u0442\u0435\u043a\u0441\u0442) \u043f\u0440\u0438 \u043f\u043e\u043c\u043e\u0449\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 whisper \u043e\u0442 openAI:\n## **\u0421\u041f\u041e\u0421\u041e\u0411 1 \u0431\u0435\u0437 \u043a\u043b\u044e\u0447\u0430**\n# @title \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u043a \u0414\u0438\u0441\u043a\u0443\n\nfrom google.colab import drive\n\ndrive.mount('/content/drive')\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0442\u0443\u0442: https://github.com/openai/whisper\n# @title \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 whisper \u0438 youtube-dl\n\n!pip install git+https://github.com/ytdl-org/youtube-dl.git\n\n!pip install git+https://github.com/openai/whisper.git\n\n!pip install tiktoken==0.4.0 openai==0.28.0 langchain==0.0.281 faiss-cpu==1.7.4\n\n!pip install -qq python-docx\n\n!pip install -U pytube\n\nfrom IPython.display import clear_output\n\nclear_output()\nimport whisper\n\nimport os\n\nimport gdown\n\nimport requests\n\nimport re\n\nimport time\n\nfrom IPython.display import HTML, clear_output\n\nimport subprocess\n\nfrom pathlib import Path\n\nimport json\n\nfrom pytube import YouTube\n\nimport tiktoken\n\nfrom docx import Document\n\nfrom docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n\nimport ipywidgets as widgets\n\nfrom IPython.display import display\n\nfrom tqdm.auto import tqdm\n\nimport getpass\n\nimport pickle\n\nfrom urllib.request import urlopen\n\nimport openai\n\nimport subprocess\n\nimport codecs\n\nfrom langchain.chains import ConversationChain         # \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0441 \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0446\u0435\u043f\u043e\u0447\u0435\u043a \u0434\u0438\u0430\u043b\u043e\u0433\u043e\u0432\n\nfrom langchain.chat_models import ChatOpenAI           # \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0441 \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441 \u0447\u0430\u0442\u0430\u043c\u0438 \u043d\u0430 \u0431\u0430\u0437\u0435 OpenAI\n\nfrom langchain.llms import OpenAI\n\nfrom langchain.memory import ConversationBufferMemory  # \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u043a\u043b\u0430\u0441\u0441 \u0434\u043b\u044f \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u043f\u0430\u043c\u044f\u0442\u044c\u044e \u0434\u0438\u0430\u043b\u043e\u0433\u043e\u0432\n\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter, Document, RecursiveCharacterTextSplitter\n\nfrom langchain.schema import (\n\n    AIMessage,\n\n    HumanMessage,\n\n    SystemMessage\n\n)\n\nimport urllib\n# \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0441\u0441\u044b\u043b\u043a\u0443 \u043d\u0430 \u043d\u0443\u0436\u043d\u043e\u0435 \u043d\u0430\u043c \u0432\u0438\u0434\u0435\u043e \u043d\u0430 \u044e\u0442\u0443\u0431\n\nyt_urls = ['https://www.youtube.com/watch?v=KdZ4HF1SrFs&list=PLRDzFCPr95fK7tr47883DFUbm4GeOjjc0']\n\nYouTube_video_title = \"\u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0438 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 Python\"\n\n## \u041f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0430\u0443\u0434\u0438\u043e-\u0434\u043e\u0440\u043e\u0436\u043a\u0438 \u0438\u0437 \u0432\u0438\u0434\u0435\u043e \u043f\u043e \u0441\u0441\u044b\u043b\u043a\u0435 \u0438 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0432 \u043a\u043e\u043b\u0430\u0431\ndef my_mkdirs(folder):\n\n  if os.path.exists(folder)==False:\n\n    os.makedirs(folder)\n\nmy_mkdirs('/content/')\n\noutput_folder = '/content/drive/MyDrive/data_structure/'\n\nmy_mkdirs(output_folder)\n# \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u0435\u0440\u0432\u0443\u044e (\u0438 \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u0443\u044e) \u0441\u0441\u044b\u043b\u043a\u0443 \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430 yt_urls\n\nurl = yt_urls[0]\n\n\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c youtube-dl \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0438\u043c\u0435\u043d\u0438 \u0444\u0430\u0439\u043b\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\n\nfile_name = !youtube-dl $url -f 'bestaudio[ext=m4a]' --get-filename -o 'tmp/%(title)s.m4a'\n\n\n\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0430\u0443\u0434\u0438\u043e \u0441 \u043b\u0443\u0447\u0448\u0438\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e\u043c (\u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 m4a)\n\n!youtube-dl $url -f 'bestaudio[ext=m4a]' -o 'tmp/%(title)s.m4a'\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c Whisper \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0430\u0443\u0434\u0438\u043e\u0444\u0430\u0439\u043b\u0430\n\n%%time\n\n!whisper \"/content/\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043d\u0430 Python 3. \u041b\u0435\u043a\u0446\u0438\u044f \u21161-KdZ4HF1SrFs.mp4\" --model large --language Russian\n\nimport glob\n\nimport shutil\n\n\n\nsource_directory = '/content/'\n\ndestination_directory = '/content/drive/MyDrive/data_structure/'\n\n\n\n# \u041d\u0430\u0445\u043e\u0434\u0438\u043c \u043f\u0435\u0440\u0432\u044b\u0439 \u0444\u0430\u0439\u043b .txt \u0432 \u043f\u0430\u043f\u043a\u0435 /content/\n\ntxt_files = glob.glob(os.path.join(source_directory, '*.txt'))\n\n\n\nif txt_files:\n\n    # \u0411\u0435\u0440\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u0435\u0440\u0432\u044b\u0439 \u0444\u0430\u0439\u043b\n\n    file = txt_files[0]\n\n    destination_path = os.path.join(destination_directory, os.path.basename(file))\n\n\n\n    # \u041f\u0435\u0440\u0435\u043c\u0435\u0449\u0430\u0435\u043c \u0444\u0430\u0439\u043b\n\n    shutil.move(file, destination_path)\n\n    print(f'\u0424\u0430\u0439\u043b {file} \u043f\u0435\u0440\u0435\u043c\u0435\u0449\u0435\u043d \u0432 {destination_path}')\n\nelse:\n\n    print('\u0424\u0430\u0439\u043b\u044b .txt \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d\u044b \u0432 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438 /content/')\n\n\u0412\u044b\u0432\u043e\u0434\u0438\u043c \u0442\u0435\u043a\u0441\u0442, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0441\u044f\n# \u041f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u043d\u0430 Google \u0414\u0440\u0430\u0439\u0432\u0435\n\nfile_path = '/content/drive/MyDrive/data_structure/\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043d\u0430 Python 3. \u041b\u0435\u043a\u0446\u0438\u044f \u21161-KdZ4HF1SrFs.txt'\n\n\n\n# \u0427\u0442\u0435\u043d\u0438\u0435 \u0438 \u0432\u044b\u0432\u043e\u0434 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0433\u043e \u0444\u0430\u0439\u043b\u0430\n\ntry:\n\n    with open(file_path, 'r') as file:\n\n        content = file.read()\n\n        print(content)\n\nexcept FileNotFoundError:\n\n    print(f'\u0424\u0430\u0439\u043b \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d: {file_path}')\n\n## **\u0421\u041f\u041e\u0421\u041e\u0411 2 \u0441 \u043a\u043b\u044e\u0447\u043e\u043c**\n\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0443\u044e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0442\u0443\u0442: https://platform.openai.com/docs/guides/speech-to-text\nimport getpass\n\nimport os\n\nimport openai\n\nopenai_key = getpass.getpass(\"OpenAI API Key:\")\n\nos.environ[\"OPENAI_API_KEY\"] = openai_key\n\nopenai.api_key = openai_key\n!pip install pydub\n# \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0441\u0441\u044b\u043b\u043a\u0443 \u043d\u0430 \u043d\u0443\u0436\u043d\u043e\u0435 \u043d\u0430\u043c \u0432\u0438\u0434\u0435\u043e \u043d\u0430 \u044e\u0442\u0443\u0431\n\nyt_urls = ['https://www.youtube.com/watch?v=Uqp-pzGMjlU']\n\nYouTube_video_title = \"\u0413\u0440\u0430\u0444\u044b: \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0438 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 Python\"\n# \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043f\u0435\u0440\u0432\u0443\u044e (\u0438 \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u0443\u044e) \u0441\u0441\u044b\u043b\u043a\u0443 \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430 yt_urls\n\nurl = yt_urls[0]\n\n\n\n# \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c youtube-dl \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0438\u043c\u0435\u043d\u0438 \u0444\u0430\u0439\u043b\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\n\nfile_name = !youtube-dl $url -f 'bestaudio[ext=m4a]' --get-filename -o 'tmp/%(title)s.m4a'\n\n\n\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0430\u0443\u0434\u0438\u043e \u0441 \u043b\u0443\u0447\u0448\u0438\u043c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e\u043c (\u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 m4a)\n\n!youtube-dl $url -f 'bestaudio[ext=m4a]' -o 'tmp/%(title)s.m4a'\nfrom pydub import AudioSegment\n\ndef transcribe_audio_whisper_chunked(audio_path, file_title, save_folder_path, max_duration=5 * 60 * 1000):  # 5 \u043c\u0438\u043d\u0443\u0442\n\n    \"\"\"\n\n    \u0422\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0438\u0440\u0443\u0435\u0442 \u0430\u0443\u0434\u0438\u043e\u0444\u0430\u0439\u043b \u043f\u043e \u0447\u0430\u0441\u0442\u044f\u043c, \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u043e\u0432\u0430\u0442\u044c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u0430 API.\n\n    \"\"\"\n\n    # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043a\u0430\u0442\u0430\u043b\u043e\u0433 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432, \u0435\u0441\u043b\u0438 \u043e\u043d \u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442\n\n    os.makedirs(save_folder_path, exist_ok=True)\n\n    # \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0430\u0443\u0434\u0438\u043e\u0444\u0430\u0439\u043b\n\n    audio = AudioSegment.from_file(audio_path)\n\n    # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e \u043f\u0430\u043f\u043a\u0443 \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0447\u0430\u0441\u0442\u0435\u0439 \u0430\u0443\u0434\u0438\u043e\n\n    temp_dir = os.path.join(save_folder_path, \"temp_audio_chunks\")\n\n    os.makedirs(temp_dir, exist_ok=True)\n\n\n\n    # \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0430\u0443\u0434\u0438\u043e \u043f\u043e \u0447\u0430\u0441\u0442\u044f\u043c\n\n    current_start_time = 0    # \u0422\u0435\u043a\u0443\u0449\u0435\u0435 \u0432\u0440\u0435\u043c\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u0430\n\n    chunk_index = 1           # \u0418\u043d\u0434\u0435\u043a\u0441 \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u0430\n\n    transcriptions = []       # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0439 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u0430\n\n\n\n    # \u0426\u0438\u043a\u043b \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u0430\u0443\u0434\u0438\u043e\n\n    while current_start_time < len(audio):\n\n        # \u0412\u044b\u0440\u0435\u0437\u0430\u0435\u043c \u0447\u0430\u0441\u0442\u044c \u0430\u0443\u0434\u0438\u043e\u0444\u0430\u0439\u043b\u0430 \u0434\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0435 \u0431\u043e\u043b\u0435\u0435 max_duration\n\n        chunk = audio[current_start_time:current_start_time + max_duration]\n\n        # \u0424\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0438\u043c\u044f \u0444\u0430\u0439\u043b\u0430 \u0434\u043b\u044f \u0447\u0430\u0441\u0442\u0438 \u0430\u0443\u0434\u0438\u043e\n\n        chunk_name = f\"chunk_{chunk_index}.wav\"\n\n        # \u041f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u0447\u0430\u0441\u0442\u0438 \u0430\u0443\u0434\u0438\u043e\n\n        chunk_path = os.path.join(temp_dir, chunk_name)\n\n        # \u042d\u043a\u0441\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0447\u0430\u0441\u0442\u044c \u0430\u0443\u0434\u0438\u043e \u0432 \u0444\u0430\u0439\u043b\n\n        chunk.export(chunk_path, format=\"wav\")\n\n\n\n        # \u041f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0444\u0430\u0439\u043b\u0430 \u043f\u0435\u0440\u0435\u0434 \u043e\u0442\u043f\u0440\u0430\u0432\u043a\u043e\u0439\n\n        if os.path.getsize(chunk_path) > 26214400:\n\n            print(f\"Chunk {chunk_index} exceeds the maximum size limit for the API. Trying a smaller duration...\")\n\n            max_duration = int(max_duration * 0.9)  # \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0443\u043c\u0435\u043d\u044c\u0448\u0438\u0442\u044c \u043d\u0430 10% \u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0441\u043d\u043e\u0432\u0430\n\n            os.remove(chunk_path)   # \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0441\u043b\u0438\u0448\u043a\u043e\u043c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0444\u0430\u0439\u043b\n\n            continue  # \u041f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u043a\u0443\u0441\u043e\u043a \u0438 \u043f\u044b\u0442\u0430\u0435\u043c\u0441\u044f \u0441\u043d\u043e\u0432\u0430 \u0441 \u043c\u0435\u043d\u044c\u0448\u0435\u0439 \u0434\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u044c\u044e\n\n\n\n        # \u041f\u0440\u043e\u0446\u0435\u0441\u0441 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u0430\n\n        with open(chunk_path, \"rb\") as src_file:\n\n            print(f\"Transcribing {chunk_name}...\")\n\n            try:\n\n                # \u0412\u044b\u0437\u043e\u0432 API \u0434\u043b\u044f \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438 \u0430\u0443\u0434\u0438\u043e\n\n                transcription = openai.Audio.transcribe(\"whisper-1\", src_file)\n\n                # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a\n\n                transcriptions.append(transcription[\"text\"])\n\n            except openai.error.APIError as e:\n\n                print(f\"An error occurred: {e}\")\n\n                break   # \u0412 \u0441\u043b\u0443\u0447\u0430\u0435 \u043e\u0448\u0438\u0431\u043a\u0438 API \u043f\u0440\u0435\u0440\u044b\u0432\u0430\u0435\u043c \u0446\u0438\u043a\u043b\n\n\n\n        # \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0439 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\n\n        os.remove(chunk_path)\n\n        # \u041f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u043c \u043a \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u043c\u0443 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u0443 \u0430\u0443\u0434\u0438\u043e\n\n        current_start_time += max_duration\n\n        chunk_index += 1\n\n    # \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e \u043f\u0430\u043f\u043a\u0443 \u0441 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u0430\u043c\u0438 \u0430\u0443\u0434\u0438\u043e\n\n    os.rmdir(temp_dir)\n\n\n\n    # \u0424\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u043f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0430 \u0438\u0442\u043e\u0433\u043e\u0432\u0430\u044f \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u044f\n\n    result_path = os.path.join(save_folder_path, f\"{file_title}.txt\")\n\n    with open(result_path, \"w\") as txt_file:\n\n        # \u0421\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u0432\u0441\u0435 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438 \u0432 \u043e\u0434\u0438\u043d \u0444\u0430\u0439\u043b, \u0440\u0430\u0437\u0434\u0435\u043b\u044f\u044f \u0438\u0445 \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0430\u043c\u0438 \u0441\u0442\u0440\u043e\u043a\n\n        txt_file.write(\"\\n\".join(transcriptions))\n\n    # \u0412\u044b\u0432\u043e\u0434\u0438\u043c \u0441\u043e\u043e\u0431\u0449\u0435\u043d\u0438\u0435 \u043e\u0431 \u0443\u0441\u043f\u0435\u0448\u043d\u043e\u043c \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0438 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438\n\n    print(f\"Transcribe saved to {result_path}\")\n\n\n\n# \u0417\u0430\u0434\u0430\u0435\u043c \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e\n\naudio_path = '/content/tmp/\u0413\u0440\u0430\u0444\u044b - \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0438 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0430 Python.m4a'\n\nfile_title = '\u0413\u0440\u0430\u0444\u044b_\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b_\u0438_\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b_\u0414\u0430\u043d\u043d\u044b\u0445_\u043d\u0430_Python'\n\nsave_folder_path = '/content/transcriptions/'\n\n\n\n# \u0412\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438 \u0430\u0443\u0434\u0438\u043e\u0444\u0430\u0439\u043b\u0430\n\ntranscribe_audio_whisper_chunked(audio_path, file_title, save_folder_path)", "metadata": {"subid": 0, "total": 3, "source": "https://colab.research.google.com/drive/1fCk7I2XcA9x_kYOW8-UZIJZMConKOp28?usp=sharing"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n\u0418\u0442\u0430\u043a, \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u044e \u0432\u0438\u0434\u0435\u043e \u043f\u043e \u0441\u0441\u044b\u043b\u043a\u0435 \u0441 \u044e\u0442\u0443\u0431.\n# @title \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0438 \u0438\u043c\u043f\u043e\u0440\u0442\u044b\n\nimport shutil\n\nfrom langchain.docstore.document import Document\n\nfrom langchain.llms import OpenAI\n\n\n\n#from google.colab import drive\n\n#drive.mount('/content/drive', force_remount=True)\n#@title \u0420\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0431\u043b\u043e\u043a\u0438 \u0441 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u043c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0440\u0430\u0437\u0434\u0435\u043b\u0430:\n\nsystem = '\u0412\u044b \u0433\u0435\u043d\u0438\u0439 \u0442\u0435\u043a\u0441\u0442\u0430, \u043a\u043e\u043f\u0438\u0440\u0430\u0439\u0442\u0438\u043d\u0433\u0430, \u043f\u0438\u0441\u0430\u0442\u0435\u043b\u044c\u0441\u0442\u0432\u0430. \u0412\u0430\u0448\u0430 \u0437\u0430\u0434\u0430\u0447\u0430 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0442\u044c \u0440\u0430\u0437\u0434\u0435\u043b\u044b \u0432 \u0442\u0435\u043a\u0441\u0442\u0435 \u0438 \u0440\u0430\u0437\u0431\u0438\u0442\u044c \u0435\u0433\u043e \u043d\u0430 \u044d\u0442\u0438 \u0440\u0430\u0437\u0434\u0435\u043b\u044b \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u044f \u0432\u0435\u0441\u044c \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 100%' #@param {type:\"string\"}\n\nuser = '\u041f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430, \u0434\u0430\u0432\u0430\u0439\u0442\u0435 \u043f\u043e\u0434\u0443\u043c\u0430\u0435\u043c \u0448\u0430\u0433 \u0437\u0430 \u0448\u0430\u0433\u043e\u043c: \u041f\u043e\u0434\u0443\u043c\u0430\u0439\u0442\u0435, \u043a\u0430\u043a\u0438\u0435 \u0440\u0430\u0437\u0434\u0435\u043b\u044b \u0432 \u0442\u0435\u043a\u0441\u0442\u0435 \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0442\u044c \u0438 \u043a\u0430\u043a\u043e\u0435 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u043f\u043e \u0441\u043c\u044b\u0441\u043b\u0443 \u043c\u043e\u0436\u043d\u043e \u0434\u0430\u0442\u044c \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \u0440\u0430\u0437\u0434\u0435\u043b\u0443. \u0414\u0430\u043b\u0435\u0435 \u043d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043e\u0442\u0432\u0435\u0442 \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442\u0443 \u0432 \u043f\u043e\u0440\u044f\u0434\u043a\u0435: ## \u041d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0440\u0430\u0437\u0434\u0435\u043b\u0430, \u043f\u043e\u0441\u043b\u0435 \u0447\u0435\u0433\u043e \u0432\u0435\u0441\u044c \u0442\u0435\u043a\u0441\u0442, \u043e\u0442\u043d\u043e\u0441\u044f\u0449\u0438\u0439\u0441\u044f \u043a \u044d\u0442\u043e\u043c\u0443 \u0440\u0430\u0437\u0434\u0435\u043b\u0443. \u0422\u0435\u043a\u0441\u0442:' #@param {type:\"string\"}\n\n\n\ntemperature = 0 #@param {type: \"slider\", min: 0, max: 1, step:0.1}\n\nchunk_size = 6000 #@param {type: \"slider\", min: 1000, max: 7000, step:500}\n# @title \u0424\u0443\u043d\u043a\u0446\u0438\u0438\n\n# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0441\u0442\u0438\u043b\u044f \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0430 \u0442\u0435\u043a\u0441\u0442\u0430 \u0432 \u0432\u044b\u0432\u043e\u0434\u0435 \u044f\u0447\u0435\u0435\u043a\n\n# \u0434\u043b\u044f \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0441\u0442\u0438\u043b\u044f \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0442\u0435\u043a\u0441\u0442\u0430, \u0442\u0430\u043a \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u0435\u0434\u043e\u0442\u0432\u0440\u0430\u0442\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u0442\u0435\u043a\u0441\u0442\u0430 \u0437\u0430 \u0433\u0440\u0430\u043d\u0438\u0446\u044b \u044f\u0447\u0435\u0439\u043a\u0438 \u0432\u044b\u0432\u043e\u0434\u0430 \u0438 \u043e\u0431\u0435\u0441\u043f\u0435\u0447\u0438\u0442\u044c \u0435\u0433\u043e \u043f\u0435\u0440\u0435\u043d\u043e\u0441.\n\ndef set_text_wrap_css():\n\n    css = '''\n\n    <style>\n\n    pre {\n\n        white-space: pre-wrap;\n\n    }\n\n    </style>\n\n    '''\n\n    display(HTML(css))\n\n\n\nget_ipython().events.register('pre_run_cell', set_text_wrap_css)\n\n\n\n# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0434\u0441\u0447\u0435\u0442\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0442\u043e\u043a\u0435\u043d\u043e\u0432\n\ndef num_tokens_from_messages(messages, model='gpt-3.5-turbo-0301'):\n\n    try:\n\n        encoding = tiktoken.encoding_for_model(model)\n\n    except KeyError:\n\n        encoding = tiktoken.get_encoding('cl100k_base')\n\n\n\n    if model in ['gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo']:\n\n        num_tokens = 0\n\n\n\n        for message in messages:\n\n            num_tokens += 4\n\n\n\n            for key, value in message.items():\n\n                num_tokens += len(encoding.encode(value))\n\n\n\n                if key == 'name':\n\n                    num_tokens -= 1\n\n\n\n        num_tokens += 2\n\n        return num_tokens\n\n\n\n    else:\n\n        raise NotImplementedError(f'''num_tokens_from_messages() is not presently implemented for model {model}.''')\n\n\n\n\n\n# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u0440\u043e\u0431\u043b\u0435\u043d\u0438\u044f \u0442\u0435\u043a\u0441\u0442\u0430 \u043d\u0430 \u0447\u0430\u043d\u043a\u0438\n\ndef split_text(txt_file, chunk_size=chunk_size):\n\n    source_chunks = []\n\n    splitter = RecursiveCharacterTextSplitter(separators=['\\n', '\\n\\n', '. '], chunk_size=chunk_size, chunk_overlap=0)\n\n\n\n    for chunk in splitter.split_text(txt_file):\n\n        source_chunks.append(Document(page_content=chunk, metadata={}))\n\n\n\n    print(f'\\n\\n\u0422\u0435\u043a\u0441\u0442 \u0440\u0430\u0437\u0431\u0438\u0442 \u043d\u0430 {len(source_chunks)} \u0447\u0430\u043d\u043a\u043e\u0432.')\n\n\n\n    return source_chunks\n\n\n\n\n\n# \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043e\u0442 \u043c\u043e\u0434\u0435\u043b\u0438\n\ndef answer_index(system, user, chunk, temp=temperature, model='gpt-3.5-turbo-16k'):\n\n\n\n    messages = [\n\n        {'role': 'system', 'content': system},\n\n        {'role': 'user', 'content': user + f'{chunk}'}\n\n    ]\n\n\n\n    completion = openai.ChatCompletion.create(\n\n        model=model,\n\n        messages=messages,\n\n        temperature=temp\n\n    )\n\n\n\n    # \u0412\u044b\u0432\u043e\u0434 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0442\u043e\u043a\u0435\u043d\u043e\u0432 \u043e\u0442\u043a\u043b\u044e\u0447\u0435\u043d\n\n    # print(f'\\n====================\\n\\n{num_tokens_from_messages(messages)} \u0442\u043e\u043a\u0435\u043d\u043e\u0432 \u0431\u0443\u0434\u0435\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u043e \u043d\u0430 \u0447\u0430\u043d\u043a\\n\\n')\n\n    answer = completion.choices[0].message.content\n\n\n\n    return answer\n\n\n\n\n\ndef process_one_file(file_path, system, user):\n\n    with open(file_path, 'r') as txt_file:\n\n        text = txt_file.read()\n\n    source_chunks = split_text(text)\n\n    processed_text = ''\n\n    unprocessed_text = ''\n\n\n\n    for chunk in source_chunks:\n\n        attempt = 0\n\n\n\n        while attempt < 3:\n\n            try:\n\n                answer = answer_index(system, user, chunk.page_content)\n\n                break  # \u0423\u0441\u043f\u0435\u0448\u043d\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u043e\u0442\u0432\u0435\u0442, \u0432\u044b\u0445\u043e\u0434\u0438\u043c \u0438\u0437 \u0446\u0438\u043a\u043b\u0430 \u043f\u043e\u043f\u044b\u0442\u043e\u043a\n\n\n\n            except Exception as e:\n\n                attempt += 1  # \u0423\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u043c \u0441\u0447\u0435\u0442\u0447\u0438\u043a \u043f\u043e\u043f\u044b\u0442\u043e\u043a\n\n                print(f'\\n\\n\u041f\u043e\u043f\u044b\u0442\u043a\u0430 {attempt} \u043d\u0435 \u0443\u0434\u0430\u043b\u0430\u0441\u044c \u0438\u0437-\u0437\u0430 \u043e\u0448\u0438\u0431\u043a\u0438: {str(e)}')\n\n                time.sleep(10)  # \u041e\u0436\u0438\u0434\u0430\u0435\u043c \u043f\u0435\u0440\u0435\u0434 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u043f\u043e\u043f\u044b\u0442\u043a\u043e\u0439\n\n                if attempt == 3:\n\n                    answer = ''\n\n                    print(f'\\n\\n\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430 {chunk} \u043d\u0435 \u0443\u0434\u0430\u043b\u0430\u0441\u044c \u043f\u043e\u0441\u043b\u0435 3 \u043f\u043e\u043f\u044b\u0442\u043e\u043a')\n\n                    unprocessed_text += f'{chunk}\\n\\n'\n\n\n\n        processed_text += f'{answer}\\n\\n'  # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043e\u0442\u0432\u0435\u0442 \u0432 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\n\n        print(f'{answer}')  # \u0412\u044b\u0432\u043e\u0434\u0438\u043c \u043e\u0442\u0432\u0435\u0442\n\n\n\n    return processed_text, unprocessed_text\n# @title \u0417\u0430\u043f\u0443\u0441\u043a\n\nfile_path = '/content/transcriptions/\u0413\u0440\u0430\u0444\u044b_\u0410\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b_\u0438_\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b_\u0414\u0430\u043d\u043d\u044b\u0445_\u043d\u0430_Python.txt'\n\n# \u0412\u044b\u0437\u044b\u0432\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0444\u0430\u0439\u043b\u0430\n\nprocessed_text, unprocessed_text = process_one_file(file_path, system, user)\n\n\n\u0418\u0442\u0430\u043a, \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u0442\u0435\u043a\u0441\u0442 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438, \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u0439 \u043d\u0430 \u0440\u0430\u0437\u0434\u0435\u043b\u044b \u0441 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0440\u0430\u0437\u0434\u0435\u043b\u043e\u0432. \u0422\u0435\u043f\u0435\u0440\u044c \u0440\u0430\u0437\u0434\u0435\u043b\u0438\u043c \u044d\u0442\u043e\u0442 \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \u0447\u0430\u043d\u043a\u0438 \u043f\u0440\u0438 \u043f\u043e\u043c\u043e\u0449\u0438 MarkdownHeaderTextSplitter, \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0438\u0437 \u043d\u0435\u0433\u043e \u0432\u0435\u043a\u0442\u043e\u0440\u043d\u0443\u044e \u0431\u0430\u0437\u0443 Faiss \u0438 \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u043d\u0435\u0439\u0440\u043e-\u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u043d\u0442\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0442 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u043f\u043e \u0442\u0435\u043a\u0441\u0442\u0443, \u0430 \u0438\u0437 \u0442\u0435\u043a\u0441\u0442\u0430 \u0442\u0440\u0430\u043d\u0441\u043a\u0440\u0438\u0431\u0430\u0446\u0438\u0438 \u0441 \u0440\u0430\u0437\u0434\u0435\u043b\u0430\u043c\u0438 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043c \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0443.\n# \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043a\u0438, \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u0440\u0430\u0437\u0431\u0438\u0442\u044c \u0442\u0435\u043a\u0441\u0442\n\nheaders_to_split_on = [\n\n    (\"##\", \"Header 2\")\n\n    ]\n\n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442 \u0434\u043b\u044f \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u044f \u0442\u0435\u043a\u0441\u0442\u0430 \u043d\u0430 \u0441\u0435\u043a\u0446\u0438\u0438 \u043f\u043e \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043a\u0430\u043c\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n\n\n\n# \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u043e\u0432, \u0440\u0430\u0437\u0431\u0438\u0442\u044b\u0445 \u043f\u043e \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043a\u0430\u043c\n\nmd_header_splits = markdown_splitter.split_text(processed_text)\nmd_header_splits\n#@title \u041e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0436\u0434\u044b\u0439 \u0447\u0430\u043d\u043a, \u0432\u044b\u0434\u0435\u043b\u044f\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u0441\u0443\u0442\u044c \u0434\u043b\u044f \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0438\n\nsystem = \"\u0412\u044b \u0433\u0435\u043d\u0438\u0439 \u043a\u043e\u043f\u0438\u0440\u0430\u0439\u0442\u0438\u043d\u0433\u0430, \u044d\u043a\u0441\u043f\u0435\u0440\u0442 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0438 \u043d\u0430 \u043f\u0430\u0439\u0442\u043e\u043d \u0438 \u0432 \u0442\u0435\u043c\u0435 \\\"\u0413\u0440\u0430\u0444\u044b, \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0438 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445\\\". \u0412\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442\u0435 \u0440\u0430\u0437\u0434\u0435\u043b \u043d\u0435\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430 \u043f\u043e \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u0439 \u0442\u0435\u043c\u0435. \u041d\u0443\u0436\u043d\u043e \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430 \u0432\u044b\u0434\u0435\u043b\u0438\u0442\u044c \u0441\u0430\u043c\u0443\u044e \u0441\u0443\u0442\u044c, \u0442\u043e\u043b\u044c\u043a\u043e \u0441\u0430\u043c\u043e\u0435 \u0432\u0430\u0436\u043d\u043e\u0435, \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u0432 \u0432\u0441\u0435 \u043d\u0443\u0436\u043d\u044b\u0435 \u043f\u043e\u0434\u0440\u043e\u0431\u043d\u043e\u0441\u0442\u0438 \u0438 \u0434\u0435\u0442\u0430\u043b\u0438, \u043d\u043e \u0443\u0431\u0440\u0430\u0432 \u0432\u0441\u044e \\\"\u0432\u043e\u0434\u0443\\\" \u0438 \u0441\u043b\u043e\u0432\u0430 (\u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f), \u043d\u0435 \u043d\u0435\u0441\u0443\u0449\u0438\u0435 \u0441\u043c\u044b\u0441\u043b\u043e\u0432\u043e\u0439 \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0438.\" #@param {type:\"string\"}\n\nuser = \"\u0418\u0437 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430 \u0432\u044b\u0434\u0435\u043b\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u0446\u0435\u043d\u043d\u0443\u044e \u0441 \u0442\u043e\u0447\u043a\u0438 \u0437\u0440\u0435\u043d\u0438\u044f \u0442\u0435\u043c\u044b \\\"\u0433\u0440\u0430\u0444\u044b, \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0438 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445\\\" \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e. \u0423\u0434\u0430\u043b\u0438 \u0432\u0441\u044e \\\"\u0432\u043e\u0434\u0443\\\". \u0412 \u0438\u0442\u043e\u0433\u0435 \u0443 \u0442\u0435\u0431\u044f \u0434\u043e\u043b\u0436\u0435\u043d \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0441\u044f \u0440\u0430\u0437\u0434\u0435\u043b \u0434\u043b\u044f \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0438 \u043f\u043e \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0439 \u0442\u0435\u043c\u0435. \u041e\u043f\u0438\u0440\u0430\u0439\u0441\u044f \u0442\u043e\u043b\u044c\u043a\u043e \u043d\u0430 \u0434\u0430\u043d\u043d\u044b\u0439 \u0442\u0435\u0431\u0435 \u0442\u0435\u043a\u0441\u0442, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041e\u0442\u0432\u0435\u0442 \u043d\u0443\u0436\u0435\u043d \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 ## \u041d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0440\u0430\u0437\u0434\u0435\u043b\u0430, \u0438 \u0434\u0430\u043b\u0435\u0435 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u043d\u0430\u044f \u0442\u043e\u0431\u043e\u0439 \u0446\u0435\u043d\u043d\u0430\u044f \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0438\u0437 \u0442\u0435\u043a\u0441\u0442\u0430. \u0415\u0441\u043b\u0438 \u0432 \u0442\u0435\u043a\u0441\u0442\u0435 \u043d\u0435 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442\u0441\u044f \u0446\u0435\u043d\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438, \u0442\u043e \u043e\u0441\u0442\u0430\u0432\u044c \u0442\u043e\u043b\u044c\u043a\u043e  \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0440\u0430\u0437\u0434\u0435\u043b\u0430, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440: \\\"## \u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435\\\". \u0422\u0435\u043a\u0441\u0442:\" #@param {type:\"string\"}\n\n\n\ntemperature = 0 #@param {type: \"slider\", min: 0, max: 1, step:0.1}\n\ndef process_documents(documents, system, user, temperature):\n\n    \"\"\"\n\n    \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0447\u0430\u043d\u043a\u0438, system, user, temperature \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0438.\n\n    \u041e\u043d\u0430 \u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u0442 \u043a\u0430\u0436\u0434\u044b\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u043c\u043e\u0434\u0435\u043b\u044c GPT, \u043a\u043e\u043d\u043a\u0430\u0442\u0435\u043d\u0438\u0440\u0443\u0435\u0442 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432 \u043e\u0434\u0438\u043d \u0442\u0435\u043a\u0441\u0442 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u0432 \u0444\u0430\u0439\u043b .txt.\n\n    \u0412 \u0438\u0442\u043e\u0433\u0435 \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0443 \u043f\u043e \u043b\u0435\u043a\u0446\u0438\u0438.\n\n    \"\"\"\n\n    processed_text_for_handbook = \"\"  # \u0421\u0442\u0440\u043e\u043a\u0430 \u0434\u043b\u044f \u043a\u043e\u043d\u043a\u0430\u0442\u0435\u043d\u0430\u0446\u0438\u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u043e\u0433\u043e \u0442\u0435\u043a\u0441\u0442\u0430\n\n\n\n    for document in documents:\n\n        # \u0424\u043e\u0440\u043c\u0430\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u0435\u0442\u0430\u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0432\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u0432 \u0447\u0430\u043d\u043a\n\n        metadata_str = \"\\n\".join([f\"{key}: {value}\" for key, value in document.metadata.items()])\n\n        # \u041a\u043e\u043d\u043a\u0430\u0442\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u043c\u0435\u0442\u0430\u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u0434\u0430\u0447\u0438 \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u044e\n\n        chunk_with_metadata = f\"{metadata_str}\\n\\n{document.page_content}\"\n\n\n\n        # \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u043e\u0442\u0432\u0435\u0442 \u043e\u0442 \u043c\u043e\u0434\u0435\u043b\u0438\n\n        answer = answer_index(system, user, chunk_with_metadata, temperature, model='gpt-4-0613')\n\n        # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0439 \u0442\u0435\u043a\u0441\u0442 \u0432 \u043e\u0431\u0449\u0443\u044e \u0441\u0442\u0440\u043e\u043a\u0443\n\n        processed_text_for_handbook += f\"{answer}\\n\\n\"\n\n\n\n    # \u0417\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0439 \u0442\u0435\u043a\u0441\u0442 \u0432 \u0444\u0430\u0439\u043b\n\n    with open('processed_documents.txt', 'w', encoding='utf-8') as f:\n\n        f.write(processed_text_for_handbook)\n\n\n\n    # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u0441 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u043c \u0442\u0435\u043a\u0441\u0442\u043e\u043c\n\n    return 'processed_documents.txt'\n\n\n\n# \u041f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\n\nfile_path = process_documents(md_header_splits, system, user, temperature)\n\nprint(f\"\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u043d\u043d\u044b\u0439 \u0442\u0435\u043a\u0441\u0442 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d \u0432 \u0444\u0430\u0439\u043b\u0435: {file_path}\")\n# \u0427\u0442\u0435\u043d\u0438\u0435 \u0438 \u0432\u044b\u0432\u043e\u0434 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0433\u043e \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0438:\n\nwith open(file_path, 'r', encoding='utf-8') as f:\n\n    processed_text = f.read()\n\n\n\nprint(processed_text)", "metadata": {"subid": 1, "total": 3, "source": "https://colab.research.google.com/drive/1fCk7I2XcA9x_kYOW8-UZIJZMConKOp28?usp=sharing"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n\u0422\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u043c\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u0438 \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0443 \u043f\u043e \u0442\u0435\u043c\u0435 \u043b\u0435\u043a\u0446\u0438\u0438. \u0422\u0435\u043f\u0435\u0440\u044c \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043d\u0435\u0439\u0440\u043e-\u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u043d\u0442\u0430 \u043f\u043e \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c \u0434\u0430\u043d\u043d\u043e\u0439 \u043b\u0435\u043a\u0446\u0438\u0438, \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0432\u0435\u043a\u0442\u043e\u0440\u043d\u0443\u044e \u0431\u0430\u0437\u0443 Faiss:\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043d\u0435\u0439\u0440\u043e-\u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u043d\u0442\u0430 \u043f\u043e \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c \u043b\u0435\u043a\u0446\u0438\u0438:\n!pip install faiss-cpu\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom langchain.vectorstores import FAISS\n\n\n\n# \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u044d\u043c\u0431\u0435\u0434\u0434\u0438\u043d\u0433\u043e\u0432\n\nembeddings = OpenAIEmbeddings()\n\n\n\n# \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0438\u043d\u0434\u0435\u043a\u0441\u043d\u0443\u044e \u0431\u0430\u0437\u0443 \u0438\u0437 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u043d\u044b\u0445 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u043e\u0432 \u0442\u0435\u043a\u0441\u0442\u0430\n\ndb = FAISS.from_documents(md_header_splits, embeddings)\nsystem_for_NA = \"\"\"\u0422\u044b - \u043f\u0440\u0435\u043f\u043e\u0434\u0430\u0432\u0430\u0442\u0435\u043b\u044c, \u044d\u043a\u0441\u043f\u0435\u0440\u0442 \u043f\u043e \u0442\u0435\u043c\u0435 '\u0413\u0440\u0430\u0444\u044b, \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0438 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445.'\n\n                  \u0422\u0432\u043e\u044f \u0437\u0430\u0434\u0430\u0447\u0430 - \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0443 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 \u0442\u043e\u043b\u044c\u043a\u043e \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u043d\u044b\u0445 \u0442\u0435\u0431\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u043e\u0432, \u043d\u0435 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u044f \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f.\"\"\"\ndef answer_neuro_assist(system, topic, search_index, verbose=1):\n\n\n\n    # \u041f\u043e\u0438\u0441\u043a \u0440\u0435\u043b\u0435\u0432\u0430\u043d\u0442\u043d\u044b\u0445 \u043e\u0442\u0440\u0435\u0437\u043a\u043e\u0432 \u0438\u0437 \u0431\u0430\u0437\u044b \u0437\u043d\u0430\u043d\u0438\u0439\n\n    docs = search_index.similarity_search(topic, k=3)\n\n    if verbose: print('\\n ===========================================: ')\n\n    message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\\n\u041e\u0442\u0440\u044b\u0432\u043e\u043a \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u2116{i+1}\\n=====================' + doc.page_content + '\\n' for i, doc in enumerate(docs)]))\n\n    if verbose: print('message_content :\\n ======================================== \\n', message_content)\n\n\n\n    messages = [\n\n        {\"role\": \"system\", \"content\": system_for_NA},\n\n        {\"role\": \"user\", \"content\": f\"\u041e\u0442\u0432\u0435\u0442\u044c \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0430. \u041d\u0435 \u0443\u043f\u043e\u043c\u0438\u043d\u0430\u0439 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u043e\u0432 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0443 \u0432 \u043e\u0442\u0432\u0435\u0442\u0435. \u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0443: {message_content}\\n\\n\u0412\u043e\u043f\u0440\u043e\u0441 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0430: \\n{topic}\"}\n\n    ]\n\n\n\n    if verbose: print('\\n ===========================================: ')\n\n\n\n    completion = openai.ChatCompletion.create(\n\n        model=\"gpt-3.5-turbo\",\n\n        messages=messages,\n\n        temperature=0\n\n    )\n\n    answer = completion.choices[0].message.content\n\n    return answer  # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043e\u0442\u0432\u0435\u0442\ntopic=\"\u0427\u0442\u043e \u0442\u0430\u043a\u043e\u0435 \u0433\u0440\u0430\u0444\u044b\"\n\nans=answer_neuro_assist(system, topic, db, verbose=1)\n\nans\ntopic=\"\u043a\u0430\u043a \u043c\u043e\u0436\u043d\u043e \u043e\u0431\u0445\u043e\u0434\u0438\u0442\u044c \u0433\u0440\u0430\u0444\u044b\"\n\nans=answer_neuro_assist(system, topic, db, verbose=1)\n\nans\ntopic=\"\u0427\u0442\u043e \u0438\u0437 \u0441\u0435\u0431\u044f \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0442\u043e\u043f\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0430\"\n\nans=answer_neuro_assist(system, topic, db, verbose=1)\n\nans", "metadata": {"subid": 2, "total": 3, "source": "https://colab.research.google.com/drive/1fCk7I2XcA9x_kYOW8-UZIJZMConKOp28?usp=sharing"}}}]