[{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n\n# \u0417\u0430\u043f\u0443\u0441\u043a \u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 SoTA (state of the art) \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u044b\u0445 (\u043a\u043e\u043d\u0442\u0443\u0440\u043d\u044b\u0445) \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0438\u0437 \u043e\u0442\u043a\u0440\u044b\u0442\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u044b \u043b\u0438\u0434\u0435\u0440\u043e\u0432 LLM HuggingFace \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u0442\u0435\u043a\u0441\u0442\u0430.\n\n\n\nhttps://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard - \ud83d\udcd0 \u0422\u0430\u0431\u043b\u0438\u0446\u0430 \u043b\u0438\u0434\u0435\u0440\u043e\u0432 Open LLM \u043f\u0440\u0435\u0434\u043d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u0430 \u0434\u043b\u044f \u043e\u0442\u0441\u043b\u0435\u0436\u0438\u0432\u0430\u043d\u0438\u044f, \u0440\u0430\u043d\u0436\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0438 \u043e\u0446\u0435\u043d\u043a\u0438 \u043e\u0442\u043a\u0440\u044b\u0442\u044b\u0445 LLM \u0438 \u0447\u0430\u0442-\u0431\u043e\u0442\u043e\u0432.\n\n\n\nPlatypus2-70B-Instruct \ud83d\udcd1\n\n\n\nStableBeluga2-70B\n\n\n\nLlama-2-70B-Chat\n\n\n\nLlama-2-70B-instruct\n\n\n\nSaiga2-70b\n\n\n\nFalcon-180B\n\n\n\nStableBeluga2-13B\n\ud83d\udcc8 \u041e\u043d\u0438 \u043e\u0446\u0435\u043d\u0438\u0432\u0430\u044e\u0442 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u043e 4 \u043a\u043b\u044e\u0447\u0435\u0432\u044b\u043c \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044f\u043c, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f Eleuther AI Language Model Evaluation Harness, \u0443\u043d\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u0441\u0440\u0435\u0434\u0443 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u044b\u0445 \u044f\u0437\u044b\u043a\u043e\u0432\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043d\u0430 \u0431\u043e\u043b\u044c\u0448\u043e\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u0437\u0430\u0434\u0430\u0447 \u043e\u0446\u0435\u043d\u043a\u0438.\n\n\n\n**AI2 Reasoning Challenge** (25-shot) \u2014 \u043d\u0430\u0431\u043e\u0440 \u0432\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u043f\u043e \u0435\u0441\u0442\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u043c \u043d\u0430\u0443\u043a\u0430\u043c \u0434\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0439 \u0448\u043a\u043e\u043b\u044b.\n\n\n\n**HellaSwag** (10-shot) \u2014 \u0442\u0435\u0441\u0442 \u043d\u0430 \u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u0432\u044b\u0432\u043e\u0434\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043f\u0440\u043e\u0441\u0442 \u0434\u043b\u044f \u043b\u044e\u0434\u0435\u0439 (~95%), \u043d\u043e \u0441\u043b\u043e\u0436\u0435\u043d \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439 SOTA.\n\n\n\n**MMLU** (5-shot) \u2014 \u0442\u0435\u0441\u0442 \u0434\u043b\u044f \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043c\u043d\u043e\u0433\u043e\u0437\u0430\u0434\u0430\u0447\u043d\u043e\u0441\u0442\u0438 \u0442\u0435\u043a\u0441\u0442\u043e\u0432\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438. \u0422\u0435\u0441\u0442 \u043e\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u0435\u0442 57 \u0437\u0430\u0434\u0430\u0447, \u0432\u043a\u043b\u044e\u0447\u0430\u044f \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u0440\u043d\u0443\u044e \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u043a\u0443, \u0438\u0441\u0442\u043e\u0440\u0438\u044e \u0421\u0428\u0410, \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u043a\u0443, \u043f\u0440\u0430\u0432\u043e \u0438 \u043c\u043d\u043e\u0433\u043e\u0435 \u0434\u0440\u0443\u0433\u043e\u0435.\n\n\n\n**TruthfulQA** (0-shot) \u2014 \u0442\u0435\u0441\u0442 \u0434\u043b\u044f \u0438\u0437\u043c\u0435\u0440\u0435\u043d\u0438\u044f \u0441\u043a\u043b\u043e\u043d\u043d\u043e\u0441\u0442\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u044c \u043b\u043e\u0436\u044c, \u0447\u0430\u0441\u0442\u043e \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u044e\u0449\u0443\u044e\u0441\u044f \u0432 \u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442\u0435.\n## \u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435\n**\u0412\u0435\u0441\u043e\u0432\u043e\u0435 \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u0435** \u2014 \u044d\u0442\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 (\u0432\u0435\u0441\u043e\u0432) \u0432 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438. \u0412 \u0442\u0438\u043f\u0438\u0447\u043d\u044b\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u044f\u0445 \u0432\u0435\u0441\u0430 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u044b \u043a\u0430\u043a \u0447\u0438\u0441\u043b\u0430 \u0441 \u043f\u043b\u0430\u0432\u0430\u044e\u0449\u0435\u0439 \u0437\u0430\u043f\u044f\u0442\u043e\u0439 \u0441 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0432\u044b\u0441\u043e\u043a\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c\u044e, \u0447\u0430\u0441\u0442\u043e 16 \u0431\u0438\u0442 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0444\u043e\u0440\u043c\u0430\u0442\u044b fp16 \u0438 bf16). \u041e\u0434\u043d\u0430\u043a\u043e \u044d\u0442\u043e\u0442 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432 \u043f\u0430\u043c\u044f\u0442\u0438 \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430.\n\n\n\n\u041a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0435\u0441\u043e\u0432 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u043d\u0430 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u044d\u0442\u0438\u0445 \u0432\u0435\u0441\u043e\u0432 \u0441 \u043c\u0435\u043d\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0431\u0438\u0442\u043e\u0432, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, 8-\u0431\u0438\u0442\u043d\u044b\u043c\u0438 \u0438\u043b\u0438 \u0434\u0430\u0436\u0435 4-\u0431\u0438\u0442\u043d\u044b\u043c\u0438 \u0446\u0435\u043b\u044b\u043c\u0438 \u0447\u0438\u0441\u043b\u0430\u043c\u0438. \u0422\u0430\u043a\u043e\u0435 \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u0435 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043c\u043e\u0436\u0435\u0442 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0441\u043d\u0438\u0437\u0438\u0442\u044c \u0442\u0440\u0435\u0431\u043e\u0432\u0430\u043d\u0438\u044f \u043a \u043f\u0430\u043c\u044f\u0442\u0438, \u0447\u0442\u043e \u0434\u0435\u043b\u0430\u0435\u0442 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u043c \u0440\u0430\u0437\u0432\u0435\u0440\u0442\u044b\u0432\u0430\u043d\u0438\u0435 LLM \u043d\u0430 \u043c\u0435\u043d\u044c\u0448\u0435\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u043e\u0432.\n\n\n\n**\u0412\u0438\u0434\u044b \u0438 \u0444\u043e\u0440\u043c\u0430\u0442\u044b \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439:**\n\n\n\nAWQ - Activation-aware Weight Quantization \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0435\u0441\u0430 \u0441 \u0443\u0447\u0435\u0442\u043e\u043c \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438, \u043c\u0435\u0442\u043e\u0434, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u0442 LLM \u0434\u043b\u044f \u043f\u043e\u0432\u044b\u0448\u0435\u043d\u0438\u044f \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u0438 \u0431\u0435\u0437 \u0443\u0449\u0435\u0440\u0431\u0430 \u0434\u043b\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043c\u043e\u0434\u0435\u043b\u0438 (\u0438\u043d\u0444\u0435\u0440\u0435\u043d\u0441 \u043d\u0430 GPU)(\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0444\u0440\u0435\u0439\u043c\u0432\u043e\u0440\u043a transformers, AutoAWQ, vLLM)\n\n\n\nGPTQ -  \u043c\u0435\u0442\u043e\u0434 \u043e\u0434\u043d\u043e\u0440\u0430\u0437\u043e\u0432\u043e\u0433\u043e \u0432\u0435\u0441\u043e\u0432\u043e\u0433\u043e \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u044f, \u043e\u0441\u043d\u043e\u0432\u0430\u043d\u043d\u044b\u0439 \u043d\u0430 \u043f\u0440\u0438\u0431\u043b\u0438\u0437\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u0432\u0442\u043e\u0440\u043e\u0433\u043e \u043f\u043e\u0440\u044f\u0434\u043a\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043e\u0434\u043d\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e \u0432\u044b\u0441\u043e\u043a\u043e\u0442\u043e\u0447\u043d\u044b\u043c \u0438 \u0432\u044b\u0441\u043e\u043a\u043e\u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u044b\u043c. \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442 \u0440\u0430\u0437\u043d\u044b\u0435 \u0443\u0440\u043e\u0432\u043d\u0438 \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u044f 2, 3, 4, 8bit (\u0438\u043d\u0444\u0435\u0440\u0435\u043d\u0441 \u043d\u0430 GPU)(\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0444\u0440\u0435\u0439\u043c\u0432\u043e\u0440\u043a transformers, AutoGPTQ)\n\n\n\nGGML, GGUF - \u0444\u043e\u0440\u043c\u0430\u0442 \u043c\u0435\u0442\u043e\u0434\u0430 \u0432\u0435\u0441\u043e\u0432\u043e\u0433\u043e \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u044f \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 C++. \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442 \u0440\u0430\u0437\u043d\u044b\u0435 \u0443\u0440\u043e\u0432\u043d\u0438 \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u044f 2, 3, 4, 5, 8bit (\u0438\u043d\u0444\u0435\u0440\u0435\u043d\u0441 \u043d\u0430 CPU + GPU)(\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0444\u0440\u0435\u0439\u043c\u0432\u043e\u0440\u043a transformers, llama-cpp-python)\n\n\n\nHF16 - \u043d\u0435 \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 c \u0432\u0435\u0441\u0430\u043c\u0438 \u0432 float16 (\u0438\u043d\u0444\u0435\u0440\u0435\u043d\u0441 \u043d\u0430 CPU + GPU)(\u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u044b\u0439 \u0444\u0440\u0435\u0439\u043c\u0432\u043e\u0440\u043a transformers, vLLM)\n## \u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n\u041e\u0441\u043d\u043e\u0432\u043d\u043e\u0439 \u0438 \u0443\u043d\u0438\u0432\u0435\u0440\u0441\u0430\u043b\u044c\u043d\u044b\u0439 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a (\u043a\u043e\u043d\u043d\u0446\u0435\u043d\u0442\u0440\u0430\u0442\u043e\u0440) \u0432\u0441\u0435\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u044d\u0442\u043e \u043f\u043b\u0430\u0442\u0444\u043e\u0440\u043c\u0430 Hugging Face https://huggingface.co/\n\n\n\n**Hugging Face**, Inc. \u2014 \u0430\u043c\u0435\u0440\u0438\u043a\u0430\u043d\u0441\u043a\u0430\u044f \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u044f, \u0440\u0430\u0437\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u044e\u0449\u0430\u044f \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u044b \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0439 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.[3] \u041e\u043d\u0430 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0438\u0437\u0432\u0435\u0441\u0442\u043d\u0430 \u0441\u0432\u043e\u0435\u0439 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u043e\u0439 Transformers, \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u043e\u0439 \u0434\u043b\u044f \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0439 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0435\u0441\u0442\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u044f\u0437\u044b\u043a\u0430, \u0438 \u0441\u0432\u043e\u0435\u0439 \u043f\u043b\u0430\u0442\u0444\u043e\u0440\u043c\u043e\u0439, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\u043c \u043e\u0431\u043c\u0435\u043d\u0438\u0432\u0430\u0442\u044c\u0441\u044f \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u043d\u0430\u0431\u043e\u0440\u0430\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u0445.\n* https://huggingface.co/stabilityai \u0434\u043b\u044f \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 StableBeluga\n\n\n\n* https://huggingface.co/IlyaGusev \u0434\u043b\u044f \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0421\u0430\u0439\u0433\u0430 (\u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u0430\u044f \u043f\u043e\u043b\u043d\u043e\u0446\u0435\u043d\u043d\u0430\u044f \u0440\u0443\u0441\u0441\u043a\u043e\u044f\u0437\u044b\u0447\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c)\n\n\n\n* https://huggingface.co/garage-bAInd \u0434\u043b\u044f \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 Platypus\n\n\n\n* \u0411\u043e\u043b\u044c\u0448\u043e\u0439 \u0432\u043a\u043b\u0430\u0434 \u0432 \u0441\u0431\u043e\u0440 \u0432 \u043e\u0434\u043d\u043e\u043c \u043c\u0435\u0441\u0442\u0435 \u0438 \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0434\u0435\u043b\u0430\u0435\u0442 \u044d\u043a\u043f\u0435\u0440\u0442-\u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a https://huggingface.co/TheBloke (\u0432 \u0435\u0433\u043e \u0440\u0435\u043f\u043e\u0437\u0438\u0442\u043e\u0440\u0438\u0438 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u044b \u0431\u043e\u043b\u0435\u0435 2000 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0432 \u0440\u0430\u0437\u043d\u044b\u0445 \u0444\u043e\u0440\u043c\u0430\u0442\u0430\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043f\u043e\u043b\u043d\u044f\u044e\u0442\u0441\u044f \u0435\u0436\u0435\u0434\u043d\u0435\u0432\u043d\u043e)\n# Langchain \u0438 llama-cpp-python\n**Langchain Llama.cpp**\n\n\n\n\u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0438 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0434\u043b\u044f CPU, GPU, Metal (\u0434\u043b\u044f ios)\n\n\n\nhttps://python.langchain.com/docs/integrations/llms/llamacpp\n**llama-cpp-python**\n\n\n\n\u044d\u0442\u043e Python \u0432\u0435\u0440\u0441\u0438\u044f \u0434\u043b\u044f llama.cpp\n\n\n\nhttps://github.com/abetlen/llama-cpp-python\n**\u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0442\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u044f \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430:**\n\n\n\n!pip install llama-cpp-python\n\n\n\n**\u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0434\u043b\u044f \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430:**\n\n\n\n!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir\n## \u041f\u0440\u0438\u043c\u0435\u0440\u044b \u0442\u0435\u043c\u043f\u043b\u0435\u0439\u0442\u043e\u0432 \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n**Platypus 2**\n\"\"\"\n\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n\n### Instruction:\n\n{prompt}\n\n\n\n### Response:\n\n\"\"\"\n\n**Llama 2**\n\"\"\"\n\n [INST] <<SYS>>\n\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\n\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n\n<</SYS>>\n\n\n\n{prompt} [/INST]\n\n\"\"\"\n\n**StableBeluga 2**\n\"\"\"\n\n### System: You are a helpful, respectful and honest assistant.\n\n\n\n### User: {prompt}\n\n\n\n### Assistant:\n\n\"\"\"\n\n## \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0437\u0430\u043f\u0443\u0441\u043a\u0430 GGML, GGUF \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n\"\"\"\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()]) # \u041a\u043e\u043b\u0431\u044d\u043a \u0434\u043b\u044f \u0441\u0442\u0440\u0438\u043c\u0438\u043d\u0433\u043e\u0432\u043e\u0433\u043e \u0432\u044b\u0432\u043e\u0434\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u043f\u043e \u0442\u043e\u043a\u0435\u043d\u0430\u043c\n\nllama = LlamaCpp(\n\n    model_path=\"/content/platypus2-70b-instruct.ggmlv3.q4_0.bin\", # \u041f\u0443\u0442\u044c \u043a \u043c\u043e\u0434\u0435\u043b\u0438\n\n    n_gpu_layers=70,  # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043b\u043e\u0435\u0432 \u043c\u043e\u0434\u0435\u043b\u0438 \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u043d\u043e\u0441\u0430 \u043d\u0430 GPU. \u041f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e 1\n\n    n_batch=512, # \u0414\u043e\u043b\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u043e\u0442 1 \u0434\u043e n_ctx, \u0443\u0447\u0438\u0442\u044b\u0432\u0430\u044f \u043e\u0431\u044a\u0435\u043c \u043e\u043f\u0435\u0440\u0430\u0442\u0438\u0432\u043d\u043e\u0439 \u043f\u0430\u043c\u044f\u0442\u0438. \u041f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e 512\n\n    n_gqa=8, # \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u0441 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438 70B\n\n    n_ctx=4096,  # \u0420\u0430\u0437\u043c\u0435\u0440 \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u0438\n\n    max_tokens=1000,  # \u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0442\u043e\u043a\u0435\u043d\u043e\u0432 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438\n\n    f16_kv=True,  # \u0414\u041e\u041b\u0416\u041d\u041e \u0431\u044b\u0442\u044c \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 True, \u0438\u043d\u0430\u0447\u0435 \u043f\u043e\u0441\u043b\u0435 \u043f\u0430\u0440\u044b \u0432\u044b\u0437\u043e\u0432\u043e\u0432 \u0443 \u0432\u0430\u0441 \u0432\u043e\u0437\u043d\u0438\u043a\u043d\u0443\u0442 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b.\n\n    callback_manager=callback_manager, # \u041a\u043e\u043b\u0431\u044d\u043a\n\n    verbose=True, # \u041e\u0442\u043e\u0431\u0440\u0430\u0436\u0430\u0442\u044c \u043f\u0440\u043e\u043c\u0435\u0436\u0443\u0442\u043e\u0447\u043d\u044b\u0439 \u0432\u044b\u0432\u043e\u0434 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u043b\u0438 \u043d\u0435\u0442\n\n)\n\n\"\"\"\n\n## \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0435\u0439 \u0434\u043b\u044f ggml \u0444\u043e\u0440\u043c\u0430\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n\nlangchain==0.0.275\n\n\n\nllama-cpp-python==0.1.77\n!pip install langchain==0.0.275 pydantic==1.10.13 openai==0.28.1 faiss-cpu==1.7.4 tiktoken==0.5.1 sentence_transformers==2.2.2 nltk==3.8.1\n\n!pip install -U deep-translator==1.11.4\nimport os\n\nos.environ[\"LANGCHAIN_TRACING\"] = \"true\" # If you want to trace the execution of the program, set to \"true\"\n!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python==0.1.77 --no-cache-dir\n\n## \u0423\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0435\u0439 \u0434\u043b\u044f gguf \u0444\u043e\u0440\u043c\u0430\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u0435\u0439\n\n\n\n\n\n!pip install langchain==0.0.322 pydantic openai==0.28.1 faiss-cpu==1.7.4 tiktoken==0.5.1 sentence_transformers==2.2.2 nltk==3.8.1\n\n!pip install -U deep-translator==1.11.4\nimport os\n\nos.environ[\"LANGCHAIN_TRACING\"] = \"true\" # If you want to trace the execution of the program, set to \"true\"\n!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python==0.2.11 --no-cache-dir\n\n## \u0421\u0435\u0440\u0432\u0438\u0441\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\nimport os\n\nimport getpass\n\n\n\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\nfrom google.colab import drive\n\ndrive.mount('/content/drive')\n\n### \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c\nfrom langchain.document_loaders import TextLoader\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.llms import OpenAI\n\nfrom langchain.docstore.document import Document\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, NLTKTextSplitter, CharacterTextSplitter\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nproject_path = \"/content/drive/MyDrive/\u041f\u0440\u043e\u0435\u043a\u0442\u044b/LLMs_local\"\n\n\n\n\n\nloader = TextLoader(\"/content/0 \u041a\u043e\u043f\u0438\u0440\u0430\u0439\u0442\u0438\u043d\u0433. \u0422\u0435\u043a\u0441\u0442 \u0434\u043b\u044f ChatGPT (\u043a\u043e\u043f. \u043e\u0442 15.08.2023).txt\")\n\ndocuments = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n\ndocs = text_splitter.split_documents(documents)\n\ndb = FAISS.from_documents(docs, OpenAIEmbeddings())", "metadata": {"subid": 0, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n### \u043d\u0430 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c\n#### \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435\nfrom langchain.document_loaders import TextLoader\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.llms import OpenAI\n\nfrom langchain.docstore.document import Document\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, NLTKTextSplitter, CharacterTextSplitter\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nproject_path = \"/content/drive/MyDrive\"\n\n\n\n\n\nloader = TextLoader(\"/content/0 \u041a\u043e\u043f\u0438\u0440\u0430\u0439\u0442\u0438\u043d\u0433. \u0422\u0435\u043a\u0441\u0442 \u0434\u043b\u044f ChatGPT (\u043a\u043e\u043f. \u043e\u0442 15.08.2023).txt\")\n\ndocuments = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=0)\n\ndocs = text_splitter.split_documents(documents)\n\nimport tqdm\n\nfrom deep_translator import GoogleTranslator\n\n\n\ndocs_translate = []\n\nfor doc in tqdm.tqdm(docs):\n\n  docs_translate.append(Document(page_content=GoogleTranslator(source='auto', target='en').translate(doc.page_content)))\n\n\n\ndb = FAISS.from_documents(docs_translate, OpenAIEmbeddings())\nproject_path = \"/content/drive/MyDrive\"\n\n\n\ndb.save_local(os.path.join(project_path, 'UII_15_08_2023_en'))\nimport pickle\n\n\n\nwith open(os.path.join(project_path, 'docs_translate_new.pkl'), 'wb') as f:\n\n  pickle.dump(docs_translate, f, protocol = None, fix_imports = True)\n\n#### \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0441\u043e\u0437\u0434\u0430\u043d\u043d\u043e\u0439 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u0439 \u0431\u0430\u0437\u044b \u0438\u0437 \u0444\u0430\u0439\u043b\u0430\nfrom langchain.document_loaders import TextLoader\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.llms import OpenAI\n\nfrom langchain.docstore.document import Document\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, NLTKTextSplitter, CharacterTextSplitter\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nproject_path = \"/content/drive/MyDrive/\u041f\u0440\u043e\u0435\u043a\u0442\u044b/Local LLMs en\"\n\n\n\ndb = FAISS.load_local(os.path.join(project_path, 'UII_15_08_2023_en'), OpenAIEmbeddings())\n\n## \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0432\u043e\u043f\u0440\u043e\u0441\u044b\nimport pandas as pd\n\n\n\ndf_qw = pd.read_csv(\"/content/\u0412\u043e\u043f\u0440\u043e\u0441\u044b \u0434\u043b\u044f \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439.csv\", delimiter='/n', encoding='cp1251')\n\ndf_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values\n\n## \u0422\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u0438\n#### Platypus2-70b-instruct ggml\n!wget https://huggingface.co/TheBloke/Platypus2-70B-Instruct-GGML/resolve/main/platypus2-70b-instruct.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\n\n\nn_gpu_layers = 70  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/platypus2-70b-instruct.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n# Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n\n# ### Instruction:\n\n# {prompt}\n\n\n\n# ### Response:\ntemplate = \"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \\n\\n\n\nInstruction: \u0422\u044b \u0434\u043e\u043b\u0436\u0435\u043d \u0432\u0441\u0435\u0433\u0434\u0430 \u043e\u0442\u0432\u0435\u0447\u0430\u0442\u044c \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435, \u0438 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\"\\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\\n\\n\n\nResponse:\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), str(result), str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Platypus2-70b-instruct-ggml-4' + '.csv'), index=False)\n\n#### Llama-2-70B-Chat-GGML 4\n!wget https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/resolve/main/llama-2-70b-chat.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\n# /usr/local/lib/python3.10/dist-packages/langchain/llms/llamacpp.py\n\n# \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0448\u0438\u0431\u043a\u0438 https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/discussions/5\n\nn_gpu_layers = 70  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-70b-chat.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n# [INST] <<SYS>>\n\n# You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\n\n\n# If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n\n# <</SYS>>\n\n\n\n# {prompt} [/INST]\ntemplate = \"\"\"<s>[INST] <<SYS>>\\n\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\\n\n\n<</SYS>>\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result), str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-70B-Chat-GGML-4' + '.csv'), index=False)", "metadata": {"subid": 1, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### Llama-2-13B-chat ggml\n!wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\nn_gpu_layers = 4000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-13b-chat.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"<s>[INST] <<SYS>>\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n<</SYS>>\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), result, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-13B-Chat-GGML-4' + '.csv'), index=False)\n\n#### Llama-2-7B-chat ggml 4\n!wget https://huggingface.co/TheBloke/Llama-2-7B-chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\nn_gpu_layers = 20000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-7b-chat.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"<s>[INST] <<SYS>>\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n<</SYS>>\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result), str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-7B-Chat-GGML-4' + '.csv'), index=False)\n\n#### StableBeluga 2 13B gguf\n!wget https://huggingface.co/TheBloke/StableBeluga-13B-GGUF/resolve/main/stablebeluga-13b.Q4_0.gguf\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, NLTKTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nfrom langchain.document_loaders import TextLoader\n\nfrom deep_translator import GoogleTranslator\n\nimport re\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nn_gpu_layers = 1000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/stablebeluga-13b.Q4_0.gguf\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    temperature=0,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"### System: \\n\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\\n\\n\n\n### User: \\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\\n\\n\n\n### Assistant:\\n\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), result, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'StableBeluga-2-13B-GGUF-4' + '.csv'), index=False)", "metadata": {"subid": 2, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### Stablebeluga2-70b ggml\n!wget https://huggingface.co/TheBloke/StableBeluga2-70B-GGML/resolve/main/stablebeluga2-70b.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\n\n\n\n\nn_gpu_layers = 60  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/stablebeluga2-70b.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    temperature=0,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\ntemplate = \"\"\"### System: \\n\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\\n\\n\n\n### User: \\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\\n\\n\n\n### Assistant:\\n\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), result, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'StableBeluga-2-70B-GGML-4' + '.csv'), index=False)\n\n#### WizardMath-13B-V1.0-GGML\n!wget https://huggingface.co/TheBloke/WizardMath-13B-V1.0-GGML/resolve/main/wizardmath-13b-v1.0.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, NLTKTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nfrom langchain.document_loaders import TextLoader\n\nfrom deep_translator import GoogleTranslator\n\nimport re\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nn_gpu_layers = 4000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/wizardmath-13b-v1.0.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    temperature=0,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\n# Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n\n\n\n# ### Instruction:\n\n# {prompt}\n\n\n\n\n\n# ### Response: Let's think step by step.\ntemplate = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n\n### Instruction: \\n\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\n\n### Response: Let's think step by step.\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result), str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'WizardMath-13B-V1-GGML' + '.csv'), index=False)\n\n#### Upstage-Llama-2-70B-instruct-v2-GGML\n!wget https://huggingface.co/TheBloke/Upstage-Llama-2-70B-instruct-v2-GGML/resolve/main/upstage-llama-2-70b-instruct-v2.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\n# /usr/local/lib/python3.10/dist-packages/langchain/llms/llamacpp.py\n\n# \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0448\u0438\u0431\u043a\u0438 https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/discussions/5\n\nn_gpu_layers = 70  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-70b-chat.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n# ### System:\n\n# This is a system prompt, please behave and help the user.\n\n\n\n# ### User:\n\n# {prompt}\n\n\n\n# ### Assistant:\ntemplate = \"\"\"### System: \\n\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\\n\\n\n\n### User: \\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\\n\\n\n\n### Assistant:\\n\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result), str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Upstage-Llama-2-70B-instruct-v2-GGML-4' + '.csv'), index=False)", "metadata": {"subid": 3, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### OpenAI chatgpt\nimport openai\n\nimport re\n\n\n\nchat_manager_system = \"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f.\n\n\u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\"\"\"\n\n\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  messages = [\n\n    {\"role\": \"system\", \"content\": f\"{chat_manager_system}\"},\n\n    {\"role\": \"user\", \"content\": f\"\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \"\n\n                                f\"\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430.\\n\\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\\n{query}\\n\\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \"\n\n                                f\"\u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\"}\n\n  ]\n\n  result = openai.ChatCompletion.create(\n\n    model='gpt-3.5-turbo',\n\n    messages=messages,\n\n    temperature=0.0\n\n)\n\n  history.append([str(query), result.choices[0].message.content, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'OpenAI_chatgpt' + '.csv'), index=False)\n\n#### OpenAI gpt-3.5-turbo-instruct\nimport openai\n\nimport re\n\n\n\n\n\n\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  prompt = f\"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f.\n\n\u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430.\\n\\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\\n{query}\\n\\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}. \u041e\u0442\u0432\u0435\u0442: \"\n\n\"\"\"\n\n\n\n  result = openai.Completion.create(\n\n    model=\"gpt-3.5-turbo-instruct\",\n\n    prompt=prompt,\n\n    max_tokens=1500,\n\n    temperature=0\n\n  )\n\n  history.append([str(query), result.choices[0].text, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'OpenAI_gptturbo-instruct' + '.csv'), index=False)", "metadata": {"subid": 4, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n##### \u0418\u043c\u043c\u0438\u0442\u0430\u0446\u0438\u044f \u0434\u0438\u0430\u043b\u043e\u0433\u0430\nquery = '\u0414\u043e\u0431\u0440\u044b\u0439 \u0434\u0435\u043d\u044c! \u041c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u0438\u0442\u0441\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \u0411\u0430\u0437\u043e\u0432\u044b\u0439?'\n\nsim_docs = db.similarity_search(query)\n\n\n\ndocs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\nprompt = f\"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u0415\u0441\u043b\u0438 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u0438\u043b\u0441\u044f \u043e\u0431\u0440\u0430\u0449\u0430\u0439\u0441\u044f \u043a \u043d\u0435\u043c\u0443 \u043f\u043e \u0438\u043c\u0435\u043d\u0438. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442.\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n{query}\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \"\n\n\"\"\"\n\n\n\nresult = openai.Completion.create(\n\n  model=\"gpt-3.5-turbo-instruct\",\n\n  prompt=prompt,\n\n  max_tokens=1500,\n\n  temperature=0\n\n)\n\nprint(result.choices[0].text)\nquery = '\u0414\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043b\u0438 \u0443 \u0432\u0430\u0441 \u0435\u0441\u0442\u044c \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u043f\u043e\u0441\u043b\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f?'\n\nsim_docs = db.similarity_search(query)\n\n\n\ndocs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\nprompt = f\"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442.\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u0414\u043e\u0431\u0440\u044b\u0439 \u0434\u0435\u043d\u044c! \u041c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u0438\u0442\u0441\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \u0411\u0430\u0437\u043e\u0432\u044b\u0439?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0434\u043b\u0438\u0442\u0441\u044f 7 \u043c\u0435\u0441\u044f\u0446\u0435\u0432. \u042d\u0442\u043e \u0441\u0430\u043c\u044b\u0439 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u043f\u043e \u0446\u0435\u043d\u0435 \u0442\u0430\u0440\u0438\u0444 \u043e\u0442 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0430 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u0412 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 32 \u0443\u0440\u043e\u043a\u0430, \u043e\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u044e\u0449\u0438\u0445 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043a\u043e\u043d\u0446\u0435\u043f\u0446\u0438\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439, \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u0433\u0435\u043d\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432, \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0442\u0435\u043c\u044b. \u0422\u0430\u043a\u0436\u0435 \u0432\u0430\u0441 \u0436\u0434\u0435\u0442 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0443\u0440\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u043f\u0440\u043e\u0442\u044f\u0436\u0435\u043d\u0438\u0438 32 \u043d\u0435\u0434\u0435\u043b\u044c, \u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u0438 \u043f\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044e \u0434\u0438\u043f\u043b\u043e\u043c\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430, \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u0438 \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0432 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u0443\u0440\u0441 \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0437\u0430\u043f\u0438\u0441\u044f\u043c \u0432 \u0443\u0434\u043e\u0431\u043d\u043e\u043c \u0434\u043b\u044f \u0432\u0430\u0441 \u0433\u0440\u0430\u0444\u0438\u043a\u0435, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0435\u0433\u043e \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u0442\u0430\u0440\u0438\u0444\u0430, \u043a\u0440\u043e\u043c\u0435 \u0431\u0430\u0437\u043e\u0432\u043e\u0433\u043e, \u0438\u043b\u0438 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u0432\u044b \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u043d\u0430\u0448\u0438\u043c \u043a\u0443\u0440\u0441\u043e\u043c \u0438 \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u0441\u044c \u043a \u043d\u0430\u0448\u0435\u0439 \u043a\u043e\u043c\u0430\u043d\u0434\u0435 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432! \u0416\u0435\u043b\u0430\u044e \u0432\u0430\u043c \u0443\u0441\u043f\u0435\u0445\u043e\u0432 \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n{query}\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI:\n\n\"\"\"\n\n\n\nresult = openai.Completion.create(\n\n  model=\"gpt-3.5-turbo-instruct\",\n\n  prompt=prompt,\n\n  max_tokens=1500,\n\n  temperature=0\n\n)\n\nprint(result.choices[0].text)\nquery = '\u041a\u0430\u043a\u043e\u0432\u0430 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0443\u0440\u0441\u0430 \u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u0438 \u043c\u043e\u0436\u0435\u0442 \u0435\u0441\u0442\u044c \u043a\u0430\u043a\u0438\u0435 \u043d\u0438\u0431\u0443\u0434\u044c \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u0441\u043a\u0438\u0434\u043e\u043a?'\n\nsim_docs = db.similarity_search(query)\n\n\n\ndocs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\nprompt = f\"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442.\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u0414\u043e\u0431\u0440\u044b\u0439 \u0434\u0435\u043d\u044c! \u041c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u0438\u0442\u0441\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \u0411\u0430\u0437\u043e\u0432\u044b\u0439?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0434\u043b\u0438\u0442\u0441\u044f 7 \u043c\u0435\u0441\u044f\u0446\u0435\u0432. \u042d\u0442\u043e \u0441\u0430\u043c\u044b\u0439 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u043f\u043e \u0446\u0435\u043d\u0435 \u0442\u0430\u0440\u0438\u0444 \u043e\u0442 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0430 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u0412 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 32 \u0443\u0440\u043e\u043a\u0430, \u043e\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u044e\u0449\u0438\u0445 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043a\u043e\u043d\u0446\u0435\u043f\u0446\u0438\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439, \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u0433\u0435\u043d\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432, \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0442\u0435\u043c\u044b. \u0422\u0430\u043a\u0436\u0435 \u0432\u0430\u0441 \u0436\u0434\u0435\u0442 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0443\u0440\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u043f\u0440\u043e\u0442\u044f\u0436\u0435\u043d\u0438\u0438 32 \u043d\u0435\u0434\u0435\u043b\u044c, \u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u0438 \u043f\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044e \u0434\u0438\u043f\u043b\u043e\u043c\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430, \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u0438 \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0432 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u0443\u0440\u0441 \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0437\u0430\u043f\u0438\u0441\u044f\u043c \u0432 \u0443\u0434\u043e\u0431\u043d\u043e\u043c \u0434\u043b\u044f \u0432\u0430\u0441 \u0433\u0440\u0430\u0444\u0438\u043a\u0435, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0435\u0433\u043e \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u0442\u0430\u0440\u0438\u0444\u0430, \u043a\u0440\u043e\u043c\u0435 \u0431\u0430\u0437\u043e\u0432\u043e\u0433\u043e, \u0438\u043b\u0438 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u0432\u044b \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u043d\u0430\u0448\u0438\u043c \u043a\u0443\u0440\u0441\u043e\u043c \u0438 \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u0441\u044c \u043a \u043d\u0430\u0448\u0435\u0439 \u043a\u043e\u043c\u0430\u043d\u0434\u0435 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432! \u0416\u0435\u043b\u0430\u044e \u0432\u0430\u043c \u0443\u0441\u043f\u0435\u0445\u043e\u0432 \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n'\u0414\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043b\u0438 \u0443 \u0432\u0430\u0441 \u0435\u0441\u0442\u044c \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u043f\u043e\u0441\u043b\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f?'\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0414\u0430, \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u043e\u043f\u0438\u0441\u0430\u043d\u0430 \u0432 \u0434\u043e\u0433\u043e\u0432\u043e\u0440\u0435. \u041f\u043e\u0441\u043b\u0435 \u043f\u0440\u043e\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u0435\u0440\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u0430, \u0432\u044b \u0441\u043c\u043e\u0436\u0435\u0442\u0435 \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0438\u0442\u044c\u0441\u044f \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430 \u0438\u043b\u0438 \u0432 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u043d\u0430\u0448\u0438\u0445 \u043f\u0430\u0440\u0442\u043d\u0435\u0440\u0441\u043a\u0438\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0439. \u0422\u0430\u043a\u0436\u0435 \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u043a\u0443\u043f\u0438\u0442\u044c \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0437\u0430 \u0441\u0447\u0435\u0442 \u0437\u0430\u0440\u0430\u0431\u043e\u0442\u043d\u043e\u0439 \u043f\u043b\u0430\u0442\u044b, \u0435\u0441\u043b\u0438 \u0432\u044b \u0440\u0435\u0448\u0438\u0442\u0435 \u043e\u0441\u0442\u0430\u0442\u044c\u0441\u044f \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u044d\u0442\u043e \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0436\u0434\u0430\u0435\u0442 \u043d\u0430\u0448\u0443 \u0441\u0435\u0440\u044c\u0435\u0437\u043d\u043e\u0441\u0442\u044c \u0438 \u0433\u043e\u0442\u043e\u0432\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u043d\u0430\u0448\u0438\u0445 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432 \u0432 \u0438\u0445 \u043a\u0430\u0440\u044c\u0435\u0440\u043d\u043e\u043c \u0440\u043e\u0441\u0442\u0435.\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n{query}\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI:\n\n\"\"\"\n\n\n\nresult = openai.Completion.create(\n\n  model=\"gpt-3.5-turbo-instruct\",\n\n  prompt=prompt,\n\n  max_tokens=1500,\n\n  temperature=0\n\n)\n\nprint(result.choices[0].text)\nquery = '\u0414\u0430! \u0425\u043e\u0447\u0443 \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0441\u044f \u043a \u044d\u0442\u043e\u043c\u0443 \u043a\u0443\u0440\u0441\u0443, \u0447\u0442\u043e \u043c\u043d\u0435 \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u0443\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c?'\n\nsim_docs = db.similarity_search(query)\n\n\n\ndocs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\nprompt = f\"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442.\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u0414\u043e\u0431\u0440\u044b\u0439 \u0434\u0435\u043d\u044c! \u041c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u0438\u0442\u0441\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \u0411\u0430\u0437\u043e\u0432\u044b\u0439?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0434\u043b\u0438\u0442\u0441\u044f 7 \u043c\u0435\u0441\u044f\u0446\u0435\u0432. \u042d\u0442\u043e \u0441\u0430\u043c\u044b\u0439 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u043f\u043e \u0446\u0435\u043d\u0435 \u0442\u0430\u0440\u0438\u0444 \u043e\u0442 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0430 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u0412 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 32 \u0443\u0440\u043e\u043a\u0430, \u043e\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u044e\u0449\u0438\u0445 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043a\u043e\u043d\u0446\u0435\u043f\u0446\u0438\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439, \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u0433\u0435\u043d\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432, \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0442\u0435\u043c\u044b. \u0422\u0430\u043a\u0436\u0435 \u0432\u0430\u0441 \u0436\u0434\u0435\u0442 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0443\u0440\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u043f\u0440\u043e\u0442\u044f\u0436\u0435\u043d\u0438\u0438 32 \u043d\u0435\u0434\u0435\u043b\u044c, \u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u0438 \u043f\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044e \u0434\u0438\u043f\u043b\u043e\u043c\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430, \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u0438 \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0432 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u0443\u0440\u0441 \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0437\u0430\u043f\u0438\u0441\u044f\u043c \u0432 \u0443\u0434\u043e\u0431\u043d\u043e\u043c \u0434\u043b\u044f \u0432\u0430\u0441 \u0433\u0440\u0430\u0444\u0438\u043a\u0435, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0435\u0433\u043e \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u0442\u0430\u0440\u0438\u0444\u0430, \u043a\u0440\u043e\u043c\u0435 \u0431\u0430\u0437\u043e\u0432\u043e\u0433\u043e, \u0438\u043b\u0438 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u0432\u044b \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u043d\u0430\u0448\u0438\u043c \u043a\u0443\u0440\u0441\u043e\u043c \u0438 \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u0441\u044c \u043a \u043d\u0430\u0448\u0435\u0439 \u043a\u043e\u043c\u0430\u043d\u0434\u0435 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432! \u0416\u0435\u043b\u0430\u044e \u0432\u0430\u043c \u0443\u0441\u043f\u0435\u0445\u043e\u0432 \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n'\u0414\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043b\u0438 \u0443 \u0432\u0430\u0441 \u0435\u0441\u0442\u044c \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u043f\u043e\u0441\u043b\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f?'\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0414\u0430, \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u043e\u043f\u0438\u0441\u0430\u043d\u0430 \u0432 \u0434\u043e\u0433\u043e\u0432\u043e\u0440\u0435. \u041f\u043e\u0441\u043b\u0435 \u043f\u0440\u043e\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u0435\u0440\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u0430, \u0432\u044b \u0441\u043c\u043e\u0436\u0435\u0442\u0435 \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0438\u0442\u044c\u0441\u044f \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430 \u0438\u043b\u0438 \u0432 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u043d\u0430\u0448\u0438\u0445 \u043f\u0430\u0440\u0442\u043d\u0435\u0440\u0441\u043a\u0438\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0439. \u0422\u0430\u043a\u0436\u0435 \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u043a\u0443\u043f\u0438\u0442\u044c \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0437\u0430 \u0441\u0447\u0435\u0442 \u0437\u0430\u0440\u0430\u0431\u043e\u0442\u043d\u043e\u0439 \u043f\u043b\u0430\u0442\u044b, \u0435\u0441\u043b\u0438 \u0432\u044b \u0440\u0435\u0448\u0438\u0442\u0435 \u043e\u0441\u0442\u0430\u0442\u044c\u0441\u044f \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u044d\u0442\u043e \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0436\u0434\u0430\u0435\u0442 \u043d\u0430\u0448\u0443 \u0441\u0435\u0440\u044c\u0435\u0437\u043d\u043e\u0441\u0442\u044c \u0438 \u0433\u043e\u0442\u043e\u0432\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u043d\u0430\u0448\u0438\u0445 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432 \u0432 \u0438\u0445 \u043a\u0430\u0440\u044c\u0435\u0440\u043d\u043e\u043c \u0440\u043e\u0441\u0442\u0435.\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u041a\u0430\u043a\u043e\u0432\u0430 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0443\u0440\u0441\u0430 \u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u0438 \u043c\u043e\u0436\u0435\u0442 \u0435\u0441\u0442\u044c \u043a\u0430\u043a\u0438\u0435 \u043d\u0438\u0431\u0443\u0434\u044c \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u0441\u043a\u0438\u0434\u043e\u043a?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0443\u0440\u0441\u0430 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 89 900 \u0440\u0443\u0431\u043b\u0435\u0439. \u041e\u0434\u043d\u0430\u043a\u043e, \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u0441\u043a\u0438\u0434\u043e\u043a \u0438 \u0431\u043e\u043d\u0443\u0441\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0435\u0449\u0435 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0433\u043e\u0434\u043d\u044b\u043c \u0434\u043b\u044f \u0432\u0430\u0441. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u0442\u0430\u0440\u0438\u0444\u0430, \u043a\u0440\u043e\u043c\u0435 \"\u0411\u0430\u0437\u043e\u0432\u043e\u0433\u043e\", \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043a\u0443\u0440\u0441 \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a. \u0422\u0430\u043a\u0436\u0435 \u043c\u044b \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u0435\u043c \u043a\u0443\u0440\u0441 \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u0442\u0430\u0440\u0438\u0444\u0430 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0438 4 \u0441\u0442\u0430\u0436\u0438\u0440\u043e\u0432\u043e\u043a. \u0414\u043b\u044f \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432, \u0443\u0436\u0435 \u043f\u0440\u043e\u0445\u043e\u0434\u0438\u0432\u0448\u0438\u0445 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430, \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u044b\u0439 \u043a\u0443\u0440\u0441 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u043e\u0432 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 39 900 \u0440\u0443\u0431\u043b\u0435\u0439, \u043f\u0440\u043e\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0438 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0441\u0442\u0430\u0436\u0438\u0440\u043e\u0432\u043e\u043a \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439 \u0438\u043b\u0438 \u0432\u043d\u0435\u0441\u0435\u043d\u0438\u0438 \u0434\u0435\u043f\u043e\u0437\u0438\u0442\u0430 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439. \u0422\u0430\u043a\u0436\u0435 \u043c\u044b \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u0435\u043c \u0431\u043e\u043d\u0443\u0441\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043d\u0430 \u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u0438 \u0438\u043b\u0438 \u043a\u0443\u0440\u0441\u044b, \u0438 \u0432\u044b\u0438\u0433\u0440\u0430\u0442\u044c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0441\u0442\u0430\u0436\u0438\u0440\u043e\u0432\u043a\u0438 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u0442\u0430\u0440\u0438\u0444\u043e\u0432 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\", \"\u041f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0439\" \u0438\u043b\u0438 \"AI \u043f\u043e\u0434 \u043a\u043b\u044e\u0447\". \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u044d\u0442\u0438 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u0441\u043a\u0438\u0434\u043e\u043a \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u0443\u044e\u0442 \u0432\u0430\u0441 \u0438 \u0432\u044b \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u0441\u044c \u043a \u043d\u0430\u0448\u0435\u043c\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n{query}\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI:\n\n\"\"\"\n\n\n\nresult = openai.Completion.create(\n\n  model=\"gpt-3.5-turbo-instruct\",\n\n  prompt=prompt,\n\n  max_tokens=1500,\n\n  temperature=0\n\n)\n\nprint(result.choices[0].text)\nquery = '\u041f\u0435\u0440\u0435\u0447\u0438\u0441\u043b\u0438 \u043a\u0430\u043a\u0438\u0435 \u0435\u0441\u0442\u044c \u0435\u0449\u0435 \u0442\u0430\u0440\u0438\u0444\u044b \u043f\u043e\u0434\u0445\u043e\u0434\u044f\u0449\u0438\u0435 \u0434\u043b\u044f \u043c\u0435\u043d\u044f?'\n\nsim_docs = db.similarity_search(query)\n\n\n\ndocs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\nprompt = f\"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442.\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u0414\u043e\u0431\u0440\u044b\u0439 \u0434\u0435\u043d\u044c! \u041c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u0421\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u043b\u0438\u0442\u0441\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \u0411\u0430\u0437\u043e\u0432\u044b\u0439?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0417\u0434\u0440\u0430\u0432\u0441\u0442\u0432\u0443\u0439\u0442\u0435, \u0412\u0430\u043b\u0435\u043d\u0442\u0438\u043d! \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u043a\u0443\u0440\u0441\u0435 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0434\u043b\u0438\u0442\u0441\u044f 7 \u043c\u0435\u0441\u044f\u0446\u0435\u0432. \u042d\u0442\u043e \u0441\u0430\u043c\u044b\u0439 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u043f\u043e \u0446\u0435\u043d\u0435 \u0442\u0430\u0440\u0438\u0444 \u043e\u0442 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0430 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u0412 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 32 \u0443\u0440\u043e\u043a\u0430, \u043e\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u044e\u0449\u0438\u0445 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043a\u043e\u043d\u0446\u0435\u043f\u0446\u0438\u0438 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439, \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u0433\u0435\u043d\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432, \u043e\u0431\u043d\u0430\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0442\u0435\u043c\u044b. \u0422\u0430\u043a\u0436\u0435 \u0432\u0430\u0441 \u0436\u0434\u0435\u0442 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u043a\u0443\u0440\u0430\u0442\u043e\u0440\u0430 \u043d\u0430 \u043f\u0440\u043e\u0442\u044f\u0436\u0435\u043d\u0438\u0438 32 \u043d\u0435\u0434\u0435\u043b\u044c, \u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u0438 \u043f\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044e \u0434\u0438\u043f\u043b\u043e\u043c\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430, \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0430\u044f \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u0438 \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0432 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u0443\u0440\u0441 \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0437\u0430\u043f\u0438\u0441\u044f\u043c \u0432 \u0443\u0434\u043e\u0431\u043d\u043e\u043c \u0434\u043b\u044f \u0432\u0430\u0441 \u0433\u0440\u0430\u0444\u0438\u043a\u0435, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0435\u0433\u043e \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u0442\u0430\u0440\u0438\u0444\u0430, \u043a\u0440\u043e\u043c\u0435 \u0431\u0430\u0437\u043e\u0432\u043e\u0433\u043e, \u0438\u043b\u0438 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u0432\u044b \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043e\u0432\u0430\u043b\u0438\u0441\u044c \u043d\u0430\u0448\u0438\u043c \u043a\u0443\u0440\u0441\u043e\u043c \u0438 \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u0441\u044c \u043a \u043d\u0430\u0448\u0435\u0439 \u043a\u043e\u043c\u0430\u043d\u0434\u0435 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432! \u0416\u0435\u043b\u0430\u044e \u0432\u0430\u043c \u0443\u0441\u043f\u0435\u0445\u043e\u0432 \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n'\u0414\u0435\u0439\u0441\u0442\u0432\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u043b\u0438 \u0443 \u0432\u0430\u0441 \u0435\u0441\u0442\u044c \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430 \u043f\u043e\u0441\u043b\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f?'\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0414\u0430, \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u043e\u043f\u0438\u0441\u0430\u043d\u0430 \u0432 \u0434\u043e\u0433\u043e\u0432\u043e\u0440\u0435. \u041f\u043e\u0441\u043b\u0435 \u043f\u0440\u043e\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u0435\u0440\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u0430, \u0432\u044b \u0441\u043c\u043e\u0436\u0435\u0442\u0435 \u0442\u0440\u0443\u0434\u043e\u0443\u0441\u0442\u0440\u043e\u0438\u0442\u044c\u0441\u044f \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430 \u0438\u043b\u0438 \u0432 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u043d\u0430\u0448\u0438\u0445 \u043f\u0430\u0440\u0442\u043d\u0435\u0440\u0441\u043a\u0438\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0439. \u0422\u0430\u043a\u0436\u0435 \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u043a\u0443\u043f\u0438\u0442\u044c \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0437\u0430 \u0441\u0447\u0435\u0442 \u0437\u0430\u0440\u0430\u0431\u043e\u0442\u043d\u043e\u0439 \u043f\u043b\u0430\u0442\u044b, \u0435\u0441\u043b\u0438 \u0432\u044b \u0440\u0435\u0448\u0438\u0442\u0435 \u043e\u0441\u0442\u0430\u0442\u044c\u0441\u044f \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u044d\u0442\u043e \u043f\u043e\u0434\u0442\u0432\u0435\u0440\u0436\u0434\u0430\u0435\u0442 \u043d\u0430\u0448\u0443 \u0441\u0435\u0440\u044c\u0435\u0437\u043d\u043e\u0441\u0442\u044c \u0438 \u0433\u043e\u0442\u043e\u0432\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u043d\u0430\u0448\u0438\u0445 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432 \u0432 \u0438\u0445 \u043a\u0430\u0440\u044c\u0435\u0440\u043d\u043e\u043c \u0440\u043e\u0441\u0442\u0435.\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u041a\u0430\u043a\u043e\u0432\u0430 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0443\u0440\u0441\u0430 \u0411\u0430\u0437\u043e\u0432\u044b\u0439 \u0438 \u043c\u043e\u0436\u0435\u0442 \u0435\u0441\u0442\u044c \u043a\u0430\u043a\u0438\u0435 \u043d\u0438\u0431\u0443\u0434\u044c \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u0441\u043a\u0438\u0434\u043e\u043a?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0443\u0440\u0441\u0430 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 89 900 \u0440\u0443\u0431\u043b\u0435\u0439. \u041e\u0434\u043d\u0430\u043a\u043e, \u0443 \u043d\u0430\u0441 \u0435\u0441\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u0441\u043a\u0438\u0434\u043e\u043a \u0438 \u0431\u043e\u043d\u0443\u0441\u043e\u0432, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0433\u0443\u0442 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0435\u0449\u0435 \u0431\u043e\u043b\u0435\u0435 \u0432\u044b\u0433\u043e\u0434\u043d\u044b\u043c \u0434\u043b\u044f \u0432\u0430\u0441. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u0442\u0430\u0440\u0438\u0444\u0430, \u043a\u0440\u043e\u043c\u0435 \"\u0411\u0430\u0437\u043e\u0432\u043e\u0433\u043e\", \u0432\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u043a\u0443\u0440\u0441 \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a. \u0422\u0430\u043a\u0436\u0435 \u043c\u044b \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u0435\u043c \u043a\u0443\u0440\u0441 \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u0442\u0430\u0440\u0438\u0444\u0430 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\" \u0438 4 \u0441\u0442\u0430\u0436\u0438\u0440\u043e\u0432\u043e\u043a. \u0414\u043b\u044f \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432, \u0443\u0436\u0435 \u043f\u0440\u043e\u0445\u043e\u0434\u0438\u0432\u0448\u0438\u0445 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u0432 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442\u0435 \u0418\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0418\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430, \u0434\u043e\u0441\u0442\u0443\u043f\u0435\u043d \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u044b\u0439 \u043a\u0443\u0440\u0441 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u043e\u0432 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 39 900 \u0440\u0443\u0431\u043b\u0435\u0439, \u043f\u0440\u043e\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0438 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0441\u0442\u0430\u0436\u0438\u0440\u043e\u0432\u043e\u043a \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439 \u0438\u043b\u0438 \u0432\u043d\u0435\u0441\u0435\u043d\u0438\u0438 \u0434\u0435\u043f\u043e\u0437\u0438\u0442\u0430 \u043d\u0430 \u0441\u0443\u043c\u043c\u0443 40 000 \u0440\u0443\u0431\u043b\u0435\u0439. \u0422\u0430\u043a\u0436\u0435 \u043c\u044b \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u0435\u043c \u0431\u043e\u043d\u0443\u0441\u044b, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043c\u043e\u0436\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043d\u0430 \u043a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u0438 \u0438\u043b\u0438 \u043a\u0443\u0440\u0441\u044b, \u0438 \u0432\u044b\u0438\u0433\u0440\u0430\u0442\u044c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0441\u0442\u0430\u0436\u0438\u0440\u043e\u0432\u043a\u0438 \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u0442\u0430\u0440\u0438\u0444\u043e\u0432 \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439\", \"\u041f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0439\" \u0438\u043b\u0438 \"AI \u043f\u043e\u0434 \u043a\u043b\u044e\u0447\". \u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u044d\u0442\u0438 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u0441\u043a\u0438\u0434\u043e\u043a \u0437\u0430\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u0443\u044e\u0442 \u0432\u0430\u0441 \u0438 \u0432\u044b \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0435\u0441\u044c \u043a \u043d\u0430\u0448\u0435\u043c\u0443 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n\u0414\u0430! \u0425\u043e\u0447\u0443 \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u0441\u044f \u043a \u044d\u0442\u043e\u043c\u0443 \u043a\u0443\u0440\u0441\u0443, \u0447\u0442\u043e \u043c\u043d\u0435 \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u0443\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c?\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI: \u041e\u0442\u043b\u0438\u0447\u043d\u043e, \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0440\u0430\u0434\u044b \u043f\u0440\u0438\u0432\u0435\u0442\u0441\u0442\u0432\u043e\u0432\u0430\u0442\u044c \u0432\u0430\u0441 \u043d\u0430 \u043d\u0430\u0448\u0435\u043c \u043a\u0443\u0440\u0441\u0435! \u0414\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u0438\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u0442\u044c\u0441\u044f \u043a \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e, \u0432\u0430\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0432\u044b\u0431\u0440\u0430\u0442\u044c \u043f\u043e\u0434\u0445\u043e\u0434\u044f\u0449\u0438\u0439 \u0434\u043b\u044f \u0432\u0430\u0441 \u0442\u0430\u0440\u0438\u0444 \u0438 \u043e\u0444\u043e\u0440\u043c\u0438\u0442\u044c \u043f\u043e\u043a\u0443\u043f\u043a\u0443 \u043d\u0430 \u043d\u0430\u0448\u0435\u043c \u0441\u0430\u0439\u0442\u0435. \u041f\u043e\u0441\u043b\u0435 \u044d\u0442\u043e\u0433\u043e \u0432\u044b \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u0435 \u0434\u043e\u0441\u0442\u0443\u043f \u043a \u043f\u043b\u0430\u0442\u0444\u043e\u0440\u043c\u0435 \u0438 \u0441\u043c\u043e\u0436\u0435\u0442\u0435 \u043d\u0430\u0447\u0430\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u0415\u0441\u043b\u0438 \u0443 \u0432\u0430\u0441 \u0432\u043e\u0437\u043d\u0438\u043a\u043d\u0443\u0442 \u043a\u0430\u043a\u0438\u0435-\u043b\u0438\u0431\u043e \u0432\u043e\u043f\u0440\u043e\u0441\u044b, \u043d\u0430\u0448\u0438 \u043a\u0443\u0440\u0430\u0442\u043e\u0440\u044b \u0432\u0441\u0435\u0433\u0434\u0430 \u0433\u043e\u0442\u043e\u0432\u044b \u043f\u043e\u043c\u043e\u0447\u044c \u0432\u0430\u043c. \u0416\u0435\u043b\u0430\u0435\u043c \u0432\u0430\u043c \u0443\u0441\u043f\u0435\u0448\u043d\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0438 \u0440\u0430\u0437\u0432\u0438\u0442\u0438\u044f \u0432 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0438\u0441\u043a\u0443\u0441\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430!\n\n\u0412\u043e\u043f\u0440\u043e\u0441 User:\\n{query}\\n\n\n\u041e\u0442\u0432\u0435\u0442 AI:\n\n\"\"\"\n\n\n\nresult = openai.Completion.create(\n\n  model=\"gpt-3.5-turbo-instruct\",\n\n  prompt=prompt,\n\n  max_tokens=1000,\n\n  temperature=0\n\n)\n\nprint(result.choices[0].text)\nresult\n", "metadata": {"subid": 5, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### OpenAI gpt4\nimport openai\n\nimport re\n\n\n\nchat_manager_system = \"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f.\n\n\u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\"\"\"\n\n\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  messages = [\n\n    {\"role\": \"system\", \"content\": f\"{chat_manager_system}\"},\n\n    {\"role\": \"user\", \"content\": f\"\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443, \u0438 \u0434\u0430\u0439 \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0438 \"\n\n                                f\"\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430.\\n\\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\\n{query}\\n\\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \"\n\n                                f\"\u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\\n{docs}.\"}\n\n  ]\n\n  result = openai.ChatCompletion.create(\n\n    model='gpt-4',\n\n    messages=messages,\n\n    temperature=0.0\n\n)\n\n  history.append([str(query), result.choices[0].message.content, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'OpenAI_gpt4' + '.csv'), index=False)\n\n#### Llama-2-7B-32K-Instruct-GGML\n!wget https://huggingface.co/TheBloke/Llama-2-7B-32K-Instruct-GGML/resolve/main/llama-2-7b-32k-instruct.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\nn_gpu_layers = 400  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-7b-32k-instruct.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_ctx=32000,  # Context window\n\n    max_tokens=2000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"[INST] \u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{question}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':query, 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result), str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-7B-32K-Instruct-GGML' + '.csv'), index=False)", "metadata": {"subid": 6, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### Saiga2_70b_gguf\n!wget https://huggingface.co/IlyaGusev/saiga2_70b_gguf/resolve/main/ggml-model-q4_1.gguf\n!wget https://huggingface.co/IlyaGusev/saiga2_7b_gguf/resolve/main/model-q8_0.gguf\n!wget https://huggingface.co/IlyaGusev/saiga2_13b_gguf/resolve/main/model-q4_K.gguf\n# import fire\n\nfrom llama_cpp import Llama\n\n\n\nSYSTEM_PROMPT = \"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\"\"\"\n\nSYSTEM_TOKEN = 1788\n\nUSER_TOKEN = 1404\n\nBOT_TOKEN = 9225\n\nLINEBREAK_TOKEN = 13\n\n\n\nROLE_TOKENS = {\n\n    \"user\": USER_TOKEN,\n\n    \"bot\": BOT_TOKEN,\n\n    \"system\": SYSTEM_TOKEN\n\n}\n\n\n\ndef get_message_tokens(model, role, content):\n\n    message_tokens = model.tokenize(content.encode(\"utf-8\"))\n\n    message_tokens.insert(1, ROLE_TOKENS[role])\n\n    message_tokens.insert(2, LINEBREAK_TOKEN)\n\n    message_tokens.append(model.token_eos())\n\n    return message_tokens\n\n\n\n\n\ndef get_system_tokens(model):\n\n    system_message = {\n\n        \"role\": \"system\",\n\n        \"content\": SYSTEM_PROMPT\n\n    }\n\n    return get_message_tokens(model, **system_message)\n\n\n\n\n\ndef interact(\n\n    model,\n\n    query,\n\n    tokens,\n\n    top_k=30,\n\n    top_p=0.9,\n\n    temperature=0.2,\n\n    repeat_penalty=1.1\n\n):\n\n\n\n    answer = []\n\n\n\n    while True:\n\n        user_message = f\"User: {query}\"\n\n        message_tokens = get_message_tokens(model=model, role=\"user\", content=user_message)\n\n        role_tokens = [model.token_bos(), BOT_TOKEN, LINEBREAK_TOKEN]\n\n        tokens += message_tokens + role_tokens\n\n        generator = model.generate(\n\n            tokens,\n\n            top_k=top_k,\n\n            top_p=top_p,\n\n            temp=temperature,\n\n            repeat_penalty=repeat_penalty\n\n        )\n\n        for token in generator:\n\n            token_str = model.detokenize([token]).decode(\"utf-8\", errors=\"ignore\")\n\n            tokens.append(token)\n\n            answer.append(token_str)\n\n            if token == model.token_eos():\n\n                return ''.join(answer)\n\n                break\n\n\n\n            print(token_str, end=\"\", flush=True)\n\n        print()\n\n\n\n\n\n\n\nmodel = Llama(\n\n    model_path='/content/ggml-model-q4_1.gguf',\n\n    n_ctx=4096,\n\n    n_parts=1,\n\n    n_gpu_layers=70,\n\n    n_batch=512,\n\n    n_gqa=8,\n\n)\n\n\n\nsystem_tokens = get_system_tokens(model)\n\ntokens = system_tokens\n\nmodel.eval(tokens)\nquery = \"\"\"\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n\u041a\u0430\u043a\u0438\u0435 \u0442\u0435\u043c\u044b \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0432 \u0441\u0435\u0431\u044f \u043a\u0443\u0440\u0441 \"AI \u0414\u0438\u0440\u0435\u043a\u0442\u043e\u0440\"?\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n======\n\n\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0443\u0440\u0441\u0430: 24 900 \u0440\u0443\u0431\u043b\u0435\u0439\n\n\u041a\u0443\u0440\u0441 \u0432\u0445\u043e\u0434\u0438\u0442 \u0432 \u0442\u0430\u0440\u0438\u0444\u044b: AI \u043f\u043e\u0434 \u043a\u043b\u044e\u0447, \u0420\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u043d\u044b\u0439, \u041f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0439\n\n\u041a\u0443\u0440\u0441 \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0432 \u043f\u043e\u0434\u0430\u0440\u043e\u043a \u043f\u0440\u0438 \u043f\u043e\u043a\u0443\u043f\u043a\u0435 \u043b\u044e\u0431\u043e\u0433\u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430 \u0423\u0418\u0418 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\u044e \u043e\u0442  \u043e\u0442 40 000 \u0440\u0443\u0431\u043b\u0435\u0439 \u0432 \u0434\u043d\u0438 \u0430\u043a\u0446\u0438\u0438.\n\n\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u043a\u0443\u0440\u0441\u0430 \u201cAI \u0414\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u201d\n\n\u0422\u0435\u043c\u044b \u0437\u0430\u043d\u044f\u0442\u0438\u0439 \u0432 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u201cAI \u0414\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u201d:\n\n1. \u0412\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f  AI \u0432 \u0431\u0438\u0437\u043d\u0435\u0441\u0435\n\n\u0421\u0442\u0443\u0434\u0435\u043d\u0442\u044b \u0443\u0437\u043d\u0430\u044e\u0442 \u0432\u0441\u0435 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f AI \u0432 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u0441\u0444\u0435\u0440\u0430\u0445 \u0431\u0438\u0437\u043d\u0435\u0441\u0430: \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0441\u0442\u0432\u043e (\u0437\u0430\u0432\u043e\u0434\u044b, \u043a\u043e\u043d\u0432\u0435\u0439\u0435\u0440\u044b), \u0444\u0430\u0440\u043c\u0430\u043a\u043e\u043b\u043e\u0433\u0438\u044f, \u043c\u0430\u0440\u043a\u0435\u0442\u0438\u043d\u0433 \u0438 \u043f\u0440\u043e\u0434\u0430\u0436\u0438, \u0421\u041c\u0418 \u0438 \u0442.\u0434\n\n2. \u0427\u0442\u043e \u0442\u0430\u043a\u043e\u0435 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0435 \u0441\u0435\u0442\u0438 \u0438 \u043a\u0430\u043a \u043e\u043d\u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442\n\n\u041d\u0430 \u0437\u0430\u043d\u044f\u0442\u0438\u0438 \u043f\u043e\u0434\u0440\u043e\u0431\u043d\u043e \u0440\u0430\u0437\u0431\u0438\u0440\u0430\u0435\u0442\u0441\u044f, \u043a\u0430\u043a \u0443\u0441\u0442\u0440\u043e\u0435\u043d\u044b \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0435 \u0441\u0435\u0442\u0438, \u043a\u0430\u043a \u043e\u043d\u0438 \u043e\u0431\u0443\u0447\u0430\u044e\u0442\u0441\u044f \u0438 \u0437\u0430 \u0441\u0447\u0435\u0442 \u0447\u0435\u0433\u043e \u043c\u043e\u0433\u0443\u0442 \u0440\u0435\u0448\u0430\u0442\u044c \u0437\u0430\u0434\u0430\u0447\u0438\n\n3. \u041d\u0430\u0439\u043c AI-\u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u043e\u0432. \u0421\u0442\u0443\u0434\u0435\u043d\u0442\u044b \u0432 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u201cAI \u0414\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u201d \u0443\u0437\u043d\u0430\u044e\u0442 \u043a\u0430\u043a \u043d\u0430\u043d\u0438\u043c\u0430\u0442\u044c AI-\u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u043e\u0432, \u043f\u043e \u043a\u0430\u043a\u0438\u043c \u043a\u043b\u044e\u0447\u0430\u043c \u0438\u0445 \u0438\u0441\u043a\u0430\u0442\u044c \u043d\u0430 hh, \u043d\u0430 \u043a\u0430\u043a\u0438\u0435 \u043a\u043e\u043c\u043f\u0435\u0442\u0435\u043d\u0446\u0438\u0438 \u043e\u0431\u0440\u0430\u0449\u0430\u0442\u044c \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435, \u043a\u0430\u043a \u0441\u043e\u0431\u0435\u0441\u0435\u0434\u043e\u0432\u0430\u0442\u044c\n\n4. \u0423\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 AI-\u043f\u0440\u043e\u0435\u043a\u0442\u043e\u043c, \u0440\u0430\u0441\u0447\u0451\u0442 \u0441\u0440\u043e\u043a\u043e\u0432 \u0438 \u0440\u0438\u0441\u043a\u043e\u0432, \u0441\u0431\u043e\u0440 \u0431\u0430\u0437\u044b  ======\n\n\u0422\u0435\u043c\u044b 1-\u0433\u043e \u0432\u0435\u0431\u0438\u043d\u0430\u0440\u0430:\n\n                                                                                          1. \u041c\u043e\u0442\u0438\u0432\u0430\u0446\u0438\u044f: \u043f\u0440\u0438\u0447\u0438\u043d\u044b \u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0430 \u0432 IT, \u043f\u043e\u0447\u0435\u043c\u0443 \u044d\u0442\u0430 \u0441\u0444\u0435\u0440\u0430 \u0441\u0435\u0439\u0447\u0430\u0441 \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u0430 \u0438 \u043f\u043e\u0447\u0435\u043c\u0443 \u043c\u043e\u0436\u043d\u043e \u0432 \u043d\u0435\u0439 \u043f\u0440\u0435\u0443\u0441\u043f\u0435\u0442\u044c\n\n                                                                                          2. \u0412\u044b\u0431\u043e\u0440: \u043a\u0430\u043a \u0432\u044b\u0431\u0440\u0430\u0442\u044c \u0441\u0432\u043e\u0435 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435, \u0435\u0441\u043b\u0438 \u0445\u043e\u0447\u0435\u0442\u0441\u044f \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u0432 IT. \u041a\u0430\u043a\u0438\u0435 \u0435\u0441\u0442\u044c \u043f\u0443\u0442\u0438 \u0438 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f\n\n                                                                                          3. \u041f\u0435\u0440\u0435\u0445\u043e\u0434 \u0432 IT: \u043a\u0430\u043a \u0441\u043f\u043b\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u0435\u0440\u0435\u0445\u043e\u0434, \u0440\u044b\u043d\u043e\u043a \u0432\u0430\u043a\u0430\u043d\u0441\u0438\u0439 \u0432 IT, \u043f\u043e\u0437\u0438\u0442\u0438\u0432\u043d\u044b\u0435 \u043a\u0435\u0439\u0441\u044b\n\n                                                                                          4. \u0412\u043e\u043f\u0440\u043e\u0441\u044b \u0438 \u043e\u0442\u0432\u0435\u0442\u044b \u043d\u0430 \u043d\u0438\u0445\n\n\u041c\u0430\u0441\u0442\u0435\u0440-\u043a\u043b\u0430\u0441\u0441\u044b\n\n\u041c\u0430\u0441\u0442\u0435\u0440-\u043a\u043b\u0430\u0441\u0441 \u201c\u041a\u0430\u043a \u0432\u044b\u0431\u0440\u0430\u0442\u044c \u0442\u0435\u043c\u0443 AI \u043f\u0440\u043e\u0435\u043a\u0442\u0430\u201d\n\n\u041c\u0430\u0441\u0442\u0435\u0440-\u043a\u043b\u0430\u0441\u0441 \u0432\u0430\u0436\u0435\u043d \u0434\u043b\u044f \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0432\u0445\u043e\u0434\u0430 \u0432 \u043c\u0438\u0440 AI, \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u043d\u044f\u0442\u044c, \u043a\u0430\u043a\u043e\u0439 \u043f\u0440\u043e\u0435\u043a\u0442 \u043c\u043e\u0436\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0438 \u0432\u0434\u043e\u0445\u043d\u043e\u0432\u0438\u0442\u044c\u0441\u044f \u0435\u0433\u043e \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435\u043c.\n\n\u0414\u043c\u0438\u0442\u0440\u0438\u0439 \u0420\u043e\u043c\u0430\u043d\u043e\u0432 \u0431\u0443\u0434\u0435\u0442 \u0440\u0430\u0437\u0431\u0438\u0440\u0430\u0442\u044c \u0442\u0435\u043c\u044b \u043f\u0440\u043e\u0435\u043a\u0442\u043e\u0432, \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0435 \u0443\u0447\u0430\u0441\u0442\u043d\u0438\u043a\u0430\u043c\u0438 \u043c\u0430\u0441\u0442\u0435\u0440-\u043a\u043b\u0430\u0441\u0441\u0430 \u0438 \u0440\u0430\u0437\u0431\u0438\u0440\u0430\u0442\u044c \u0438\u0445 \u043f\u043e \u043f\u0443\u043d\u043a\u0442\u0430\u043c:  ======\n\n\u041f\u0440\u0435\u0438\u043c\u0443\u0449\u0435\u0441\u0442\u0432\u0430 \u043a\u0443\u0440\u0441\u0430 \u0432\u043a\u043b\u044e\u0447\u0430\u044e\u0442 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u0431\u044b\u0441\u0442\u0440\u043e\u0433\u043e \u043e\u0441\u0432\u043e\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0445 \u0442\u0435\u043c, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0445 \u0441 AI, \u0431\u0435\u0437 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0443\u0433\u043b\u0443\u0431\u043b\u044f\u0442\u044c\u0441\u044f \u0432 \u0442\u0435\u043e\u0440\u0438\u044e \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439 \u0438\u043b\u0438 \u0438\u0445 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f. \u0412\u0441\u0435 \u0437\u0430\u043d\u044f\u0442\u0438\u044f \u043f\u0440\u043e\u0432\u043e\u0434\u044f\u0442\u0441\u044f \u0432 \u0440\u0435\u0436\u0438\u043c\u0435 \u0440\u0435\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u0447\u0442\u043e \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u0437\u0430\u0434\u0430\u0432\u0430\u0442\u044c \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u0438 \u043f\u043e\u043b\u0443\u0447\u0430\u0442\u044c \u043e\u0442\u0432\u0435\u0442\u044b \u043e\u0442 \u043e\u043f\u044b\u0442\u043d\u044b\u0445 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u0438\u0441\u0442\u043e\u0432. \u0417\u0430\u043d\u044f\u0442\u0438\u044f \u0442\u0430\u043a\u0436\u0435 \u0431\u0443\u0434\u0443\u0442 \u0437\u0430\u043f\u0438\u0441\u044b\u0432\u0430\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u043f\u0440\u043e\u0441\u043c\u043e\u0442\u0440\u0430.\n\n\u041a\u0443\u0440\u0441 \u0432\u043a\u043b\u044e\u0447\u0430\u0435\u0442 \u0448\u0438\u0440\u043e\u043a\u0438\u0439 \u0441\u043f\u0435\u043a\u0442\u0440 \u0442\u0435\u043c, \u0442\u0430\u043a\u0438\u0445 \u043a\u0430\u043a \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u0442\u0435\u043a\u0441\u0442\u043e\u0432, \u043e\u0446\u0435\u043d\u043a\u0430 \u0442\u0430\u0431\u043b\u0438\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0440\u044f\u0434\u043e\u0432, \u0441\u0435\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, Object detection \u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445 \u0438 \u0432\u0438\u0434\u0435\u043e, \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u0435 \u0442\u0435\u043a\u0441\u0442\u0430 \u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u0445, \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0438 \u0440\u0435\u0447\u0438, \u0430 \u0442\u0430\u043a\u0436\u0435 \u0441\u0432\u043e\u0431\u043e\u0434\u043d\u0430\u044f \u0442\u0435\u043c\u0430 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440 \u0433\u0440\u0443\u043f\u043f\u044b. \u0422\u0430\u043a\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0442 \u043a\u043e\u043c\u043f\u043b\u0435\u043a\u0441\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 AI \u0438 \u0441\u043c\u043e\u0433\u0443\u0442 \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0442\u044c \u0441\u0432\u043e\u0438 \u0437\u043d\u0430\u043d\u0438\u044f \u043d\u0430 \u043f\u0440\u0430\u043a\u0442\u0438\u043a\u0435, \u0447\u0442\u043e \u043f\u043e\u043c\u043e\u0436\u0435\u0442 \u0438\u043c \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0441\u0432\u043e\u0439 \u0443\u0440\u043e\u0432\u0435\u043d\u044c \u043a\u0432\u0430\u043b\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0438 \u043f\u043e\u0432\u044b\u0441\u0438\u0442\u044c \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0441\u0442\u044c \u0441\u0432\u043e\u0435\u0439 \u0440\u0430\u0431\u043e\u0442\u044b \u0432 \u044d\u0442\u043e\u0439 \u043e\u0431\u043b\u0430\u0441\u0442\u0438.\n\n\u0422\u0435\u043c\u044b \u0437\u0430\u043d\u044f\u0442\u0438\u0439:\n\n\u0412 \u0440\u0430\u043c\u043a\u0430\u0445 \u043a\u0443\u0440\u0441\u0430 \u0431\u0443\u0434\u0443\u0442 \u0440\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0435\u043d\u044b \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u0442\u0435\u043c\u044b:  ======\n\n* \u0418\u043d\u0442\u0435\u0440\u0430\u043a\u0442\u0438\u0432\u043d\u044b\u0439 \u043c\u0430\u0441\u0442\u0435\u0440-\u043a\u043b\u0430\u0441\u0441\u0435 \u00ab\u0422\u0440\u0435\u043a AI \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430\u00bb\n\n                                                                                          * \u0424\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0431\u0443\u0434\u0443\u0449\u0435\u0433\u043e \u0432 AI, \u0432\u044b\u0441\u0442\u0440\u0430\u0438\u0432\u0430\u043d\u0438\u0435  \u043a\u0430\u0440\u044c\u0435\u0440\u043d\u043e\u0433\u043e \u0442\u0440\u0435\u043a\u0430 \u0438 \u0432\u044b\u0431\u043e\u0440 \u0442\u0435\u043c\u044b AI \u043f\u0440\u043e\u0435\u043a\u0442\u0430.\n\n2 \u0447\u0430\u0441\u0430 \u0438\u043d\u0442\u0435\u0440\u0430\u043a\u0442\u0438\u0432\u043d\u043e\u0439 \u0440\u0430\u0431\u043e\u0442\u044b:\n\n                                                                                          1. \u0412\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0439 \u0432\u0436\u0438\u0432\u0443\u044e \u043d\u0430 \u0432\u0435\u0431\u0438\u043d\u0430\u0440\u0435.\n\n                                                                                          2. \u0417\u043d\u0430\u043a\u043e\u043c\u0441\u0442\u0432\u043e \u0441 \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u043e\u0439 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u043a\u043e\u0439, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0437\u0430 4 \u0432\u043e\u043f\u0440\u043e\u0441\u0430 \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u0442\u044c \u0442\u0435\u043c\u0443 AI \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0432 \u0440\u0430\u0431\u043e\u0442\u0435.\n\n                                                                                          3. \u0422\u043e\u0440\u0436\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u0435 \u0438\u043d\u0442\u0435\u043d\u0441\u0438\u0432\u0430\n\n\u041a\u043e\u043d\u043a\u0443\u0440\u0441 \u0438\u0434\u0435\u0439 AI \u043f\u0440\u043e\u0435\u043a\u0442\u043e\u0432.\n\n\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043d\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u043a\u0430\u043a \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0435\u043a\u0442, \u0442\u0430\u043a \u0438 \u0444\u0430\u043d\u0442\u0430\u0441\u0442\u0438\u0447\u043d\u0443\u044e, \u043d\u043e \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u0443\u044e \u0438\u0434\u0435\u044e.\n\n\u0411\u043e\u043d\u0443\u0441 \u0432\u0441\u0435\u043c \u0443\u0447\u0430\u0441\u0442\u043d\u0438\u043a\u0430\u043c: \u043c\u0435\u0442\u043e\u0434\u0438\u0447\u043a\u0430 \u043e\u0442 \u043c\u0430\u0441\u0442\u0435\u0440-\u043a\u043b\u0430\u0441\u0441\u0430 \u2014 37 \u0441\u0442\u0440\u0430\u043d\u0438\u0446.\n\n\n\n\"\"\"\nresult = interact(model, query=query, tokens=tokens)\nimport re\n\n\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  template = f\"\"\"\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{query}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\"\"\"\n\n  system_tokens = get_system_tokens(model)\n\n  tokens = system_tokens\n\n  model.eval(tokens)\n\n  result = interact(model, query=template, tokens=tokens)\n\n  history.append([str(query), result, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Saiga2_70b_GGUF-4' + '.csv'), index=False)", "metadata": {"subid": 7, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### Saiga2_7B_8_gguf\n# import fire\n\nfrom llama_cpp import Llama\n\n\n\nSYSTEM_PROMPT = \"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\"\"\"\n\nSYSTEM_TOKEN = 1788\n\nUSER_TOKEN = 1404\n\nBOT_TOKEN = 9225\n\nLINEBREAK_TOKEN = 13\n\n\n\nROLE_TOKENS = {\n\n    \"user\": USER_TOKEN,\n\n    \"bot\": BOT_TOKEN,\n\n    \"system\": SYSTEM_TOKEN\n\n}\n\n\n\ndef get_message_tokens(model, role, content):\n\n    message_tokens = model.tokenize(content.encode(\"utf-8\"))\n\n    message_tokens.insert(1, ROLE_TOKENS[role])\n\n    message_tokens.insert(2, LINEBREAK_TOKEN)\n\n    message_tokens.append(model.token_eos())\n\n    return message_tokens\n\n\n\n\n\ndef get_system_tokens(model):\n\n    system_message = {\n\n        \"role\": \"system\",\n\n        \"content\": SYSTEM_PROMPT\n\n    }\n\n    return get_message_tokens(model, **system_message)\n\n\n\n\n\ndef interact(\n\n    model,\n\n    query,\n\n    tokens,\n\n    top_k=30,\n\n    top_p=0.9,\n\n    temperature=0.2,\n\n    repeat_penalty=1.1\n\n):\n\n\n\n    answer = []\n\n\n\n    while True:\n\n        user_message = f\"User: {query}\"\n\n        message_tokens = get_message_tokens(model=model, role=\"user\", content=user_message)\n\n        role_tokens = [model.token_bos(), BOT_TOKEN, LINEBREAK_TOKEN]\n\n        tokens += message_tokens + role_tokens\n\n        generator = model.generate(\n\n            tokens,\n\n            top_k=top_k,\n\n            top_p=top_p,\n\n            temp=temperature,\n\n            repeat_penalty=repeat_penalty\n\n        )\n\n        for token in generator:\n\n            token_str = model.detokenize([token]).decode(\"utf-8\", errors=\"ignore\")\n\n            tokens.append(token)\n\n            answer.append(token_str)\n\n            if token == model.token_eos():\n\n                return ''.join(answer)\n\n                break\n\n\n\n            print(token_str, end=\"\", flush=True)\n\n        print()\n\n\n\n\n\n\n\nmodel = Llama(\n\n    model_path='/content/model-q8_0.gguf',\n\n    n_ctx=4096,\n\n    n_parts=1,\n\n    n_gpu_layers=150,\n\n    n_batch=512,\n\n    n_gqa=8,\n\n)\n\n\n\nsystem_tokens = get_system_tokens(model)\n\ntokens = system_tokens\n\nmodel.eval(tokens)\nimport re\n\n\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  template = f\"\"\"\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{query}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\"\"\"\n\n  system_tokens = get_system_tokens(model)\n\n  tokens = system_tokens\n\n  model.eval(tokens)\n\n  result = interact(model, query=template, tokens=tokens)\n\n  history.append([str(query), result, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Saiga2_7b_GGUF-8' + '.csv'), index=False)\n\n#### Saiga2_13B_4_gguf\n# import fire\n\nfrom llama_cpp import Llama\n\n\n\nSYSTEM_PROMPT = \"\"\"\u0422\u044b \u043c\u0435\u043d\u0435\u0434\u0436\u0435\u0440 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0438 \u0432 \u0447\u0430\u0442\u0435 \u0420\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0423\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 \u0418\u0441\u0441\u043a\u0443\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u0438\u043d\u0442\u0435\u043b\u043b\u0435\u043a\u0442\u0430. \u041a\u043e\u043c\u043f\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0430\u0435\u0442 \u043a\u0443\u0440\u0441\u044b \u043f\u043e AI.\n\n\u0423 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u0435\u0441\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441\u043e \u0432\u0441\u0435\u043c\u0438 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u0430\u043c\u0438 \u043e \u043f\u0440\u043e\u0434\u0443\u043a\u0442\u0430\u0445 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435. \u0422\u0435\u0431\u0435 \u0437\u0430\u0434\u0430\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442 \u0432 \u0447\u0430\u0442\u0435, \u0434\u0430\u0439 \u0435\u043c\u0443 \u043e\u0442\u0432\u0435\u0442 \u043d\u0430 \u044f\u0437\u044b\u043a\u0435 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u0430,\n\n\u043e\u043f\u0438\u0440\u0430\u044f\u0441\u044c \u043d\u0430 \u043e\u0442\u0440\u044b\u0432\u043a\u0438 \u0438\u0437 \u044d\u0442\u043e\u0433\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430, \u043f\u043e\u0441\u0442\u0430\u0440\u0430\u0439\u0441\u044f \u043e\u0442\u0432\u0435\u0442\u0438\u0442\u044c \u0442\u0430\u043a, \u0447\u0442\u043e\u0431\u044b \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0437\u0430\u0445\u043e\u0442\u0435\u043b \u043f\u043e\u0441\u043b\u0435 \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u0443\u043f\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\n\n\u0442\u043e\u0447\u043d\u043e \u043f\u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0443, \u043d\u0435 \u043f\u0440\u0438\u0434\u0443\u043c\u044b\u0432\u0430\u0439 \u043d\u0438\u0447\u0435\u0433\u043e \u043e\u0442 \u0441\u0435\u0431\u044f. \u041d\u0438\u043a\u043e\u0433\u0434\u0430 \u043d\u0435 \u0441\u0441\u044b\u043b\u0430\u0439\u0441\u044f \u043d\u0430 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430 \u0438\u043b\u0438 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u0435\u0433\u043e \u043e\u0442\u0440\u044b\u0432\u043a\u043e\u0432 \u043f\u0440\u0438 \u043e\u0442\u0432\u0435\u0442\u0435, \u043a\u043b\u0438\u0435\u043d\u0442 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u043e\u043b\u0436\u0435\u043d\n\n\u0437\u043d\u0430\u0442\u044c \u043e \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u043e\u043c\u0443 \u0442\u044b \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0448\u044c. \u041e\u0442\u0432\u0435\u0447\u0430\u0439 \u043e\u0442 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0441\u0441\u044b\u043b\u043e\u043a \u043d\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0438 \u043d\u0430 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0442\u044b \u043e\u043f\u0438\u0440\u0430\u0435\u0448\u044c\u0441\u044f. \u0415\u0441\u043b\u0438 \u0442\u044b \u043d\u0435 \u0437\u043d\u0430\u0435\u0448\u044c \u043e\u0442\u0432\u0435\u0442\u0430 \u0438\u043b\u0438 \u0435\u0433\u043e \u043d\u0435\u0442 \u0432 \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0435, \u0442\u043e \u043e\u0442\u0432\u0435\u0442\u044c \"\u042f \u043d\u0435 \u043c\u043e\u0433\u0443 \u043e\u0442\u0435\u0442\u0438\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u0442 \u0432\u043e\u043f\u0440\u043e\u0441\".\n\n\"\"\"\n\nSYSTEM_TOKEN = 1788\n\nUSER_TOKEN = 1404\n\nBOT_TOKEN = 9225\n\nLINEBREAK_TOKEN = 13\n\n\n\nROLE_TOKENS = {\n\n    \"user\": USER_TOKEN,\n\n    \"bot\": BOT_TOKEN,\n\n    \"system\": SYSTEM_TOKEN\n\n}\n\n\n\ndef get_message_tokens(model, role, content):\n\n    message_tokens = model.tokenize(content.encode(\"utf-8\"))\n\n    message_tokens.insert(1, ROLE_TOKENS[role])\n\n    message_tokens.insert(2, LINEBREAK_TOKEN)\n\n    message_tokens.append(model.token_eos())\n\n    return message_tokens\n\n\n\n\n\ndef get_system_tokens(model):\n\n    system_message = {\n\n        \"role\": \"system\",\n\n        \"content\": SYSTEM_PROMPT\n\n    }\n\n    return get_message_tokens(model, **system_message)\n\n\n\n\n\ndef interact(\n\n    model,\n\n    query,\n\n    tokens,\n\n    top_k=30,\n\n    top_p=0.9,\n\n    temperature=0.2,\n\n    repeat_penalty=1.1\n\n):\n\n\n\n    answer = []\n\n\n\n    while True:\n\n        user_message = f\"User: {query}\"\n\n        message_tokens = get_message_tokens(model=model, role=\"user\", content=user_message)\n\n        role_tokens = [model.token_bos(), BOT_TOKEN, LINEBREAK_TOKEN]\n\n        tokens += message_tokens + role_tokens\n\n        generator = model.generate(\n\n            tokens,\n\n            top_k=top_k,\n\n            top_p=top_p,\n\n            temp=temperature,\n\n            repeat_penalty=repeat_penalty\n\n        )\n\n        for token in generator:\n\n            token_str = model.detokenize([token]).decode(\"utf-8\", errors=\"ignore\")\n\n            tokens.append(token)\n\n            answer.append(token_str)\n\n            if token == model.token_eos():\n\n                return ''.join(answer)\n\n                break\n\n\n\n            print(token_str, end=\"\", flush=True)\n\n        print()\n\n\n\n\n\n\n\nmodel = Llama(\n\n    model_path='/content/model-q4_K.gguf',\n\n    n_ctx=4096,\n\n    n_parts=1,\n\n    n_gpu_layers=150,\n\n    n_batch=512,\n\n    n_gqa=8,\n\n)\n\n\n\nsystem_tokens = get_system_tokens(model)\n\ntokens = system_tokens\n\nmodel.eval(tokens)\nimport re\n\n\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(query)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'======\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  template = f\"\"\"\n\n\u0412\u043e\u043f\u0440\u043e\u0441 \u043a\u043b\u0438\u0435\u043d\u0442\u0430:\n\n{query}\n\n\n\n\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u0434\u043b\u044f \u043e\u0442\u0432\u0435\u0442\u0430 \u043a\u043b\u0438\u0435\u043d\u0442\u0443:\n\n{docs}\n\n\"\"\"\n\n  system_tokens = get_system_tokens(model)\n\n  tokens = system_tokens\n\n  model.eval(tokens)\n\n  result = interact(model, query=template, tokens=tokens)\n\n  history.append([str(query), result, str(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Saiga2_13b_GGUF-4' + '.csv'), index=False)\n\n## \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u0432 \u043e\u0434\u043d\u0443 \u0442\u0430\u0431\u043b\u0438\u0446\u0443\nimport os\n\nimport pandas as pd\n\n\n\nproject_path = \"/content/drive/MyDrive/\u041f\u0440\u043e\u0435\u043a\u0442\u044b/LLMs_local\"\n\nfiles = os.listdir(project_path)\n\nfiles\ndf_all = pd.DataFrame(columns=['\u0412\u043e\u043f\u0440\u043e\u0441']+files)\n\nfor count, file in enumerate(files):\n\n  if file not in ['score_result.csv', 'score_result.xlsx', \".ipynb_checkpoints\"]:\n\n    df = pd.read_csv(os.path.join(project_path, file))\n\n    if count == 0:\n\n      df_all['\u0412\u043e\u043f\u0440\u043e\u0441'] = df['\u0412\u043e\u043f\u0440\u043e\u0441']\n\n      df_all[file] = df['\u041e\u0442\u0432\u0435\u0442']\n\n    else:\n\n      df_all[file] = df['\u041e\u0442\u0432\u0435\u0442']\n\n\n\ndf_all.to_csv(os.path.join(project_path, 'score_result'+'.csv'), index=False)\n\ndf_all.to_excel(os.path.join(project_path, 'score_result.xlsx'), index=False)\nimport os\n\nimport pandas as pd\n\n\n\nproject_path = \"/content/drive/MyDrive/\u041f\u0440\u043e\u0435\u043a\u0442\u044b/LLMs_local\"\n\nfiles = [file for file in os.listdir(project_path) if file not in ['score_result.csv', 'score_result.xlsx', \".ipynb_checkpoints\", 'Platypus2-70b-instruct-ggml-4.csv',\n\n 'Llama-2-70B-Chat-GGML-4.csv',\n\n 'Llama-2-13B-Chat-GGML-4.csv',\n\n 'Llama-2-7B-Chat-GGML-4.csv',\n\n 'StableBeluga-2-13B-GGML-4.csv',\n\n 'StableBeluga-2-70B-GGML-4.csv',\n\n 'OpenAI_chatgpt.csv',\n\n 'OpenAI_gpt4.csv']]\n\n\n\n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0443\u0441\u0442\u043e\u0439 DataFrame \u0441 \u043d\u0443\u0436\u043d\u043e\u0439 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u043e\u0439\n\ndf_all = pd.DataFrame(columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041c\u043e\u0434\u0435\u043b\u044c', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442'])\n\n\n\nfor file in files:\n\n    df = pd.read_csv(os.path.join(project_path, file))\n\n    # \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u043c \"\u0412\u043e\u043f\u0440\u043e\u0441\", \"\u041e\u0442\u0432\u0435\u0442\" \u0438 \"\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\"\n\n    df_merged = df[['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']]\n\n    # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0438\u043c\u044f \u0444\u0430\u0439\u043b\u0430 (\u043c\u043e\u0434\u0435\u043b\u0438) \u0432 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u0443\u044e \u043a\u043e\u043b\u043e\u043d\u043a\u0443\n\n    df_merged['\u041c\u043e\u0434\u0435\u043b\u044c'] = file\n\n    # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043a \u043e\u0431\u0449\u0435\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435\n\n    df_all = pd.concat([df_all, df_merged], ignore_index=True)\n\n\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u043e\u0431\u0449\u0443\u044e \u0442\u0430\u0431\u043b\u0438\u0446\u0443 \u0432 CSV \u0438 XLSX\n\ndf_all.to_csv(os.path.join(project_path, 'score_result_add.csv'), index=False)\n\ndf_all.to_excel(os.path.join(project_path, 'score_result_add.xlsx'), index=False)", "metadata": {"subid": 8, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n## \u0422\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c (\u0441 \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u043e\u043c)\n#### Falcon_180B_chat_gguf_2\n!wget https://huggingface.co/TheBloke/Falcon-180B-Chat-GGUF/resolve/main/falcon-180b-chat.Q2_K.gguf-split-a\n!wget https://huggingface.co/TheBloke/Falcon-180B-Chat-GGUF/resolve/main/falcon-180b-chat.Q2_K.gguf-split-b\n!cat falcon-180b-chat.Q2_K.gguf-split-* > falcon-180b-chat.Q2_K.gguf && rm falcon-180b-chat.Q2_K.gguf-split-*\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\nn_gpu_layers = 32  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/falcon-180b-chat.Q2_K.gguf\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_ctx=2048,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\n\n{system_message}\n\nUser: {prompt}\n\nAssistant:\ntemplate = \"\"\"You are the chat support manager for the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in chat, give him an answer in the original language,\n\nBased on excerpts from this document, try to answer in such a way that the person will want to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\n\n\n\nUser:\n\nClient Question:\n\n{question}\n\n\n\nDocument with information to respond to the client:\n\n{docs}\n\n\n\nAssistant:\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query), k=3)\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question': GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\n\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Falcon_180B_chat_gguf_2' + '.csv'), index=False)\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Falcon_180B_chat_gguf_2' + '.csv'), index=False)\n\n#### Platypus2-70b-instruct ggml\n!wget https://huggingface.co/TheBloke/Platypus2-70B-Instruct-GGML/resolve/main/platypus2-70b-instruct.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\n\n\nn_gpu_layers = 70  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/platypus2-70b-instruct.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n# Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n\n# ### Instruction:\n\n# {prompt}\n\n\n\n# ### Response:\ntemplate = \"\"\"You are a chat support manager at the University of Artificial Intelligence company. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products. A client asks you a question in chat, give him an answer,\n\nBased on excerpts from this document, try to answer in such a way that the person will want to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. \\n\\n\n\nInstruction: You must always answer in Russian, and in the first person, without citing the sources on which you rely. If you don\u2019t know the answer or it\u2019s not in the document, then answer \u201cI can\u2019t answer this question.\u201d\\nClient question:\n\n{question}\\n\n\nDocument with information to respond to the client:\n\n{docs}\\n\\n\n\nResponse:\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Platypus2-70b-instruct-ggml-4-en' + '.csv'), index=False)\n\n#### Llama-2-70B-Chat-GGML 4\n!wget https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/resolve/main/llama-2-70b-chat.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\n# /usr/local/lib/python3.10/dist-packages/langchain/llms/llamacpp.py\n\n# \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0448\u0438\u0431\u043a\u0438 https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML/discussions/5\n\nn_gpu_layers = 70  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-70b-chat.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n# [INST] <<SYS>>\n\n# You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\n\n\n# If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n\n# <</SYS>>\n\n\n\n# {prompt} [/INST]\ntemplate = \"\"\"<s>[INST] <<SYS>>\\nYou are the chat support manager for the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in chat, give him answer an based on excerpts from this document, try to answer in such a way that the person will want to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\\n\n\n<</SYS>>\n\n\n\nClient Question:\n\n{question}\n\n\n\nDocument with information to respond to the client:\n\n{docs}\n\n\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-70B-Chat-GGML-4-en' + '.csv'), index=False)", "metadata": {"subid": 9, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### Llama-2-13B-chat ggml\n!wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\nn_gpu_layers = 4000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-13b-chat.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"<s>[INST] <<SYS>>You are the chat support manager for the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in chat, give him an answer Based on excerpts from this document, try to answer in such a way that the person will want to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\n\n<</SYS>>\n\n\n\nClient Question:\n\n{question}\n\n\n\nDocument with information to respond to the client:\n\n{docs}\n\n\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-13B-Chat-GGML-4_en' + '.csv'), index=False)\n\n#### Llama-2-7B-chat ggml 4\n!wget https://huggingface.co/TheBloke/Llama-2-7B-chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nimport re\n\n\n\nn_gpu_layers = 20000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/llama-2-7b-chat.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"<s>[INST] <<SYS>>You are the chat support manager for the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in chat, give him an answer Based on excerpts from this document, try to answer in such a way that the person will want to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\n\n<</SYS>>\n\n\n\nClient Question:\n\n{question}\n\n\n\nDocument with information to respond to the client:\n\n{docs}\n\n\n\n[/INST]\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Llama-2-7B-Chat-GGML-4-en' + '.csv'), index=False)\n\n#### Stablebeluga-7b-ggml-4\n!wget https://huggingface.co/TheBloke/StableBeluga-7B-GGML/resolve/main/stablebeluga-7b.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, NLTKTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nfrom langchain.document_loaders import TextLoader\n\nfrom deep_translator import GoogleTranslator\n\nimport re\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nn_gpu_layers = 4000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"stablebeluga-7b.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    temperature=0,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"### System: \\nYou are the chat support manager of the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in a chat, give him an answer based on excerpts from this document, try to answer in such a way that the person wants to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\\n\\n\n\n### User: \\nClient question:\n\n{question}\\n\n\nDocument with information to respond to the client:\n\n{docs}\\n\\n\n\n### Assistant:\\n\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\n# pd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'Stablebeluga-7b-ggml-4-en' + '.csv'), index=False)", "metadata": {"subid": 10, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n#### StableBeluga 2 13B ggml\n!wget https://huggingface.co/TheBloke/StableBeluga-13B-GGML/resolve/main/stablebeluga-13b.ggmlv3.q4_1.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, NLTKTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\nfrom langchain.document_loaders import TextLoader\n\nfrom deep_translator import GoogleTranslator\n\nimport re\n\nimport nltk\n\nnltk.download('punkt')\n\n\n\nn_gpu_layers = 4000  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/stablebeluga-13b.ggmlv3.q4_1.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    temperature=0,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"### System: \\nYou are the chat support manager of the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in a chat, give him an answer based on excerpts from this document, try to answer in such a way that the person wants to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\\n\\n\n\n### User: \\nClient question:\n\n{question}\\n\n\nDocument with information to respond to the client:\n\n{docs}\\n\\n\n\n### Assistant:\\n\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'StableBeluga-2-13B-GGML-4-en' + '.csv'), index=False)\n\n#### Stablebeluga2-70b ggml\n!wget https://huggingface.co/TheBloke/StableBeluga2-70B-GGML/resolve/main/stablebeluga2-70b.ggmlv3.q4_0.bin\nfrom langchain.llms import LlamaCpp\n\nfrom langchain.embeddings import GPT4AllEmbeddings\n\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n\nfrom langchain.callbacks.manager import CallbackManager\n\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n\nfrom langchain.vectorstores import FAISS\n\nfrom langchain.docstore.document import Document\n\nfrom langchain import PromptTemplate, LLMChain\n\n\n\n\n\nn_gpu_layers = 60  # Metal set to 1 is enough.\n\nn_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n\ncallback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n\nllama = LlamaCpp(\n\n    model_path=\"/content/stablebeluga2-70b.ggmlv3.q4_0.bin\",\n\n    n_gpu_layers=n_gpu_layers,\n\n    n_batch=n_batch,\n\n    temperature=0,\n\n    n_gqa=8,\n\n    n_ctx=4096,  # Context window\n\n    max_tokens=1000,  # Max tokens to generate\n\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n\n    callback_manager=callback_manager,\n\n    verbose=True,\n\n)\n\n\n\n# vectorstore_llama = Chroma(embedding_function=GPT4AllEmbeddings(),persist_directory=\"./chroma_db_llama\")\ntemplate = \"\"\"### System: \\nYou are the chat support manager of the Russian company University of Artificial Intelligence. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products in Russian. A client asks you a question in a chat, give him an answer based on excerpts from this document, try to answer in such a way that the person wants to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Answer in the first person without citing the sources you rely on. If you do not know the answer or it is not in the document, then answer \u201cI cannot answer this question.\u201d\\n\\n\n\n### User: \\nClient question:\n\n{question}\\n\n\nDocument with information to respond to the client:\n\n{docs}\\n\\n\n\n### Assistant:\\n\n\n\"\"\"\n\n\n\nprompt = PromptTemplate(template=template, input_variables=[\"question\", 'docs'])\nimport re\n\nfrom deep_translator import GoogleTranslator\n\n\n\nllm_chain = LLMChain(prompt=prompt, llm=llama)\n\nhistory = []\n\n\n\nfor query in df_qw['\u0412\u043e\u043f\u0440\u043e\u0441'].values:\n\n  sim_docs = db.similarity_search(GoogleTranslator(source='auto', target='en').translate(query))\n\n  docs = re.sub(r'\\n{2}', ' ', '\\n '.join([f'\"======\"\\n' + doc.page_content + '\\n' for i, doc in enumerate(sim_docs)]))\n\n  result = llm_chain.run({'question':GoogleTranslator(source='auto', target='en').translate(query), 'docs': docs})\n\n  history.append([str(query), GoogleTranslator(source='auto', target='ru').translate(result),\n\n                  GoogleTranslator(source='auto', target='ru').translate(docs)])\n\npd.DataFrame(history, columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']).to_csv(os.path.join(project_path, 'StableBeluga-2-70B-GGML-4-en' + '.csv'), index=False)\n\n\n## \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u043d\u0430 \u0430\u043d\u0433\u043b\u0438\u0439\u0441\u043a\u043e\u043c \u0432 \u043e\u0434\u043d\u0443 \u0442\u0430\u0431\u043b\u0438\u0446\u0443\nimport os\n\nimport pandas as pd\n\n\n\nproject_path = \"/content/drive/MyDrive/\u041f\u0440\u043e\u0435\u043a\u0442\u044b/Local LLMs en\"\n\nfiles = os.listdir(project_path)\n\nfiles\nfiles = [file for file in os.listdir(project_path) if file not in ['UII_15_08_2023_en',\n\n 'docs_translate_new.pkl',\n\n 'Falcon_180B_chat_gguf_2.csv',\n\n 'Falcon_180B_chat_gguf_2.gsheet',\n\n ]]\n\n\n\n# \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0443\u0441\u0442\u043e\u0439 DataFrame \u0441 \u043d\u0443\u0436\u043d\u043e\u0439 \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u043e\u0439\n\ndf_all = pd.DataFrame(columns=['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041c\u043e\u0434\u0435\u043b\u044c', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442'])\n\n\n\nfor file in files:\n\n    df = pd.read_csv(os.path.join(project_path, file))\n\n    # \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043f\u043e \u043a\u043e\u043b\u043e\u043d\u043a\u0430\u043c \"\u0412\u043e\u043f\u0440\u043e\u0441\", \"\u041e\u0442\u0432\u0435\u0442\" \u0438 \"\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442\"\n\n    df_merged = df[['\u0412\u043e\u043f\u0440\u043e\u0441', '\u041e\u0442\u0432\u0435\u0442', '\u041a\u043e\u043d\u0442\u0435\u043a\u0441\u0442']]\n\n    # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0438\u043c\u044f \u0444\u0430\u0439\u043b\u0430 (\u043c\u043e\u0434\u0435\u043b\u0438) \u0432 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u0443\u044e \u043a\u043e\u043b\u043e\u043d\u043a\u0443\n\n    df_merged['\u041c\u043e\u0434\u0435\u043b\u044c'] = file\n\n    # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043a \u043e\u0431\u0449\u0435\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u0435\n\n    df_all = pd.concat([df_all, df_merged], ignore_index=True)\n\n\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u043e\u0431\u0449\u0443\u044e \u0442\u0430\u0431\u043b\u0438\u0446\u0443 \u0432 CSV \u0438 XLSX\n\ndf_all.to_csv(os.path.join(project_path, 'score_result_eng.csv'), index=False)\n\ndf_all.to_excel(os.path.join(project_path, 'score_result_eng.xlsx'), index=False)\n\n# vLLM\nvLLM \u2014 \u044d\u0442\u043e \u0431\u044b\u0441\u0442\u0440\u0430\u044f \u0438 \u043f\u0440\u043e\u0441\u0442\u0430\u044f \u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0434\u043b\u044f \u0432\u044b\u0432\u043e\u0434\u0430 \u0438 \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u043d\u0438\u044f LLM \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0430\u044f \u043d\u0435 \u043a\u0432\u0430\u043d\u0442\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 fp16 (\u0441 \u043d\u0435\u0434\u0430\u0432\u043d\u0435\u0433\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u0442 AWQ).\n\n\n\nvLLM \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0431\u044b\u0441\u0442\u0440\u043e:\n\n\n\n1. \u0421\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043d\u0430\u044f \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u044c \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u043d\u0438\u044f\n\n\n\n2. \u042d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0435 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0430\u043c\u044f\u0442\u044c\u044e \u043a\u043b\u044e\u0447\u0435\u0439 \u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e PagedAttention\n\n\n\n3. \u041d\u0435\u043f\u0440\u0435\u0440\u044b\u0432\u043d\u0430\u044f \u043f\u0430\u043a\u0435\u0442\u043d\u0430\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u0445\u043e\u0434\u044f\u0449\u0438\u0445 \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432.\n\n\n\n4. \u041e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u044f\u0434\u0440\u0430 CUDA\n\n\n\nvLLM \u0433\u0438\u0431\u043e\u043a \u0438 \u043f\u0440\u043e\u0441\u0442 \u0432 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0431\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u044f:\n\n\n\n* \u041f\u043e\u043b\u043d\u0430\u044f \u0438\u043d\u0442\u0435\u0433\u0440\u0430\u0446\u0438\u044f \u0441 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u043c\u0438 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438 Hugging Face.\n\n\n\n* \u0412\u044b\u0441\u043e\u043a\u043e\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0435 \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u043d\u0438\u0435 \u0441 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u043c\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\u043c\u0438 \u0434\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u0432\u043a\u043b\u044e\u0447\u0430\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 , \u043f\u043e\u0438\u0441\u043a \u043b\u0443\u0447\u0430 \u0438 \u043c\u043d\u043e\u0433\u043e\u0435 \u0434\u0440\u0443\u0433\u043e\u0435.\n\n\n\n* \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430 \u0442\u0435\u043d\u0437\u043e\u0440\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u0438\u0437\u043c\u0430 \u0434\u043b\u044f \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u0433\u043e \u0432\u044b\u0432\u043e\u0434\u0430\n\n\n\n* \u041f\u043e\u0442\u043e\u043a\u043e\u0432\u044b\u0435 \u0432\u044b\u0445\u043e\u0434\u044b\n\n\n\n* OpenAI-\u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u044b\u0439 API-\u0441\u0435\u0440\u0432\u0435\u0440\n!pip install vllm==0.2.0\n!pip install -U ipywidgets==8.1.1\ngpu_info = !nvidia-smi\n\ngpu_info = '\\n'.join(gpu_info)\n\nif gpu_info.find('failed') >= 0:\n\n  print('Not connected to a GPU')\n\nelse:\n\n  print(gpu_info)\n!git lfs install\n\n!git clone https://huggingface.co/TheBloke/Llama-2-7b-chat-fp16\nfrom vllm import LLM, SamplingParams\nllm = LLM(model=\"/content/Llama-2-7b-chat-fp16\")\n\nLLama2 7B chat hf\nprompt = \"\"\"<s>[INST] <<SYS>>\\nYou are the chat support manager for the company Artificial Intelligence University. The company sells courses on AI.\n\nThe company has a large document with all the materials about the company's products. A client asks you a question in chat, give him an answer,\n\nBased on excerpts from this document, try to answer in such a way that the person will want to buy training after answering. Answer as much as possible\n\nexactly according to the document, do not invent anything on your own. Never refer to the title of a document or the title of its passages when answering; the client does not owe anything\n\nknow about the document for which you are responding. Always answer in the first person without citing the sources you rely on.\n\n<</SYS>>\n\n\n\nClient question: Tell us about internships\n\n\n\nDocument with information to respond to the client:\n\nDocument excerpt #1:\n\nStudents who have completed an internship most often receive job offers from medium-sized companies and start working during the internship.\n\n\n\nThe internship program has a number of advantages: 1.\n\n\n\nStrong Resume and Portfolio: Students can create a strong portfolio that demonstrates their ability to successfully complete real-world projects.\n\n\n\nThis greatly increases their chances of receiving high-paying project assignments.\n\n\n\n\n\nDocument excerpt #2:\n\nAfter completing the internship, guaranteed employment for permanent or project work is provided.\n\n\n\nPractice in large projects that guarantee a line on your resume, real practice in 4 companies and experience working in a team.\n\n\n\nMore than 50% of students go on internships.\n\n\n\nThe student will gain practical skills in working in a group with a mentor.\n\n\n\nThis helps to find a job in a large company.\n\n\n\n3.\n\n\n\nA real created project for your own company, if desired.[/INST]\n\n\"\"\"\n\n\n\nsampling_params = SamplingParams(temperature=0.0, max_tokens=4096)\nfor i in range(10):\n\n  output = llm.generate(prompt, sampling_params)\n\n  print(output[0].outputs[0].text)", "metadata": {"subid": 11, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}, {"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"page_content": "\n# \u0412\u044b\u0432\u043e\u0434\u044b\n**\u0421\u0440\u0430\u0432\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043e\u0446\u0435\u043d\u043a\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0440\u0430\u0431\u043e\u0442\u044b \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043d\u0430 \u043d\u0430\u0448\u0435\u0439 \u0431\u0430\u0437\u0435 \u043f\u043e \u0448\u043a\u0430\u043b\u0435 \u043e\u0442 -2 \u0434\u043e 2**\n**\u0421\u0440\u0430\u0432\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0441\u043a\u043e\u0440\u043e\u0441\u0442\u0438 \u043e\u0442\u0432\u0435\u0442\u0430 \u043d\u0430 \u0440\u0430\u0437\u043d\u044b\u0445 GPU \u0438 llama-cpp-python**\n**\u0412 \u043a\u043e\u043b\u0430\u0431\u0435 \u0441 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0442\u043e\u043a\u0435\u043d\u043e\u0432 \u043d\u0430 \u043e\u0442\u0432\u0435\u0442 (\u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c 1000)**\n\n\n\n**T4 16GB**\n\n\n\n13B 40 \u0441\u0435\u043a\n\n\n\n**V100 16GB**\n\n\n\n13B 20 \u0441\u0435\u043a\n\n\n\n**A100 40GB**\n\n\n\n7B 9 \u0441\u0435\u043a\n\n\n\n13B 16 \u0441\u0435\u043a\n\n\n\n70B 110 \u0441\u0435\u043a\n\n\n\n**\u041d\u0430 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u043c \u0441\u0435\u0440\u0432\u0435\u0440\u0435 A100 80Gb \u0434\u0440\u0443\u0433\u0430\u044f \u0431\u0430\u0437\u0430 \u0438 \u0441 \u043c\u0435\u043d\u044c\u0448\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0445 \u0442\u043e\u043a\u0435\u043d\u043e\u0432 \u043d\u0430 \u043e\u0442\u0432\u0435\u0442 (\u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u043c 300 \u0442\u043e\u043a\u0435\u043d\u043e\u0432)**\n\n\n\n7B 2.5 \u0441\u0435\u043a\n\n\n\n13B 4-5 \u0441\u0435\u043a\n\n\n\n70B 13-16 \u0441\u0435\u043a", "metadata": {"subid": 12, "total": 13, "source": "https://colab.research.google.com/drive/1yuKRF2_8chx3WnAsysxTq8YHk3hgC2aM"}}}]