{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936c8c82-bc56-496a-9b00-2d079a3e202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from consultant import VectorStore\n",
    "from langchain_core.load import loads\n",
    "from langchain_nomic.embeddings import NomicEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda0fc5a-ad3a-41db-917d-618f09793f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('documents')\n",
    "langchain_path = base_path / '–ü–∞—Ä—Å–∏–Ω–≥ langchain.com/langchain.tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2edabe-e388-4772-a7f5-52bdec212975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/.miniconda3/envs/gpt/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "with langchain_path.open() as f:\n",
    "    documents = loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fdfb4c-27c9-481a-98cb-799bfdeac4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9381"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723fff1b-5c79-4f7c-8df1-248845ad1158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Templates\\n‚≠ê Popular\\n\\nThese are some of the more popular templates to get started with.  \\n-  [Retrieval Augmented Generation Chatbot](/v0.2/docs/templates/rag-conversation/) : Build a chatbot over your data. Defaults to OpenAI and PineconeVectorStore.  \\n-  [Extraction with OpenAI Functions](/v0.2/docs/templates/extraction-openai-functions/) : Do extraction of structured data from unstructured data. Uses OpenAI function calling.  \\n-  [Local Retrieval Augmented Generation](/v0.2/docs/templates/rag-chroma-private/) : Build a chatbot over your data. Uses only local tooling: Ollama, GPT4all, Chroma.  \\n-  [OpenAI Functions Agent](/v0.2/docs/templates/openai-functions-agent/) : Build a chatbot that can take actions. Uses OpenAI function calling and Tavily.  \\n-  [XML Agent](/v0.2/docs/templates/xml-agent/) : Build a chatbot that can take actions. Uses Anthropic and You.com.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d58a7a5-4a07-45df-80d4-78d7056db64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://python.langchain.com/v0.2/docs/templates/',\n",
       " 'content_type': 'text/html; charset=utf-8',\n",
       " 'title': 'Templates | ü¶úÔ∏èüîó LangChain',\n",
       " 'description': 'Highlighting a few different categories of templates',\n",
       " 'language': 'en',\n",
       " 'h1': 'Templates',\n",
       " 'h2': '‚≠ê Popular'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf96c9a-e7ca-465f-a7f1-4f12a2defa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = NomicEmbeddings(\n",
    "    model=\"nomic-embed-text-v1.5\",\n",
    "    dimensionality=512,\n",
    "    inference_mode='local',\n",
    "    device='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea06b76-242c-4d95-a643-9879968d6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = VectorStore.from_documents(\n",
    "    documents, \n",
    "    name='langchain-nomic-512', \n",
    "    embedding=embeddings,\n",
    "    dimensions=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac763539-e01f-419f-9a47-cffc795c7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51017a8d-bd34-470a-9c71-9f51093d5b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
