{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w4tnQKQEc-vH",
        "BDRPCArAK3dl",
        "LPI2RJa0hibP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sawa25/ConsultantIntegrator/blob/dev/%D0%94%D0%97_Pro_14_%D0%B7%D0%B0%D0%BD%D1%8F%D1%82%D0%B8%D0%B5_%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_Faiss_%D0%BF%D0%B0%D1%80%D1%81%D0%B8%D0%BD%D0%B3_%D1%81%D0%B0%D0%B9%D1%82%D0%B0_%D0%BD%D0%B0_%D0%B8%D0%BD%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%BD%D0%BE%D0%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведите парсинг сайта на любом **иностранном** языке по вашему выбору.\n",
        "Посмотрите на длины чанков. Выведите **околонулевые** (по длине в токенах) чанки и примите решение о том, нужны ли они в БЗ. Если они не содержат информации, избавьтесь от них.\n",
        "На основании полученных материалов сделайте нейро-консультанта, который бы отвечал на вопросы по содержимому сайта на **русском** языке. Примените методы экономии токенов (насколько возможно)."
      ],
      "metadata": {
        "id": "MsPFUfRSCIT3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_QqsT508FVe"
      },
      "outputs": [],
      "source": [
        "!pip install -q nest_asyncio xmltodict faiss-cpu==1.7.4 langchain==0.1.7 openai==1.12.0 tiktoken==0.6.0 langchain_community==0.0.20 langchain-openai==0.0.6 unstructured"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixes a bug with asyncio and jupyter\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "import xmltodict\n",
        "from langchain.document_loaders import ReadTheDocsLoader\n",
        "from langchain.document_loaders.sitemap import SitemapLoader\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from openai import OpenAI\n",
        "\n",
        "import tiktoken\n",
        "import matplotlib.pyplot as plt\n",
        "import getpass\n",
        "from langchain.vectorstores import FAISS\n",
        "import re\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from IPython.display import display_html\n",
        "from langchain.document_loaders import UnstructuredFileLoader\n",
        "# from langchain.document_loaders import NotebookLoader работает глючно - теряет ячейки кода\n",
        "import hashlib\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "\n"
      ],
      "metadata": {
        "id": "jSTAusrsI8yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "\n",
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key"
      ],
      "metadata": {
        "id": "rhc_9Gt7Sfmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ваше решение:\n",
        "### из роботикс получен хмл\n",
        "https://api.python.langchain.com/robots.txt ->Sitemap: https://api.python.langchain.com/sitemap.xml\n",
        "### из хмл видно список корневых адресов для разных версий библиотеки лангчейн\n",
        "### большинство из этих адресов запрещены к доступу на скачивание,\n",
        "'https://api.python.langchain.com/en/stable/'- доступа нет\n",
        "\n",
        "'https://api.python.langchain.com/en/latest/' -доступ есть\n",
        "с ним и будем работать"
      ],
      "metadata": {
        "id": "77KlIEoLOkeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# этим способом ничего интересного не загружается\n",
        "# sitemap_loader.requests_per_second = 2\n",
        "# # Optional: avoid `[SSL: CERTIFICATE_VERIFY_FAILED]` issue\n",
        "# sitemap_loader.requests_kwargs = {\"verify\": False}\n",
        "\n",
        "loader = SitemapLoader(\n",
        "    web_path=\"https://api.python.langchain.com/sitemap.xml\",\n",
        "    filter_urls=[\"https://api.python.langchain.com/en/latest\"],\n",
        ")\n",
        "documents = loader.load()\n",
        "print(documents[0])\n",
        "print(len(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4dMzRxdWTv6",
        "outputId": "957c9239-bca1-4104-b818-a083f77140fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 1/1 [00:00<00:00, 12.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLangChain Python API Reference Documentation.\\n\\n\\nYou will be automatically redirected to the new location of this page.\\n\\n' metadata={'source': 'https://api.python.langchain.com/en/latest/', 'loc': 'https://api.python.langchain.com/en/latest/', 'lastmod': '2024-04-14T16:16:42.729867+00:00', 'changefreq': 'daily', 'priority': '0.9'}\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# приготовить хранилище для локальной копии сайта\n",
        "from google.colab import drive\n",
        "# для первоначального скачивания сайта в папку docs4colab на моем гугл диске сработал такой способ монтирования\n",
        "# mountpoint = '/content/drive/docs4colab'\n",
        "# но повторное монтирование к непустой папке уже нее работает,\n",
        "# поэтому монтирование изменено\n",
        "mountpoint = '/content/drive/'\n",
        "drive.mount(mountpoint, force_remount=True)\n",
        "basaznany=None\n",
        "cnt=0\n",
        "for dirname, _, filenames in os.walk('.'):\n",
        "    if 'docs4colab' in dirname:\n",
        "        cnt+=1\n",
        "        if cnt>5:break #показать несколько папок скачанной ранее структуры файлов\n",
        "        print(dirname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GaBM-7YOC8x",
        "outputId": "412af4fa-7306-46f1-82e8-572a735e3baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "./drive/MyDrive/docs4colab\n",
            "./drive/MyDrive/docs4colab/api.python.langchain.com\n",
            "./drive/MyDrive/docs4colab/api.python.langchain.com/en\n",
            "./drive/MyDrive/docs4colab/api.python.langchain.com/en/stable\n",
            "./drive/MyDrive/docs4colab/api.python.langchain.com/en/latest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# перваначальное монтирование выглядело так:\n",
        "# folder_path  = './drive/docs4colab/MyDrive/docs4colab'\n",
        "# второй раз монтирование выглядит так:\n",
        "folder_path  = './drive/MyDrive/docs4colab'\n",
        "\n",
        "# проверка, что можно работать в этой папке docs4colab на моем гугл драйв:\n",
        "# Открываем файл для записи ('w' означает запись)\n",
        "file = open(f'{folder_path}/example88.txt', 'w')\n",
        "# Записываем строку в файл\n",
        "file.write('Hello, World!\\n')\n",
        "# Закрываем файл\n",
        "file.close()"
      ],
      "metadata": {
        "id": "kUfdIL8OZeAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# способ скачивания сайта\n",
        "# !wget -r -A.html -P folder_path 'https://api.python.langchain.com/en/stable/'"
      ],
      "metadata": {
        "id": "g3FCEKuPaxsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# долговременная процедура - скачивание целого сайта на локальный диск для дальнейшей работы\n",
        "# Total wall clock time: 9m 27s\n",
        "# Downloaded: 4157 files, 330M in 31s (10.6 MB/s)\n",
        "# запрещенный путь # command = f\"wget -r -A.html -P \\\"{folder_path}\\\" 'https://api.python.langchain.com/en/stable/'\"\n",
        "\n",
        "# разрешенный\n",
        "command = f\"wget -r -A.html -P \\\"{folder_path}\\\" 'https://api.python.langchain.com/en/latest/'\"\n",
        "# Выполняем команду\n",
        "get_ipython().system(command)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EccaM9ssggrv",
        "outputId": "d571867f-9c7e-4fe9-d1c5-4c090f339532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/owner.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.66K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:42:57 (4.06 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/owner.html’ saved [30368]\n",
            "\n",
            "--2024-04-14 11:42:57--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/rule.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/rule.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.49K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:42:57 (3.91 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/rule.html’ saved [25081]\n",
            "\n",
            "--2024-04-14 11:42:57--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/transfer.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/transfer.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.97K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:42:57 (4.87 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/transfer.html’ saved [20446]\n",
            "\n",
            "--2024-04-14 11:42:57--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/value.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/value.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.68K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:42:57 (4.20 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/value.html’ saved [25276]\n",
            "\n",
            "--2024-04-14 11:42:57--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.40K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:42:57 (3.25 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/base.html’ saved [16797]\n",
            "\n",
            "--2024-04-14 11:42:57--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/closest_airport.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/closest_airport.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.62K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:42:57 (3.32 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/closest_airport.html’ saved [23167]\n",
            "\n",
            "--2024-04-14 11:42:57--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/flight_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/flight_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.93K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:42:58 (5.81 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/flight_search.html’ saved [34743]\n",
            "\n",
            "--2024-04-14 11:42:58--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/arxiv/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/arxiv/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.14K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:42:58 (5.89 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/arxiv/tool.html’ saved [19599]\n",
            "\n",
            "--2024-04-14 11:42:58--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/audio/huggingface_text_to_speech_inference.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/audio/huggingface_text_to_speech_inference.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.72K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:42:58 (8.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/audio/huggingface_text_to_speech_inference.html’ saved [30435]\n",
            "\n",
            "--2024-04-14 11:42:58--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/document_intelligence.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/document_intelligence.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.72K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:42:58 (9.96 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/document_intelligence.html’ saved [36575]\n",
            "\n",
            "--2024-04-14 11:42:58--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/image_analysis.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/image_analysis.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.74K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:42:58 (10.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/image_analysis.html’ saved [36593]\n",
            "\n",
            "--2024-04-14 11:42:58--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/speech_to_text.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/speech_to_text.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.57K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:42:58 (11.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/speech_to_text.html’ saved [30277]\n",
            "\n",
            "--2024-04-14 11:42:58--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/text_analytics_for_health.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/text_analytics_for_health.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.46K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:42:59 (6.48 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/text_analytics_for_health.html’ saved [28114]\n",
            "\n",
            "--2024-04-14 11:42:59--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/text_to_speech.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/text_to_speech.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.98K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:42:59 (4.06 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/text_to_speech.html’ saved [28649]\n",
            "\n",
            "--2024-04-14 11:42:59--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/form_recognizer.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/form_recognizer.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.58K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:42:59 (6.28 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/form_recognizer.html’ saved [36434]\n",
            "\n",
            "--2024-04-14 11:42:59--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/image_analysis.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/image_analysis.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.09K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:42:59 (8.79 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/image_analysis.html’ saved [35928]\n",
            "\n",
            "--2024-04-14 11:42:59--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/speech2text.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/speech2text.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.48K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:42:59 (4.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/speech2text.html’ saved [30186]\n",
            "\n",
            "--2024-04-14 11:42:59--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/text2speech.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/text2speech.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.73K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:42:59 (8.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/text2speech.html’ saved [28399]\n",
            "\n",
            "--2024-04-14 11:42:59--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/text_analytics_health.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/text_analytics_health.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.39K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:00 (7.42 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/text_analytics_health.html’ saved [28050]\n",
            "\n",
            "--2024-04-14 11:43:00--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/bearly/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/bearly/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.34K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:00 (7.23 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/bearly/tool.html’ saved [40286]\n",
            "\n",
            "--2024-04-14 11:43:00--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/bing_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/bing_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.04K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:00 (5.30 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/bing_search/tool.html’ saved [20520]\n",
            "\n",
            "--2024-04-14 11:43:00--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/brave_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/brave_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.75K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:00 (6.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/brave_search/tool.html’ saved [20228]\n",
            "\n",
            "--2024-04-14 11:43:00--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/clickup/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/clickup/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.53K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:00 (5.93 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/clickup/tool.html’ saved [18974]\n",
            "\n",
            "--2024-04-14 11:43:00--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/cogniswitch/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/cogniswitch/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.50K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:00 (8.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/cogniswitch/tool.html’ saved [59904]\n",
            "\n",
            "--2024-04-14 11:43:00--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.27K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:01 (2.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/models.html’ saved [18710]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/service.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/service.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.59K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:01 (12.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/service.html’ saved [35423]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.88K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:01 (4.99 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/connery/tool.html’ saved [34692]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/dataforseo_api_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/dataforseo_api_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.03K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:01 (4.84 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/dataforseo_api_search/tool.html’ saved [23581]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/ddg_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ddg_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.66K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:01 (3.75 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ddg_search/tool.html’ saved [26274]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/e2b_data_analysis/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/e2b_data_analysis/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.21K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:01 (1.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/e2b_data_analysis/tool.html’ saved [52438]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/e2b_data_analysis/unparse.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/e2b_data_analysis/unparse.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 134.18K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:01 (21.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/e2b_data_analysis/unparse.html’ saved [137404]\n",
            "\n",
            "--2024-04-14 11:43:01--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/audio_speech_to_text.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/audio_speech_to_text.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.77K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:02 (5.47 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/audio_speech_to_text.html’ saved [28440]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/audio_text_to_speech.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/audio_text_to_speech.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.77K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:02 (8.25 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/audio_text_to_speech.html’ saved [30482]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/edenai_base_tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/edenai_base_tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.23K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:02 (5.91 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/edenai_base_tool.html’ saved [38128]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/image_explicitcontent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/image_explicitcontent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.83K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:02 (8.00 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/image_explicitcontent.html’ saved [23376]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/image_objectdetection.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/image_objectdetection.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.62K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:02 (7.23 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/image_objectdetection.html’ saved [25212]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/ocr_identityparser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/ocr_identityparser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.53K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:02 (6.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/ocr_identityparser.html’ saved [22043]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/ocr_invoiceparser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/ocr_invoiceparser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.89K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:02 (7.20 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/ocr_invoiceparser.html’ saved [22412]\n",
            "\n",
            "--2024-04-14 11:43:02--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/text_moderation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/text_moderation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.29K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:03 (5.41 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/edenai/text_moderation.html’ saved [22820]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/eleven_labs/models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/eleven_labs/models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.61K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:03 (9.86 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/eleven_labs/models.html’ saved [15980]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/eleven_labs/text2speech.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/eleven_labs/text2speech.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.99K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:03 (7.50 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/eleven_labs/text2speech.html’ saved [26616]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/copy.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/copy.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.71K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:03 (6.54 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/copy.html’ saved [22230]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/delete.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/delete.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.45K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:03 (6.82 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/delete.html’ saved [20944]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/file_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/file_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.98K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:03 (6.28 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/file_search.html’ saved [23529]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/list_dir.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/list_dir.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.76K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:03 (5.98 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/list_dir.html’ saved [21254]\n",
            "\n",
            "--2024-04-14 11:43:03--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/move.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/move.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.13K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:04 (8.38 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/move.html’ saved [22663]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/read.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/read.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.58K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:04 (4.34 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/read.html’ saved [21077]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.27K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:04 (8.42 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/utils.html’ saved [22800]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/write.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/write.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.00K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:04 (8.02 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/file_management/write.html’ saved [22532]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/github/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/github/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.08K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:04 (4.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/github/tool.html’ saved [19538]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gitlab/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gitlab/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.08K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:04 (3.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gitlab/tool.html’ saved [18518]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.17K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:04 (5.02 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/base.html’ saved [18607]\n",
            "\n",
            "--2024-04-14 11:43:04--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/create_draft.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/create_draft.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.89K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:05 (4.91 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/create_draft.html’ saved [27535]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/get_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/get_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.91K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:05 (6.56 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/get_message.html’ saved [24479]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/get_thread.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/get_thread.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.20K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:05 (8.05 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/get_thread.html’ saved [21706]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.93K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:05 (7.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/search.html’ saved [35765]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/send_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/send_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.42K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:05 (9.10 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/send_message.html’ saved [30125]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/golden_query/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/golden_query/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.25K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:05 (4.42 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/golden_query/tool.html’ saved [18692]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_cloud/texttospeech.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_cloud/texttospeech.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.41K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:05 (4.05 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_cloud/texttospeech.html’ saved [27046]\n",
            "\n",
            "--2024-04-14 11:43:05--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_finance/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_finance/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.63K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:06 (5.30 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_finance/tool.html’ saved [18057]\n",
            "\n",
            "--2024-04-14 11:43:06--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_jobs/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_jobs/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.58K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:06 (6.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_jobs/tool.html’ saved [18002]\n",
            "\n",
            "--2024-04-14 11:43:06--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_lens/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_lens/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.58K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:06 (4.13 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_lens/tool.html’ saved [17998]\n",
            "\n",
            "--2024-04-14 11:43:06--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_places/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_places/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.13K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:06 (6.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_places/tool.html’ saved [19587]\n",
            "\n",
            "--2024-04-14 11:43:06--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_scholar/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_scholar/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.63K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:06 (5.41 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_scholar/tool.html’ saved [18050]\n",
            "\n",
            "--2024-04-14 11:43:06--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.09K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:06 (4.51 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_search/tool.html’ saved [20574]\n",
            "\n",
            "--2024-04-14 11:43:06--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_serper/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_serper/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.76K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:07 (6.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_serper/tool.html’ saved [23306]\n",
            "\n",
            "--2024-04-14 11:43:07--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_trends/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_trends/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.62K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:07 (3.93 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/google_trends/tool.html’ saved [18038]\n",
            "\n",
            "--2024-04-14 11:43:07--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/graphql/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/graphql/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.42K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:07 (5.13 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/graphql/tool.html’ saved [18862]\n",
            "\n",
            "--2024-04-14 11:43:07--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/human/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/human/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.87K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:07 (5.96 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/human/tool.html’ saved [19325]\n",
            "\n",
            "--2024-04-14 11:43:07--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/ifttt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ifttt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.51K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:07 (8.02 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ifttt.html’ saved [19979]\n",
            "\n",
            "--2024-04-14 11:43:07--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/jira/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/jira/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.64K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:07 (4.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/jira/tool.html’ saved [19083]\n",
            "\n",
            "--2024-04-14 11:43:07--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/json/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/json/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.67K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:08 (6.00 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/json/tool.html’ saved [33451]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/memorize/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/memorize/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.22K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:08 (8.54 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/memorize/tool.html’ saved [22756]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/merriam_webster/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/merriam_webster/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.61K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:08 (6.87 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/merriam_webster/tool.html’ saved [18032]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/metaphor_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/metaphor_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.89K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:08 (9.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/metaphor_search/tool.html’ saved [26508]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/close_session.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/close_session.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.84K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:08 (7.96 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/close_session.html’ saved [21344]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/create_session.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/create_session.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.08K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:08 (5.13 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/create_session.html’ saved [22612]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/update_session.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/update_session.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.64K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:08 (7.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/multion/update_session.html’ saved [24206]\n",
            "\n",
            "--2024-04-14 11:43:08--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/nasa/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/nasa/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.86K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:09 (5.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/nasa/tool.html’ saved [18288]\n",
            "\n",
            "--2024-04-14 11:43:09--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/nuclia/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/nuclia/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.16K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:09 (9.20 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/nuclia/tool.html’ saved [51363]\n",
            "\n",
            "--2024-04-14 11:43:09--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.55K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:09 (4.69 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/base.html’ saved [16950]\n",
            "\n",
            "--2024-04-14 11:43:09--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/create_draft_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/create_draft_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.24K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:09 (8.10 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/create_draft_message.html’ saved [23795]\n",
            "\n",
            "--2024-04-14 11:43:09--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/events_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/events_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.99K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:09 (6.01 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/events_search.html’ saved [30713]\n",
            "\n",
            "--2024-04-14 11:43:09--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/messages_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/messages_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.28K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:10 (8.50 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/messages_search.html’ saved [29985]\n",
            "\n",
            "--2024-04-14 11:43:10--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/send_event.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/send_event.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.36K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:10 (9.08 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/send_event.html’ saved [24943]\n",
            "\n",
            "--2024-04-14 11:43:10--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/send_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/send_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.05K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:10 (8.35 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/send_message.html’ saved [23608]\n",
            "\n",
            "--2024-04-14 11:43:10--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/openai_dalle_image_generation/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/openai_dalle_image_generation/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.84K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:10 (5.54 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/openai_dalle_image_generation/tool.html’ saved [18273]\n",
            "\n",
            "--2024-04-14 11:43:10--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/openapi/utils/api_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/openapi/utils/api_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 102.29K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:10 (19.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/openapi/utils/api_models.html’ saved [104747]\n",
            "\n",
            "--2024-04-14 11:43:10--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/openweathermap/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/openweathermap/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.94K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:11 (5.40 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/openweathermap/tool.html’ saved [18373]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/passio_nutrition_ai/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/passio_nutrition_ai/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.01K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:11 (4.00 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/passio_nutrition_ai/tool.html’ saved [19469]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.68K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:11 (7.15 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/base.html’ saved [23224]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/click.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/click.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.35K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:11 (6.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/click.html’ saved [26984]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/current_page.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/current_page.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.30K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:11 (7.33 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/current_page.html’ saved [20788]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/extract_hyperlinks.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/extract_hyperlinks.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.33K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:11 (6.47 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/extract_hyperlinks.html’ saved [27989]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/extract_text.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/extract_text.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.38K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:11 (7.37 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/extract_text.html’ saved [23945]\n",
            "\n",
            "--2024-04-14 11:43:11--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/get_elements.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/get_elements.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.82K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:12 (6.11 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/get_elements.html’ saved [31561]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/navigate.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/navigate.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.18K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:12 (9.45 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/navigate.html’ saved [25781]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/navigate_back.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/navigate_back.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.09K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:12 (6.21 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/navigate_back.html’ saved [22620]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/plugin.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/plugin.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.87K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:12 (9.14 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/plugin.html’ saved [28534]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/aggregates.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/aggregates.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.88K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:12 (7.82 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/aggregates.html’ saved [23427]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/financials.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/financials.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.98K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:12 (2.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/financials.html’ saved [19439]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/last_quote.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/last_quote.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.79K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:12 (8.36 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/last_quote.html’ saved [19241]\n",
            "\n",
            "--2024-04-14 11:43:12--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/ticker_news.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/ticker_news.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.81K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:13 (5.82 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/polygon/ticker_news.html’ saved [19258]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/powerbi/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/powerbi/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.72K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:13 (10.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/powerbi/tool.html’ saved [60129]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/pubmed/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/pubmed/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.89K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:13 (7.05 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/pubmed/tool.html’ saved [18315]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/reddit_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/reddit_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.95K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:13 (8.61 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/reddit_search/tool.html’ saved [22480]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/requests/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/requests/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  43.53K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:13 (7.23 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/requests/tool.html’ saved [44574]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/scenexplain/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/scenexplain/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.78K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:13 (5.93 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/scenexplain/tool.html’ saved [19234]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/searchapi/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/searchapi/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.58K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:13 (8.01 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/searchapi/tool.html’ saved [23127]\n",
            "\n",
            "--2024-04-14 11:43:13--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/searx_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/searx_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.10K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:14 (8.28 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/searx_search/tool.html’ saved [24677]\n",
            "\n",
            "--2024-04-14 11:43:14--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/semanticscholar/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/semanticscholar/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.17K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:14 (5.29 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/semanticscholar/tool.html’ saved [19627]\n",
            "\n",
            "--2024-04-14 11:43:14--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/shell/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/shell/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.60K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:14 (4.77 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/shell/tool.html’ saved [27237]\n",
            "\n",
            "--2024-04-14 11:43:14--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.49K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:14 (4.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/base.html’ saved [16881]\n",
            "\n",
            "--2024-04-14 11:43:14--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/get_channel.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/get_channel.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.63K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:14 (5.01 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/get_channel.html’ saved [20097]\n",
            "\n",
            "--2024-04-14 11:43:14--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/get_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/get_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.80K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:14 (4.15 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/get_message.html’ saved [21298]\n",
            "\n",
            "--2024-04-14 11:43:14--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/schedule_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/schedule_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.17K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:15 (4.95 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/schedule_message.html’ saved [22697]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/send_message.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/send_message.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.84K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:15 (2.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/send_message.html’ saved [20319]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/sleep/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/sleep/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.93K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:15 (6.31 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/sleep/tool.html’ saved [20409]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/spark_sql/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/spark_sql/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.22K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:15 (6.82 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/spark_sql/tool.html’ saved [31973]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/sql_database/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/sql_database/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.69K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:15 (12.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/sql_database/tool.html’ saved [36547]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/stackexchange/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/stackexchange/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.63K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:15 (6.66 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/stackexchange/tool.html’ saved [18054]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/steam/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/steam/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.69K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:15 (6.02 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/steam/tool.html’ saved [18114]\n",
            "\n",
            "--2024-04-14 11:43:15--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/steamship_image_generation/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/steamship_image_generation/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.87K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:16 (7.07 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/steamship_image_generation/tool.html’ saved [28541]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/tavily_search/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/tavily_search/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.89K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:16 (2.45 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/tavily_search/tool.html’ saved [28556]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/vectorstore/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/vectorstore/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.74K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:16 (6.77 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/vectorstore/tool.html’ saved [34550]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/wikidata/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/wikidata/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.69K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:16 (4.10 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/wikidata/tool.html’ saved [18112]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/wikipedia/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/wikipedia/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.61K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:16 (5.11 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/wikipedia/tool.html’ saved [18028]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/wolfram_alpha/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/wolfram_alpha/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.66K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:16 (6.30 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/wolfram_alpha/tool.html’ saved [18081]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/yahoo_finance_news.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/yahoo_finance_news.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.29K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:16 (8.75 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/yahoo_finance_news.html’ saved [24870]\n",
            "\n",
            "--2024-04-14 11:43:16--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/you/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/you/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.13K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:17 (6.58 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/you/tool.html’ saved [20611]\n",
            "\n",
            "--2024-04-14 11:43:17--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/youtube/search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/youtube/search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.78K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:17 (3.38 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/youtube/search.html’ saved [21274]\n",
            "\n",
            "--2024-04-14 11:43:17--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/zapier/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/zapier/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.78K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:17 (6.01 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/zapier/tool.html’ saved [36642]\n",
            "\n",
            "--2024-04-14 11:43:17--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.50K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:17 (5.25 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/ainetwork/utils.html’ saved [23038]\n",
            "\n",
            "--2024-04-14 11:43:17--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.37K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:17 (7.11 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/amadeus/utils.html’ saved [19837]\n",
            "\n",
            "--2024-04-14 11:43:17--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.23K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:17 (4.12 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_ai_services/utils.html’ saved [19689]\n",
            "\n",
            "--2024-04-14 11:43:17--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.28K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:18 (4.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/azure_cognitive_services/utils.html’ saved [19745]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.96K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:18 (1.10 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/gmail/utils.html’ saved [31706]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/interaction/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/interaction/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.54K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:18 (4.17 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/interaction/tool.html’ saved [16938]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.92K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:18 (7.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/office365/utils.html’ saved [23475]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.88K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:18 (5.27 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/playwright/utils.html’ saved [27523]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.19K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:18 (5.29 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/slack/utils.html’ saved [19652]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/tools/steamship_image_generation/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/steamship_image_generation/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.91K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:18 (723 KB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/tools/steamship_image_generation/utils.html’ saved [20383]\n",
            "\n",
            "--2024-04-14 11:43:18--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/alpha_vantage.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/alpha_vantage.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.90K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:19 (9.09 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/alpha_vantage.html’ saved [38812]\n",
            "\n",
            "--2024-04-14 11:43:19--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/apify.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/apify.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.84K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:19 (8.06 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/apify.html’ saved [38744]\n",
            "\n",
            "--2024-04-14 11:43:19--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/arcee.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/arcee.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  47.68K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:19 (16.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/arcee.html’ saved [48821]\n",
            "\n",
            "--2024-04-14 11:43:19--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/arxiv.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/arxiv.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  47.62K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:19 (8.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/arxiv.html’ saved [48766]\n",
            "\n",
            "--2024-04-14 11:43:19--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/astradb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/astradb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  36.62K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:19 (10.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/astradb.html’ saved [37497]\n",
            "\n",
            "--2024-04-14 11:43:19--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/awslambda.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/awslambda.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.09K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:19 (4.05 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/awslambda.html’ saved [23641]\n",
            "\n",
            "--2024-04-14 11:43:19--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/bibtex.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/bibtex.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.59K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:20 (8.39 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/bibtex.html’ saved [26200]\n",
            "\n",
            "--2024-04-14 11:43:20--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/bing_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/bing_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.76K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:20 (8.49 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/bing_search.html’ saved [28429]\n",
            "\n",
            "--2024-04-14 11:43:20--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/brave_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/brave_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.84K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:20 (5.89 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/brave_search.html’ saved [25438]\n",
            "\n",
            "--2024-04-14 11:43:20--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/clickup.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/clickup.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 116.91K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:20 (21.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/clickup.html’ saved [119718]\n",
            "\n",
            "--2024-04-14 11:43:20--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dalle_image_generator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dalle_image_generator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:20 (7.44 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dalle_image_generator.html’ saved [41071]\n",
            "\n",
            "--2024-04-14 11:43:20--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dataforseo_api_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dataforseo_api_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.68K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:20 (9.81 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dataforseo_api_search.html’ saved [51895]\n",
            "\n",
            "--2024-04-14 11:43:20--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dria_index.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dria_index.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.51K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:43:21 (1.23 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/dria_index.html’ saved [30222]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/duckduckgo_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/duckduckgo_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.03K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:21 (6.64 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/duckduckgo_search.html’ saved [32795]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/github.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/github.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 134.89K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:21 (23.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/github.html’ saved [138128]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/gitlab.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/gitlab.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.30K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:21 (27.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/gitlab.html’ saved [60726]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/golden_query.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/golden_query.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.75K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:21 (5.33 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/golden_query.html’ saved [22272]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_finance.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_finance.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.15K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:21 (10.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_finance.html’ saved [27797]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_jobs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_jobs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.25K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:21 (8.32 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_jobs.html’ saved [24831]\n",
            "\n",
            "--2024-04-14 11:43:21--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_lens.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_lens.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.30K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:22 (10.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_lens.html’ saved [26930]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_places_api.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_places_api.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.94K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:22 (10.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_places_api.html’ saved [31684]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_scholar.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_scholar.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.60K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:22 (8.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_scholar.html’ saved [31334]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.65K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:22 (5.97 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_search.html’ saved [31383]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_serper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_serper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.96K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:22 (7.68 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_serper.html’ saved [46034]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_trends.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_trends.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.38K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:22 (6.76 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/google_trends.html’ saved [33159]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/graphql.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/graphql.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.96K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:22 (6.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/graphql.html’ saved [23509]\n",
            "\n",
            "--2024-04-14 11:43:22--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/infobip.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/infobip.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.49K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:23 (7.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/infobip.html’ saved [38388]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/jira.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/jira.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.76K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-04-14 11:43:23 (905 KB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/jira.html’ saved [43786]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/max_compute.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/max_compute.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.61K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:23 (7.17 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/max_compute.html’ saved [25205]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/merriam_webster.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/merriam_webster.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.05K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:23 (7.50 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/merriam_webster.html’ saved [31794]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/metaphor_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/metaphor_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.21K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:23 (9.18 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/metaphor_search.html’ saved [40152]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/nasa.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/nasa.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.01K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:23 (6.21 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/nasa.html’ saved [24589]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/nvidia_riva.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/nvidia_riva.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 100.66K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:23 (19.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/nvidia_riva.html’ saved [103077]\n",
            "\n",
            "--2024-04-14 11:43:23--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/openapi.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/openapi.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.66K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:24 (12.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/openapi.html’ saved [65186]\n",
            "\n",
            "--2024-04-14 11:43:24--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/openweathermap.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/openweathermap.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.18K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:24 (6.06 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/openweathermap.html’ saved [25783]\n",
            "\n",
            "--2024-04-14 11:43:24--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/outline.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/outline.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.84K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:24 (5.87 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/outline.html’ saved [28506]\n",
            "\n",
            "--2024-04-14 11:43:24--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/passio_nutrition_ai.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/passio_nutrition_ai.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.91K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:24 (9.04 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/passio_nutrition_ai.html’ saved [40865]\n",
            "\n",
            "--2024-04-14 11:43:24--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/pebblo.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/pebblo.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.43K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:24 (9.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/pebblo.html’ saved [45500]\n",
            "\n",
            "--2024-04-14 11:43:24--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/polygon.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/polygon.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.49K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:24 (7.19 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/polygon.html’ saved [36344]\n",
            "\n",
            "--2024-04-14 11:43:24--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/portkey.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/portkey.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.64K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:25 (967 KB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/portkey.html’ saved [25236]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/powerbi.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/powerbi.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.52K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:25 (9.11 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/powerbi.html’ saved [65045]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/pubmed.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/pubmed.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.93K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:25 (6.93 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/pubmed.html’ saved [43965]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/python.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/python.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.17K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:25 (5.42 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/python.html’ saved [24750]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/reddit_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/reddit_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.53K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:25 (7.83 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/reddit_search.html’ saved [32288]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/redis.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/redis.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.29K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:25 (7.64 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/redis.html’ saved [43308]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/requests.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/requests.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.59K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:25 (12.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/requests.html’ saved [65120]\n",
            "\n",
            "--2024-04-14 11:43:25--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/scenexplain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/scenexplain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.76K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:26 (6.09 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/scenexplain.html’ saved [23309]\n",
            "\n",
            "--2024-04-14 11:43:26--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searchapi.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searchapi.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.03K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:26 (7.68 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searchapi.html’ saved [39971]\n",
            "\n",
            "--2024-04-14 11:43:26--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  73.29K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:26 (12.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html’ saved [75050]\n",
            "\n",
            "--2024-04-14 11:43:26--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/semanticscholar.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/semanticscholar.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.75K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:26 (4.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/semanticscholar.html’ saved [25339]\n",
            "\n",
            "--2024-04-14 11:43:26--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/serpapi.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/serpapi.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  53.01K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:26 (12.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/serpapi.html’ saved [54278]\n",
            "\n",
            "--2024-04-14 11:43:26--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/spark_sql.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/spark_sql.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.62K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:26 (5.48 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/spark_sql.html’ saved [46718]\n",
            "\n",
            "--2024-04-14 11:43:26--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/sql_database.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/sql_database.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  97.12K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:26 (14.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/sql_database.html’ saved [99449]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/stackexchange.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/stackexchange.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.83K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:27 (8.27 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/stackexchange.html’ saved [26447]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/steam.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/steam.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.24K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:27 (12.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/steam.html’ saved [42231]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/tavily_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/tavily_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.15K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:27 (7.84 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/tavily_search.html’ saved [42140]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/tensorflow_datasets.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/tensorflow_datasets.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.34K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:27 (4.85 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/tensorflow_datasets.html’ saved [25947]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/twilio.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/twilio.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.91K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:27 (3.46 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/twilio.html’ saved [24481]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wikidata.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wikidata.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  36.64K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:27 (9.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wikidata.html’ saved [37518]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wikipedia.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wikipedia.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.61K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:27 (8.32 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wikipedia.html’ saved [32370]\n",
            "\n",
            "--2024-04-14 11:43:27--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wolfram_alpha.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wolfram_alpha.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.67K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:28 (5.63 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/wolfram_alpha.html’ saved [22187]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/you.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/you.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.08K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:28 (6.13 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/you.html’ saved [47190]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/zapier.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/zapier.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  55.24K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:28 (8.59 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/zapier.html’ saved [56566]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/anthropic.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/anthropic.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.98K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:28 (4.00 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/anthropic.html’ saved [18411]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/opaqueprompts.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/opaqueprompts.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.41K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:28 (4.63 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/opaqueprompts.html’ saved [25000]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/vertexai.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/vertexai.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.13K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:28 (6.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utilities/vertexai.html’ saved [30851]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utils/ernie_functions.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/ernie_functions.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.57K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:28 (6.70 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/ernie_functions.html’ saved [22087]\n",
            "\n",
            "--2024-04-14 11:43:28--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utils/google.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/google.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.38K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:43:29 (728 KB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/google.html’ saved [17792]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utils/math.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/math.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  28.47K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-04-14 11:43:29 (23.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/math.html’ saved [29154]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/utils/openai.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/openai.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.72K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:29 (6.76 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/utils/openai.html’ saved [16100]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/alibabacloud_opensearch.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/alibabacloud_opensearch.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  91.89K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:29 (15.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/alibabacloud_opensearch.html’ saved [94096]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/analyticdb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/analyticdb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  75.16K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:29 (12.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/analyticdb.html’ saved [76967]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/annoy.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/annoy.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  76.29K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:29 (14.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/annoy.html’ saved [78116]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/apache_doris.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/apache_doris.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  85.92K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:29 (13.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/apache_doris.html’ saved [87977]\n",
            "\n",
            "--2024-04-14 11:43:29--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/astradb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/astradb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 170.46K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:30 (17.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/astradb.html’ saved [174549]\n",
            "\n",
            "--2024-04-14 11:43:30--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/atlas.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/atlas.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  56.43K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:30 (10.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/atlas.html’ saved [57788]\n",
            "\n",
            "--2024-04-14 11:43:30--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/awadb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/awadb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  89.54K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:30 (14.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/awadb.html’ saved [91690]\n",
            "\n",
            "--2024-04-14 11:43:30--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azure_cosmos_db.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azure_cosmos_db.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  87.50K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:30 (11.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azure_cosmos_db.html’ saved [89599]\n",
            "\n",
            "--2024-04-14 11:43:30--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azuresearch.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azuresearch.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 112.07K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:30 (14.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/azuresearch.html’ saved [114758]\n",
            "\n",
            "--2024-04-14 11:43:30--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/bageldb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/bageldb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  74.02K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:30 (10.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/bageldb.html’ saved [75801]\n",
            "\n",
            "--2024-04-14 11:43:30--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/baiducloud_vector_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/baiducloud_vector_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  78.83K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:31 (12.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/baiducloud_vector_search.html’ saved [80718]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/baiduvectordb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/baiduvectordb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  84.87K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:31 (13.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/baiduvectordb.html’ saved [86911]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/bigquery_vector_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/bigquery_vector_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 139.02K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:31 (19.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/bigquery_vector_search.html’ saved [142358]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/cassandra.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/cassandra.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  71.86K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:31 (11.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/cassandra.html’ saved [73583]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/chroma.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/chroma.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 122.42K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:31 (16.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/chroma.html’ saved [125353]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/clarifai.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/clarifai.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  57.14K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:31 (8.81 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/clarifai.html’ saved [58513]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/clickhouse.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/clickhouse.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  90.74K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:31 (15.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/clickhouse.html’ saved [92922]\n",
            "\n",
            "--2024-04-14 11:43:31--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/couchbase.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/couchbase.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  85.48K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:32 (13.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/couchbase.html’ saved [87534]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/dashvector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/dashvector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  62.44K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:32 (11.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/dashvector.html’ saved [63940]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/databricks_vector_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/databricks_vector_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  91.57K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:32 (22.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/databricks_vector_search.html’ saved [93766]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/deeplake.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/deeplake.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 116.67K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:32 (18.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/deeplake.html’ saved [119465]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/dingo.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/dingo.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  65.37K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:32 (6.40 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/dingo.html’ saved [66934]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.74K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:32 (7.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/base.html’ saved [43763]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/hnsw.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/hnsw.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.12K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:32 (5.25 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/hnsw.html’ saved [27774]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/in_memory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/in_memory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.57K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:32 (4.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/docarray/in_memory.html’ saved [23116]\n",
            "\n",
            "--2024-04-14 11:43:32--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/documentdb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/documentdb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  57.48K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:33 (7.80 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/documentdb.html’ saved [58864]\n",
            "\n",
            "--2024-04-14 11:43:33--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/duckdb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/duckdb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.59K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:33 (8.16 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/duckdb.html’ saved [45660]\n",
            "\n",
            "--2024-04-14 11:43:33--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/ecloud_vector_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/ecloud_vector_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  97.29K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:33 (12.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/ecloud_vector_search.html’ saved [99620]\n",
            "\n",
            "--2024-04-14 11:43:33--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/elastic_vector_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/elastic_vector_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 115.13K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:33 (17.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/elastic_vector_search.html’ saved [117898]\n",
            "\n",
            "--2024-04-14 11:43:33--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/elasticsearch.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/elasticsearch.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 173.32K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:33 (5.47 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/elasticsearch.html’ saved [177476]\n",
            "\n",
            "--2024-04-14 11:43:33--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/epsilla.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/epsilla.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.89K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:33 (9.35 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/epsilla.html’ saved [65426]\n",
            "\n",
            "--2024-04-14 11:43:33--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/faiss.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/faiss.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 173.09K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:34 (12.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/faiss.html’ saved [177243]\n",
            "\n",
            "--2024-04-14 11:43:34--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hanavector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hanavector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  96.34K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:34 (11.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hanavector.html’ saved [98650]\n",
            "\n",
            "--2024-04-14 11:43:34--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hippo.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hippo.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 110.68K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:34 (15.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hippo.html’ saved [113332]\n",
            "\n",
            "--2024-04-14 11:43:34--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hologres.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hologres.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  66.00K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:34 (10.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/hologres.html’ saved [67579]\n",
            "\n",
            "--2024-04-14 11:43:34--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/infinispanvs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/infinispanvs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 107.10K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:34 (24.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/infinispanvs.html’ saved [109674]\n",
            "\n",
            "--2024-04-14 11:43:34--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/inmemory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/inmemory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.02K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:34 (9.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/inmemory.html’ saved [50197]\n",
            "\n",
            "--2024-04-14 11:43:34--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/jaguar.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/jaguar.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  78.11K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:35 (21.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/jaguar.html’ saved [79988]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/kdbai.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/kdbai.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  50.17K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:35 (9.40 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/kdbai.html’ saved [51370]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/kinetica.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/kinetica.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 127.33K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:35 (16.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/kinetica.html’ saved [130388]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/lancedb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/lancedb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.13K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:35 (7.68 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/lancedb.html’ saved [39041]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/lantern.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/lantern.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 144.20K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:35 (23.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/lantern.html’ saved [147664]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/llm_rails.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/llm_rails.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.33K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:35 (6.69 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/llm_rails.html’ saved [46422]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/marqo.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/marqo.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  71.52K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:35 (11.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/marqo.html’ saved [73232]\n",
            "\n",
            "--2024-04-14 11:43:35--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/matching_engine.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/matching_engine.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  82.41K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:36 (7.16 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/matching_engine.html’ saved [84389]\n",
            "\n",
            "--2024-04-14 11:43:36--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/meilisearch.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/meilisearch.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  57.50K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-04-14 11:43:36 (5.96 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/meilisearch.html’ saved [58879]\n",
            "\n",
            "--2024-04-14 11:43:36--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/milvus.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/milvus.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 158.15K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:36 (10.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/milvus.html’ saved [161948]\n",
            "\n",
            "--2024-04-14 11:43:36--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/momento_vector_index.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/momento_vector_index.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  76.08K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:36 (14.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/momento_vector_index.html’ saved [77901]\n",
            "\n",
            "--2024-04-14 11:43:36--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/mongodb_atlas.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/mongodb_atlas.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  60.30K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:36 (8.49 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/mongodb_atlas.html’ saved [61748]\n",
            "\n",
            "--2024-04-14 11:43:36--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/myscale.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/myscale.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 106.95K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:43:37 (4.39 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/myscale.html’ saved [109515]\n",
            "\n",
            "--2024-04-14 11:43:37--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/neo4j_vector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/neo4j_vector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 183.83K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:37 (13.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/neo4j_vector.html’ saved [188241]\n",
            "\n",
            "--2024-04-14 11:43:37--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/nucliadb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/nucliadb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.90K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:37 (8.32 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/nucliadb.html’ saved [40860]\n",
            "\n",
            "--2024-04-14 11:43:37--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/opensearch_vector_search.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/opensearch_vector_search.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 176.13K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:37 (27.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/opensearch_vector_search.html’ saved [180355]\n",
            "\n",
            "--2024-04-14 11:43:37--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pathway.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pathway.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.74K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:37 (5.60 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pathway.html’ saved [43768]\n",
            "\n",
            "--2024-04-14 11:43:37--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgembedding.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgembedding.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  94.01K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:37 (28.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgembedding.html’ saved [96270]\n",
            "\n",
            "--2024-04-14 11:43:37--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.96K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-04-14 11:43:37 (4.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html’ saved [48090]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 196.10K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:38 (13.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvector.html’ saved [200809]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pinecone.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pinecone.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  79.10K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:38 (13.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pinecone.html’ saved [80996]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/qdrant.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/qdrant.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 287.34K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:38 (21.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/qdrant.html’ saved [294235]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 183.47K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:38 (29.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/base.html’ saved [187873]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/filters.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/filters.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  79.57K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:38 (20.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/filters.html’ saved [81476]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/schema.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/schema.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  64.57K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:38 (18.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/redis/schema.html’ saved [66117]\n",
            "\n",
            "--2024-04-14 11:43:38--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/rocksetdb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/rocksetdb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  70.10K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:39 (8.63 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/rocksetdb.html’ saved [71781]\n",
            "\n",
            "--2024-04-14 11:43:39--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/scann.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/scann.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  88.39K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:39 (22.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/scann.html’ saved [90514]\n",
            "\n",
            "--2024-04-14 11:43:39--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/semadb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/semadb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  56.55K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:39 (10.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/semadb.html’ saved [57903]\n",
            "\n",
            "--2024-04-14 11:43:39--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/singlestoredb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/singlestoredb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  77.29K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:39 (19.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/singlestoredb.html’ saved [79146]\n",
            "\n",
            "--2024-04-14 11:43:39--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/sklearn.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/sklearn.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  74.26K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:39 (9.87 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/sklearn.html’ saved [76042]\n",
            "\n",
            "--2024-04-14 11:43:39--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/sqlitevss.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/sqlitevss.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.88K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:39 (7.48 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/sqlitevss.html’ saved [46977]\n",
            "\n",
            "--2024-04-14 11:43:39--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/starrocks.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/starrocks.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  86.65K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:40 (12.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/starrocks.html’ saved [88726]\n",
            "\n",
            "--2024-04-14 11:43:40--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/supabase.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/supabase.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  76.33K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:40 (9.07 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/supabase.html’ saved [78158]\n",
            "\n",
            "--2024-04-14 11:43:40--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/surrealdb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/surrealdb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  72.51K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:40 (6.01 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/surrealdb.html’ saved [74255]\n",
            "\n",
            "--2024-04-14 11:43:40--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tair.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tair.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  54.58K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:40 (1.73 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tair.html’ saved [55893]\n",
            "\n",
            "--2024-04-14 11:43:40--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tencentvectordb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tencentvectordb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 107.79K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:40 (15.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tencentvectordb.html’ saved [110372]\n",
            "\n",
            "--2024-04-14 11:43:40--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/thirdai_neuraldb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/thirdai_neuraldb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.08K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:41 (8.85 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/thirdai_neuraldb.html’ saved [60494]\n",
            "\n",
            "--2024-04-14 11:43:41--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tidb_vector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tidb_vector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  55.03K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:41 (6.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tidb_vector.html’ saved [56347]\n",
            "\n",
            "--2024-04-14 11:43:41--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tigris.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tigris.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.57K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:41 (5.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tigris.html’ saved [36420]\n",
            "\n",
            "--2024-04-14 11:43:41--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tiledb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tiledb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.38K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:41 (8.57 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/tiledb.html’ saved [129417]\n",
            "\n",
            "--2024-04-14 11:43:41--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/timescalevector.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/timescalevector.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 126.19K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-04-14 11:43:41 (13.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/timescalevector.html’ saved [129217]\n",
            "\n",
            "--2024-04-14 11:43:41--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/typesense.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/typesense.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.15K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:41 (9.04 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/typesense.html’ saved [52376]\n",
            "\n",
            "--2024-04-14 11:43:41--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/usearch.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/usearch.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.97K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:42 (6.16 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/usearch.html’ saved [40932]\n",
            "\n",
            "--2024-04-14 11:43:42--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.59K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:42 (5.75 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/utils.html’ saved [26205]\n",
            "\n",
            "--2024-04-14 11:43:42--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vald.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vald.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  65.38K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:42 (12.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vald.html’ saved [66953]\n",
            "\n",
            "--2024-04-14 11:43:42--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vdms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vdms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 229.31K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:42 (27.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vdms.html’ saved [234813]\n",
            "\n",
            "--2024-04-14 11:43:42--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vearch.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vearch.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  96.80K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:42 (14.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vearch.html’ saved [99125]\n",
            "\n",
            "--2024-04-14 11:43:42--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vectara.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vectara.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  90.82K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:43 (13.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vectara.html’ saved [92997]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vespa.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vespa.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.25K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-04-14 11:43:43 (6.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vespa.html’ saved [59651]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vikingdb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vikingdb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  80.33K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:43 (19.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/vikingdb.html’ saved [82260]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/weaviate.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/weaviate.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  88.66K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:43 (16.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/weaviate.html’ saved [90788]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/xata.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/xata.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  56.86K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:43 (24.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/xata.html’ saved [58227]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/yellowbrick.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/yellowbrick.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  57.78K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:43 (11.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/yellowbrick.html’ saved [59162]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/zep.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/zep.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 100.51K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:43:43 (4.09 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/zep.html’ saved [102920]\n",
            "\n",
            "--2024-04-14 11:43:43--  https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/zilliz.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/zilliz.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.05K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:44 (6.86 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/zilliz.html’ saved [34864]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/csv/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/csv/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.64K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:44 (8.11 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/csv/base.html’ saved [23182]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/pandas/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/pandas/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  57.35K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:44 (9.76 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/pandas/base.html’ saved [58729]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/python/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/python/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.73K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:44 (5.35 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/python/base.html’ saved [24298]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/spark/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/spark/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.49K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:44 (7.06 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/spark/base.html’ saved [27121]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/xorbits/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/xorbits/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  28.38K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:44 (10.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/agents/agent_toolkits/xorbits/base.html’ saved [29060]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  36.06K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:44 (7.43 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/agent.html’ saved [36927]\n",
            "\n",
            "--2024-04-14 11:43:44--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/memory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/memory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.21K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:45 (2.86 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/memory.html’ saved [20696]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/output_parser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/output_parser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.89K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:45 (5.71 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/output_parser.html’ saved [24461]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/prompt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/prompt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.14K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:45 (5.69 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/prompt.html’ saved [32911]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/prompt_generator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/prompt_generator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.54K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:45 (5.02 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/autogpt/prompt_generator.html’ saved [40493]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/baby_agi.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/baby_agi.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  52.25K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:45 (9.22 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/baby_agi.html’ saved [53507]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_creation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_creation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.99K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:45 (4.07 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_creation.html’ saved [19445]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_execution.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_execution.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.31K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:45 (3.87 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_execution.html’ saved [18748]\n",
            "\n",
            "--2024-04-14 11:43:45--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_prioritization.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_prioritization.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.71K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:46 (4.22 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/baby_agi/task_prioritization.html’ saved [19161]\n",
            "\n",
            "--2024-04-14 11:43:46--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/hugginggpt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/hugginggpt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.14K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:46 (2.91 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/hugginggpt.html’ saved [20628]\n",
            "\n",
            "--2024-04-14 11:43:46--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/repsonse_generator.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/repsonse_generator.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.03K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:43:46 (986 KB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/repsonse_generator.html’ saved [23587]\n",
            "\n",
            "--2024-04-14 11:43:46--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/task_executor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/task_executor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.08K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:46 (6.84 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/task_executor.html’ saved [45138]\n",
            "\n",
            "--2024-04-14 11:43:46--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/task_planner.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/task_planner.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.53K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:46 (7.16 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/autonomous_agents/hugginggpt/task_planner.html’ saved [45594]\n",
            "\n",
            "--2024-04-14 11:43:46--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/chat_models/llm_wrapper.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/chat_models/llm_wrapper.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  40.54K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:46 (5.26 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/chat_models/llm_wrapper.html’ saved [41511]\n",
            "\n",
            "--2024-04-14 11:43:46--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/amazon_comprehend_moderation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/amazon_comprehend_moderation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.84K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:47 (6.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/amazon_comprehend_moderation.html’ saved [33628]\n",
            "\n",
            "--2024-04-14 11:43:47--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.98K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:47 (8.33 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation.html’ saved [40944]\n",
            "\n",
            "--2024-04-14 11:43:47--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_callbacks.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_callbacks.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.43K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:47 (8.53 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_callbacks.html’ saved [25019]\n",
            "\n",
            "--2024-04-14 11:43:47--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_config.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_config.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.68K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:47 (5.13 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_config.html’ saved [21174]\n",
            "\n",
            "--2024-04-14 11:43:47--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_exceptions.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_exceptions.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.16K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:47 (7.72 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/base_moderation_exceptions.html’ saved [19617]\n",
            "\n",
            "--2024-04-14 11:43:47--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/pii.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/pii.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.80K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:48 (5.38 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/pii.html’ saved [38709]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/prompt_safety.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/prompt_safety.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.75K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:48 (4.80 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/prompt_safety.html’ saved [26367]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/toxicity.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/toxicity.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.38K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:43:48 (4.28 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/comprehend_moderation/toxicity.html’ saved [35200]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  54.10K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:48 (8.18 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/base.html’ saved [55402]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/constants.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/constants.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.46K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:48 (6.93 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/constants.html’ saved [15833]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  52.05K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:48 (4.99 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/cpal/models.html’ saved [53298]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.40K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:48 (7.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/base.html’ saved [22937]\n",
            "\n",
            "--2024-04-14 11:43:48--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_mapping.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_mapping.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.80K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:49 (11.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_mapping.html’ saved [33585]\n",
            "\n",
            "--2024-04-14 11:43:49--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/presidio.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/presidio.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  69.42K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:49 (11.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/presidio.html’ saved [71090]\n",
            "\n",
            "--2024-04-14 11:43:49--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_matching_strategies.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_matching_strategies.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  36.86K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:49 (11.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_matching_strategies.html’ saved [37747]\n",
            "\n",
            "--2024-04-14 11:43:49--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/faker_presidio_mapping.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/faker_presidio_mapping.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.30K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:49 (5.73 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/faker_presidio_mapping.html’ saved [29999]\n",
            "\n",
            "--2024-04-14 11:43:49--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/fallacy_removal/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/fallacy_removal/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.58K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:49 (13.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/fallacy_removal/base.html’ saved [38479]\n",
            "\n",
            "--2024-04-14 11:43:49--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/fallacy_removal/models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/fallacy_removal/models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  15.59K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:49 (7.95 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/fallacy_removal/models.html’ saved [15962]\n",
            "\n",
            "--2024-04-14 11:43:49--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/generative_agents/generative_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/generative_agents/generative_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.93K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:50 (16.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/generative_agents/generative_agent.html’ saved [61366]\n",
            "\n",
            "--2024-04-14 11:43:50--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/generative_agents/memory.html\n",
            "Connecting to api.python.langchain.com (api.python.langchain.com)|104.17.32.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/generative_agents/memory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  65.61K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:50 (4.36 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/generative_agents/memory.html’ saved [67188]\n",
            "\n",
            "--2024-04-14 11:43:50--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/diffbot.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/diffbot.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  54.08K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:50 (7.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/diffbot.html’ saved [55376]\n",
            "\n",
            "--2024-04-14 11:43:50--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/llm.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/llm.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  72.67K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:50 (6.41 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/graph_transformers/llm.html’ saved [74411]\n",
            "\n",
            "--2024-04-14 11:43:50--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.49K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:50 (11.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/base.html’ saved [33265]\n",
            "\n",
            "--2024-04-14 11:43:50--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/bash.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/bash.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.85K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:50 (7.23 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/bash.html’ saved [36707]\n",
            "\n",
            "--2024-04-14 11:43:50--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/prompt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/prompt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.00K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:51 (3.05 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_bash/prompt.html’ saved [22533]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_symbolic_math/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_symbolic_math/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.60K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:51 (13.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llm_symbolic_math/base.html’ saved [39530]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/anthropic_functions.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/anthropic_functions.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.70K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:51 (12.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/anthropic_functions.html’ saved [47820]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/jsonformer_decoder.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/jsonformer_decoder.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.67K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:51 (5.09 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/jsonformer_decoder.html’ saved [23217]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/llamaapi.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/llamaapi.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.59K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:51 (12.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/llamaapi.html’ saved [35416]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/lmformatenforcer_decoder.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/lmformatenforcer_decoder.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.21K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:51 (7.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/lmformatenforcer_decoder.html’ saved [24789]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/ollama_functions.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/ollama_functions.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.38K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:51 (8.68 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/ollama_functions.html’ saved [33160]\n",
            "\n",
            "--2024-04-14 11:43:51--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/rellm_decoder.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/rellm_decoder.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.80K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:51 (7.74 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/llms/rellm_decoder.html’ saved [23350]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/open_clip/open_clip.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/open_clip/open_clip.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  28.15K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:52 (5.92 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/open_clip/open_clip.html’ saved [28826]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/pal_chain/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/pal_chain/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.40K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:52 (12.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/pal_chain/base.html’ saved [59802]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/agent_executor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/agent_executor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.20K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:43:52 (1.61 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/agent_executor.html’ saved [30927]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/executors/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/executors/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.14K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:52 (8.00 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/executors/base.html’ saved [22676]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/planners/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/planners/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  23.28K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:52 (9.12 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/planners/base.html’ saved [23840]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/planners/chat_planner.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/planners/chat_planner.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.60K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:52 (7.27 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/planners/chat_planner.html’ saved [22120]\n",
            "\n",
            "--2024-04-14 11:43:52--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/schema.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/schema.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.12K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:53 (4.37 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/schema.html’ saved [24699]\n",
            "\n",
            "--2024-04-14 11:43:53--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/executors/agent_executor.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/executors/agent_executor.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.97K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:53 (4.35 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/plan_and_execute/executors/agent_executor.html’ saved [20448]\n",
            "\n",
            "--2024-04-14 11:43:53--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/prompt_injection_identifier/hugging_face_identifier.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/prompt_injection_identifier/hugging_face_identifier.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.87K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:53 (4.84 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/prompt_injection_identifier/hugging_face_identifier.html’ saved [27513]\n",
            "\n",
            "--2024-04-14 11:43:53--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/recommenders/amazon_personalize.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/recommenders/amazon_personalize.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.56K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:53 (6.75 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/recommenders/amazon_personalize.html’ saved [39482]\n",
            "\n",
            "--2024-04-14 11:43:53--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/recommenders/amazon_personalize_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/recommenders/amazon_personalize_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.31K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:43:53 (1.12 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/recommenders/amazon_personalize_chain.html’ saved [36160]\n",
            "\n",
            "--2024-04-14 11:43:53--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/retrievers/vector_sql_database.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/retrievers/vector_sql_database.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.53K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:53 (3.52 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/retrievers/vector_sql_database.html’ saved [19996]\n",
            "\n",
            "--2024-04-14 11:43:53--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 116.17K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:54 (15.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/base.html’ saved [118960]\n",
            "\n",
            "--2024-04-14 11:43:54--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/metrics.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/metrics.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.42K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:54 (9.40 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/metrics.html’ saved [30124]\n",
            "\n",
            "--2024-04-14 11:43:54--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/model_repository.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/model_repository.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.23K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:54 (8.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/model_repository.html’ saved [26861]\n",
            "\n",
            "--2024-04-14 11:43:54--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/pick_best_chain.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/pick_best_chain.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  84.41K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:54 (13.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/pick_best_chain.html’ saved [86436]\n",
            "\n",
            "--2024-04-14 11:43:54--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/vw_logger.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/vw_logger.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.77K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:54 (6.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/rl_chain/vw_logger.html’ saved [19222]\n",
            "\n",
            "--2024-04-14 11:43:54--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/smart_llm/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/smart_llm/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  66.03K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:54 (30.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/smart_llm/base.html’ saved [67618]\n",
            "\n",
            "--2024-04-14 11:43:54--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/sql/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/sql/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  61.44K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:55 (11.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/sql/base.html’ saved [62916]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/sql/vector_sql.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/sql/vector_sql.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  52.46K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:43:55 (7.19 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/sql/vector_sql.html’ saved [53717]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tabular_synthetic_data/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tabular_synthetic_data/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.79K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:55 (3.41 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tabular_synthetic_data/base.html’ saved [34596]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tabular_synthetic_data/openai.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tabular_synthetic_data/openai.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.85K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-04-14 11:43:55 (15.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tabular_synthetic_data/openai.html’ saved [21351]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/text_splitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/text_splitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.96K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:55 (8.22 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/text_splitter.html’ saved [53206]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tools/python/tool.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tools/python/tool.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.39K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:55 (11.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tools/python/tool.html’ saved [35217]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.44K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:55 (5.24 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/base.html’ saved [35266]\n",
            "\n",
            "--2024-04-14 11:43:55--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/checker.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/checker.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:55 (4.81 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/checker.html’ saved [20596]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/controller.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/controller.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  20.43K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:56 (7.28 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/controller.html’ saved [20916]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/memory.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/memory.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.84K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:56 (8.09 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/memory.html’ saved [23390]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/prompts.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/prompts.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.81K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:56 (9.80 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/prompts.html’ saved [28475]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/thought.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/thought.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.07K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:56 (6.85 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/thought.html’ saved [17478]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/thought_generation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/thought_generation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.55K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:56 (9.76 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/tot/thought_generation.html’ saved [27188]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/utilities/python.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/utilities/python.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.19K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:56 (9.92 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/utilities/python.html’ saved [24775]\n",
            "\n",
            "--2024-04-14 11:43:56--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.65K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:57 (7.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/base.html’ saved [34456]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.60K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:57 (8.44 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/models.html’ saved [42599]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/audio_service.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/audio_service.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.76K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:57 (8.73 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/audio_service.html’ saved [28428]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/caption_service.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/caption_service.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  53.19K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:57 (26.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/caption_service.html’ saved [54469]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/combine_service.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/combine_service.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.65K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:57 (5.25 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/combine_service.html’ saved [33431]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/image_service.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/image_service.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.93K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:57 (10.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/image_service.html’ saved [30653]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/srt_service.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/srt_service.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.18K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:57 (4.57 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_experimental/video_captioning/services/srt_service.html’ saved [17594]\n",
            "\n",
            "--2024-04-14 11:43:57--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  62.23K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:58 (11.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/base.html’ saved [63726]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  86.59K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:58 (19.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html’ saved [88664]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/html.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/html.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.21K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:43:58 (13.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/html.html’ saved [36051]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/json.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/json.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.17K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:58 (5.99 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/json.html’ saved [33968]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/konlpy.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/konlpy.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.78K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:58 (3.82 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/konlpy.html’ saved [19226]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/latex.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/latex.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.63K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:58 (4.36 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/latex.html’ saved [17032]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/markdown.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/markdown.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  44.64K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:43:58 (4.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/markdown.html’ saved [45710]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/nltk.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/nltk.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  18.96K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:58 (5.80 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/nltk.html’ saved [19413]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/python.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/python.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  16.67K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:58 (5.74 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/python.html’ saved [17065]\n",
            "\n",
            "--2024-04-14 11:43:58--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/sentence_transformers.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/sentence_transformers.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  26.79K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:59 (4.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/sentence_transformers.html’ saved [27429]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/spacy.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/spacy.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.53K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:43:59 (6.23 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_text_splitters/spacy.html’ saved [22043]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_ai21/ai21_base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/ai21_base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.10K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:43:59 (4.84 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/ai21_base.html’ saved [21604]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_ai21/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  39.59K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:59 (6.29 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/chat_models.html’ saved [40540]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_ai21/contextual_answers.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/contextual_answers.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.55K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:59 (4.32 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/contextual_answers.html’ saved [28216]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_ai21/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  24.12K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:43:59 (4.31 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/embeddings.html’ saved [24698]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_ai21/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.22K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:43:59 (5.82 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/llms.html’ saved [36068]\n",
            "\n",
            "--2024-04-14 11:43:59--  https://api.python.langchain.com/en/latest/_modules/langchain_ai21/semantic_text_splitter.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/semantic_text_splitter.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.52K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:00 (5.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_ai21/semantic_text_splitter.html’ saved [36373]\n",
            "\n",
            "--2024-04-14 11:44:00--  https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 105.18K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:00 (14.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html’ saved [107708]\n",
            "\n",
            "--2024-04-14 11:44:00--  https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/experimental.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/experimental.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.44K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:00 (6.88 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/experimental.html’ saved [36288]\n",
            "\n",
            "--2024-04-14 11:44:00--  https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.68K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:00 (8.48 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/llms.html’ saved [60087]\n",
            "\n",
            "--2024-04-14 11:44:00--  https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/output_parsers.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/output_parsers.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.82K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:00 (5.96 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_anthropic/output_parsers.html’ saved [26441]\n",
            "\n",
            "--2024-04-14 11:44:00--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/cache.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/cache.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  94.02K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:01 (12.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/cache.html’ saved [96272]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/chat_message_histories.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/chat_message_histories.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.95K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:01 (7.05 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/chat_message_histories.html’ saved [36816]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/document_loaders.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/document_loaders.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.04K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:01 (7.35 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/document_loaders.html’ saved [31787]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/storage.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/storage.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.33K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:01 (10.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/storage.html’ saved [52558]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/utils/astradb.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/utils/astradb.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  53.58K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-04-14 11:44:01 (27.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/utils/astradb.html’ saved [54861]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/utils/mmr.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/utils/mmr.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.51K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:01 (9.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/utils/mmr.html’ saved [30223]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_astradb/vectorstores.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/vectorstores.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 180.00K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:01 (17.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_astradb/vectorstores.html’ saved [184316]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_chroma/vectorstores.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_chroma/vectorstores.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 127.25K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:01 (16.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_chroma/vectorstores.html’ saved [130301]\n",
            "\n",
            "--2024-04-14 11:44:01--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  75.83K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:02 (11.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/chat_models.html’ saved [77653]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/cohere_agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/cohere_agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  45.84K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:02 (7.26 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/cohere_agent.html’ saved [46940]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/common.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/common.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  17.22K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:02 (4.54 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/common.html’ saved [17637]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  36.80K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:02 (5.67 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/embeddings.html’ saved [37679]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.33K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:02 (8.00 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/llms.html’ saved [47438]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/rag_retrievers.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/rag_retrievers.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  28.35K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2024-04-14 11:44:02 (3.18 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/rag_retrievers.html’ saved [29027]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  58.01K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:02 (5.91 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html’ saved [59406]\n",
            "\n",
            "--2024-04-14 11:44:02--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/agent.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/agent.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  27.81K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:03 (5.15 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/agent.html’ saved [28478]\n",
            "\n",
            "--2024-04-14 11:44:03--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/prompt.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/prompt.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  55.05K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:03 (6.40 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/prompt.html’ saved [56374]\n",
            "\n",
            "--2024-04-14 11:44:03--  https://api.python.langchain.com/en/latest/_modules/langchain_cohere/rerank.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/rerank.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  29.45K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:03 (6.62 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_cohere/rerank.html’ saved [30152]\n",
            "\n",
            "--2024-04-14 11:44:03--  https://api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/chat_history.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/chat_history.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.09K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:03 (11.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/chat_history.html’ saved [35932]\n",
            "\n",
            "--2024-04-14 11:44:03--  https://api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/client.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/client.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  19.54K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:03 (7.63 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/client.html’ saved [20014]\n",
            "\n",
            "--2024-04-14 11:44:03--  https://api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  34.15K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:03 (8.19 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/embeddings.html’ saved [34971]\n",
            "\n",
            "--2024-04-14 11:44:03--  https://api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/retrievers.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/retrievers.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.42K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:04 (6.44 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/retrievers.html’ saved [34225]\n",
            "\n",
            "--2024-04-14 11:44:04--  https://api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/vectorstores.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/vectorstores.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 180.92K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:04 (26.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_elasticsearch/vectorstores.html’ saved [185265]\n",
            "\n",
            "--2024-04-14 11:44:04--  https://api.python.langchain.com/en/latest/_modules/langchain_exa/retrievers.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_exa/retrievers.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  28.43K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:04 (7.29 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_exa/retrievers.html’ saved [29109]\n",
            "\n",
            "--2024-04-14 11:44:04--  https://api.python.langchain.com/en/latest/_modules/langchain_exa/tools.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_exa/tools.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  32.72K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:04 (5.61 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_exa/tools.html’ saved [33509]\n",
            "\n",
            "--2024-04-14 11:44:04--  https://api.python.langchain.com/en/latest/_modules/langchain_fireworks/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_fireworks/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 138.93K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:04 (18.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_fireworks/chat_models.html’ saved [142269]\n",
            "\n",
            "--2024-04-14 11:44:04--  https://api.python.langchain.com/en/latest/_modules/langchain_fireworks/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_fireworks/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.94K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:44:04 (1.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_fireworks/embeddings.html’ saved [22462]\n",
            "\n",
            "--2024-04-14 11:44:04--  https://api.python.langchain.com/en/latest/_modules/langchain_fireworks/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_fireworks/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  43.60K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:05 (7.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_fireworks/llms.html’ saved [44651]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_genai/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 105.20K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:05 (14.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/chat_models.html’ saved [107729]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_genai/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.01K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:05 (8.20 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/embeddings.html’ saved [30728]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_genai/genai_aqa.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/genai_aqa.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  28.74K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:05 (10.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/genai_aqa.html’ saved [29428]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_genai/google_vector_store.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/google_vector_store.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  77.37K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:44:05 (2.70 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/google_vector_store.html’ saved [79230]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_genai/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.16K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:05 (10.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_genai/llms.html’ saved [64672]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/callbacks.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/callbacks.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  25.98K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:05 (4.65 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/callbacks.html’ saved [26604]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/chains.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/chains.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  31.49K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:05 (5.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/chains.html’ saved [32243]\n",
            "\n",
            "--2024-04-14 11:44:05--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 144.21K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:06 (17.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/chat_models.html’ saved [147674]\n",
            "\n",
            "--2024-04-14 11:44:06--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  70.65K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:06 (12.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/embeddings.html’ saved [72341]\n",
            "\n",
            "--2024-04-14 11:44:06--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/functions_utils.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/functions_utils.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.07K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:06 (9.37 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/functions_utils.html’ saved [38982]\n",
            "\n",
            "--2024-04-14 11:44:06--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/gemma.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/gemma.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  72.05K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:06 (9.94 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/gemma.html’ saved [73775]\n",
            "\n",
            "--2024-04-14 11:44:06--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  60.38K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:06 (8.53 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/llms.html’ saved [61827]\n",
            "\n",
            "--2024-04-14 11:44:06--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/model_garden.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/model_garden.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  51.48K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:06 (6.33 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/model_garden.html’ saved [52714]\n",
            "\n",
            "--2024-04-14 11:44:06--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vectorstores/document_storage.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vectorstores/document_storage.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  49.07K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:44:07 (2.44 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vectorstores/document_storage.html’ saved [50247]\n",
            "\n",
            "--2024-04-14 11:44:07--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vectorstores/vectorstores.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vectorstores/vectorstores.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  61.90K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:07 (9.44 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vectorstores/vectorstores.html’ saved [63384]\n",
            "\n",
            "--2024-04-14 11:44:07--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vision_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vision_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  83.41K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:07 (11.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/vision_models.html’ saved [85411]\n",
            "\n",
            "--2024-04-14 11:44:07--  https://api.python.langchain.com/en/latest/_modules/langchain_groq/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_groq/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 147.09K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:07 (17.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_groq/chat_models.html’ saved [150617]\n",
            "\n",
            "--2024-04-14 11:44:07--  https://api.python.langchain.com/en/latest/_modules/langchain_mistralai/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_mistralai/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 108.51K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:07 (14.0 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_mistralai/chat_models.html’ saved [111114]\n",
            "\n",
            "--2024-04-14 11:44:07--  https://api.python.langchain.com/en/latest/_modules/langchain_mistralai/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_mistralai/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  37.92K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:07 (5.87 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_mistralai/embeddings.html’ saved [38832]\n",
            "\n",
            "--2024-04-14 11:44:07--  https://api.python.langchain.com/en/latest/_modules/langchain_nomic/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nomic/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  22.87K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:08 (4.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nomic/embeddings.html’ saved [23417]\n",
            "\n",
            "--2024-04-14 11:44:08--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/callbacks.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/callbacks.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  52.50K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:08 (13.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/callbacks.html’ saved [53759]\n",
            "\n",
            "--2024-04-14 11:44:08--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/chat_models.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/chat_models.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  87.11K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:08 (7.33 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/chat_models.html’ saved [89204]\n",
            "\n",
            "--2024-04-14 11:44:08--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.82K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:08 (5.09 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/embeddings.html’ saved [34632]\n",
            "\n",
            "--2024-04-14 11:44:08--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/image_gen.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/image_gen.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.38K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:08 (5.90 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/image_gen.html’ saved [34185]\n",
            "\n",
            "--2024-04-14 11:44:08--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/llm.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/llm.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  47.07K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:08 (6.85 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/llm.html’ saved [48203]\n",
            "\n",
            "--2024-04-14 11:44:08--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/tools.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/tools.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  38.02K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:09 (6.95 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/tools.html’ saved [38932]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_trt/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_trt/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  77.79K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:09 (15.3 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_trt/llms.html’ saved [79662]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_openai/chat_models/azure.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/chat_models/azure.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  48.35K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:09 (13.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/chat_models/azure.html’ saved [49512]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_openai/chat_models/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/chat_models/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 170.31K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:44:09 (6.63 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/chat_models/base.html’ saved [174396]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_openai/embeddings/azure.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/embeddings/azure.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  35.74K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:44:09 (1.54 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/embeddings/azure.html’ saved [36599]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_openai/embeddings/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/embeddings/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  96.12K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:09 (16.1 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/embeddings/base.html’ saved [98426]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_openai/llms/azure.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/llms/azure.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  41.99K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:09 (8.59 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/llms/azure.html’ saved [42993]\n",
            "\n",
            "--2024-04-14 11:44:09--  https://api.python.langchain.com/en/latest/_modules/langchain_openai/llms/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/llms/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 106.72K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-04-14 11:44:10 (3.61 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_openai/llms/base.html’ saved [109280]\n",
            "\n",
            "--2024-04-14 11:44:10--  https://api.python.langchain.com/en/latest/_modules/langchain_pinecone/vectorstores.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_pinecone/vectorstores.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  78.83K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:10 (14.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_pinecone/vectorstores.html’ saved [80726]\n",
            "\n",
            "--2024-04-14 11:44:10--  https://api.python.langchain.com/en/latest/_modules/langchain_postgres/chat_message_histories.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_postgres/chat_message_histories.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  59.73K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:10 (10.5 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_postgres/chat_message_histories.html’ saved [61168]\n",
            "\n",
            "--2024-04-14 11:44:10--  https://api.python.langchain.com/en/latest/_modules/langchain_postgres/checkpoint.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_postgres/checkpoint.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  82.15K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2024-04-14 11:44:10 (13.8 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_postgres/checkpoint.html’ saved [84122]\n",
            "\n",
            "--2024-04-14 11:44:10--  https://api.python.langchain.com/en/latest/_modules/langchain_postgres/vectorstores.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_postgres/vectorstores.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 189.94K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:10 (22.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_postgres/vectorstores.html’ saved [194499]\n",
            "\n",
            "--2024-04-14 11:44:10--  https://api.python.langchain.com/en/latest/_modules/langchain_robocorp/toolkits.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_robocorp/toolkits.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  46.81K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:11 (9.47 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_robocorp/toolkits.html’ saved [47932]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/langchain_together/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_together/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  21.43K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:11 (6.38 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_together/embeddings.html’ saved [21943]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/langchain_together/llms.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_together/llms.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  42.56K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:11 (7.97 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_together/llms.html’ saved [43583]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/langchain_voyageai/embeddings.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_voyageai/embeddings.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.86K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:11 (4.61 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_voyageai/embeddings.html’ saved [34674]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/langchain_voyageai/rerank.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_voyageai/rerank.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  33.68K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-14 11:44:11 (9.06 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_voyageai/rerank.html’ saved [34485]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/index.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/index.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 168.47K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:11 (24.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/index.html’ saved [172514]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/_markupbase.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/_markupbase.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  71.96K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2024-04-14 11:44:11 (13.7 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/_markupbase.html’ saved [73690]\n",
            "\n",
            "--2024-04-14 11:44:11--  https://api.python.langchain.com/en/latest/_modules/ast.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/ast.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 280.83K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:12 (23.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/ast.html’ saved [287573]\n",
            "\n",
            "--2024-04-14 11:44:12--  https://api.python.langchain.com/en/latest/_modules/concurrent/futures/thread.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/concurrent/futures/thread.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  43.53K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:44:12 (1.96 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/concurrent/futures/thread.html’ saved [44574]\n",
            "\n",
            "--2024-04-14 11:44:12--  https://api.python.langchain.com/en/latest/_modules/html/parser.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/html/parser.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  80.22K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:12 (6.42 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/html/parser.html’ saved [82145]\n",
            "\n",
            "--2024-04-14 11:44:12--  https://api.python.langchain.com/en/latest/_modules/langchain_core/_api/deprecation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_core/_api/deprecation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  63.56K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:12 (4.97 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_core/_api/deprecation.html’ saved [65087]\n",
            "\n",
            "--2024-04-14 11:44:12--  https://api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/_base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/_base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  54.73K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:12 (7.74 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_google_vertexai/_base.html’ saved [56048]\n",
            "\n",
            "--2024-04-14 11:44:12--  https://api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/_common.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/_common.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 143.10K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:13 (20.2 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langchain_nvidia_ai_endpoints/_common.html’ saved [146536]\n",
            "\n",
            "--2024-04-14 11:44:13--  https://api.python.langchain.com/en/latest/_modules/langgraph/checkpoint/base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langgraph/checkpoint/base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  30.34K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-14 11:44:13 (9.91 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/langgraph/checkpoint/base.html’ saved [31064]\n",
            "\n",
            "--2024-04-14 11:44:13--  https://api.python.langchain.com/en/latest/_modules/pydantic/fields.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-04-14 11:44:13 ERROR 404: Not Found.\n",
            "\n",
            "--2024-04-14 11:44:13--  https://api.python.langchain.com/en/latest/_modules/pydantic/main.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-04-14 11:44:13 ERROR 404: Not Found.\n",
            "\n",
            "--2024-04-14 11:44:13--  https://api.python.langchain.com/en/latest/_modules/queue.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/queue.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  47.78K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:13 (7.03 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/queue.html’ saved [48922]\n",
            "\n",
            "--2024-04-14 11:44:13--  https://api.python.langchain.com/en/latest/_modules/sqlalchemy/orm/decl_base.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/sqlalchemy/orm/decl_base.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 280.68K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-14 11:44:13 (18.4 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/sqlalchemy/orm/decl_base.html’ saved [287415]\n",
            "\n",
            "--2024-04-14 11:44:13--  https://api.python.langchain.com/en/latest/_modules/sqlalchemy/orm/instrumentation.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/sqlalchemy/orm/instrumentation.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 107.48K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-14 11:44:14 (12.9 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/sqlalchemy/orm/instrumentation.html’ saved [110063]\n",
            "\n",
            "--2024-04-14 11:44:14--  https://api.python.langchain.com/en/latest/_modules/string.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/string.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ]  48.63K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-14 11:44:14 (6.55 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/string.html’ saved [49802]\n",
            "\n",
            "--2024-04-14 11:44:14--  https://api.python.langchain.com/en/latest/_modules/typing.html\n",
            "Reusing existing connection to api.python.langchain.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/typing.html’\n",
            "\n",
            "api.python.langchai     [ <=>                ] 344.50K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-14 11:44:14 (20.6 MB/s) - ‘./drive/docs4colab/MyDrive/docs4colab/api.python.langchain.com/en/latest/_modules/typing.html’ saved [352767]\n",
            "\n",
            "FINISHED --2024-04-14 11:44:14--\n",
            "Total wall clock time: 9m 27s\n",
            "Downloaded: 4157 files, 330M in 31s (10.6 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# долговременная процедура прочитать все файлы из файловой структуры скачанного сайта\n",
        "# заняло 27 минут\n",
        "# прочитать все файлы из локальной папки folder_path\n",
        "loader = ReadTheDocsLoader(folder_path)\n",
        "docs = loader.load()\n",
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLBRLzIDaAmP",
        "outputId": "05b07ede-3b86-4ebd-f81e-02f6d4b45ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4157"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, encoding_name: str=\"cl100k_base\") -> int:\n",
        "    \"\"\"Возвращает количество токенов в строке\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ],
      "metadata": {
        "id": "5TMWBqJWcqiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка, как можно сопоставить локальные документы с соответствующими интернет-ресурсами\n",
        "print(docs[0])\n",
        "print(docs[0].page_content)\n",
        "# сейчас в метаданных сохранен полный локальный путь\n",
        "# можно заменить folder_path на https:// и тогда обращаться к оригинальному документу на сайте\n",
        "print(folder_path)\n",
        "print(docs[0].metadata['source'].replace(f'{folder_path}/'[2:], 'https://'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beeR1rlga_4v",
        "outputId": "9b0b00b5-a569-4ea5-ceaa-4e55dd4a6c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='' metadata={'source': 'drive/MyDrive/docs4colab/api.python.langchain.com/en/stable/index.html'}\n",
            "\n",
            "./drive/MyDrive/docs4colab\n",
            "https://api.python.langchain.com/en/stable/index.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# т.к. ответы консультанта будут касаться кода питон, то полезно иметь\n",
        "# раскраску кода питон с помощбю библиотеки cdnjs\n",
        "def wrap(code,ind=\"\",startend=True):\n",
        "    startchunk=f\"startchunk[{ind}]\"\n",
        "    html1 = \"\"\"\n",
        "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
        "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
        "    <script>hljs.highlightAll();</script>\n",
        "    \"\"\"\n",
        "    if startend:\n",
        "        html2=f\"\"\"</br>{startchunk:=^50}</br>{code}{\"endchunk\":=^50}</br>\"\"\"\n",
        "    else:\n",
        "        html2=f\"\"\"{code}\"\"\"\n",
        "    return html1+html2\n",
        "# display(HTML(f\"<div>{}</div>\"))"
      ],
      "metadata": {
        "id": "DBf0LC4Qgr5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## изучение базы знаний"
      ],
      "metadata": {
        "id": "w4tnQKQEc-vH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет токенов для каждого фрагмента и построение графика\n",
        "fragment_token_counts = [num_tokens_from_string(doc.page_content) for doc in docs]\n",
        "plt.hist(fragment_token_counts, bins=50, alpha=0.5, label='Fragments')\n",
        "plt.title('Distribution of Token Counts by ReadTheDocsLoader')\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7o3YZGP9d1iu",
        "outputId": "90212d0a-97f3-48bc-920e-b8849d8181be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# есть очень длинные документы\n",
        "bigchunks=[]\n",
        "for i,count in enumerate(fragment_token_counts):\n",
        "    if count > 15000:\n",
        "        bigchunks.append(i)\n",
        "        print(f\"{count}[{i}]\",end=\" \")\n",
        "len(bigchunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE98LtYnfQsN",
        "outputId": "dbc9b932-71ea-4022-d932-f3fd72f01769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32121[29] 20396[834] 21321[2747] 36699[3055] 16993[3083] 18063[3892] 15534[4156] "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# распределение размеров чанков с отброшенными наиболее крупными\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if item not in bigchunks]\n",
        "plt.hist([fragment_token_counts[i] for i in new_list], bins=50, alpha=0.5, label='Fragments')\n",
        "plt.title('Distribution of Token Counts by ReadTheDocsLoader')\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "EbHhapB2tuN_",
        "outputId": "0b210926-e78e-44a5-a1d5-af1fcd491d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAHHCAYAAABjvibXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQQ0lEQVR4nO3de3zP9f//8ft7dt7s4LDNclrIucipRSmWOSWlj9RipEjkGPGpCEmRQxTSp1BR6KvyUTkr0nKe86kIYZvSNiMb2/P3h99eH28bZl5ss9v1cnlfLt7P1/P9ej1ez/dhd8/X6/16O4wxRgAAALCNS14XAAAAcKshYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNg3cJef/11ORyOm7KtBx54QA888IB1/4cffpDD4dCXX355U7bfuXNnlS9f/qZsK7dSUlL07LPPKiQkRA6HQ3379r2h28t8/v/8888buh1c2c1+L+QnM2fOlMPh0O+//37Nj+3cubN8fX3tLwo5dunnOq4NAauAyPygyrx5enoqNDRUkZGRmjRpkk6dOmXLdo4dO6bXX39dsbGxtqzPTvm5tpx48803NXPmTPXo0UOffvqpOnbsmKVPZii62q2gfujFx8frpZdeUpUqVeTt7S0fHx/VqVNHb7zxhhITE/O6PEnSnDlzNHHixLwu45pd+tpxc3NT+fLl1bt373wxtpd+hl3udiP/o/TAAw9Y23FxcZGfn58qV66sjh07atmyZTdsu9eifPnyat26dV6XARu45nUBuDYjRoxQWFiYzp07p7i4OP3www/q27evxo8fr4ULF+rOO++0+r766qsaPHjwNa3/2LFjGj58uMqXL69atWrl+HFLly69pu3kxpVq+/DDD5WRkXHDa7geK1eu1D333KNhw4Zdts9jjz2mihUrWvdTUlLUo0cPPfroo3rssces9uDg4Bta642wYcMGtWzZUikpKXr66adVp04dSdLGjRv11ltvafXq1TfldXQ1c+bM0Y4dO274DOONMnXqVPn6+ur06dNasWKFJk+erM2bN+unn37K07ruv/9+ffrpp05tzz77rOrXr69u3bpZbTd61qp06dIaPXq0JOn06dP69ddftWDBAn322Wdq3769PvvsM7m5ud3QGlA4ELAKmBYtWqhu3brW/SFDhmjlypVq3bq12rRpo927d8vLy0uS5OrqKlfXG/sUnzlzRt7e3nJ3d7+h27magvCBmJCQoGrVql2xz5133ukUkv/880/16NFDd955p55++ukbXeINk5iYqEcffVRFihTRli1bVKVKFaflo0aN0ocffphH1d1aHn/8cZUoUUKS1L17d3Xo0EFz587V+vXrVb9+/Tyr6/bbb9ftt9/u1Pb888/r9ttvv6mvbX9//yzbe+utt9S7d29NmTJF5cuX19tvv33T6iksMjIylJaWJk9Pz7wu5abhEOEtoEmTJnrttdd06NAhffbZZ1Z7dudgLVu2TI0aNVJAQIB8fX1VuXJl/fvf/5Z04VyRevXqSZK6dOliTaXPnDlT0oXp9Ro1amjTpk26//775e3tbT32csfq09PT9e9//1shISHy8fFRmzZtdOTIEac+5cuXV+fOnbM89uJ1Xq227M7BOn36tAYMGKAyZcrIw8NDlStX1jvvvCNjjFM/h8OhXr166euvv1aNGjXk4eGh6tWra/HixdkP+CUSEhLUtWtXBQcHy9PTU3fddZdmzZplLc88B+fgwYP69ttvrdpzc15KppUrV+q+++6Tj4+PAgIC9Mgjj2j37t1XfdyhQ4dUsWJF1ahRQ/Hx8ZIuhJ++ffta41SxYkW9/fbbTjOCv//+uxwOh9555x1Nnz5dFSpUkIeHh+rVq6cNGzZcdbsffPCBjh49qvHjx2cJV9KFGblXX33VqW3KlCmqXr26PDw8FBoaqp49e2Y51JWT1470v+dg3rx5GjVqlEqXLi1PT081bdpUv/76q9Pjvv32Wx06dCjbQ1aTJ09W9erV5e3trcDAQNWtW1dz5sy56v5LV38vDBs2TG5ubjpx4kSWx3br1k0BAQE6e/ZsjrZ1sfvuu0+S9Ntvvzm1r1u3Ts2bN5e/v7+8vb3VuHFjrV271qnPoUOH9MILL6hy5cry8vJS8eLF9a9//Svb1+7OnTvVpEkTeXl5qXTp0nrjjTdsmVU+evSo2rZtK19fX5UsWVIvvfSS0tPTnfpkZGRo4sSJql69ujw9PRUcHKzu3bvr77//ztE2ihQpokmTJqlatWp67733lJSUZC07f/68Ro4cab3my5cvr3//+99KTU3Nsp7vv/9ejRs3VtGiReXn56d69eo5vT7279+vdu3aKSQkRJ6enipdurQ6dOjgtL2cyGlN33zzjVq1aqXQ0FB5eHioQoUKGjlyZJbxk2S9r728vFS/fn2tWbMm222npqZq2LBhqlixojw8PFSmTBkNGjQoy7YzP1dnz55tvY9z+pl6q2AG6xbRsWNH/fvf/9bSpUv13HPPZdtn586dat26te68806NGDFCHh4e+vXXX60P1apVq2rEiBEaOnSounXrZn0w33vvvdY6/vrrL7Vo0UIdOnTQ008/fdVDVaNGjZLD4dDLL7+shIQETZw4UREREYqNjbVm2nIiJ7VdzBijNm3aaNWqVeratatq1aqlJUuWaODAgTp69KgmTJjg1P+nn37SggUL9MILL6ho0aKaNGmS2rVrp8OHD6t48eKXreuff/7RAw88oF9//VW9evVSWFiY5s+fr86dOysxMVF9+vRR1apV9emnn6pfv34qXbq0BgwYIEkqWbJkjvf/YsuXL1eLFi10++236/XXX9c///yjyZMnq2HDhtq8efNlz2H57bff1KRJExUrVkzLli1TiRIldObMGTVu3FhHjx5V9+7dVbZsWf38888aMmSIjh8/nuVcpDlz5ujUqVPq3r27HA6HxowZo8cee0wHDhy44iziwoUL5eXlpccffzxH+/j6669r+PDhioiIUI8ePbR3715NnTpVGzZs0Nq1a3M9Y/nWW2/JxcVFL730kpKSkjRmzBhFRUVp3bp1kqRXXnlFSUlJ+uOPP6zXSOYhqw8//FC9e/fW448/rj59+ujs2bPatm2b1q1bp6eeeuqq277ae6Fjx44aMWKE5s6dq169elmPS0tL05dffql27drl6n//mWEoMDDQalu5cqVatGihOnXqaNiwYXJxcdGMGTPUpEkTrVmzxprp2rBhg37++Wd16NBBpUuX1u+//66pU6fqgQce0K5du+Tt7S1JiouL04MPPqjz589r8ODB8vHx0fTp06/pPZ6d9PR0RUZGqkGDBnrnnXe0fPlyjRs3ThUqVFCPHj2sft27d9fMmTPVpUsX9e7dWwcPHtR7772nLVu25Pj1UqRIET355JN67bXX9NNPP6lVq1aSLhzGnDVrlh5//HENGDBA69at0+jRo7V792599dVX1uNnzpypZ555RtWrV9eQIUMUEBCgLVu2aPHixXrqqaeUlpamyMhIpaam6sUXX1RISIiOHj2qRYsWKTExUf7+/jkel2upydfXV/3795evr69WrlypoUOHKjk5WWPHjrX6ffTRR+revbvuvfde9e3bVwcOHFCbNm1UrFgxlSlTxuqXkZGhNm3a6KefflK3bt1UtWpVbd++XRMmTNC+ffv09ddfO9W5cuVKzZs3T7169VKJEiXy/ReRbGdQIMyYMcNIMhs2bLhsH39/f1O7dm3r/rBhw8zFT/GECROMJHPixInLrmPDhg1GkpkxY0aWZY0bNzaSzLRp07Jd1rhxY+v+qlWrjCRz2223meTkZKt93rx5RpJ59913rbZy5cqZ6Ojoq67zSrVFR0ebcuXKWfe//vprI8m88cYbTv0ef/xx43A4zK+//mq1STLu7u5ObVu3bjWSzOTJk7Ns62ITJ040ksxnn31mtaWlpZnw8HDj6+vrtO/lypUzrVq1uuL6LnXixAkjyQwbNsxqq1WrlgkKCjJ//fWXU70uLi6mU6dOVlvm83/ixAmze/duExoaaurVq2dOnjxp9Rk5cqTx8fEx+/btc9ru4MGDTZEiRczhw4eNMcYcPHjQSDLFixd3evw333xjJJn//ve/V9yPwMBAc9ddd+VonxMSEoy7u7tp1qyZSU9Pt9rfe+89I8l8/PHHVltOXzuZr8eqVaua1NRUq/3dd981ksz27duttlatWjm9ljI98sgjpnr16jnah4tdy3shPDzcNGjQwOnxCxYsMJLMqlWrrridzOd779695sSJE+b33383H3/8sfHy8jIlS5Y0p0+fNsYYk5GRYSpVqmQiIyNNRkaG9fgzZ86YsLAw89BDDzm1XSomJsZIMp988onV1rdvXyPJrFu3zmpLSEgw/v7+RpI5ePBgtjX7+Phk+/wZc+E9LcmMGDHCqb127dqmTp061v01a9YYSWb27NlO/RYvXpylvXHjxld8Dr/66iun5yQ2NtZIMs8++6xTv5deeslIMitXrjTGGJOYmGiKFi1qGjRoYP755x+nvpljvGXLFiPJzJ8//7LbN+bqnxM5rcmY7J+/7t27G29vb3P27FljzIXPq6CgIFOrVi2n98b06dONJKf30aeffmpcXFzMmjVrnNY5bdo0I8msXbvWapNkXFxczM6dO6+4v7cyDhHeQnx9fa/4bcKAgABJF6aNczt17+HhoS5duuS4f6dOnVS0aFHr/uOPP65SpUrpu+++y9X2c+q7775TkSJF1Lt3b6f2AQMGyBij77//3qk9IiJCFSpUsO7feeed8vPz04EDB666nZCQED355JNWm5ubm3r37q2UlBT9+OOPNuzN/xw/flyxsbHq3LmzihUr5lTvQw89lO247tixQ40bN1b58uW1fPlyp5mM+fPn67777lNgYKD+/PNP6xYREaH09HStXr3aaV1PPPGE0+MzZxKvNk7JyclOr4MrWb58udLS0tS3b1+5uPzvI+q5556Tn5+fvv322xytJztdunRxOl8wp/VLF94/f/zxR44OiWYnJ++FTp06ad26dU6H82bPnq0yZcqocePGOdpO5cqVVbJkSZUvX17PPPOMKlasqO+//96abYqNjdX+/fv11FNP6a+//rKe89OnT6tp06ZavXq19flw8QzUuXPn9Ndff6lixYoKCAjQ5s2brWXfffed7rnnHqdzvEqWLKmoqKhrHKWsnn/+eaf79913n9PzNX/+fPn7++uhhx5yeg3XqVNHvr6+WrVqVY63lTlbmfk5mvnc9O/f36lf5ix05mtx2bJlOnXqlAYPHpxlljHzNI3MGaolS5bozJkzOa7pUjmtSXJ+/k6dOqU///xT9913n86cOaM9e/ZIuvAlk4SEBD3//PNO743OnTtnmVWbP3++qlatqipVqjiNdZMmTSQpy1g3btz4qued3soIWLeQlJSUK/4Re+KJJ9SwYUM9++yzCg4OVocOHTRv3rxrClu33XbbNZ3QXqlSJaf7DodDFStWvK7zj3Li0KFDCg0NzTIeVatWtZZfrGzZslnWERgYeNVzOA4dOqRKlSo5BYErbed6Za6vcuXKWZZVrVrV+kN5sYcfflhFixbVkiVL5Ofn57Rs//79Wrx4sUqWLOl0i4iIkHTh/LKLXTpOmWHrauPk5+eX40uJXG4f3d3ddfvtt1/XmOa2fkl6+eWX5evrq/r166tSpUrq2bNnlnOWriQn74UnnnhCHh4emj17tiQpKSlJixYtUlRUVI6vafd///d/WrZsmebMmaN77rlHCQkJTn9o9+/fL0mKjo7O8rz/5z//UWpqqnVO0D///KOhQ4da5+eVKFFCJUuWVGJiotN5Q5nvg0tl9zq9Fp6enlkOpV/6vty/f7+SkpIUFBSUZX9SUlKyvIavJCUlRZKsz41Dhw7JxcXF6Zu9khQSEqKAgADrtZgZiGvUqHHZdYeFhal///76z3/+oxIlSigyMlLvv//+NZ9/ldOapAunhTz66KPy9/eXn5+fSpYsaZ3gn7ndzP6XPn9ubm5ZvpSwf/9+7dy5M8s433HHHZKyfl6EhYVd077dajgH6xbxxx9/KCkpKcub7mJeXl5avXq1Vq1apW+//VaLFy/W3Llz1aRJEy1dulRFihS56nau95yK7FzuD0d6enqOarLD5bZjLjkhviBq166dZs2apdmzZ6t79+5OyzIyMvTQQw9p0KBB2T4284MzU27HqUqVKoqNjVVaWpqt3zi91tfO9TzPVatW1d69e7Vo0SItXrxY//d//6cpU6Zo6NChGj58+LUVfhmBgYFq3bq1Zs+eraFDh+rLL79UamrqNX3L7v7777e+Rfjwww+rZs2aioqK0qZNm+Ti4mL9h2rs2LGXvRRL5kzOiy++qBkzZqhv374KDw+Xv7+/HA6HOnTocFMui5KT939GRoaCgoKsUHqpaznXcceOHZKU5XPUrgs2jxs3Tp07d9Y333yjpUuXqnfv3ho9erR++eUXlS5d+prWdbWaEhMT1bhxY/n5+WnEiBGqUKGCPD09tXnzZr388su5ev4yMjJUs2ZNjR8/PtvlF5+vJd2YvxcFCQHrFpF5fZnIyMgr9nNxcVHTpk3VtGlTjR8/Xm+++aZeeeUVrVq1ShEREbZf+T3zf8uZjDH69ddfnS5FEBgYmO2FEA8dOuT0P6hrqa1cuXJavny5Tp065TSLlTktXq5cuRyv62rb2bZtmzIyMpxmsezezsXbk6S9e/dmWbZnzx6VKFFCPj4+Tu1jx46Vq6urdQL/xSdkV6hQQSkpKdaM1Y3y8MMPKyYmRv/3f//ndDg1Oxfv48XPf1pamg4ePOhUa05fO9fiSq8zHx8fPfHEE3riiSeUlpamxx57TKNGjdKQIUOuegJ6Tt4L0oXDhI888og2bNig2bNnq3bt2qpevXqu9sXX11fDhg1Tly5dNG/ePHXo0ME6FO7n53fV5/3LL79UdHS0xo0bZ7WdPXs2y5iXK1cuy/5J2b9O7VahQgUtX75cDRs2vK4/6Onp6ZozZ468vb3VqFEjSRf2KyMjQ/v377dmpaULF8xNTEy0XquZY7pjx44r/idXkmrWrKmaNWvq1Vdf1c8//6yGDRtq2rRpeuONN3JUZ05r+uGHH/TXX39pwYIFuv/++61+Bw8ezLI+6cLrM/NQn3ThkPDBgwd11113WW0VKlTQ1q1b1bRp05v2KyEFGYcIbwErV67UyJEjFRYWdsVzHk6ePJmlLfN/sJlfsc3842zXlZ8/+eQTp0NDX375pY4fP64WLVpYbRUqVNAvv/yitLQ0q23RokVZLudwLbW1bNlS6enpeu+995zaJ0yYIIfD4bT969GyZUvFxcVp7ty5Vtv58+c1efJk+fr65vi8mZwqVaqUatWqpVmzZjmNw44dO7R06VK1bNkyy2McDoemT5+uxx9/XNHR0Vq4cKG1rH379oqJidGSJUuyPC4xMVHnz5+3pe7nn39epUqV0oABA7Rv374syxMSEqw/MBEREXJ3d9ekSZOcZpY++ugjJSUlWd/uknL+2rkWPj4+2R62+euvv5zuu7u7q1q1ajLG6Ny5c1ddb07eC9KFa92VKFFCb7/9tn788cfrvkZUVFSUSpcubV3bqU6dOqpQoYLeeecd65DYxS6+TESRIkWyzO5Nnjw5y9f8W7ZsqV9++UXr1693Ws/lZpXs1L59e6Wnp2vkyJFZlp0/fz5Hnxfp6enq3bu3du/erd69e1uH0jPfT5d+mzZzBifztdisWTMVLVpUo0ePznIpjczxS05OzvJ+qlmzplxcXLK95MPl5LSmzNm/i5+/tLQ0TZkyxelxdevWVcmSJTVt2jSn99HMmTOzjF379u119OjRbK9Z988//2Q5PaGwYwargPn++++1Z88enT9/XvHx8Vq5cqWWLVumcuXKaeHChVf8X/SIESO0evVqtWrVSuXKlVNCQoKmTJmi0qVLW/9jq1ChggICAjRt2jQVLVpUPj4+atCgQa6PpRcrVkyNGjVSly5dFB8fr4kTJ6pixYpOl5J49tln9eWXX6p58+Zq3769fvvtN3322WdOJ51fa20PP/ywHnzwQb3yyiv6/fffddddd2np0qX65ptv1Ldv3yzrzq1u3brpgw8+UOfOnbVp0yaVL19eX375pdauXauJEyfm+MTuazF27Fi1aNFC4eHh6tq1q3WZBn9/f73++uvZPsbFxUWfffaZ2rZtq/bt2+u7775TkyZNNHDgQC1cuFCtW7dW586dVadOHZ0+fVrbt2/Xl19+qd9//9063HQ9AgMD9dVXX6lly5aqVauW05XcN2/erM8//1zh4eGSLhzSGTJkiIYPH67mzZurTZs22rt3r6ZMmaJ69eo5BY6cvnauRZ06dTR37lz1799f9erVk6+vrx5++GE1a9ZMISEhatiwoYKDg7V792699957atWqVY6e55y8F6QL57506NBB7733nnXpgOvh5uamPn36aODAgVq8eLGaN2+u//znP2rRooWqV6+uLl266LbbbtPRo0e1atUq+fn56b///a8kqXXr1vr000/l7++vatWqKSYmRsuXL89y6ZJBgwbp008/VfPmzdWnTx/rMg2ZM7w3UuPGjdW9e3eNHj1asbGxatasmdzc3LR//37Nnz9f7777rtPlQZKSkqzrBZ45c8a6kvtvv/2mDh06OAW1u+66S9HR0Zo+fbp1yG39+vWaNWuW2rZtqwcffFDShdnACRMm6Nlnn1W9evX01FNPKTAwUFu3btWZM2c0a9YsrVy5Ur169dK//vUv3XHHHTp//rw+/fRTFSlSRO3atXPap19//TXbGa3atWurVatWOarp3nvvVWBgoKKjo9W7d285HA59+umnWQKzm5ub3njjDXXv3l1NmjTRE088oYMHD2rGjBlZZoE7duyoefPm6fnnn9eqVavUsGFDpaena8+ePZo3b56WLFnidCHsQi9vvryIa5V5mYbMm7u7uwkJCTEPPfSQeffdd52+/p3p0ss0rFixwjzyyCMmNDTUuLu7m9DQUPPkk09m+Yr+N998Y6pVq2ZcXV2dLotwpa84X+5r8Z9//rkZMmSICQoKMl5eXqZVq1bm0KFDWR4/btw4c9tttxkPDw/TsGFDs3HjxizrvFJtl16mwRhjTp06Zfr162dCQ0ONm5ubqVSpkhk7dqzTV9ONufB14p49e2ap6XKXALhUfHy86dKliylRooRxd3c3NWvWzPZSEnZdpsEYY5YvX24aNmxovLy8jJ+fn3n44YfNrl27nPpcfJmGTGfOnDGNGzc2vr6+5pdffjHGXBinIUOGmIoVKxp3d3dTokQJc++995p33nnHpKWlGWP+d5mGsWPHZqkxu/ou59ixY6Zfv37mjjvuMJ6ensbb29vUqVPHjBo1yiQlJTn1fe+990yVKlWMm5ubCQ4ONj169DB///13lnXm5LWT+Xq89Cvymft18fOVkpJinnrqKRMQEGAkWa+rDz74wNx///2mePHixsPDw1SoUMEMHDgwS92Xutb3gjHGrF+/3kgyzZo1u+K6L5bd850pKSnJ+Pv7O43Jli1bzGOPPWbtT7ly5Uz79u3NihUrrD5///239dr29fU1kZGRZs+ePdm+N7Zt22YaN25sPD09zW233WZGjhxpPvroo+u6TIOPj89l9/NS06dPN3Xq1DFeXl6maNGipmbNmmbQoEHm2LFjVp/MS81k3nx9fU2lSpXM008/bZYuXZptHefOnTPDhw83YWFhxs3NzZQpU8YMGTLEuszBxRYuXGjuvfde631Zv3598/nnnxtjjDlw4IB55plnTIUKFYynp6cpVqyYefDBB83y5cud1lGuXDmnGi++de3a9ZpqWrt2rbnnnnuMl5eXCQ0NNYMGDTJLlizJ9rIfU6ZMMWFhYcbDw8PUrVvXrF69OtvP4LS0NPP222+b6tWrGw8PDxMYGGjq1Kljhg8f7vReuNznamHiMOYWOIsXAG4hW7duVa1atfTJJ59k+6PgAPI/zsECgHzmww8/lK+vr9MPfAMoWDgHCwDyif/+97/atWuXpk+frl69emX5RiiAgoNDhACQT5QvX17x8fGKjIzUp59+ekO+JAHg5iBgAQAA2IxzsAAAAGxGwAIAALAZJ7nnQEZGho4dO6aiRYvy8wAAABQQxhidOnVKoaGhTj9ndjMQsHLg2LFjWX7EEgAAFAxHjhy55h/Uvl4ErBzI/CbPkSNHrN+oAgAA+VtycrLKlCmTJ9/IJWDlQOZhQT8/PwIWAAAFTF6c3sNJ7gAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2CxPA9bq1av18MMPKzQ0VA6HQ19//bXTcmOMhg4dqlKlSsnLy0sRERHav3+/U5+TJ08qKipKfn5+CggIUNeuXZWSkuLUZ9u2bbrvvvvk6empMmXKaMyYMTd61wAAQCGWpwHr9OnTuuuuu/T+++9nu3zMmDGaNGmSpk2bpnXr1snHx0eRkZE6e/as1ScqKko7d+7UsmXLtGjRIq1evVrdunWzlicnJ6tZs2YqV66cNm3apLFjx+r111/X9OnTb/j+AQCAwslhjDF5XYR04YcYv/rqK7Vt21bShdmr0NBQDRgwQC+99JIkKSkpScHBwZo5c6Y6dOig3bt3q1q1atqwYYPq1q0rSVq8eLFatmypP/74Q6GhoZo6dapeeeUVxcXFyd3dXZI0ePBgff3119qzZ0+OaktOTpa/v7+SkpL4sWcAAAqIvPz7nW/PwTp48KDi4uIUERFhtfn7+6tBgwaKiYmRJMXExCggIMAKV5IUEREhFxcXrVu3zupz//33W+FKkiIjI7V37179/fffN2lvAABAYeKa1wVcTlxcnCQpODjYqT04ONhaFhcXp6CgIKflrq6uKlasmFOfsLCwLOvIXBYYGJhl26mpqUpNTbXuJycnX+feAACAwiTfBqy8NHr0aA0fPvymbW/Csn1X7dPvoTtuQiUAAMAO+fYQYUhIiCQpPj7eqT0+Pt5aFhISooSEBKfl58+f18mTJ536ZLeOi7dxqSFDhigpKcm6HTly5Pp3CAAAFBr5NmCFhYUpJCREK1assNqSk5O1bt06hYeHS5LCw8OVmJioTZs2WX1WrlypjIwMNWjQwOqzevVqnTt3zuqzbNkyVa5cOdvDg5Lk4eEhPz8/pxsAAEBO5WnASklJUWxsrGJjYyVdOLE9NjZWhw8flsPhUN++ffXGG29o4cKF2r59uzp16qTQ0FDrm4ZVq1ZV8+bN9dxzz2n9+vVau3atevXqpQ4dOig0NFSS9NRTT8nd3V1du3bVzp07NXfuXL377rvq379/Hu01AAC41eXpOVgbN27Ugw8+aN3PDD3R0dGaOXOmBg0apNOnT6tbt25KTExUo0aNtHjxYnl6elqPmT17tnr16qWmTZvKxcVF7dq106RJk6zl/v7+Wrp0qXr27Kk6deqoRIkSGjp0qNO1sgAAAOyUb66DlZ/d6OtocJI7AAD24zpYAAAAtxACFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2CxfB6z09HS99tprCgsLk5eXlypUqKCRI0fKGGP1McZo6NChKlWqlLy8vBQREaH9+/c7refkyZOKioqSn5+fAgIC1LVrV6WkpNzs3QEAAIVEvg5Yb7/9tqZOnar33ntPu3fv1ttvv60xY8Zo8uTJVp8xY8Zo0qRJmjZtmtatWycfHx9FRkbq7NmzVp+oqCjt3LlTy5Yt06JFi7R69Wp169YtL3YJAAAUAg5z8XRQPtO6dWsFBwfro48+stratWsnLy8vffbZZzLGKDQ0VAMGDNBLL70kSUpKSlJwcLBmzpypDh06aPfu3apWrZo2bNigunXrSpIWL16sli1b6o8//lBoaOhV60hOTpa/v7+SkpLk5+dn+35OWLbvqn36PXSH7dsFAOBWdqP/fl9Jvp7Buvfee7VixQrt23chgGzdulU//fSTWrRoIUk6ePCg4uLiFBERYT3G399fDRo0UExMjCQpJiZGAQEBVriSpIiICLm4uGjdunXZbjc1NVXJyclONwAAgJxyzesCrmTw4MFKTk5WlSpVVKRIEaWnp2vUqFGKioqSJMXFxUmSgoODnR4XHBxsLYuLi1NQUJDTcldXVxUrVszqc6nRo0dr+PDhdu8OAAAoJPL1DNa8efM0e/ZszZkzR5s3b9asWbP0zjvvaNasWTd0u0OGDFFSUpJ1O3LkyA3dHgAAuLXk6xmsgQMHavDgwerQoYMkqWbNmjp06JBGjx6t6OhohYSESJLi4+NVqlQp63Hx8fGqVauWJCkkJEQJCQlO6z1//rxOnjxpPf5SHh4e8vDwuAF7BAAACoN8PYN15swZubg4l1ikSBFlZGRIksLCwhQSEqIVK1ZYy5OTk7Vu3TqFh4dLksLDw5WYmKhNmzZZfVauXKmMjAw1aNDgJuwFAAAobPL1DNbDDz+sUaNGqWzZsqpevbq2bNmi8ePH65lnnpEkORwO9e3bV2+88YYqVaqksLAwvfbaawoNDVXbtm0lSVWrVlXz5s313HPPadq0aTp37px69eqlDh065OgbhAAAANcqXwesyZMn67XXXtMLL7yghIQEhYaGqnv37ho6dKjVZ9CgQTp9+rS6deumxMRENWrUSIsXL5anp6fVZ/bs2erVq5eaNm0qFxcXtWvXTpMmTcqLXQIAAIVAvr4OVn7BdbAAACh4uA4WAADALYSABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYLFcB68CBA3bXAQAAcMvIVcCqWLGiHnzwQX322Wc6e/as3TUBAAAUaLkKWJs3b9add96p/v37KyQkRN27d9f69evtrk2SdPToUT399NMqXry4vLy8VLNmTW3cuNFabozR0KFDVapUKXl5eSkiIkL79+93WsfJkycVFRUlPz8/BQQEqGvXrkpJSbkh9QIAAOQqYNWqVUvvvvuujh07po8//ljHjx9Xo0aNVKNGDY0fP14nTpywpbi///5bDRs2lJubm77//nvt2rVL48aNU2BgoNVnzJgxmjRpkqZNm6Z169bJx8dHkZGRTjNrUVFR2rlzp5YtW6ZFixZp9erV6tatmy01AgAAXMphjDHXu5LU1FRNmTJFQ4YMUVpamtzd3dW+fXu9/fbbKlWqVK7XO3jwYK1du1Zr1qzJdrkxRqGhoRowYIBeeuklSVJSUpKCg4M1c+ZMdejQQbt371a1atW0YcMG1a1bV5K0ePFitWzZUn/88YdCQ0OvWkdycrL8/f2VlJQkPz+/XO/P5UxYtu+qffo9dIft2wUA4FZ2o/9+X8l1fYtw48aNeuGFF1SqVCmNHz9eL730kn777TctW7ZMx44d0yOPPHJdxS1cuFB169bVv/71LwUFBal27dr68MMPreUHDx5UXFycIiIirDZ/f381aNBAMTExkqSYmBgFBARY4UqSIiIi5OLionXr1l1XfQAAANlxzc2Dxo8frxkzZmjv3r1q2bKlPvnkE7Vs2VIuLhfyWlhYmGbOnKny5ctfV3EHDhzQ1KlT1b9/f/373//Whg0b1Lt3b7m7uys6OlpxcXGSpODgYKfHBQcHW8vi4uIUFBTktNzV1VXFihWz+lwqNTVVqamp1v3k5OTr2g8AAFC45CpgTZ06Vc8884w6d+582UOAQUFB+uijj66ruIyMDNWtW1dvvvmmJKl27drasWOHpk2bpujo6Ota95WMHj1aw4cPv2HrBwAAt7ZcHSLcv3+/hgwZcsXzqzJnma5HqVKlVK1aNae2qlWr6vDhw5KkkJAQSVJ8fLxTn/j4eGtZSEiIEhISnJafP39eJ0+etPpcasiQIUpKSrJuR44cua79AAAAhUuuAtaMGTM0f/78LO3z58/XrFmzrruoTA0bNtTevXud2vbt26dy5cpJunAoMiQkRCtWrLCWJycna926dQoPD5ckhYeHKzExUZs2bbL6rFy5UhkZGWrQoEG22/Xw8JCfn5/TDQAAIKdyFbBGjx6tEiVKZGkPCgqyDufZoV+/fvrll1/05ptv6tdff9WcOXM0ffp09ezZU5LkcDjUt29fvfHGG1q4cKG2b9+uTp06KTQ0VG3btpV0YcarefPmeu6557R+/XqtXbtWvXr1UocOHXL0DUIAAIBrlatzsA4fPqywsLAs7eXKlbMO39mhXr16+uqrrzRkyBCNGDFCYWFhmjhxoqKioqw+gwYN0unTp9WtWzclJiaqUaNGWrx4sTw9Pa0+s2fPVq9evdS0aVO5uLioXbt2mjRpkm11AgAAXCxXASsoKEjbtm3L8i3BrVu3qnjx4nbUZWndurVat2592eUOh0MjRozQiBEjLtunWLFimjNnjq11AQAAXE6uDhE++eST6t27t1atWqX09HSlp6dr5cqV6tOnjzp06GB3jQAAAAVKrmawRo4cqd9//11NmzaVq+uFVWRkZKhTp062noMFAABQEOUqYLm7u2vu3LkaOXKktm7dav0Ic+a3+wAAAAqzXAWsTHfccYfuuIPfyAMAALhYrgJWenq6Zs6cqRUrVighIUEZGRlOy1euXGlLcQAAAAVRrgJWnz59NHPmTLVq1Uo1atSQw+Gwuy4AAIACK1cB64svvtC8efPUsmVLu+sBAAAo8HJ1mQZ3d3dVrFjR7loAAABuCbkKWAMGDNC7774rY4zd9QAAABR4uTpE+NNPP2nVqlX6/vvvVb16dbm5uTktX7BggS3FAQAAFES5ClgBAQF69NFH7a4FAADglpCrgDVjxgy76wAAALhl5OocLEk6f/68li9frg8++ECnTp2SJB07dkwpKSm2FQcAAFAQ5WoG69ChQ2revLkOHz6s1NRUPfTQQypatKjefvttpaamatq0aXbXCQAAUGDkagarT58+qlu3rv7++295eXlZ7Y8++qhWrFhhW3EAAAAFUa5msNasWaOff/5Z7u7uTu3ly5fX0aNHbSkMAACgoMrVDFZGRobS09OztP/xxx8qWrTodRcFAABQkOUqYDVr1kwTJ0607jscDqWkpGjYsGH8fA4AACj0cnWIcNy4cYqMjFS1atV09uxZPfXUU9q/f79KlCihzz//3O4aAQAACpRcBazSpUtr69at+uKLL7Rt2zalpKSoa9euioqKcjrpHQAAoDDKVcCSJFdXVz399NN21gIAAHBLyFXA+uSTT664vFOnTrkqBgAA4FaQq4DVp08fp/vnzp3TmTNn5O7uLm9vbwIWAAAo1HL1LcK///7b6ZaSkqK9e/eqUaNGnOQOAAAKvVz/FuGlKlWqpLfeeivL7BYAAEBhY1vAki6c+H7s2DE7VwkAAFDg5OocrIULFzrdN8bo+PHjeu+999SwYUNbCgMAACiochWw2rZt63Tf4XCoZMmSatKkicaNG2dHXQAAAAVWrgJWRkaG3XUAAADcMmw9BwsAAAC5nMHq379/jvuOHz8+N5sAAAAosHIVsLZs2aItW7bo3Llzqly5siRp3759KlKkiO6++26rn8PhsKdKAACAAiRXAevhhx9W0aJFNWvWLAUGBkq6cPHRLl266L777tOAAQNsLRIAAKAgydU5WOPGjdPo0aOtcCVJgYGBeuONN/gWIQAAKPRyFbCSk5N14sSJLO0nTpzQqVOnrrsoAACAgixXAevRRx9Vly5dtGDBAv3xxx/6448/9H//93/q2rWrHnvsMbtrBAAAKFBydQ7WtGnT9NJLL+mpp57SuXPnLqzI1VVdu3bV2LFjbS0QAACgoMlVwPL29taUKVM0duxY/fbbb5KkChUqyMfHx9biAAAACqLrutDo8ePHdfz4cVWqVEk+Pj4yxthVFwAAQIGVq4D1119/qWnTprrjjjvUsmVLHT9+XJLUtWtXLtEAAAAKvVwFrH79+snNzU2HDx+Wt7e31f7EE09o8eLFthUHAABQEOXqHKylS5dqyZIlKl26tFN7pUqVdOjQIVsKAwAAKKhyNYN1+vRpp5mrTCdPnpSHh8d1FwUAAFCQ5Spg3Xffffrkk0+s+w6HQxkZGRozZowefPBB24oDAAAoiHJ1iHDMmDFq2rSpNm7cqLS0NA0aNEg7d+7UyZMntXbtWrtrBAAAKFByNYNVo0YN7du3T40aNdIjjzyi06dP67HHHtOWLVtUoUIFu2sEAAAoUK55BuvcuXNq3ry5pk2bpldeeeVG1AQAAFCgXfMMlpubm7Zt23YjagEAALgl5OoQ4dNPP62PPvrI7loAAABuCbk6yf38+fP6+OOPtXz5ctWpUyfLbxCOHz/eluIAAAAKomsKWAcOHFD58uW1Y8cO3X333ZKkffv2OfVxOBz2VQfLhGX7rtqn30N33IRKAADA1VxTwKpUqZKOHz+uVatWSbrw0ziTJk1ScHDwDSkOAACgILqmc7CMMU73v//+e50+fdrWggAAAAq6XJ3knunSwAUAAIBrDFgOhyPLOVaccwUAAODsms7BMsaoc+fO1g86nz17Vs8//3yWbxEuWLDAvgoBAAAKmGsKWNHR0U73n376aVuLAQAAuBVcU8CaMWPGjaoDAADglnFdJ7kDAAAgKwIWAACAzQpUwHrrrbfkcDjUt29fq+3s2bPq2bOnihcvLl9fX7Vr107x8fFOjzt8+LBatWolb29vBQUFaeDAgTp//vxNrh4AABQWufotwrywYcMGffDBB7rzzjud2vv166dvv/1W8+fPl7+/v3r16qXHHntMa9eulSSlp6erVatWCgkJ0c8//6zjx4+rU6dOcnNz05tvvpkXu3LD8HM6AADkDwViBislJUVRUVH68MMPFRgYaLUnJSXpo48+0vjx49WkSRPVqVNHM2bM0M8//6xffvlFkrR06VLt2rVLn332mWrVqqUWLVpo5MiRev/995WWlpZXuwQAAG5hBSJg9ezZU61atVJERIRT+6ZNm3Tu3Dmn9ipVqqhs2bKKiYmRJMXExKhmzZpOv5cYGRmp5ORk7dy5M9vtpaamKjk52ekGAACQU/n+EOEXX3yhzZs3a8OGDVmWxcXFyd3dXQEBAU7twcHBiouLs/pc+mPUmfcz+1xq9OjRGj58uA3VAwCAwihfz2AdOXJEffr00ezZs+Xp6XnTtjtkyBAlJSVZtyNHjty0bQMAgIIvXwesTZs2KSEhQXfffbdcXV3l6uqqH3/8UZMmTZKrq6uCg4OVlpamxMREp8fFx8crJCREkhQSEpLlW4WZ9zP7XMrDw0N+fn5ONwAAgJzK1wGradOm2r59u2JjY61b3bp1FRUVZf3bzc1NK1assB6zd+9eHT58WOHh4ZKk8PBwbd++XQkJCVafZcuWyc/PT9WqVbvp+wQAAG59+focrKJFi6pGjRpObT4+PipevLjV3rVrV/Xv31/FihWTn5+fXnzxRYWHh+uee+6RJDVr1kzVqlVTx44dNWbMGMXFxenVV19Vz549rR+tBgAAsFO+Dlg5MWHCBLm4uKhdu3ZKTU1VZGSkpkyZYi0vUqSIFi1apB49eig8PFw+Pj6Kjo7WiBEj8rBqAABwK3MYY0xeF5HfJScny9/fX0lJSTfkfKycXCDULlxoFABQWNzov99Xkq/PwQIAACiICFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNXPO6AOQ/E5btu2qffg/dcRMqAQCgYGIGCwAAwGYELAAAAJsRsAAAAGxGwAIAALAZAQsAAMBmBCwAAACbEbAAAABsRsACAACwGQELAADAZgQsAAAAmxGwAAAAbEbAAgAAsBkBCwAAwGYELAAAAJsRsAAAAGxGwAIAALAZAQsAAMBmBCwAAACbueZ1ASiYJizbd9U+/R664yZUAgBA/sMMFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgM9e8LgA314Rl+/K6BAAAbnnMYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYLF8HrNGjR6tevXoqWrSogoKC1LZtW+3du9epz9mzZ9WzZ08VL15cvr6+ateuneLj4536HD58WK1atZK3t7eCgoI0cOBAnT9//mbuCgAAKETydcD68ccf1bNnT/3yyy9atmyZzp07p2bNmun06dNWn379+um///2v5s+frx9//FHHjh3TY489Zi1PT09Xq1atlJaWpp9//lmzZs3SzJkzNXTo0LzYJQAAUAg4jDEmr4vIqRMnTigoKEg//vij7r//fiUlJalkyZKaM2eOHn/8cUnSnj17VLVqVcXExOiee+7R999/r9atW+vYsWMKDg6WJE2bNk0vv/yyTpw4IXd396tuNzk5Wf7+/kpKSpKfn5/t+3WrXpuq30N35HUJAIBC7Eb//b6SfD2DdamkpCRJUrFixSRJmzZt0rlz5xQREWH1qVKlisqWLauYmBhJUkxMjGrWrGmFK0mKjIxUcnKydu7cme12UlNTlZyc7HQDAADIqQITsDIyMtS3b181bNhQNWrUkCTFxcXJ3d1dAQEBTn2Dg4MVFxdn9bk4XGUuz1yWndGjR8vf39+6lSlTxua9AQAAt7ICE7B69uypHTt26Isvvrjh2xoyZIiSkpKs25EjR274NgEAwK2jQPwWYa9evbRo0SKtXr1apUuXttpDQkKUlpamxMREp1ms+Ph4hYSEWH3Wr1/vtL7Mbxlm9rmUh4eHPDw8bN4LAABQWOTrgGWM0YsvvqivvvpKP/zwg8LCwpyW16lTR25ublqxYoXatWsnSdq7d68OHz6s8PBwSVJ4eLhGjRqlhIQEBQUFSZKWLVsmPz8/VatW7ebuUCGTk5P3OREeAHArytcBq2fPnpozZ46++eYbFS1a1Dpnyt/fX15eXvL391fXrl3Vv39/FStWTH5+fnrxxRcVHh6ue+65R5LUrFkzVatWTR07dtSYMWMUFxenV199VT179mSWCgAA3BD5OmBNnTpVkvTAAw84tc+YMUOdO3eWJE2YMEEuLi5q166dUlNTFRkZqSlTplh9ixQpokWLFqlHjx4KDw+Xj4+PoqOjNWLEiJu1GwAAoJApUNfByitcB+vG4RAhAOBG4TpYAAAAtxACFgAAgM0IWAAAADYjYAEAANiMgAUAAGCzfH2ZBgDA9eGCv0DeYAYLAADAZgQsAAAAmxGwAAAAbEbAAgAAsBkBCwAAwGYELAAAAJsRsAAAAGxGwAIAALAZAQsAAMBmBCwAAACbEbAAAABsRsACAACwGQELAADAZgQsAAAAmxGwAAAAbEbAAgAAsBkBCwAAwGYELAAAAJsRsAAAAGxGwAIAALAZAQsAAMBmBCwAAACbEbAAAABsRsACAACwGQELAADAZq55XQAAAHllwrJ9V+3T76E7bkIluNUQsJCn+HADANyKOEQIAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADbjOli4JXA9LQBAfsIMFgAAgM2YwUK+l5PZKQAA8hMCFgDkMxzytgf/OUNeImABAAocwhPyOwIWABRABAwgfyNgAcBNRDACCgcCFgoNzmsBANwsBCwAAK6A/5whN7gOFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzTnIHLsLJrAAAOxCwgBvArmsdEeYAoGAiYAH52M28KCVhDrixmCEvXAhYwDXiStwAgKshYAFAIcfMyvXjP164FAELAJCvFOawQti9dRSqgPX+++9r7NixiouL01133aXJkyerfv36eV0WkC/wwQ4A9ik0AWvu3Lnq37+/pk2bpgYNGmjixImKjIzU3r17FRQUlNflAQVCQfx2JMERQF4oNAFr/Pjxeu6559SlSxdJ0rRp0/Ttt9/q448/1uDBg/O4OgC5cTMPJRXmw1bIX/hPQ8FQKAJWWlqaNm3apCFDhlhtLi4uioiIUExMTB5WBhRO+S2s5Ld6Cir+8ONyCuNro1AErD///FPp6ekKDg52ag8ODtaePXuy9E9NTVVqaqp1PykpSZKUnJx8Q+o7ezrlhqwXAOwy+uvN+Wo9uLKc/L16f+WvN6GSnLsRf2Mz12mMsX3dV1MoAta1Gj16tIYPH56lvUyZMnlQDQAA1+bfeV1ALtzImk+dOiV/f/8buIWsCkXAKlGihIoUKaL4+Hin9vj4eIWEhGTpP2TIEPXv39+6n5GRoZMnT6p48eJyOBy21pacnKwyZcroyJEj8vPzs3XdBQ1j4Yzx+B/Gwhnj8T+Mxf8wFs4yx2PXrl0KDQ296dsvFAHL3d1dderU0YoVK9S2bVtJF0LTihUr1KtXryz9PTw85OHh4dQWEBBwQ2v08/PjDfH/MRbOGI//YSycMR7/w1j8D2Ph7LbbbpOLi8tN326hCFiS1L9/f0VHR6tu3bqqX7++Jk6cqNOnT1vfKgQAALBLoQlYTzzxhE6cOKGhQ4cqLi5OtWrV0uLFi7Oc+A4AAHC9Ck3AkqRevXple0gwL3l4eGjYsGFZDkkWRoyFM8bjfxgLZ4zH/zAW/8NYOMvr8XCYvPjuIgAAwC3s5p/1BQAAcIsjYAEAANiMgAUAAGAzAhYAAIDNCFh56P3331f58uXl6empBg0aaP369Xld0nUbPXq06tWrp6JFiyooKEht27bV3r17nfqcPXtWPXv2VPHixeXr66t27dplucr+4cOH1apVK3l7eysoKEgDBw7U+fPnnfr88MMPuvvuu+Xh4aGKFStq5syZN3r3rstbb70lh8Ohvn37Wm2FbSyOHj2qp59+WsWLF5eXl5dq1qypjRs3WsuNMRo6dKhKlSolLy8vRUREaP/+/U7rOHnypKKiouTn56eAgAB17dpVKSnOv+e5bds23XffffL09FSZMmU0ZsyYm7J/OZWenq7XXntNYWFh8vLyUoUKFTRy5Ein30u7lcdi9erVevjhhxUaGiqHw6Gvv/7aafnN3Pf58+erSpUq8vT0VM2aNfXdd9/Zvr9XcqWxOHfunF5++WXVrFlTPj4+Cg0NVadOnXTs2DGndRSGsbjU888/L4fDoYkTJzq156uxMMgTX3zxhXF3dzcff/yx2blzp3nuuedMQECAiY+Pz+vSrktkZKSZMWOG2bFjh4mNjTUtW7Y0ZcuWNSkpKVaf559/3pQpU8asWLHCbNy40dxzzz3m3nvvtZafP3/e1KhRw0RERJgtW7aY7777zpQoUcIMGTLE6nPgwAHj7e1t+vfvb3bt2mUmT55sihQpYhYvXnxT9zen1q9fb8qXL2/uvPNO06dPH6u9MI3FyZMnTbly5Uznzp3NunXrzIEDB8ySJUvMr7/+avV56623jL+/v/n666/N1q1bTZs2bUxYWJj5559/rD7Nmzc3d911l/nll1/MmjVrTMWKFc2TTz5pLU9KSjLBwcEmKirK7Nixw3z++efGy8vLfPDBBzd1f69k1KhRpnjx4mbRokXm4MGDZv78+cbX19e8++67Vp9beSy+++4788orr5gFCxYYSearr75yWn6z9n3t2rWmSJEiZsyYMWbXrl3m1VdfNW5ubmb79u03fAwyXWksEhMTTUREhJk7d67Zs2ePiYmJMfXr1zd16tRxWkdhGIuLLViwwNx1110mNDTUTJgwwWlZfhoLAlYeqV+/vunZs6d1Pz093YSGhprRo0fnYVX2S0hIMJLMjz/+aIy58IHh5uZm5s+fb/XZvXu3kWRiYmKMMRfeZC4uLiYuLs7qM3XqVOPn52dSU1ONMcYMGjTIVK9e3WlbTzzxhImMjLzRu3TNTp06ZSpVqmSWLVtmGjdubAWswjYWL7/8smnUqNFll2dkZJiQkBAzduxYqy0xMdF4eHiYzz//3BhjzK5du4wks2HDBqvP999/bxwOhzl69KgxxpgpU6aYwMBAa3wyt125cmW7dynXWrVqZZ555hmntscee8xERUUZYwrXWFz6h/Rm7nv79u1Nq1atnOpp0KCB6d69u637mFNXChWZ1q9fbySZQ4cOGWMK31j88ccf5rbbbjM7duww5cqVcwpY+W0sOESYB9LS0rRp0yZFRERYbS4uLoqIiFBMTEweVma/pKQkSVKxYsUkSZs2bdK5c+ec9r1KlSoqW7aste8xMTGqWbOm01X2IyMjlZycrJ07d1p9Ll5HZp/8OH49e/ZUq1atstRb2MZi4cKFqlu3rv71r38pKChItWvX1ocffmgtP3jwoOLi4pz2xd/fXw0aNHAaj4CAANWtW9fqExERIRcXF61bt87qc//998vd3d3qExkZqb179+rvv/++0buZI/fee69WrFihffv2SZK2bt2qn376SS1atJBUuMbiUjdz3wvKe+diSUlJcjgc1u/jFqaxyMjIUMeOHTVw4EBVr149y/L8NhYErDzw559/Kj09PcvP9AQHBysuLi6PqrJfRkaG+vbtq4YNG6pGjRqSpLi4OLm7u2f58eyL9z0uLi7bsclcdqU+ycnJ+ueff27E7uTKF198oc2bN2v06NFZlhW2sThw4ICmTp2qSpUqacmSJerRo4d69+6tWbNmSfrf/lzpfREXF6egoCCn5a6uripWrNg1jVleGzx4sDp06KAqVarIzc1NtWvXVt++fRUVFSWpcI3FpW7mvl+uT34dm7Nnz+rll1/Wk08+af2Yc2Eai7fffluurq7q3bt3tsvz21gUqp/Kwc3Vs2dP7dixQz/99FNel5Injhw5oj59+mjZsmXy9PTM63LyXEZGhurWras333xTklS7dm3t2LFD06ZNU3R0dB5Xd3PNmzdPs2fP1pw5c1S9enXFxsaqb9++Cg0NLXRjgZw5d+6c2rdvL2OMpk6dmtfl3HSbNm3Su+++q82bN8vhcOR1OTnCDFYeKFGihIoUKZLl22Lx8fEKCQnJo6rs1atXLy1atEirVq1S6dKlrfaQkBClpaUpMTHRqf/F+x4SEpLt2GQuu1IfPz8/eXl52b07ubJp0yYlJCTo7rvvlqurq1xdXfXjjz9q0qRJcnV1VXBwcKEZC0kqVaqUqlWr5tRWtWpVHT58WNL/9udK74uQkBAlJCQ4LT9//rxOnjx5TWOW1wYOHGjNYtWsWVMdO3ZUv379rJnOwjQWl7qZ+365PvltbDLD1aFDh7Rs2TJr9koqPGOxZs0aJSQkqGzZstbn6aFDhzRgwACVL19eUv4bCwJWHnB3d1edOnW0YsUKqy0jI0MrVqxQeHh4HlZ2/Ywx6tWrl7766iutXLlSYWFhTsvr1KkjNzc3p33fu3evDh8+bO17eHi4tm/f7vRGyfxQyfwDHR4e7rSOzD75afyaNm2q7du3KzY21rrVrVtXUVFR1r8Ly1hIUsOGDbNcsmPfvn0qV66cJCksLEwhISFO+5KcnKx169Y5jUdiYqI2bdpk9Vm5cqUyMjLUoEEDq8/q1at17tw5q8+yZctUuXJlBQYG3rD9uxZnzpyRi4vzx2+RIkWUkZEhqXCNxaVu5r4XhPdOZrjav3+/li9fruLFizstLyxj0bFjR23bts3p8zQ0NFQDBw7UkiVLJOXDsbimU+Jhmy+++MJ4eHiYmTNnml27dplu3bqZgIAAp2+LFUQ9evQw/v7+5ocffjDHjx+3bmfOnLH6PP/886Zs2bJm5cqVZuPGjSY8PNyEh4dbyzMvTdCsWTMTGxtrFi9ebEqWLJntpQkGDhxodu/ebd5///18eWmCS138LUJjCtdYrF+/3ri6uppRo0aZ/fv3m9mzZxtvb2/z2WefWX3eeustExAQYL755huzbds288gjj2T79fzatWubdevWmZ9++slUqlTJ6WvYiYmJJjg42HTs2NHs2LHDfPHFF8bb2zvPL01wsejoaHPbbbdZl2lYsGCBKVGihBk0aJDV51Yei1OnTpktW7aYLVu2GElm/PjxZsuWLdY3427Wvq9du9a4urqad955x+zevdsMGzbspl+a4EpjkZaWZtq0aWNKly5tYmNjnT5TL/4WXGEYi+xc+i1CY/LXWBCw8tDkyZNN2bJljbu7u6lfv7755Zdf8rqk6yYp29uMGTOsPv/884954YUXTGBgoPH29jaPPvqoOX78uNN6fv/9d9OiRQvj5eVlSpQoYQYMGGDOnTvn1GfVqlWmVq1axt3d3dx+++1O28ivLg1YhW0s/vvf/5oaNWoYDw8PU6VKFTN9+nSn5RkZGea1114zwcHBxsPDwzRt2tTs3bvXqc9ff/1lnnzySePr62v8/PxMly5dzKlTp5z6bN261TRq1Mh4eHiY2267zbz11ls3fN+uRXJysunTp48pW7as8fT0NLfffrt55ZVXnP5o3spjsWrVqmw/J6Kjo40xN3ff582bZ+644w7j7u5uqlevbr799tsbtt/ZudJYHDx48LKfqatWrbLWURjGIjvZBaz8NBYOYy66dDAAAACuG+dgAQAA2IyABQAAYDMCFgAAgM0IWAAAADYjYAEAANiMgAUAAGAzAhYAAIDNCFgA8qXff/9dDodDsbGxeV0KAFwzAhaAG8bhcFzx9vrrr+d1idn69ddf1aVLF5UuXVoeHh4KCwvTk08+qY0bN97UOgiZQMHlmtcFALh1HT9+3Pr33LlzNXToUKcffPb19c2Lsq5o48aNatq0qWrUqKEPPvhAVapU0alTp/TNN99owIAB+vHHH/O6RAAFADNYAG6YkJAQ6+bv7y+Hw2HdDwoK0vjx461Zolq1amnx4sWXXVd6erqeeeYZValSRYcPH5YkffPNN7r77rvl6emp22+/XcOHD9f58+etxzgcDv3nP//Ro48+Km9vb1WqVEkLFy687DaMMercubMqVaqkNWvWqFWrVqpQoYJq1aqlYcOG6ZtvvrH6bt++XU2aNJGXl5eKFy+ubt26KSUlxVr+wAMPqG/fvk7rb9u2rTp37mzdL1++vN58800988wzKlq0qMqWLavp06dby8PCwiRJtWvXlsPh0AMPPHDF8QaQfxCwAOSJd999V+PGjdM777yjbdu2KTIyUm3atNH+/fuz9E1NTdW//vUvxcbGas2aNSpbtqzWrFmjTp06qU+fPtq1a5c++OADzZw5U6NGjXJ67PDhw9W+fXtt27ZNLVu2VFRUlE6ePJltTbGxsdq5c6cGDBggF5esH48BAQGSpNOnTysyMlKBgYHasGGD5s+fr+XLl6tXr17XPA7jxo1T3bp1tWXLFr3wwgvq0aOHNcu3fv16SdLy5ct1/PhxLViw4JrXDyCPXPPPQwNALsyYMcP4+/tb90NDQ82oUaOc+tSrV8+88MILxhhjDh48aCSZNWvWmKZNm5pGjRqZxMREq2/Tpk3Nm2++6fT4Tz/91JQqVcq6L8m8+uqr1v2UlBQjyXz//ffZ1jh37lwjyWzevPmK+zJ9+nQTGBhoUlJSrLZvv/3WuLi4mLi4OGOMMY0bNzZ9+vRxetwjjzxioqOjrfvlypUzTz/9tHU/IyPDBAUFmalTpzqNwZYtW65YD4D8h3OwANx0ycnJOnbsmBo2bOjU3rBhQ23dutWp7cknn1Tp0qW1cuVKeXl5We1bt27V2rVrnWas0tPTdfbsWZ05c0be3t6SpDvvvNNa7uPjIz8/PyUkJGRblzEmR/Xv3r1bd911l3x8fJxqz8jI0N69exUcHJyj9VxaX+Yh1MvVB6Dg4BAhgHytZcuW2rZtm2JiYpzaU1JSNHz4cMXGxlq37du3a//+/fL09LT6ubm5OT3O4XAoIyMj223dcccdkqQ9e/Zcd90uLi5ZAtu5c+ey9LuW+gAUHAQsADedn5+fQkNDtXbtWqf2tWvXqlq1ak5tPXr00FtvvaU2bdo4fYPv7rvv1t69e1WxYsUst+zOn8qJWrVqqVq1aho3bly2IScxMVGSVLVqVW3dulWnT592qt3FxUWVK1eWJJUsWdLpW5Tp6enasWPHNdXj7u5uPRZAwULAApAnBg4cqLfffltz587V3r17NXjwYMXGxqpPnz5Z+r744ot644031Lp1a/3000+SpKFDh+qTTz7R8OHDtXPnTu3evVtffPGFXn311VzX5HA4NGPGDO3bt0/33XefvvvuOx04cEDbtm3TqFGj9Mgjj0iSoqKi5OnpqejoaO3YsUOrVq3Siy++qI4dO1qHB5s0aaJvv/1W3377rfbs2aMePXpYAS2ngoKC5OXlpcWLFys+Pl5JSUm53jcANxcBC0Ce6N27t/r3768BAwaoZs2aWrx4sRYuXKhKlSpl279v374aPny4WrZsqZ9//lmRkZFatGiRli5dqnr16umee+7RhAkTVK5cueuqq379+tq4caMqVqyo5557TlWrVlWbNm20c+dOTZw4UZLk7e2tJUuW6OTJk6pXr54ef/xxNW3aVO+99561nmeeeUbR0dHq1KmTGjdurNtvv10PPvjgNdXi6uqqSZMm6YMPPlBoaKgV8ADkfw6T07M6AQAAkCPMYAEAANiMgAUAAGAzAhYAAIDNCFgAAAA2I2ABAADYjIAFAABgMwIWAACAzQhYAAAANiNgAQAA2IyABQAAYDMCFgAAgM0IWAAAADb7fx+YkNDnuP5nAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# есть очень короткие документы\n",
        "smallchunks=[]\n",
        "middlechunks=[]\n",
        "for i,count in enumerate(fragment_token_counts):\n",
        "    if count < 100:\n",
        "        smallchunks.append(i)\n",
        "        print(f\"{count}[{i}]\",end=\" \")\n",
        "    elif count<200:\n",
        "        middlechunks.append(i)\n",
        "print(\"\\n\")\n",
        "for i in middlechunks:\n",
        "    print(f\"{fragment_token_counts[i]}[{i}]\",end=\" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OISTfzx4feCK",
        "outputId": "6d9ec319-eab4-4e93-d4dd-27f6fe763647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0[0] 0[1] 66[2] 63[5] 11[6] 44[13] 99[14] 11[15] 99[17] 78[18] 11[21] 79[22] 44[24] 66[52] 82[76] 46[92] 79[93] 87[112] 49[119] 49[128] 54[129] 50[133] 39[141] 40[142] 66[146] 46[148] 97[152] 48[159] 49[161] 89[163] 35[164] 67[172] 44[175] 58[176] 50[181] 45[183] 73[189] 53[191] 77[199] 53[203] 54[211] 56[222] 82[224] 87[225] 71[233] 48[236] 45[237] 62[238] 60[247] 93[258] 87[269] 75[271] 83[277] 80[282] 59[287] 79[297] 65[298] 77[301] 56[309] 73[320] 79[321] 50[327] 90[333] 62[336] 49[337] 35[349] 69[350] 65[369] 64[376] 75[385] 83[388] 87[399] 72[400] 72[416] 75[432] 77[433] 74[442] 81[448] 85[462] 76[463] 42[467] 52[474] 84[491] 78[529] 79[552] 58[570] 62[573] 31[586] 73[593] 58[603] 89[610] 74[618] 65[621] 70[631] 70[636] 74[639] 68[648] 74[665] 85[668] 55[674] 55[675] 63[684] 62[696] 54[712] 88[720] 88[725] 72[727] 47[729] 83[732] 44[734] 72[739] 67[740] 62[743] 62[745] 32[746] 60[754] 65[757] 81[761] 88[763] 65[769] 51[775] 60[776] 42[778] 81[779] 63[786] 73[793] 68[797] 86[798] 73[800] 65[801] 68[804] 72[812] 93[814] 44[815] 68[816] 38[823] 37[829] 37[844] 59[856] 33[858] 39[861] 53[877] 65[886] 48[892] 82[900] 86[902] 52[904] 59[913] 55[923] 74[925] 57[926] 98[936] 61[938] 62[939] 55[941] 81[942] 50[964] 95[967] 50[974] 64[976] 65[978] 75[989] 50[994] 79[1010] 62[1027] 36[1028] 46[1039] 78[1041] 44[1043] 74[1046] 75[1047] 72[1050] 36[1100] 75[1108] 92[1115] 36[1125] 63[1128] 79[1132] 48[1137] 95[1138] 51[1139] 98[1140] 47[1141] 71[1147] 71[1148] 90[1151] 46[1155] 52[1160] 92[1161] 94[1162] 77[1163] 45[1164] 44[1165] 25[1167] 46[1168] 56[1170] 44[1172] 78[1173] 41[1174] 26[1177] 25[1178] 80[1179] 54[1180] 57[1181] 48[1183] 69[1184] 89[1185] 92[1186] 52[1187] 64[1188] 96[1189] 74[1191] 97[1194] 82[1195] 77[1196] 98[1197] 99[1198] 51[1200] 82[1201] 87[1202] 54[1205] 87[1206] 91[1208] 90[1215] 43[1263] 57[1276] 60[1290] 91[1292] 72[1297] 95[1325] 89[1328] 62[1362] 74[1390] 41[1394] 78[1423] 60[1426] 54[1436] 73[1441] 59[1443] 67[1454] 70[1460] 33[1466] 65[1486] 30[1490] 26[1491] 48[1493] 36[1494] 64[1495] 44[1496] 36[1497] 48[1498] 65[1502] 59[1509] 67[1518] 60[1519] 94[1520] 67[1521] 69[1522] 76[1525] 79[1526] 55[1528] 52[1529] 68[1534] 81[1535] 77[1547] 64[1548] 59[1551] 76[1552] 81[1554] 57[1577] 86[1582] 54[1583] 60[1584] 80[1594] 59[1599] 59[1601] 59[1604] 35[1605] 92[1606] 59[1611] 66[1612] 47[1619] 91[1630] 76[1632] 58[1633] 64[1636] 90[1637] 85[1659] 48[1661] 83[1670] 77[1679] 97[1686] 41[1699] 99[1701] 65[1703] 80[1704] 72[1708] 56[1709] 58[1722] 64[1726] 54[1731] 68[1733] 57[1736] 37[1737] 75[1741] 65[1742] 47[1748] 97[1751] 47[1753] 48[1754] 95[1758] 49[1759] 95[1760] 70[1761] 53[1763] 62[1765] 85[1766] 49[1772] 63[1780] 97[1801] 54[1803] 39[1807] 48[1815] 61[1819] 47[1820] 61[1821] 61[1844] 41[1848] 80[1852] 71[1853] 79[1855] 90[1856] 59[1942] 91[1947] 91[1956] 74[1961] 65[1967] 48[1978] 75[1981] 84[1983] 76[1986] 36[1990] 77[1992] 74[2003] 76[2007] 41[2010] 82[2017] 87[2019] 92[2020] 91[2022] 80[2025] 83[2031] 85[2032] 57[2033] 70[2038] 72[2049] 78[2057] 43[2059] 66[2060] 73[2061] 80[2066] 68[2069] 38[2070] 65[2077] 44[2081] 55[2085] 82[2089] 78[2094] 86[2097] 85[2109] 99[2116] 95[2128] 56[2138] 95[2140] 65[2141] 56[2150] 39[2156] 73[2161] 71[2168] 84[2169] 70[2179] 34[2183] 53[2192] 44[2200] 57[2201] 75[2212] 77[2214] 68[2242] 72[2251] 84[2263] 82[2264] 92[2270] 73[2282] 56[2285] 53[2286] 96[2289] 71[2293] 55[2298] 59[2301] 73[2305] 52[2308] 47[2309] 78[2312] 65[2313] 48[2315] 68[2316] 60[2318] 74[2325] 49[2326] 79[2345] 43[2347] 83[2354] 98[2355] 91[2356] 64[2361] 85[2363] 77[2371] 40[2374] 52[2375] 79[2376] 75[2377] 34[2382] 64[2383] 45[2385] 81[2388] 81[2394] 42[2411] 61[2421] 65[2428] 42[2430] 55[2432] 89[2434] 68[2437] 40[2446] 77[2447] 60[2451] 65[2456] 53[2459] 69[2462] 93[2463] 99[2465] 36[2466] 59[2467] 88[2468] 42[2469] 32[2470] 79[2472] 53[2476] 84[2479] 69[2483] 96[2502] 85[2506] 75[2507] 73[2508] 89[2512] 85[2516] 88[2519] 88[2521] 64[2539] 90[2545] 78[2548] 59[2564] 59[2566] 59[2569] 80[2592] 67[2602] 50[2605] 80[2609] 40[2610] 58[2611] 54[2612] 62[2613] 82[2615] 96[2616] 61[2617] 64[2619] 78[2631] 87[2635] 50[2642] 53[2643] 60[2649] 72[2662] 54[2669] 46[2673] 47[2675] 49[2683] 47[2686] 90[2687] 84[2690] 79[2693] 64[2695] 59[2696] 65[2697] 56[2698] 61[2699] 90[2702] 96[2704] 70[2705] 72[2706] 64[2707] 64[2714] 68[2720] 45[2734] 46[2743] 91[2757] 74[2826] 81[2867] 48[2972] 77[3027] 49[3072] 87[3075] 78[3561] 47[3662] 72[3712] 74[3874] 72[3998] 80[4006] \n",
            "\n",
            "146[8] 101[10] 173[11] 194[12] 104[23] 111[25] 110[38] 159[50] 125[57] 116[75] 174[86] 121[91] 126[107] 117[110] 105[123] 120[125] 101[131] 122[150] 116[151] 130[154] 131[157] 116[158] 121[162] 182[184] 187[188] 181[196] 140[208] 125[209] 120[220] 173[221] 157[227] 132[229] 116[245] 166[253] 188[273] 155[276] 175[284] 188[289] 154[310] 172[316] 191[323] 103[325] 135[326] 124[332] 165[342] 186[348] 109[353] 119[354] 163[355] 134[375] 106[391] 135[422] 115[450] 101[468] 118[496] 186[501] 160[502] 102[510] 160[516] 195[519] 118[521] 197[530] 152[532] 114[579] 115[588] 195[649] 117[662] 110[667] 113[703] 167[733] 171[742] 194[750] 145[762] 183[767] 101[773] 118[774] 109[782] 182[790] 173[791] 159[802] 183[805] 112[811] 150[817] 165[818] 128[853] 110[880] 100[930] 174[961] 123[995] 103[1044] 117[1053] 113[1082] 101[1143] 172[1146] 107[1150] 112[1152] 154[1153] 180[1154] 140[1156] 113[1157] 172[1158] 113[1166] 108[1176] 117[1182] 110[1192] 105[1193] 120[1203] 141[1204] 162[1224] 193[1254] 128[1265] 128[1269] 172[1288] 156[1319] 117[1322] 168[1343] 108[1345] 136[1351] 134[1365] 139[1376] 139[1389] 173[1429] 184[1431] 145[1489] 125[1499] 157[1501] 150[1503] 151[1505] 131[1511] 171[1523] 156[1524] 194[1530] 109[1539] 125[1542] 182[1571] 154[1574] 112[1579] 107[1589] 115[1615] 103[1617] 168[1621] 132[1628] 103[1649] 104[1655] 100[1692] 104[1705] 100[1714] 125[1715] 116[1727] 126[1735] 138[1744] 106[1769] 131[1776] 126[1789] 126[1795] 178[1804] 122[1806] 110[1813] 188[1814] 107[1846] 197[1851] 136[1909] 193[1918] 183[1932] 117[1935] 122[1936] 122[1940] 103[1943] 137[1994] 157[2001] 120[2006] 172[2012] 121[2026] 175[2029] 177[2030] 113[2041] 135[2045] 114[2048] 161[2065] 113[2068] 107[2074] 125[2091] 134[2102] 108[2105] 150[2107] 192[2110] 126[2112] 121[2144] 104[2159] 170[2166] 110[2171] 165[2173] 114[2176] 123[2181] 119[2211] 121[2216] 117[2218] 112[2219] 191[2223] 116[2248] 113[2291] 112[2302] 130[2342] 150[2352] 129[2380] 128[2400] 110[2404] 161[2414] 182[2423] 176[2438] 117[2443] 154[2453] 143[2474] 137[2487] 166[2495] 189[2503] 192[2511] 124[2546] 164[2552] 156[2554] 192[2555] 103[2562] 108[2563] 186[2570] 133[2579] 192[2589] 151[2597] 104[2599] 177[2607] 162[2614] 174[2618] 127[2620] 141[2623] 121[2624] 122[2625] 100[2637] 151[2638] 184[2652] 179[2654] 111[2655] 182[2657] 120[2692] 120[2701] 122[2703] 136[2710] 132[2738] 162[2792] 133[2793] 137[2795] 175[2806] 188[2898] 190[2900] 155[2911] 156[2912] 197[2961] 110[2980] 188[3018] 118[3029] 120[3056] 122[3070] 101[3087] 142[3099] 114[3156] 100[3230] 129[3231] 196[3235] 141[3259] 124[3296] 177[3326] 147[3334] 128[3373] 137[3400] 191[3411] 139[3412] 194[3418] 186[3426] 179[3427] 187[3428] 189[3622] 155[3642] 157[3646] 156[3652] 113[3676] 192[3682] 193[3686] 172[3697] 195[3732] 192[3733] 194[3734] 198[3739] 198[3750] 123[3752] 111[3787] 193[3794] 195[3801] 121[3806] 177[3875] 162[4034] 140[4050] 122[4057] 140[4065] 135[4066] "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# распределение размеров небольших чанков\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if fragment_token_counts[item]<700]\n",
        "plt.hist([fragment_token_counts[i] for i in new_list], bins=50, alpha=0.5, label='Fragments')\n",
        "plt.title('Distribution of Token Counts by ReadTheDocsLoader')\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rgLLiCCMztg0",
        "outputId": "d379ae26-ed2c-4e6a-91af-43c980c1a360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# распределение размеров чанков с устаревшими методами [Deprecated]\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if '[Deprecated]' in docs[item].page_content]\n",
        "print(len(new_list))\n",
        "plt.hist([fragment_token_counts[i] for i in new_list], bins=50, alpha=0.5, label='Fragments')\n",
        "plt.title('Distribution of Token Counts by ReadTheDocsLoader')\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "EJjpdtBa75Jv",
        "outputId": "d6048b76-e5e7-4301-93ca-6c31971b47c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[2].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFuD5zg9KVwZ",
        "outputId": "c3ef897c-14a3-430a-c413-d0beea63c496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'drive/MyDrive/docs4colab/api.python.langchain.com/en/latest/together_api_reference.html'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# содержимое чанков размера до ~11000токенов с устаревшими методами\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if '[Deprecated]' in docs[item].page_content]\n",
        "new_list = [item for item in new_list if 10000<fragment_token_counts[item]<11000]\n",
        "for i,somechunk in enumerate(new_list[:1]):\n",
        "    display(HTML(wrap(docs[somechunk].page_content,somechunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rBgIEVe7J3iq",
        "outputId": "c54d82a7-c87d-4e95-e635-4ffe9f68c774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[2]===================</br><pre><code class=\"python\">langchain 0.1.16¶\n",
              "langchain.agents¶\n",
              "Agent is a class that uses an LLM to choose a sequence of actions to take.\n",
              "In Chains, a sequence of actions is hardcoded. In Agents,\n",
              "a language model is used as a reasoning engine to determine which actions\n",
              "to take and in which order.\n",
              "Agents select and use Tools and Toolkits for actions.\n",
              "Class hierarchy:\n",
              "BaseSingleActionAgent --> LLMSingleActionAgent\n",
              "                          OpenAIFunctionsAgent\n",
              "                          XMLAgent\n",
              "                          Agent --> <name>Agent  # Examples: ZeroShotAgent, ChatAgent\n",
              "BaseMultiActionAgent  --> OpenAIMultiFunctionsAgent\n",
              "Main helpers:\n",
              "AgentType, AgentExecutor, AgentOutputParser, AgentExecutorIterator,\n",
              "AgentAction, AgentFinish\n",
              "Classes¶\n",
              "agents.agent.Agent\n",
              "[Deprecated] Agent that calls the language model and deciding the action.\n",
              "agents.agent.AgentExecutor\n",
              "Agent that is using tools.\n",
              "agents.agent.AgentOutputParser\n",
              "Base class for parsing agent output into agent action/finish.\n",
              "agents.agent.BaseMultiActionAgent\n",
              "Base Multi Action Agent class.\n",
              "agents.agent.BaseSingleActionAgent\n",
              "Base Single Action Agent class.\n",
              "agents.agent.ExceptionTool\n",
              "Tool that just returns the query.\n",
              "agents.agent.LLMSingleActionAgent\n",
              "[Deprecated] Base class for single action agents.\n",
              "agents.agent.MultiActionAgentOutputParser\n",
              "Base class for parsing agent output into agent actions/finish.\n",
              "agents.agent.RunnableAgent\n",
              "Agent powered by runnables.\n",
              "agents.agent.RunnableMultiActionAgent\n",
              "Agent powered by runnables.\n",
              "agents.agent_iterator.AgentExecutorIterator(...)\n",
              "Iterator for AgentExecutor.\n",
              "agents.agent_toolkits.vectorstore.toolkit.VectorStoreInfo\n",
              "Information about a VectorStore.\n",
              "agents.agent_toolkits.vectorstore.toolkit.VectorStoreRouterToolkit\n",
              "Toolkit for routing between Vector Stores.\n",
              "agents.agent_toolkits.vectorstore.toolkit.VectorStoreToolkit\n",
              "Toolkit for interacting with a Vector Store.\n",
              "agents.agent_types.AgentType(value)\n",
              "[Deprecated] An enum for agent types.\n",
              "agents.chat.base.ChatAgent\n",
              "[Deprecated] Chat Agent.\n",
              "agents.chat.output_parser.ChatOutputParser\n",
              "Output parser for the chat agent.\n",
              "agents.conversational.base.ConversationalAgent\n",
              "[Deprecated] An agent that holds a conversation in addition to using tools.\n",
              "agents.conversational.output_parser.ConvoOutputParser\n",
              "Output parser for the conversational agent.\n",
              "agents.conversational_chat.base.ConversationalChatAgent\n",
              "[Deprecated] An agent designed to hold a conversation in addition to using tools.\n",
              "agents.conversational_chat.output_parser.ConvoOutputParser\n",
              "Output parser for the conversational agent.\n",
              "agents.mrkl.base.ChainConfig(action_name, ...)\n",
              "Configuration for chain to use in MRKL system.\n",
              "agents.mrkl.base.MRKLChain\n",
              "[Deprecated] [Deprecated] Chain that implements the MRKL system.\n",
              "agents.mrkl.base.ZeroShotAgent\n",
              "[Deprecated] Agent for the MRKL chain.\n",
              "agents.mrkl.output_parser.MRKLOutputParser\n",
              "MRKL Output parser for the chat agent.\n",
              "agents.openai_assistant.base.OpenAIAssistantAction\n",
              "AgentAction with info needed to submit custom tool output to existing run.\n",
              "agents.openai_assistant.base.OpenAIAssistantFinish\n",
              "AgentFinish with run and thread metadata.\n",
              "agents.openai_assistant.base.OpenAIAssistantRunnable\n",
              "Run an OpenAI Assistant.\n",
              "agents.openai_functions_agent.agent_token_buffer_memory.AgentTokenBufferMemory\n",
              "Memory used to save agent output AND intermediate steps.\n",
              "agents.openai_functions_agent.base.OpenAIFunctionsAgent\n",
              "[Deprecated] An Agent driven by OpenAIs function powered API.\n",
              "agents.openai_functions_multi_agent.base.OpenAIMultiFunctionsAgent\n",
              "[Deprecated] An Agent driven by OpenAIs function powered API.\n",
              "agents.output_parsers.json.JSONAgentOutputParser\n",
              "Parses tool invocations and final answers in JSON format.\n",
              "agents.output_parsers.openai_functions.OpenAIFunctionsAgentOutputParser\n",
              "Parses a message into agent action/finish.\n",
              "agents.output_parsers.openai_tools.OpenAIToolsAgentOutputParser\n",
              "Parses a message into agent actions/finish.\n",
              "agents.output_parsers.react_json_single_input.ReActJsonSingleInputOutputParser\n",
              "Parses ReAct-style LLM calls that have a single tool input in json format.\n",
              "agents.output_parsers.react_single_input.ReActSingleInputOutputParser\n",
              "Parses ReAct-style LLM calls that have a single tool input.\n",
              "agents.output_parsers.self_ask.SelfAskOutputParser\n",
              "Parses self-ask style LLM calls.\n",
              "agents.output_parsers.tools.ToolAgentAction\n",
              "Override init to support instantiation by position for backward compat.\n",
              "agents.output_parsers.tools.ToolsAgentOutputParser\n",
              "Parses a message into agent actions/finish.\n",
              "agents.output_parsers.xml.XMLAgentOutputParser\n",
              "Parses tool invocations and final answers in XML format.\n",
              "agents.react.base.DocstoreExplorer(docstore)\n",
              "[Deprecated] Class to assist with exploration of a document store.\n",
              "agents.react.base.ReActChain\n",
              "[Deprecated] [Deprecated] Chain that implements the ReAct paper.\n",
              "agents.react.base.ReActDocstoreAgent\n",
              "[Deprecated] Agent for the ReAct chain.\n",
              "agents.react.base.ReActTextWorldAgent\n",
              "[Deprecated] Agent for the ReAct TextWorld chain.\n",
              "agents.react.output_parser.ReActOutputParser\n",
              "Output parser for the ReAct agent.\n",
              "agents.schema.AgentScratchPadChatPromptTemplate\n",
              "Chat prompt template for the agent scratchpad.\n",
              "agents.self_ask_with_search.base.SelfAskWithSearchAgent\n",
              "[Deprecated] Agent for the self-ask-with-search paper.\n",
              "agents.self_ask_with_search.base.SelfAskWithSearchChain\n",
              "[Deprecated] [Deprecated] Chain that does self-ask with search.\n",
              "agents.structured_chat.base.StructuredChatAgent\n",
              "[Deprecated] Structured Chat Agent.\n",
              "agents.structured_chat.output_parser.StructuredChatOutputParser\n",
              "Output parser for the structured chat agent.\n",
              "agents.structured_chat.output_parser.StructuredChatOutputParserWithRetries\n",
              "Output parser with retries for the structured chat agent.\n",
              "agents.tools.InvalidTool\n",
              "Tool that is run when invalid tool name is encountered by agent.\n",
              "agents.xml.base.XMLAgent\n",
              "[Deprecated] Agent that uses XML tags.\n",
              "Functions¶\n",
              "agents.agent_toolkits.conversational_retrieval.openai_functions.create_conversational_retrieval_agent(...)\n",
              "A convenience method for creating a conversational retrieval agent.\n",
              "agents.agent_toolkits.vectorstore.base.create_vectorstore_agent(...)\n",
              "Construct a VectorStore agent from an LLM and tools.\n",
              "agents.agent_toolkits.vectorstore.base.create_vectorstore_router_agent(...)\n",
              "Construct a VectorStore router agent from an LLM and tools.\n",
              "agents.format_scratchpad.log.format_log_to_str(...)\n",
              "Construct the scratchpad that lets the agent continue its thought process.\n",
              "agents.format_scratchpad.log_to_messages.format_log_to_messages(...)\n",
              "Construct the scratchpad that lets the agent continue its thought process.\n",
              "agents.format_scratchpad.openai_functions.format_to_openai_function_messages(...)\n",
              "Convert (AgentAction, tool output) tuples into FunctionMessages.\n",
              "agents.format_scratchpad.openai_functions.format_to_openai_functions(...)\n",
              "Convert (AgentAction, tool output) tuples into FunctionMessages.\n",
              "agents.format_scratchpad.tools.format_to_tool_messages(...)\n",
              "Convert (AgentAction, tool output) tuples into FunctionMessages.\n",
              "agents.format_scratchpad.xml.format_xml(...)\n",
              "Format the intermediate steps as XML.\n",
              "agents.initialize.initialize_agent(tools, llm)\n",
              "[Deprecated] Load an agent executor given tools and LLM.\n",
              "agents.json_chat.base.create_json_chat_agent(...)\n",
              "Create an agent that uses JSON to format its logic, build for Chat Models.\n",
              "agents.load_tools.get_all_tool_names()\n",
              "Get a list of all possible tool names.\n",
              "agents.load_tools.load_huggingface_tool(...)\n",
              "Loads a tool from the HuggingFace Hub.\n",
              "agents.load_tools.load_tools(tool_names[, ...])\n",
              "Load tools based on their name.\n",
              "agents.loading.load_agent(path, **kwargs)\n",
              "[Deprecated] Unified method for loading an agent from LangChainHub or local fs.\n",
              "agents.loading.load_agent_from_config(config)\n",
              "[Deprecated] Load agent from Config Dict.\n",
              "agents.openai_functions_agent.base.create_openai_functions_agent(...)\n",
              "Create an agent that uses OpenAI function calling.\n",
              "agents.openai_tools.base.create_openai_tools_agent(...)\n",
              "Create an agent that uses OpenAI tools.\n",
              "agents.output_parsers.openai_tools.parse_ai_message_to_openai_tool_action(message)\n",
              "Parse an AI message potentially containing tool_calls.\n",
              "agents.output_parsers.tools.parse_ai_message_to_tool_action(message)\n",
              "Parse an AI message potentially containing tool_calls.\n",
              "agents.react.agent.create_react_agent(llm, ...)\n",
              "Create an agent that uses ReAct prompting.\n",
              "agents.self_ask_with_search.base.create_self_ask_with_search_agent(...)\n",
              "Create an agent that uses self-ask with search prompting.\n",
              "agents.structured_chat.base.create_structured_chat_agent(...)\n",
              "Create an agent aimed at supporting tools with multiple inputs.\n",
              "agents.tool_calling_agent.base.create_tool_calling_agent(...)\n",
              "Create an agent that uses tools.\n",
              "agents.utils.validate_tools_single_input(...)\n",
              "Validate tools for single input.\n",
              "agents.xml.base.create_xml_agent(llm, tools, ...)\n",
              "Create an agent that uses XML to format its logic.\n",
              "langchain.callbacks¶\n",
              "Callback handlers allow listening to events in LangChain.\n",
              "Class hierarchy:\n",
              "BaseCallbackHandler --> <name>CallbackHandler  # Example: AimCallbackHandler\n",
              "Classes¶\n",
              "callbacks.file.FileCallbackHandler(filename)\n",
              "Callback Handler that writes to a file.\n",
              "callbacks.streaming_aiter.AsyncIteratorCallbackHandler()\n",
              "Callback handler that returns an async iterator.\n",
              "callbacks.streaming_aiter_final_only.AsyncFinalIteratorCallbackHandler(*)\n",
              "Callback handler that returns an async iterator.\n",
              "callbacks.streaming_stdout_final_only.FinalStreamingStdOutCallbackHandler(*)\n",
              "Callback handler for streaming in agents.\n",
              "callbacks.tracers.logging.LoggingCallbackHandler(logger)\n",
              "Tracer that logs via the input Logger.\n",
              "langchain.chains¶\n",
              "Chains are easily reusable components linked together.\n",
              "Chains encode a sequence of calls to components like models, document retrievers,\n",
              "other Chains, etc., and provide a simple interface to this sequence.\n",
              "The Chain interface makes it easy to create apps that are:\n",
              "Stateful: add Memory to any Chain to give it state,\n",
              "Observable: pass Callbacks to a Chain to execute additional functionality,\n",
              "like logging, outside the main sequence of component calls,\n",
              "Composable: combine Chains with other components, including other Chains.\n",
              "Class hierarchy:\n",
              "Chain --> <name>Chain  # Examples: LLMChain, MapReduceChain, RouterChain\n",
              "Classes¶\n",
              "chains.api.base.APIChain\n",
              "Chain that makes API calls and summarizes the responses to answer a question.\n",
              "chains.api.openapi.chain.OpenAPIEndpointChain\n",
              "Chain interacts with an OpenAPI endpoint using natural language.\n",
              "chains.api.openapi.requests_chain.APIRequesterChain\n",
              "Get the request parser.\n",
              "chains.api.openapi.requests_chain.APIRequesterOutputParser\n",
              "Parse the request and error tags.\n",
              "chains.api.openapi.response_chain.APIResponderChain\n",
              "Get the response parser.\n",
              "chains.api.openapi.response_chain.APIResponderOutputParser\n",
              "Parse the response and error tags.\n",
              "chains.base.Chain\n",
              "Abstract base class for creating structured sequences of calls to components.\n",
              "chains.combine_documents.base.AnalyzeDocumentChain\n",
              "Chain that splits documents, then analyzes it in pieces.\n",
              "chains.combine_documents.base.BaseCombineDocumentsChain\n",
              "Base interface for chains combining documents.\n",
              "chains.combine_documents.map_reduce.MapReduceDocumentsChain\n",
              "Combining documents by mapping a chain over them, then combining results.\n",
              "chains.combine_documents.map_rerank.MapRerankDocumentsChain\n",
              "Combining documents by mapping a chain over them, then reranking results.\n",
              "chains.combine_documents.reduce.AsyncCombineDocsProtocol(...)\n",
              "Interface for the combine_docs method.\n",
              "chains.combine_documents.reduce.CombineDocsProtocol(...)\n",
              "Interface for the combine_docs method.\n",
              "chains.combine_documents.reduce.ReduceDocumentsChain\n",
              "Combine documents by recursively reducing them.\n",
              "chains.combine_documents.refine.RefineDocumentsChain\n",
              "Combine documents by doing a first pass and then refining on more documents.\n",
              "chains.combine_documents.stuff.StuffDocumentsChain\n",
              "Chain that combines documents by stuffing into context.\n",
              "chains.constitutional_ai.base.ConstitutionalChain\n",
              "Chain for applying constitutional principles.\n",
              "chains.constitutional_ai.models.ConstitutionalPrinciple\n",
              "Class for a constitutional principle.\n",
              "chains.conversation.base.ConversationChain\n",
              "Chain to have a conversation and load context from memory.\n",
              "chains.conversational_retrieval.base.BaseConversationalRetrievalChain\n",
              "Chain for chatting with an index.\n",
              "chains.conversational_retrieval.base.ChatVectorDBChain\n",
              "Chain for chatting with a vector database.\n",
              "chains.conversational_retrieval.base.ConversationalRetrievalChain\n",
              "Chain for having a conversation based on retrieved documents.\n",
              "chains.conversational_retrieval.base.InputType\n",
              "Input type for ConversationalRetrievalChain.\n",
              "chains.elasticsearch_database.base.ElasticsearchDatabaseChain\n",
              "Chain for interacting with Elasticsearch Database.\n",
              "chains.flare.base.FlareChain\n",
              "Chain that combines a retriever, a question generator, and a response generator.\n",
              "chains.flare.base.QuestionGeneratorChain\n",
              "Chain that generates questions from uncertain spans.\n",
              "chains.flare.prompts.FinishedOutputParser\n",
              "Output parser that checks if the output is finished.\n",
              "chains.graph_qa.arangodb.ArangoGraphQAChain\n",
              "Chain for question-answering against a graph by generating AQL statements.\n",
              "chains.graph_qa.base.GraphQAChain\n",
              "Chain for question-answering against a graph.\n",
              "chains.graph_qa.cypher.GraphCypherQAChain\n",
              "Chain for question-answering against a graph by generating Cypher statements.\n",
              "chains.graph_qa.cypher_utils.CypherQueryCorrector(schemas)\n",
              "Used to correct relationship direction in generated Cypher statements.\n",
              "chains.graph_qa.cypher_utils.Schema(...)\n",
              "Create new instance of Schema(left_node, relation, right_node)\n",
              "chains.graph_qa.falkordb.FalkorDBQAChain\n",
              "Chain for question-answering against a graph by generating Cypher statements.\n",
              "chains.graph_qa.gremlin.GremlinQAChain\n",
              "Chain for question-answering against a graph by generating gremlin statements.\n",
              "chains.graph_qa.hugegraph.HugeGraphQAChain\n",
              "Chain for question-answering against a graph by generating gremlin statements.\n",
              "chains.graph_qa.kuzu.KuzuQAChain\n",
              "Question-answering against a graph by generating Cypher statements for Kùzu.\n",
              "chains.graph_qa.nebulagraph.NebulaGraphQAChain\n",
              "Chain for question-answering against a graph by generating nGQL statements.\n",
              "chains.graph_qa.neptune_cypher.NeptuneOpenCypherQAChain\n",
              "Chain for question-answering against a Neptune graph by generating openCypher statements.\n",
              "chains.graph_qa.neptune_sparql.NeptuneSparqlQAChain\n",
              "Chain for question-answering against a Neptune graph by generating SPARQL statements.\n",
              "chains.graph_qa.ontotext_graphdb.OntotextGraphDBQAChain\n",
              "Question-answering against Ontotext GraphDB\n",
              "chains.graph_qa.sparql.GraphSparqlQAChain\n",
              "Question-answering against an RDF or OWL graph by generating SPARQL statements.\n",
              "chains.hyde.base.HypotheticalDocumentEmbedder\n",
              "Generate hypothetical document for query, and then embed that.\n",
              "chains.llm.LLMChain\n",
              "Chain to run queries against LLMs.\n",
              "chains.llm_checker.base.LLMCheckerChain\n",
              "Chain for question-answering with self-verification.\n",
              "chains.llm_math.base.LLMMathChain\n",
              "Chain that interprets a prompt and executes python code to do math.\n",
              "chains.llm_requests.LLMRequestsChain\n",
              "Chain that requests a URL and then uses an LLM to parse results.\n",
              "chains.llm_summarization_checker.base.LLMSummarizationCheckerChain\n",
              "Chain for question-answering with self-verification.\n",
              "chains.mapreduce.MapReduceChain\n",
              "Map-reduce chain.\n",
              "chains.moderation.OpenAIModerationChain\n",
              "Pass input through a moderation endpoint.\n",
              "chains.natbot.base.NatBotChain\n",
              "Implement an LLM driven browser.\n",
              "chains.natbot.crawler.Crawler()\n",
              "A crawler for web pages.\n",
              "chains.natbot.crawler.ElementInViewPort\n",
              "A typed dictionary containing information about elements in the viewport.\n",
              "chains.openai_functions.citation_fuzzy_match.FactWithEvidence\n",
              "Class representing a single statement.\n",
              "chains.openai_functions.citation_fuzzy_match.QuestionAnswer\n",
              "A question and its answer as a list of facts each one should have a source.\n",
              "chains.openai_functions.openapi.SimpleRequestChain\n",
              "Chain for making a simple request to an API endpoint.\n",
              "chains.openai_functions.qa_with_structure.AnswerWithSources\n",
              "An answer to the question, with sources.\n",
              "chains.prompt_selector.BasePromptSelector\n",
              "Base class for prompt selectors.\n",
              "chains.prompt_selector.ConditionalPromptSelector\n",
              "Prompt collection that goes through conditionals.\n",
              "chains.qa_generation.base.QAGenerationChain\n",
              "Base class for question-answer generation chains.\n",
              "chains.qa_with_sources.base.BaseQAWithSourcesChain\n",
              "Question answering chain with sources over documents.\n",
              "chains.qa_with_sources.base.QAWithSourcesChain\n",
              "Question answering with sources over documents.\n",
              "chains.qa_with_sources.loading.LoadingCallable(...)\n",
              "Interface for loading the combine documents chain.\n",
              "chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain\n",
              "Question-answering with sources over an index.\n",
              "chains.qa_with_sources.vector_db.VectorDBQAWithSourcesChain\n",
              "Question-answering with sources over a vector database.\n",
              "chains.query_constructor.base.StructuredQueryOutputParser\n",
              "Output parser that parses a structured query.\n",
              "chains.query_constructor.ir.Comparator(value)\n",
              "Enumerator of the comparison operators.\n",
              "chains.query_constructor.ir.Comparison\n",
              "A comparison to a value.\n",
              "chains.query_constructor.ir.Expr\n",
              "Base class for all expressions.\n",
              "chains.query_constructor.ir.FilterDirective\n",
              "A filtering expression.\n",
              "chains.query_constructor.ir.Operation\n",
              "A logical operation over other directives.\n",
              "chains.query_constructor.ir.Operator(value)\n",
              "Enumerator of the operations.\n",
              "chains.query_constructor.ir.StructuredQuery\n",
              "A structured query.\n",
              "chains.query_constructor.ir.Visitor()\n",
              "Defines interface for IR translation using visitor pattern.\n",
              "chains.query_constructor.parser.ISO8601Date\n",
              "A date in ISO 8601 format (YYYY-MM-DD).\n",
              "chains.query_constructor.schema.AttributeInfo\n",
              "Information about a data source attribute.\n",
              "chains.retrieval_qa.base.BaseRetrievalQA\n",
              "Base class for question-answering chains.\n",
              "chains.retrieval_qa.base.RetrievalQA\n",
              "Chain for question-answering against an index.\n",
              "chains.retrieval_qa.base.VectorDBQA\n",
              "Chain for question-answering against a vector database.\n",
              "chains.router.base.MultiRouteChain\n",
              "Use a single chain to route an input to one of multiple candidate chains.\n",
              "chains.router.base.Route(destination, ...)\n",
              "Create new instance of Route(destination, next_inputs)\n",
              "chains.router.base.RouterChain\n",
              "Chain that outputs the name of a destination chain and the inputs to it.\n",
              "chains.router.embedding_router.EmbeddingRouterChain\n",
              "Chain that uses embeddings to route between options.\n",
              "chains.router.llm_router.LLMRouterChain\n",
              "A router chain that uses an LLM chain to perform routing.\n",
              "chains.router.llm_router.RouterOutputParser\n",
              "Parser for output of router chain in the multi-prompt chain.\n",
              "chains.router.multi_prompt.MultiPromptChain\n",
              "A multi-route chain that uses an LLM router chain to choose amongst prompts.\n",
              "chains.router.multi_retrieval_qa.MultiRetrievalQAChain\n",
              "A multi-route chain that uses an LLM router chain to choose amongst retrieval qa chains.\n",
              "chains.sequential.SequentialChain\n",
              "Chain where the outputs of one chain feed directly into next.\n",
              "chains.sequential.SimpleSequentialChain\n",
              "Simple chain where the outputs of one step feed directly into next.\n",
              "chains.sql_database.query.SQLInput\n",
              "Input for a SQL Chain.\n",
              "chains.sql_database.query.SQLInputWithTables\n",
              "Input for a SQL Chain.\n",
              "chains.transform.TransformChain\n",
              "Chain that transforms the chain output.\n",
              "Functions¶\n",
              "chains.combine_documents.reduce.acollapse_docs(...)\n",
              "Execute a collapse function on a set of documents and merge their metadatas.\n",
              "chains.combine_documents.reduce.collapse_docs(...)\n",
              "Execute a collapse function on a set of documents and merge their metadatas.\n",
              "chains.combine_documents.reduce.split_list_of_docs(...)\n",
              "Split Documents into subsets that each meet a cumulative length constraint.\n",
              "chains.combine_documents.stuff.create_stuff_documents_chain(...)\n",
              "Create a chain for passing a list of Documents to a model.\n",
              "chains.ernie_functions.base.convert_python_function_to_ernie_function(...)\n",
              "Convert a Python function to an Ernie function-calling API compatible dict.\n",
              "chains.ernie_functions.base.convert_to_ernie_function(...)\n",
              "Convert a raw function/class to an Ernie function.\n",
              "chains.ernie_functions.base.create_ernie_fn_chain(...)\n",
              "[Legacy] Create an LLM chain that uses Ernie functions.\n",
              "chains.ernie_functions.base.create_ernie_fn_runnable(...)\n",
              "Create a runnable sequence that uses Ernie functions.\n",
              "chains.ernie_functions.base.create_structured_output_chain(...)\n",
              "[Legacy] Create an LLMChain that uses an Ernie function to get a structured output.\n",
              "chains.ernie_functions.base.create_structured_output_runnable(...)\n",
              "Create a runnable that uses an Ernie function to get a structured output.\n",
              "chains.ernie_functions.base.get_ernie_output_parser(...)\n",
              "Get the appropriate function output parser given the user functions.\n",
              "chains.example_generator.generate_example(...)\n",
              "Return another example given a list of examples for a prompt.\n",
              "chains.graph_qa.cypher.construct_schema(...)\n",
              "Filter the schema based on included or excluded types\n",
              "chains.graph_qa.cypher.extract_cypher(text)\n",
              "Extract Cypher code from a text.\n",
              "chains.graph_qa.falkordb.extract_cypher(text)\n",
              "Extract Cypher code from a text.\n",
              "chains.graph_qa.gremlin.extract_gremlin(text)\n",
              "Extract Gremlin code from a text.\n",
              "chains.graph_qa.neptune_cypher.extract_cypher(text)\n",
              "Extract Cypher code from text using Regex.\n",
              "chains.graph_qa.neptune_cypher.trim_query(query)\n",
              "Trim the query to only include Cypher keywords.\n",
              "chains.graph_qa.neptune_cypher.use_simple_prompt(llm)\n",
              "Decides whether to use the simple prompt\n",
              "chains.graph_qa.neptune_sparql.extract_sparql(query)\n",
              "chains.history_aware_retriever.create_history_aware_retriever(...)\n",
              "Create a chain that takes conversation history and returns documents.\n",
              "chains.loading.load_chain(path, **kwargs)\n",
              "Unified method for loading a chain from LangChainHub or local fs.\n",
              "chains.loading.load_chain_from_config(...)\n",
              "Load chain from Config Dict.\n",
              "chains.openai_functions.base.create_openai_fn_chain(...)\n",
              "[Deprecated] [Legacy] Create an LLM chain that uses OpenAI functions.\n",
              "chains.openai_functions.base.create_structured_output_chain(...)\n",
              "[Deprecated] [Legacy] Create an LLMChain that uses an OpenAI function to get a structured output.\n",
              "chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain(llm)\n",
              "Create a citation fuzzy match chain.\n",
              "chains.openai_functions.extraction.create_extraction_chain(...)\n",
              "[Deprecated] Creates a chain that extracts information from a passage.\n",
              "chains.openai_functions.extraction.create_extraction_chain_pydantic(...)\n",
              "[Deprecated] Creates a chain that extracts information from a passage using pydantic schema.\n",
              "chains.openai_functions.openapi.get_openapi_chain(spec)\n",
              "Create a chain for querying an API from a OpenAPI spec.\n",
              "chains.openai_functions.openapi.openapi_spec_to_openai_fn(spec)\n",
              "Convert a valid OpenAPI spec to the JSON Schema format expected for OpenAI\n",
              "chains.openai_functions.qa_with_structure.create_qa_with_sources_chain(llm)\n",
              "Create a question answering chain that returns an answer with sources.\n",
              "chains.openai_functions.qa_with_structure.create_qa_with_structure_chain(...)\n",
              "Create a question answering chain that returns an answer with sources\n",
              "chains.openai_functions.tagging.create_tagging_chain(...)\n",
              "Creates a chain that extracts information from a passage\n",
              "chains.openai_functions.tagging.create_tagging_chain_pydantic(...)\n",
              "Creates a chain that extracts information from a passage\n",
              "chains.openai_functions.utils.get_llm_kwargs(...)\n",
              "Returns the kwargs for the LLMChain constructor.\n",
              "chains.openai_tools.extraction.create_extraction_chain_pydantic(...)\n",
              "[Deprecated] Creates a chain that extracts information from a passage.\n",
              "chains.prompt_selector.is_chat_model(llm)\n",
              "Check if the language model is a chat model.\n",
              "chains.prompt_selector.is_llm(llm)\n",
              "Check if the language model is a LLM.\n",
              "chains.qa_with_sources.loading.load_qa_with_sources_chain(llm)\n",
              "Load a question answering with sources chain.\n",
              "chains.query_constructor.base.construct_examples(...)\n",
              "Construct examples from input-output pairs.\n",
              "chains.query_constructor.base.fix_filter_directive(...)\n",
              "Fix invalid filter directive.\n",
              "chains.query_constructor.base.get_query_constructor_prompt(...)\n",
              "Create query construction prompt.\n",
              "chains.query_constructor.base.load_query_constructor_chain(...)\n",
              "Load a query constructor chain.\n",
              "chains.query_constructor.base.load_query_constructor_runnable(...)\n",
              "Load a query constructor runnable chain.\n",
              "chains.query_constructor.parser.get_parser([...])\n",
              "Returns a parser for the query language.\n",
              "chains.query_constructor.parser.v_args(...)\n",
              "Dummy decorator for when lark is not installed.\n",
              "chains.retrieval.create_retrieval_chain(...)\n",
              "Create retrieval chain that retrieves documents and then passes them on.\n",
              "chains.sql_database.query.create_sql_query_chain(llm, db)\n",
              "Create a chain that generates SQL queries.\n",
              "chains.structured_output.base.create_openai_fn_runnable(...)\n",
              "[Deprecated] Create a runnable sequence that uses OpenAI functions.\n",
              "chains.structured_output.base.create_structured_output_runnable(...)\n",
              "Create a runnable for extracting structured outputs.\n",
              "chains.structured_output.base.get_openai_output_parser(...)\n",
              "Get the appropriate function output parser given the user functions.\n",
              "langchain.embeddings¶\n",
              "Embedding models  are wrappers around embedding models\n",
              "from different APIs and services.\n",
              "Embedding models can be LLMs or not.\n",
              "Class hierarchy:\n",
              "Embeddings --> <name>Embeddings  # Examples: OpenAIEmbeddings, HuggingFaceEmbeddings\n",
              "Classes¶\n",
              "embeddings.cache.CacheBackedEmbeddings(...)\n",
              "Interface for caching results from embedding models.\n",
              "langchain.evaluation¶\n",
              "Evaluation chains for grading LLM and Chain outputs.\n",
              "This module contains off-the-shelf evaluation chains for grading the output of\n",
              "LangChain primitives such as language models and chains.\n",
              "Loading an evaluator\n",
              "To load an evaluator, you can use the load_evaluators or\n",
              "load_evaluator functions with the\n",
              "names of the evaluators to load.\n",
              "from langchain.evaluation import load_evaluator\n",
              "evaluator = load_evaluator(\"qa\")\n",
              "evaluator.evaluate_strings(\n",
              "    prediction=\"We sold more than 40,000 units last week\",\n",
              "    input=\"How many units did we sell last week?\",\n",
              "    reference=\"We sold 32,378 units\",\n",
              ")\n",
              "The evaluator must be one of EvaluatorType.\n",
              "Datasets\n",
              "To load one of the LangChain HuggingFace datasets, you can use the load_dataset function with the\n",
              "name of the dataset to load.\n",
              "from langchain.evaluation import load_dataset\n",
              "ds = load_dataset(\"llm-math\")\n",
              "Some common use cases for evaluation include:\n",
              "Grading the accuracy of a response against ground truth answers: QAEvalChain\n",
              "Comparing the output of two models: PairwiseStringEvalChain or LabeledPairwiseStringEvalChain when there is additionally a reference label.\n",
              "Judging the efficacy of an agent’s tool usage: TrajectoryEvalChain\n",
              "Checking whether an output complies with a set of criteria: CriteriaEvalChain or LabeledCriteriaEvalChain when there is additionally a reference label.\n",
              "Computing semantic difference between a prediction and reference: EmbeddingDistanceEvalChain or between two predictions: PairwiseEmbeddingDistanceEvalChain\n",
              "Measuring the string distance between a prediction and reference StringDistanceEvalChain or between two predictions PairwiseStringDistanceEvalChain\n",
              "Low-level API\n",
              "These evaluators implement one of the following interfaces:\n",
              "StringEvaluator: Evaluate a prediction string against a reference label and/or input context.\n",
              "PairwiseStringEvaluator: Evaluate two prediction strings against each other. Useful for scoring preferences, measuring similarity between two chain or llm agents, or comparing outputs on similar inputs.\n",
              "AgentTrajectoryEvaluator Evaluate the full sequence of actions taken by an agent.\n",
              "These interfaces enable easier composability and usage within a higher level evaluation framework.\n",
              "Classes¶\n",
              "evaluation.agents.trajectory_eval_chain.TrajectoryEval\n",
              "A named tuple containing the score and reasoning for a trajectory.\n",
              "evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain\n",
              "A chain for evaluating ReAct style agents.\n",
              "evaluation.agents.trajectory_eval_chain.TrajectoryOutputParser\n",
              "Trajectory output parser.\n",
              "evaluation.comparison.eval_chain.LabeledPairwiseStringEvalChain\n",
              "A chain for comparing two outputs, such as the outputs\n",
              "evaluation.comparison.eval_chain.PairwiseStringEvalChain\n",
              "A chain for comparing two outputs, such as the outputs\n",
              "evaluation.comparison.eval_chain.PairwiseStringResultOutputParser\n",
              "A parser for the output of the PairwiseStringEvalChain.\n",
              "evaluation.criteria.eval_chain.Criteria(value)\n",
              "A Criteria to evaluate.\n",
              "evaluation.criteria.eval_chain.CriteriaEvalChain\n",
              "LLM Chain for evaluating runs against criteria.\n",
              "evaluation.criteria.eval_chain.CriteriaResultOutputParser\n",
              "A parser for the output of the CriteriaEvalChain.\n",
              "evaluation.criteria.eval_chain.LabeledCriteriaEvalChain\n",
              "Criteria evaluation chain that requires references.\n",
              "evaluation.embedding_distance.base.EmbeddingDistance(value)\n",
              "Embedding Distance Metric.\n",
              "evaluation.embedding_distance.base.EmbeddingDistanceEvalChain\n",
              "Use embedding distances to score semantic difference between a prediction and reference.\n",
              "evaluation.embedding_distance.base.PairwiseEmbeddingDistanceEvalChain\n",
              "Use embedding distances to score semantic difference between two predictions.\n",
              "evaluation.exact_match.base.ExactMatchStringEvaluator(*)\n",
              "Compute an exact match between the prediction and the reference.\n",
              "evaluation.parsing.base.JsonEqualityEvaluator([...])\n",
              "Evaluates whether the prediction is equal to the reference after\n",
              "evaluation.parsing.base.JsonValidityEvaluator(...)\n",
              "Evaluates whether the prediction is valid JSON.\n",
              "evaluation.parsing.json_distance.JsonEditDistanceEvaluator([...])\n",
              "An evaluator that calculates the edit distance between JSON strings.\n",
              "evaluation.parsing.json_schema.JsonSchemaEvaluator(...)\n",
              "An evaluator that validates a JSON prediction against a JSON schema reference.\n",
              "evaluation.qa.eval_chain.ContextQAEvalChain\n",
              "LLM Chain for evaluating QA w/o GT based on context\n",
              "evaluation.qa.eval_chain.CotQAEvalChain\n",
              "LLM Chain for evaluating QA using chain of thought reasoning.\n",
              "evaluation.qa.eval_chain.QAEvalChain\n",
              "LLM Chain for evaluating question answering.\n",
              "evaluation.qa.generate_chain.QAGenerateChain\n",
              "LLM Chain for generating examples for question answering.\n",
              "evaluation.regex_match.base.RegexMatchStringEvaluator(*)\n",
              "Compute a regex match between the prediction and the reference.\n",
              "evaluation.schema.AgentTrajectoryEvaluator()\n",
              "Interface for evaluating agent trajectories.\n",
              "evaluation.schema.EvaluatorType(value)\n",
              "The types of the evaluators.\n",
              "evaluation.schema.LLMEvalChain\n",
              "A base class for evaluators that use an LLM.\n",
              "evaluation.schema.PairwiseStringEvaluator()\n",
              "Compare the output of two models (or two outputs of the same model).\n",
              "evaluation.schema.StringEvaluator()\n",
              "Grade, tag, or otherwise evaluate predictions relative to their inputs and/or reference labels.\n",
              "evaluation.scoring.eval_chain.LabeledScoreStringEvalChain\n",
              "A chain for scoring the output of a model on a scale of 1-10.\n",
              "evaluation.scoring.eval_chain.ScoreStringEvalChain\n",
              "A chain for scoring on a scale of 1-10 the output of a model.\n",
              "evaluation.scoring.eval_chain.ScoreStringResultOutputParser\n",
              "A parser for the output of the ScoreStringEvalChain.\n",
              "evaluation.string_distance.base.PairwiseStringDistanceEvalChain\n",
              "Compute string edit distances between two predictions.\n",
              "evaluation.string_distance.base.StringDistance(value)\n",
              "Distance metric to use.\n",
              "evaluation.string_distance.base.StringDistanceEvalChain\n",
              "Compute string distances between the prediction and the reference.\n",
              "Functions¶\n",
              "evaluation.comparison.eval_chain.resolve_pairwise_criteria(...)\n",
              "Resolve the criteria for the pairwise evaluator.\n",
              "evaluation.criteria.eval_chain.resolve_criteria(...)\n",
              "Resolve the criteria to evaluate.\n",
              "evaluation.loading.load_dataset(uri)\n",
              "Load a dataset from the LangChainDatasets on HuggingFace.\n",
              "evaluation.loading.load_evaluator(evaluator, *)\n",
              "Load the requested evaluation chain specified by a string.\n",
              "evaluation.loading.load_evaluators(evaluators, *)\n",
              "Load evaluators specified by a list of evaluator types.\n",
              "evaluation.scoring.eval_chain.resolve_criteria(...)\n",
              "Resolve the criteria for the pairwise evaluator.\n",
              "langchain.hub¶\n",
              "Interface with the LangChain Hub.\n",
              "Functions¶\n",
              "hub.pull(owner_repo_commit, *[, api_url, ...])\n",
              "Pulls an object from the hub and returns it as a LangChain object.\n",
              "hub.push(repo_full_name, object, *[, ...])\n",
              "Pushes an object to the hub and returns the URL it can be viewed at in a browser.\n",
              "langchain.indexes¶\n",
              "Index is used to avoid writing duplicated content\n",
              "into the vectostore and to avoid over-writing content if it’s unchanged.\n",
              "Indexes also :\n",
              "Create knowledge graphs from data.\n",
              "Support indexing workflows from LangChain data loaders to vectorstores.\n",
              "Importantly, Index keeps on working even if the content being written is derived\n",
              "via a set of transformations from some source content (e.g., indexing children\n",
              "documents that were derived from parent documents by chunking.)\n",
              "Classes¶\n",
              "indexes.base.RecordManager(namespace)\n",
              "An abstract base class representing the interface for a record manager.\n",
              "indexes.graph.GraphIndexCreator\n",
              "Functionality to create graph index.\n",
              "indexes.vectorstore.VectorStoreIndexWrapper\n",
              "Wrapper around a vectorstore for easy access.\n",
              "indexes.vectorstore.VectorstoreIndexCreator\n",
              "Logic for creating indexes.\n",
              "langchain.memory¶\n",
              "Memory maintains Chain state, incorporating context from past runs.\n",
              "Class hierarchy for Memory:\n",
              "BaseMemory --> BaseChatMemory --> <name>Memory  # Examples: ZepMemory, MotorheadMemory\n",
              "Main helpers:\n",
              "BaseChatMessageHistory\n",
              "Chat Message History stores the chat message history in different stores.\n",
              "Class hierarchy for ChatMessageHistory:\n",
              "BaseChatMessageHistory --> <name>ChatMessageHistory  # Example: ZepChatMessageHistory\n",
              "Main helpers:\n",
              "AIMessage, BaseMessage, HumanMessage\n",
              "Classes¶\n",
              "memory.buffer.ConversationBufferMemory\n",
              "Buffer for storing conversation memory.\n",
              "memory.buffer.ConversationStringBufferMemory\n",
              "Buffer for storing conversation memory.\n",
              "memory.buffer_window.ConversationBufferWindowMemory\n",
              "Buffer for storing conversation memory inside a limited size window.\n",
              "memory.chat_memory.BaseChatMemory\n",
              "Abstract base class for chat memory.\n",
              "memory.combined.CombinedMemory\n",
              "Combining multiple memories' data together.\n",
              "memory.entity.BaseEntityStore\n",
              "Abstract base class for Entity store.\n",
              "memory.entity.ConversationEntityMemory\n",
              "Entity extractor & summarizer memory.\n",
              "memory.entity.InMemoryEntityStore\n",
              "In-memory Entity store.\n",
              "memory.entity.RedisEntityStore\n",
              "Redis-backed Entity store.\n",
              "memory.entity.SQLiteEntityStore\n",
              "SQLite-backed Entity store\n",
              "memory.entity.UpstashRedisEntityStore\n",
              "Upstash Redis backed Entity store.\n",
              "memory.kg.ConversationKGMemory\n",
              "Knowledge graph conversation memory.\n",
              "memory.motorhead_memory.MotorheadMemory\n",
              "Chat message memory backed by Motorhead service.\n",
              "memory.readonly.ReadOnlySharedMemory\n",
              "A memory wrapper that is read-only and cannot be changed.\n",
              "memory.simple.SimpleMemory\n",
              "Simple memory for storing context or other information that shouldn't ever change between prompts.\n",
              "memory.summary.ConversationSummaryMemory\n",
              "Conversation summarizer to chat memory.\n",
              "memory.summary.SummarizerMixin\n",
              "Mixin for summarizer.\n",
              "memory.summary_buffer.ConversationSummaryBufferMemory\n",
              "Buffer with summarizer for storing conversation memory.\n",
              "memory.token_buffer.ConversationTokenBufferMemory\n",
              "Conversation chat memory with token limit.\n",
              "memory.vectorstore.VectorStoreRetrieverMemory\n",
              "VectorStoreRetriever-backed memory.\n",
              "memory.zep_memory.ZepMemory\n",
              "Persist your chain history to the Zep MemoryStore.\n",
              "Functions¶\n",
              "memory.utils.get_prompt_input_key(inputs, ...)\n",
              "Get the prompt input key.\n",
              "langchain.model_laboratory¶\n",
              "Experiment with different models.\n",
              "Classes¶\n",
              "model_laboratory.ModelLaboratory(chains[, names])\n",
              "Experiment with different models.\n",
              "langchain.output_parsers¶\n",
              "OutputParser classes parse the output of an LLM call.\n",
              "Class hierarchy:\n",
              "BaseLLMOutputParser --> BaseOutputParser --> <name>OutputParser  # ListOutputParser, PydanticOutputParser\n",
              "Main helpers:\n",
              "Serializable, Generation, PromptValue\n",
              "Classes¶\n",
              "output_parsers.boolean.BooleanOutputParser\n",
              "Parse the output of an LLM call to a boolean.\n",
              "output_parsers.combining.CombiningOutputParser\n",
              "Combine multiple output parsers into one.\n",
              "output_parsers.datetime.DatetimeOutputParser\n",
              "Parse the output of an LLM call to a datetime.\n",
              "output_parsers.enum.EnumOutputParser\n",
              "Parse an output that is one of a set of values.\n",
              "output_parsers.fix.OutputFixingParser\n",
              "Wraps a parser and tries to fix parsing errors.\n",
              "output_parsers.pandas_dataframe.PandasDataFrameOutputParser\n",
              "Parse an output using Pandas DataFrame format.\n",
              "output_parsers.regex.RegexParser\n",
              "Parse the output of an LLM call using a regex.\n",
              "output_parsers.regex_dict.RegexDictParser\n",
              "Parse the output of an LLM call into a Dictionary using a regex.\n",
              "output_parsers.retry.RetryOutputParser\n",
              "Wraps a parser and tries to fix parsing errors.\n",
              "output_parsers.retry.RetryWithErrorOutputParser\n",
              "Wraps a parser and tries to fix parsing errors.\n",
              "output_parsers.structured.ResponseSchema\n",
              "A schema for a response from a structured output parser.\n",
              "output_parsers.structured.StructuredOutputParser\n",
              "Parse the output of an LLM call to a structured output.\n",
              "output_parsers.yaml.YamlOutputParser\n",
              "Parse YAML output using a pydantic model.\n",
              "Functions¶\n",
              "output_parsers.loading.load_output_parser(config)\n",
              "Load an output parser.\n",
              "langchain.retrievers¶\n",
              "Retriever class returns Documents given a text query.\n",
              "It is more general than a vector store. A retriever does not need to be able to\n",
              "store documents, only to return (or retrieve) it. Vector stores can be used as\n",
              "the backbone of a retriever, but there are other types of retrievers as well.\n",
              "Class hierarchy:\n",
              "BaseRetriever --> <name>Retriever  # Examples: ArxivRetriever, MergerRetriever\n",
              "Main helpers:\n",
              "Document, Serializable, Callbacks,\n",
              "CallbackManagerForRetrieverRun, AsyncCallbackManagerForRetrieverRun\n",
              "Classes¶\n",
              "retrievers.contextual_compression.ContextualCompressionRetriever\n",
              "Retriever that wraps a base retriever and compresses the results.\n",
              "retrievers.document_compressors.base.DocumentCompressorPipeline\n",
              "Document compressor that uses a pipeline of Transformers.\n",
              "retrievers.document_compressors.chain_extract.LLMChainExtractor\n",
              "Document compressor that uses an LLM chain to extract the relevant parts of documents.\n",
              "retrievers.document_compressors.chain_extract.NoOutputParser\n",
              "Parse outputs that could return a null string of some sort.\n",
              "retrievers.document_compressors.chain_filter.LLMChainFilter\n",
              "Filter that drops documents that aren't relevant to the query.\n",
              "retrievers.document_compressors.cohere_rerank.CohereRerank\n",
              "[Deprecated] Document compressor that uses Cohere Rerank API.\n",
              "retrievers.document_compressors.cross_encoder_rerank.CrossEncoderReranker\n",
              "Document compressor that uses CrossEncoder for reranking.\n",
              "retrievers.document_compressors.embeddings_filter.EmbeddingsFilter\n",
              "Document compressor that uses embeddings to drop documents unrelated to the query.\n",
              "retrievers.document_compressors.flashrank_rerank.FlashrankRerank\n",
              "Document compressor using Flashrank interface.\n",
              "retrievers.ensemble.EnsembleRetriever\n",
              "Retriever that ensembles the multiple retrievers.\n",
              "retrievers.merger_retriever.MergerRetriever\n",
              "Retriever that merges the results of multiple retrievers.\n",
              "retrievers.multi_query.LineListOutputParser\n",
              "Output parser for a list of lines.\n",
              "retrievers.multi_query.MultiQueryRetriever\n",
              "Given a query, use an LLM to write a set of queries.\n",
              "retrievers.multi_vector.MultiVectorRetriever\n",
              "Retrieve from a set of multiple embeddings for the same document.\n",
              "retrievers.multi_vector.SearchType(value)\n",
              "Enumerator of the types of search to perform.\n",
              "retrievers.parent_document_retriever.ParentDocumentRetriever\n",
              "Retrieve small chunks then retrieve their parent documents.\n",
              "retrievers.re_phraser.RePhraseQueryRetriever\n",
              "Given a query, use an LLM to re-phrase it.\n",
              "retrievers.self_query.astradb.AstraDBTranslator()\n",
              "Translate AstraDB internal query language elements to valid filters.\n",
              "retrievers.self_query.base.SelfQueryRetriever\n",
              "Retriever that uses a vector store and an LLM to generate the vector store queries.\n",
              "retrievers.self_query.chroma.ChromaTranslator()\n",
              "Translate Chroma internal query language elements to valid filters.\n",
              "retrievers.self_query.dashvector.DashvectorTranslator()\n",
              "Logic for converting internal query language elements to valid filters.\n",
              "retrievers.self_query.deeplake.DeepLakeTranslator()\n",
              "Translate DeepLake internal query language elements to valid filters.\n",
              "retrievers.self_query.dingo.DingoDBTranslator()\n",
              "Translate DingoDB internal query language elements to valid filters.\n",
              "retrievers.self_query.elasticsearch.ElasticsearchTranslator()\n",
              "Translate Elasticsearch internal query language elements to valid filters.\n",
              "retrievers.self_query.milvus.MilvusTranslator()\n",
              "Translate Milvus internal query language elements to valid filters.\n",
              "retrievers.self_query.mongodb_atlas.MongoDBAtlasTranslator()\n",
              "Translate Mongo internal query language elements to valid filters.\n",
              "retrievers.self_query.myscale.MyScaleTranslator([...])\n",
              "Translate MyScale internal query language elements to valid filters.\n",
              "retrievers.self_query.opensearch.OpenSearchTranslator()\n",
              "Translate OpenSearch internal query domain-specific language elements to valid filters.\n",
              "retrievers.self_query.pgvector.PGVectorTranslator()\n",
              "Translate PGVector internal query language elements to valid filters.\n",
              "retrievers.self_query.pinecone.PineconeTranslator()\n",
              "Translate Pinecone internal query language elements to valid filters.\n",
              "retrievers.self_query.qdrant.QdrantTranslator(...)\n",
              "Translate Qdrant internal query language elements to valid filters.\n",
              "retrievers.self_query.redis.RedisTranslator(schema)\n",
              "Visitor for translating structured queries to Redis filter expressions.\n",
              "retrievers.self_query.supabase.SupabaseVectorTranslator()\n",
              "Translate Langchain filters to Supabase PostgREST filters.\n",
              "retrievers.self_query.tencentvectordb.TencentVectorDBTranslator([...])\n",
              "retrievers.self_query.timescalevector.TimescaleVectorTranslator()\n",
              "Translate the internal query language elements to valid filters.\n",
              "retrievers.self_query.vectara.VectaraTranslator()\n",
              "Translate Vectara internal query language elements to valid filters.\n",
              "retrievers.self_query.weaviate.WeaviateTranslator()\n",
              "Translate Weaviate internal query language elements to valid filters.\n",
              "retrievers.time_weighted_retriever.TimeWeightedVectorStoreRetriever\n",
              "Retriever that combines embedding similarity with recency in retrieving values.\n",
              "retrievers.web_research.QuestionListOutputParser\n",
              "Output parser for a list of numbered questions.\n",
              "retrievers.web_research.SearchQueries\n",
              "Search queries to research for the user's goal.\n",
              "retrievers.web_research.WebResearchRetriever\n",
              "Google Search API retriever.\n",
              "Functions¶\n",
              "retrievers.document_compressors.chain_extract.default_get_input(...)\n",
              "Return the compression chain input.\n",
              "retrievers.document_compressors.chain_filter.default_get_input(...)\n",
              "Return the compression chain input.\n",
              "retrievers.ensemble.unique_by_key(iterable, key)\n",
              "retrievers.self_query.deeplake.can_cast_to_float(string)\n",
              "Check if a string can be cast to a float.\n",
              "retrievers.self_query.milvus.process_value(...)\n",
              "Convert a value to a string and add double quotes if it is a string.\n",
              "retrievers.self_query.vectara.process_value(value)\n",
              "Convert a value to a string and add single quotes if it is a string.\n",
              "langchain.runnables¶\n",
              "LangChain Runnable and the LangChain Expression Language (LCEL).\n",
              "The LangChain Expression Language (LCEL) offers a declarative method to build\n",
              "production-grade programs that harness the power of LLMs.\n",
              "Programs created using LCEL and LangChain Runnables inherently support\n",
              "synchronous, asynchronous, batch, and streaming operations.\n",
              "Support for async allows servers hosting the LCEL based programs\n",
              "to scale better for higher concurrent loads.\n",
              "Batch operations allow for processing multiple inputs in parallel.\n",
              "Streaming of intermediate outputs, as they’re being generated, allows for\n",
              "creating more responsive UX.\n",
              "This module contains non-core Runnable classes.\n",
              "Classes¶\n",
              "runnables.hub.HubRunnable\n",
              "An instance of a runnable stored in the LangChain Hub.\n",
              "runnables.openai_functions.OpenAIFunction\n",
              "A function description for ChatOpenAI\n",
              "runnables.openai_functions.OpenAIFunctionsRouter\n",
              "A runnable that routes to the selected function.\n",
              "langchain.smith¶\n",
              "LangSmith utilities.\n",
              "This module provides utilities for connecting to LangSmith. For more information on LangSmith, see the LangSmith documentation.\n",
              "Evaluation\n",
              "LangSmith helps you evaluate Chains and other language model application components using a number of LangChain evaluators.\n",
              "An example of this is shown below, assuming you’ve created a LangSmith dataset called <my_dataset_name>:\n",
              "from langsmith import Client\n",
              "from langchain_community.chat_models import ChatOpenAI\n",
              "from langchain.chains import LLMChain\n",
              "from langchain.smith import RunEvalConfig, run_on_dataset\n",
              "# Chains may have memory. Passing in a constructor function lets the\n",
              "# evaluation framework avoid cross-contamination between runs.\n",
              "def construct_chain():\n",
              "    llm = ChatOpenAI(temperature=0)\n",
              "    chain = LLMChain.from_string(\n",
              "        llm,\n",
              "        \"What's the answer to {your_input_key}\"\n",
              "    )\n",
              "    return chain\n",
              "# Load off-the-shelf evaluators via config or the EvaluatorType (string or enum)\n",
              "evaluation_config = RunEvalConfig(\n",
              "    evaluators=[\n",
              "        \"qa\",  # \"Correctness\" against a reference answer\n",
              "        \"embedding_distance\",\n",
              "        RunEvalConfig.Criteria(\"helpfulness\"),\n",
              "        RunEvalConfig.Criteria({\n",
              "            \"fifth-grader-score\": \"Do you have to be smarter than a fifth grader to answer this question?\"\n",
              "        }),\n",
              "    ]\n",
              ")\n",
              "client = Client()\n",
              "run_on_dataset(\n",
              "    client,\n",
              "    \"<my_dataset_name>\",\n",
              "    construct_chain,\n",
              "    evaluation=evaluation_config,\n",
              ")\n",
              "You can also create custom evaluators by subclassing the\n",
              "StringEvaluator\n",
              "or LangSmith’s RunEvaluator classes.\n",
              "from typing import Optional\n",
              "from langchain.evaluation import StringEvaluator\n",
              "class MyStringEvaluator(StringEvaluator):\n",
              "    @property\n",
              "    def requires_input(self) -> bool:\n",
              "        return False\n",
              "    @property\n",
              "    def requires_reference(self) -> bool:\n",
              "        return True\n",
              "    @property\n",
              "    def evaluation_name(self) -> str:\n",
              "        return \"exact_match\"\n",
              "    def _evaluate_strings(self, prediction, reference=None, input=None, **kwargs) -> dict:\n",
              "        return {\"score\": prediction == reference}\n",
              "evaluation_config = RunEvalConfig(\n",
              "    custom_evaluators = [MyStringEvaluator()],\n",
              ")\n",
              "run_on_dataset(\n",
              "    client,\n",
              "    \"<my_dataset_name>\",\n",
              "    construct_chain,\n",
              "    evaluation=evaluation_config,\n",
              ")\n",
              "Primary Functions\n",
              "arun_on_dataset: Asynchronous function to evaluate a chain, agent, or other LangChain component over a dataset.\n",
              "run_on_dataset: Function to evaluate a chain, agent, or other LangChain component over a dataset.\n",
              "RunEvalConfig: Class representing the configuration for running evaluation. You can select evaluators by EvaluatorType or config, or you can pass in custom_evaluators\n",
              "Classes¶\n",
              "smith.evaluation.config.EvalConfig\n",
              "Configuration for a given run evaluator.\n",
              "smith.evaluation.config.RunEvalConfig\n",
              "Configuration for a run evaluation.\n",
              "smith.evaluation.config.SingleKeyEvalConfig\n",
              "Configuration for a run evaluator that only requires a single key.\n",
              "smith.evaluation.progress.ProgressBarCallback(total)\n",
              "A simple progress bar for the console.\n",
              "smith.evaluation.runner_utils.ChatModelInput\n",
              "smith.evaluation.runner_utils.EvalError(...)\n",
              "Your architecture raised an error.\n",
              "smith.evaluation.runner_utils.InputFormatError\n",
              "Raised when the input format is invalid.\n",
              "smith.evaluation.runner_utils.TestResult\n",
              "A dictionary of the results of a single test run.\n",
              "smith.evaluation.string_run_evaluator.ChainStringRunMapper\n",
              "Extract items to evaluate from the run object from a chain.\n",
              "smith.evaluation.string_run_evaluator.LLMStringRunMapper\n",
              "Extract items to evaluate from the run object.\n",
              "smith.evaluation.string_run_evaluator.StringExampleMapper\n",
              "Map an example, or row in the dataset, to the inputs of an evaluation.\n",
              "smith.evaluation.string_run_evaluator.StringRunEvaluatorChain\n",
              "Evaluate Run and optional examples.\n",
              "smith.evaluation.string_run_evaluator.StringRunMapper\n",
              "Extract items to evaluate from the run object.\n",
              "smith.evaluation.string_run_evaluator.ToolStringRunMapper\n",
              "Map an input to the tool.\n",
              "Functions¶\n",
              "smith.evaluation.name_generation.random_name()\n",
              "Generate a random name.\n",
              "smith.evaluation.runner_utils.arun_on_dataset(...)\n",
              "Run the Chain or language model on a dataset and store traces to the specified project name.\n",
              "smith.evaluation.runner_utils.run_on_dataset(...)\n",
              "Run the Chain or language model on a dataset and store traces to the specified project name.\n",
              "langchain.storage¶\n",
              "Implementations of key-value stores and storage helpers.\n",
              "Module provides implementations of various key-value stores that conform\n",
              "to a simple key-value interface.\n",
              "The primary goal of these storages is to support implementation of caching.\n",
              "Classes¶\n",
              "storage.encoder_backed.EncoderBackedStore(...)\n",
              "Wraps a store with key and value encoders/decoders.\n",
              "storage.file_system.LocalFileStore(root_path, *)\n",
              "BaseStore interface that works on the local file system.\n",
              "storage.in_memory.InMemoryBaseStore()\n",
              "In-memory implementation of the BaseStore using a dictionary.\n",
              "langchain.tools¶\n",
              "Tools are classes that an Agent uses to interact with the world.\n",
              "Each tool has a description. Agent uses the description to choose the right\n",
              "tool for the job.\n",
              "Class hierarchy:\n",
              "ToolMetaclass --> BaseTool --> <name>Tool  # Examples: AIPluginTool, BaseGraphQLTool\n",
              "                               <name>      # Examples: BraveSearch, HumanInputRun\n",
              "Main helpers:\n",
              "CallbackManagerForToolRun, AsyncCallbackManagerForToolRun\n",
              "Classes¶\n",
              "tools.retriever.RetrieverInput\n",
              "Input to the retriever.\n",
              "Functions¶\n",
              "tools.render.render_text_description(tools)\n",
              "Render the tool name and description in plain text.\n",
              "tools.render.render_text_description_and_args(tools)\n",
              "Render the tool name, description, and args in plain text.\n",
              "tools.retriever.create_retriever_tool(...[, ...])\n",
              "Create a tool to do retrieval of documents.\n",
              "langchain.utils¶\n",
              "Utility functions for LangChain.\n",
              "These functions do not depend on any other LangChain module.\n",
              "Functions¶\n",
              "utils.interactive_env.is_interactive_env()\n",
              "Determine if running within IPython or Jupyter.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# содержимое чанков размера до 200токенов с устаревшими методами\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if '[Deprecated]' in docs[item].page_content]\n",
        "new_list = [item for item in new_list if 0<fragment_token_counts[item]<200]\n",
        "for i,somechunk in enumerate(new_list):\n",
        "    display(HTML(wrap(docs[somechunk].page_content,somechunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EzwIC--k9len",
        "outputId": "8d2a8a06-bcb8-4c40-9fba-a0992b7ca821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[9]===================</br><pre><code class=\"python\">langchain_anthropic 0.1.8¶\n",
              "langchain_anthropic.chat_models¶\n",
              "Classes¶\n",
              "chat_models.AnthropicTool\n",
              "chat_models.ChatAnthropic\n",
              "Anthropic chat model.\n",
              "chat_models.ChatAnthropicMessages\n",
              "[Deprecated]\n",
              "Functions¶\n",
              "chat_models.convert_to_anthropic_tool(tool)\n",
              "langchain_anthropic.experimental¶\n",
              "Classes¶\n",
              "experimental.ChatAnthropicTools\n",
              "[Deprecated] Chat model for interacting with Anthropic functions.\n",
              "Functions¶\n",
              "experimental.get_system_message(tools)\n",
              "langchain_anthropic.llms¶\n",
              "Classes¶\n",
              "llms.Anthropic\n",
              "[Deprecated]\n",
              "llms.AnthropicLLM\n",
              "Anthropic large language model.\n",
              "langchain_anthropic.output_parsers¶\n",
              "Classes¶\n",
              "output_parsers.ToolsOutputParser\n",
              "Fields\n",
              "Functions¶\n",
              "output_parsers.extract_tool_calls(content)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[26]==================</br><pre><code class=\"python\">langchain_pinecone 0.1.0¶\n",
              "langchain_pinecone.vectorstores¶\n",
              "Classes¶\n",
              "vectorstores.Pinecone([index, embedding, ...])\n",
              "[Deprecated] Deprecated.\n",
              "vectorstores.PineconeVectorStore([index, ...])\n",
              "Pinecone vector store.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[98]==================</br><pre><code class=\"python\">langchain.agents.loading.load_agent¶\n",
              "langchain.agents.loading.load_agent(path: Union[str, Path], **kwargs: Any) → Union[BaseSingleActionAgent, BaseMultiActionAgent][source]¶\n",
              "[Deprecated] Unified method for loading an agent from LangChainHub or local fs.\n",
              "Parameters\n",
              "path (Union[str, Path]) – Path to the agent file.\n",
              "**kwargs (Any) – Additional keyword arguments passed to the agent executor.\n",
              "Returns\n",
              "An agent executor.\n",
              "Return type\n",
              "Union[BaseSingleActionAgent, BaseMultiActionAgent]\n",
              "Notes\n",
              "Deprecated since version 0.1.0.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[99]==================</br><pre><code class=\"python\">langchain.agents.loading.load_agent_from_config¶\n",
              "langchain.agents.loading.load_agent_from_config(config: dict, llm: Optional[BaseLanguageModel] = None, tools: Optional[List[Tool]] = None, **kwargs: Any) → Union[BaseSingleActionAgent, BaseMultiActionAgent][source]¶\n",
              "[Deprecated] Load agent from Config Dict.\n",
              "Parameters\n",
              "config (dict) – Config dict to load agent from.\n",
              "llm (Optional[BaseLanguageModel]) – Language model to use as the agent.\n",
              "tools (Optional[List[Tool]]) – List of tools this agent has access to.\n",
              "**kwargs (Any) – Additional keyword arguments passed to the agent executor.\n",
              "Returns\n",
              "An agent executor.\n",
              "Return type\n",
              "Union[BaseSingleActionAgent, BaseMultiActionAgent]\n",
              "Notes\n",
              "Deprecated since version 0.1.0.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1153]=================</br><pre><code class=\"python\">langchain_core.utils.function_calling.convert_pydantic_to_openai_function¶\n",
              "langchain_core.utils.function_calling.convert_pydantic_to_openai_function(model: Type[BaseModel], *, name: Optional[str] = None, description: Optional[str] = None, rm_titles: bool = True) → FunctionDescription[source]¶\n",
              "[Deprecated] Converts a Pydantic model to a function description for the OpenAI API.\n",
              "Notes\n",
              "Deprecated since version 0.1.16: Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
              "Parameters\n",
              "model (Type[BaseModel]) – \n",
              "name (Optional[str]) – \n",
              "description (Optional[str]) – \n",
              "rm_titles (bool) – \n",
              "Return type\n",
              "FunctionDescription</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1154]=================</br><pre><code class=\"python\">langchain_core.utils.function_calling.convert_pydantic_to_openai_tool¶\n",
              "langchain_core.utils.function_calling.convert_pydantic_to_openai_tool(model: Type[BaseModel], *, name: Optional[str] = None, description: Optional[str] = None) → ToolDescription[source]¶\n",
              "[Deprecated] Converts a Pydantic model to a function description for the OpenAI API.\n",
              "Notes\n",
              "Deprecated since version 0.1.16: Use langchain_core.utils.function_calling.convert_to_openai_tool() instead.\n",
              "Parameters\n",
              "model (Type[BaseModel]) – \n",
              "name (Optional[str]) – \n",
              "description (Optional[str]) – \n",
              "Return type\n",
              "ToolDescription</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1155]=================</br><pre><code class=\"python\">langchain_core.utils.function_calling.convert_python_function_to_openai_function¶\n",
              "langchain_core.utils.function_calling.convert_python_function_to_openai_function(function: Callable) → Dict[str, Any][source]¶\n",
              "[Deprecated] Convert a Python function to an OpenAI function-calling API compatible dict.\n",
              "Assumes the Python function has type hints and a docstring with a description. Ifthe docstring has Google Python style argument descriptions, these will be\n",
              "included as well.\n",
              "Notes\n",
              "Deprecated since version 0.1.16: Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
              "Parameters\n",
              "function (Callable) – \n",
              "Return type\n",
              "Dict[str, Any]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1158]=================</br><pre><code class=\"python\">langchain_core.utils.function_calling.format_tool_to_openai_function¶\n",
              "langchain_core.utils.function_calling.format_tool_to_openai_function(tool: BaseTool) → FunctionDescription[source]¶\n",
              "[Deprecated] Format tool into the OpenAI function API.\n",
              "Notes\n",
              "Deprecated since version 0.1.16: Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
              "Parameters\n",
              "tool (BaseTool) – \n",
              "Return type\n",
              "FunctionDescription\n",
              "Examples using format_tool_to_openai_function¶\n",
              "Tools as OpenAI Functions</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1159]=================</br><pre><code class=\"python\">langchain_core.utils.function_calling.format_tool_to_openai_tool¶\n",
              "langchain_core.utils.function_calling.format_tool_to_openai_tool(tool: BaseTool) → ToolDescription[source]¶\n",
              "[Deprecated] Format tool into the OpenAI function API.\n",
              "Notes\n",
              "Deprecated since version 0.1.16: Use langchain_core.utils.function_calling.convert_to_openai_tool() instead.\n",
              "Parameters\n",
              "tool (BaseTool) – \n",
              "Return type\n",
              "ToolDescription</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1176]=================</br><pre><code class=\"python\">langchain_core.utils.loading.try_load_from_hub¶\n",
              "langchain_core.utils.loading.try_load_from_hub(*args: Any, **kwargs: Any) → Any[source]¶\n",
              "[Deprecated]\n",
              "Notes\n",
              "Deprecated since version 0.1.30: Using the hwchase17/langchain-hub repo for prompts is deprecated. Please use https://smith.langchain.com/hub instead.\n",
              "Parameters\n",
              "args (Any) – \n",
              "kwargs (Any) – \n",
              "Return type\n",
              "Any</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[1634]=================</br><pre><code class=\"python\">langchain_core.tracers.schemas.RunTypeEnum¶\n",
              "langchain_core.tracers.schemas.RunTypeEnum() → Type[RunTypeEnum][source]¶\n",
              "[Deprecated] RunTypeEnum.\n",
              "Notes\n",
              "Deprecated since version 0.1.0: Use Use string instead. instead.\n",
              "Return type\n",
              "Type[RunTypeEnum]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# содержимое чанков размера ~100токенов\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if 90<fragment_token_counts[item]<100]\n",
        "for i,somechunk in enumerate(new_list[:2]):\n",
        "    display(HTML(wrap(docs[somechunk].page_content,somechunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Gj9RBYUM6vDA",
        "outputId": "c46f15ec-1291-4ae5-8991-b5f614eefe54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[14]==================</br><pre><code class=\"python\">langchain_exa 0.0.1¶\n",
              "langchain_exa.retrievers¶\n",
              "Classes¶\n",
              "retrievers.ExaSearchRetriever\n",
              "Exa Search retriever.\n",
              "langchain_exa.tools¶\n",
              "Tool for the Exa Search API.\n",
              "Classes¶\n",
              "tools.ExaFindSimilarResults\n",
              "Tool that queries the Metaphor Search API and gets back json.\n",
              "tools.ExaSearchResults\n",
              "Tool that queries the Metaphor Search API and gets back json.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[15]==================</br><pre><code class=\"python\">langchain_fireworks 0.1.2¶\n",
              "langchain_fireworks.chat_models¶\n",
              "Fireworks chat wrapper.\n",
              "Classes¶\n",
              "chat_models.ChatFireworks\n",
              "Fireworks Chat large language models API.\n",
              "langchain_fireworks.embeddings¶\n",
              "Classes¶\n",
              "embeddings.FireworksEmbeddings\n",
              "FireworksEmbeddings embedding model.\n",
              "langchain_fireworks.llms¶\n",
              "Wrapper around Fireworks AI’s Completion API.\n",
              "Classes¶\n",
              "llms.Fireworks\n",
              "LLM models from Fireworks.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# содержимое чанков размера ~150токенов\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if 140<fragment_token_counts[item]<150]\n",
        "for i,somechunk in enumerate(new_list[:2]):\n",
        "    display(HTML(wrap(docs[somechunk].page_content,somechunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "rB894p636MMG",
        "outputId": "5bd75552-7ee5-4234-a4c4-141cf46d7333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[25]==================</br><pre><code class=\"python\">langchain_openai 0.1.3¶\n",
              "langchain_openai.chat_models¶\n",
              "Classes¶\n",
              "chat_models.azure.AzureChatOpenAI\n",
              "Azure OpenAI Chat Completion API.\n",
              "chat_models.base.ChatOpenAI\n",
              "OpenAI Chat large language models API.\n",
              "langchain_openai.embeddings¶\n",
              "Classes¶\n",
              "embeddings.azure.AzureOpenAIEmbeddings\n",
              "Azure OpenAI Embeddings API.\n",
              "embeddings.base.OpenAIEmbeddings\n",
              "OpenAI embedding models.\n",
              "langchain_openai.llms¶\n",
              "Classes¶\n",
              "llms.azure.AzureOpenAI\n",
              "Azure-specific OpenAI large language models.\n",
              "llms.base.BaseOpenAI\n",
              "Base OpenAI large language model class.\n",
              "llms.base.OpenAI\n",
              "OpenAI large language models.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[802]==================</br><pre><code class=\"python\">langchain_core.runnables.graph_mermaid.draw_mermaid_png¶\n",
              "langchain_core.runnables.graph_mermaid.draw_mermaid_png(mermaid_syntax: str, output_file_path: Optional[str] = None, draw_method: MermaidDrawMethod = MermaidDrawMethod.API, background_color: Optional[str] = 'white', padding: int = 10) → bytes[source]¶\n",
              "Draws a Mermaid graph as PNG using provided syntax.\n",
              "Parameters\n",
              "mermaid_syntax (str) – \n",
              "output_file_path (Optional[str]) – \n",
              "draw_method (MermaidDrawMethod) – \n",
              "background_color (Optional[str]) – \n",
              "padding (int) – \n",
              "Return type\n",
              "bytes</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# содержимое чанков размера 600-700токенов\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if 600<fragment_token_counts[item]<700]\n",
        "for i,somechunk in enumerate(new_list[:2]):\n",
        "    display(HTML(wrap(docs[somechunk].page_content,somechunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zXIkyIu221gd",
        "outputId": "458abcc9-e4d3-4194-fc5e-cc7bd91d5b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[93]==================</br><pre><code class=\"python\">langchain.agents.initialize.initialize_agent¶\n",
              "langchain.agents.initialize.initialize_agent(tools: Sequence[BaseTool], llm: BaseLanguageModel, agent: Optional[AgentType] = None, callback_manager: Optional[BaseCallbackManager] = None, agent_path: Optional[str] = None, agent_kwargs: Optional[dict] = None, *, tags: Optional[Sequence[str]] = None, **kwargs: Any) → AgentExecutor[source]¶\n",
              "[Deprecated] Load an agent executor given tools and LLM.\n",
              "Parameters\n",
              "tools (Sequence[BaseTool]) – List of tools this agent has access to.\n",
              "llm (BaseLanguageModel) – Language model to use as the agent.\n",
              "agent (Optional[AgentType]) – Agent type to use. If None and agent_path is also None, will default to\n",
              "AgentType.ZERO_SHOT_REACT_DESCRIPTION.\n",
              "callback_manager (Optional[BaseCallbackManager]) – CallbackManager to use. Global callback manager is used if\n",
              "not provided. Defaults to None.\n",
              "agent_path (Optional[str]) – Path to serialized agent to use.\n",
              "agent_kwargs (Optional[dict]) – Additional keyword arguments to pass to the underlying agent\n",
              "tags (Optional[Sequence[str]]) – Tags to apply to the traced runs.\n",
              "**kwargs (Any) – Additional keyword arguments passed to the agent executor\n",
              "Returns\n",
              "An agent executor\n",
              "Return type\n",
              "AgentExecutor\n",
              "Notes\n",
              "Deprecated since version 0.1.0: Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
              "Examples using initialize_agent¶\n",
              "AINetwork\n",
              "AWS Lambda\n",
              "Access intermediate steps\n",
              "Add Memory to OpenAI Functions Agent\n",
              "Agent Debates with Tools\n",
              "Agent Trajectory\n",
              "Agents\n",
              "Aim\n",
              "Amadeus\n",
              "Amazon API Gateway\n",
              "ArXiv\n",
              "Argilla\n",
              "Async API\n",
              "Azure Cognitive Services\n",
              "Bittensor\n",
              "Cap the max number of iterations\n",
              "ChatGPT Plugins\n",
              "ClearML\n",
              "Combine agents and vector stores\n",
              "Comet\n",
              "Comparing Chain Outputs\n",
              "Custom functions with OpenAI Functions Agent\n",
              "Dall-E Image Generator\n",
              "Debugging\n",
              "Defining Custom Tools\n",
              "Document Comparison\n",
              "Dynamodb Chat Message History\n",
              "Eden AI\n",
              "Eleven Labs Text2Speech\n",
              "Fake LLM\n",
              "Flyte\n",
              "Github\n",
              "Gitlab\n",
              "Gmail\n",
              "Google Drive\n",
              "Google Drive tool\n",
              "Google Serper\n",
              "Gradio\n",
              "GraphQL\n",
              "Handle parsing errors\n",
              "Hugging Face Prompt Injection Identification\n",
              "Human as a tool\n",
              "Human input LLM\n",
              "Human input chat model\n",
              "Human-in-the-loop Tool Validation\n",
              "Jira\n",
              "LLMonitor\n",
              "LangSmith Walkthrough\n",
              "Log, Trace, and Monitor\n",
              "MLflow\n",
              "Metaphor Search\n",
              "Multi-Input Tools\n",
              "Multi-modal outputs: Image & Text\n",
              "MultiOn\n",
              "Multiple callback handlers\n",
              "Natural Language APIs\n",
              "Office365\n",
              "OpenAI Multi Functions Agent\n",
              "OpenWeatherMap\n",
              "PlayWright Browser\n",
              "Portkey\n",
              "ReAct document store\n",
              "Running Agent as an Iterator\n",
              "SageMaker Tracking\n",
              "SceneXplain\n",
              "Search Tools\n",
              "Self-ask with search\n",
              "Shell (bash)\n",
              "Streaming final agent output\n",
              "Streamlit\n",
              "Timeouts for agents\n",
              "Tool Input Schema\n",
              "Tracking token usage\n",
              "Use ToolKits with OpenAI Functions\n",
              "WandB Tracing\n",
              "Weights & Biases\n",
              "Xata chat memory\n",
              "Yahoo Finance News\n",
              "Zapier Natural Language Actions\n",
              "Zep Memory</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[97]==================</br><pre><code class=\"python\">langchain.agents.load_tools.load_tools¶\n",
              "langchain.agents.load_tools.load_tools(tool_names: List[str], llm: Optional[BaseLanguageModel] = None, callbacks: Optional[Union[List[BaseCallbackHandler], BaseCallbackManager]] = None, allow_dangerous_tools: bool = False, **kwargs: Any) → List[BaseTool][source]¶\n",
              "Load tools based on their name.\n",
              "Tools allow agents to interact with various resources and services like\n",
              "APIs, databases, file systems, etc.\n",
              "Please scope the permissions of each tools to the minimum required for the\n",
              "application.\n",
              "For example, if an application only needs to read from a database,\n",
              "the database tool should not be given write permissions. Moreover\n",
              "consider scoping the permissions to only allow accessing specific\n",
              "tables and impose user-level quota for limiting resource usage.\n",
              "Please read the APIs of the individual tools to determine which configuration\n",
              "they support.\n",
              "See [Security](https://python.langchain.com/docs/security) for more information.\n",
              "Parameters\n",
              "tool_names (List[str]) – name of tools to load.\n",
              "llm (Optional[BaseLanguageModel]) – An optional language model, may be needed to initialize certain tools.\n",
              "callbacks (Optional[Union[List[BaseCallbackHandler], BaseCallbackManager]]) – Optional callback manager or list of callback handlers.\n",
              "If not provided, default global callback manager will be used.\n",
              "allow_dangerous_tools (bool) – Optional flag to allow dangerous tools.\n",
              "Tools that contain some level of risk.\n",
              "Please use with caution and read the documentation of these tools\n",
              "to understand the risks and how to mitigate them.\n",
              "Refer to https://python.langchain.com/docs/security\n",
              "for more information.\n",
              "Please note that this list may not be fully exhaustive.\n",
              "It is your responsibility to understand which tools\n",
              "you’re using and the risks associated with them.\n",
              "kwargs (Any) – \n",
              "Returns\n",
              "List of tools.\n",
              "Return type\n",
              "List[BaseTool]\n",
              "Examples using load_tools¶\n",
              "AWS Lambda\n",
              "Access intermediate steps\n",
              "Agent Debates with Tools\n",
              "Agents\n",
              "Aim\n",
              "Amazon API Gateway\n",
              "ArXiv\n",
              "Argilla\n",
              "Async API\n",
              "Bittensor\n",
              "Cap the max number of iterations\n",
              "ChatGPT Plugins\n",
              "ClearML\n",
              "Comet\n",
              "Dall-E Image Generator\n",
              "DataForSEO\n",
              "Debugging\n",
              "Defining Custom Tools\n",
              "Eleven Labs Text2Speech\n",
              "Fake LLM\n",
              "Flyte\n",
              "Golden\n",
              "Google Drive\n",
              "Google Drive tool\n",
              "Google Search\n",
              "Google Serper\n",
              "GraphQL\n",
              "Human as a tool\n",
              "Human input LLM\n",
              "Human input chat model\n",
              "Human-in-the-loop Tool Validation\n",
              "LLMonitor\n",
              "LangSmith Walkthrough\n",
              "Log, Trace, and Monitor\n",
              "MLflow\n",
              "Multiple callback handlers\n",
              "OpenWeatherMap\n",
              "Portkey\n",
              "Requests\n",
              "SageMaker Tracking\n",
              "SceneXplain\n",
              "Search Tools\n",
              "SearxNG Search API\n",
              "SerpAPI\n",
              "Streaming final agent output\n",
              "Streamlit\n",
              "Timeouts for agents\n",
              "Tracking token usage\n",
              "WandB Tracing\n",
              "Weights & Biases\n",
              "Wolfram Alpha</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,smallchunk in enumerate(smallchunks[:6]):\n",
        "    display(HTML(wrap(docs[smallchunk].page_content,smallchunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "xYb_eU_9loma",
        "outputId": "f38e5862-b94b-4493-ae3e-553dc9746e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[0]===================</br><pre><code class=\"python\"></code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[1]===================</br><pre><code class=\"python\"></code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[2]===================</br><pre><code class=\"python\">langchain_together 0.1.0¶\n",
              "langchain_together.embeddings¶\n",
              "Classes¶\n",
              "embeddings.TogetherEmbeddings\n",
              "TogetherEmbeddings embedding model.\n",
              "langchain_together.llms¶\n",
              "Wrapper around Together AI’s Completion API.\n",
              "Classes¶\n",
              "llms.Together\n",
              "LLM models from Together.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[5]===================</br><pre><code class=\"python\">langchain_pinecone 0.1.0¶\n",
              "langchain_pinecone.vectorstores¶\n",
              "Classes¶\n",
              "vectorstores.Pinecone([index, embedding, ...])\n",
              "[Deprecated] Deprecated.\n",
              "vectorstores.PineconeVectorStore([index, ...])\n",
              "Pinecone vector store.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[6]===================</br><pre><code class=\"python\">langchain_ibm 0.1.3¶</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[13]==================</br><pre><code class=\"python\">langchain_nomic 0.0.2¶\n",
              "langchain_nomic.embeddings¶\n",
              "Classes¶\n",
              "embeddings.NomicEmbeddings(*, model[, ...])\n",
              "NomicEmbeddings embedding model.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,middlechunk in enumerate(middlechunks[:6]):\n",
        "    display(HTML(wrap(docs[middlechunk].page_content,middlechunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kBzcnPjfq4DY",
        "outputId": "5498360c-e687-450c-cea5-07677e9dc8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[8]===================</br><pre><code class=\"python\">langchain_openai 0.1.3¶\n",
              "langchain_openai.chat_models¶\n",
              "Classes¶\n",
              "chat_models.azure.AzureChatOpenAI\n",
              "Azure OpenAI Chat Completion API.\n",
              "chat_models.base.ChatOpenAI\n",
              "OpenAI Chat large language models API.\n",
              "langchain_openai.embeddings¶\n",
              "Classes¶\n",
              "embeddings.azure.AzureOpenAIEmbeddings\n",
              "Azure OpenAI Embeddings API.\n",
              "embeddings.base.OpenAIEmbeddings\n",
              "OpenAI embedding models.\n",
              "langchain_openai.llms¶\n",
              "Classes¶\n",
              "llms.azure.AzureOpenAI\n",
              "Azure-specific OpenAI large language models.\n",
              "llms.base.BaseOpenAI\n",
              "Base OpenAI large language model class.\n",
              "llms.base.OpenAI\n",
              "OpenAI large language models.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[10]==================</br><pre><code class=\"python\">langchain_mistralai 0.1.2¶\n",
              "langchain_mistralai.chat_models¶\n",
              "Classes¶\n",
              "chat_models.ChatMistralAI\n",
              "A chat model that uses the MistralAI API.\n",
              "Functions¶\n",
              "chat_models.acompletion_with_retry(llm[, ...])\n",
              "Use tenacity to retry the async completion call.\n",
              "langchain_mistralai.embeddings¶\n",
              "Classes¶\n",
              "embeddings.MistralAIEmbeddings\n",
              "MistralAI embedding models.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[11]==================</br><pre><code class=\"python\">langchain_anthropic 0.1.8¶\n",
              "langchain_anthropic.chat_models¶\n",
              "Classes¶\n",
              "chat_models.AnthropicTool\n",
              "chat_models.ChatAnthropic\n",
              "Anthropic chat model.\n",
              "chat_models.ChatAnthropicMessages\n",
              "[Deprecated]\n",
              "Functions¶\n",
              "chat_models.convert_to_anthropic_tool(tool)\n",
              "langchain_anthropic.experimental¶\n",
              "Classes¶\n",
              "experimental.ChatAnthropicTools\n",
              "[Deprecated] Chat model for interacting with Anthropic functions.\n",
              "Functions¶\n",
              "experimental.get_system_message(tools)\n",
              "langchain_anthropic.llms¶\n",
              "Classes¶\n",
              "llms.Anthropic\n",
              "[Deprecated]\n",
              "llms.AnthropicLLM\n",
              "Anthropic large language model.\n",
              "langchain_anthropic.output_parsers¶\n",
              "Classes¶\n",
              "output_parsers.ToolsOutputParser\n",
              "Fields\n",
              "Functions¶\n",
              "output_parsers.extract_tool_calls(content)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[12]==================</br><pre><code class=\"python\">langchain_postgres 0.0.1¶\n",
              "langchain_postgres.chat_message_histories¶\n",
              "Client for persisting chat message history in a Postgres database.\n",
              "This client provides support for both sync and async via psycopg 3.\n",
              "Classes¶\n",
              "chat_message_histories.PostgresChatMessageHistory(...)\n",
              "Client for persisting chat message history in a Postgres database,\n",
              "langchain_postgres.checkpoint¶\n",
              "Implementation of a langgraph checkpoint saver using Postgres.\n",
              "Classes¶\n",
              "checkpoint.CheckpointSerializer()\n",
              "A serializer for serializing and deserializing objects to and from bytes.\n",
              "checkpoint.PickleCheckpointSerializer()\n",
              "Use the pickle module to serialize and deserialize objects.\n",
              "checkpoint.PostgresSaver\n",
              "LangGraph checkpoint saver for Postgres.\n",
              "langchain_postgres.vectorstores¶\n",
              "Classes¶\n",
              "vectorstores.DistanceStrategy(value)\n",
              "Enumerator of the Distance strategies.\n",
              "vectorstores.PGVector(embeddings, *[, ...])\n",
              "Vectorstore implementation using Postgres as the backend.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[23]==================</br><pre><code class=\"python\">langchain_nvidia_trt 0.0.1¶\n",
              "langchain_nvidia_trt.llms¶\n",
              "Classes¶\n",
              "llms.StreamingResponseGenerator(llm, ...)\n",
              "A Generator that provides the inference results from an LLM.\n",
              "llms.TritonTensorRTError\n",
              "Base exception for TritonTensorRT.\n",
              "llms.TritonTensorRTLLM\n",
              "TRTLLM triton models.\n",
              "llms.TritonTensorRTRuntimeError\n",
              "Runtime error for TritonTensorRT.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[25]==================</br><pre><code class=\"python\">langchain_robocorp 0.0.5¶\n",
              "langchain_robocorp.toolkits¶\n",
              "Robocorp Action Server toolkit.\n",
              "Classes¶\n",
              "toolkits.ActionServerRequestTool\n",
              "Requests POST tool with LLM-instructed extraction of truncated responses.\n",
              "toolkits.ActionServerToolkit\n",
              "Toolkit exposing Robocorp Action Server provided actions as individual tools.\n",
              "toolkits.RunDetailsCallbackHandler(run_details)\n",
              "Callback handler to add run details to the run.\n",
              "toolkits.ToolArgs\n",
              "Tool arguments.\n",
              "toolkits.ToolInputSchema\n",
              "Tool input schema.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for bigchunk in bigchunks:\n",
        "    display(HTML(wrap(docs[bigchunk].page_content,bigchunk)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LARm8uByjHpE",
        "outputId": "503da0e4-aafc-435a-ae57-192b48179d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==================startchunk[29]==================</br><pre><code class=\"python\">langchain_community 0.0.32¶\n",
              "langchain_community.adapters¶\n",
              "Adapters are used to adapt LangChain models to other APIs.\n",
              "LangChain integrates with many model providers.\n",
              "While LangChain has its own message and model APIs,\n",
              "LangChain has also made it as easy as\n",
              "possible to explore other models by exposing an adapter to adapt LangChain\n",
              "models to the other APIs, as to the OpenAI API.\n",
              "Classes¶\n",
              "adapters.openai.Chat()\n",
              "Chat.\n",
              "adapters.openai.ChatCompletion()\n",
              "Chat completion.\n",
              "adapters.openai.ChatCompletionChunk\n",
              "Chat completion chunk.\n",
              "adapters.openai.ChatCompletions\n",
              "Chat completions.\n",
              "adapters.openai.Choice\n",
              "Choice.\n",
              "adapters.openai.ChoiceChunk\n",
              "Choice chunk.\n",
              "adapters.openai.Completions()\n",
              "Completions.\n",
              "adapters.openai.IndexableBaseModel\n",
              "Allows a BaseModel to return its fields by string variable indexing.\n",
              "Functions¶\n",
              "adapters.openai.aenumerate(iterable[, start])\n",
              "Async version of enumerate function.\n",
              "adapters.openai.convert_dict_to_message(_dict)\n",
              "Convert a dictionary to a LangChain message.\n",
              "adapters.openai.convert_message_to_dict(message)\n",
              "Convert a LangChain message to a dictionary.\n",
              "adapters.openai.convert_messages_for_finetuning(...)\n",
              "Convert messages to a list of lists of dictionaries for fine-tuning.\n",
              "adapters.openai.convert_openai_messages(messages)\n",
              "Convert dictionaries representing OpenAI messages to LangChain format.\n",
              "langchain_community.agent_toolkits¶\n",
              "Toolkits are sets of tools that can be used to interact with\n",
              "various services and APIs.\n",
              "Classes¶\n",
              "agent_toolkits.ainetwork.toolkit.AINetworkToolkit\n",
              "Toolkit for interacting with AINetwork Blockchain.\n",
              "agent_toolkits.amadeus.toolkit.AmadeusToolkit\n",
              "Toolkit for interacting with Amadeus which offers APIs for travel.\n",
              "agent_toolkits.azure_ai_services.AzureAiServicesToolkit\n",
              "Toolkit for Azure AI Services.\n",
              "agent_toolkits.azure_cognitive_services.AzureCognitiveServicesToolkit\n",
              "Toolkit for Azure Cognitive Services.\n",
              "agent_toolkits.base.BaseToolkit\n",
              "Base Toolkit representing a collection of related tools.\n",
              "agent_toolkits.clickup.toolkit.ClickupToolkit\n",
              "Clickup Toolkit.\n",
              "agent_toolkits.cogniswitch.toolkit.CogniswitchToolkit\n",
              "Toolkit for CogniSwitch.\n",
              "agent_toolkits.connery.toolkit.ConneryToolkit\n",
              "Toolkit with a list of Connery Actions as tools.\n",
              "agent_toolkits.file_management.toolkit.FileManagementToolkit\n",
              "Toolkit for interacting with local files.\n",
              "agent_toolkits.github.toolkit.BranchName\n",
              "Schema for operations that require a branch name as input.\n",
              "agent_toolkits.github.toolkit.CommentOnIssue\n",
              "Schema for operations that require a comment as input.\n",
              "agent_toolkits.github.toolkit.CreateFile\n",
              "Schema for operations that require a file path and content as input.\n",
              "agent_toolkits.github.toolkit.CreatePR\n",
              "Schema for operations that require a PR title and body as input.\n",
              "agent_toolkits.github.toolkit.CreateReviewRequest\n",
              "Schema for operations that require a username as input.\n",
              "agent_toolkits.github.toolkit.DeleteFile\n",
              "Schema for operations that require a file path as input.\n",
              "agent_toolkits.github.toolkit.DirectoryPath\n",
              "Schema for operations that require a directory path as input.\n",
              "agent_toolkits.github.toolkit.GetIssue\n",
              "Schema for operations that require an issue number as input.\n",
              "agent_toolkits.github.toolkit.GetPR\n",
              "Schema for operations that require a PR number as input.\n",
              "agent_toolkits.github.toolkit.GitHubToolkit\n",
              "GitHub Toolkit.\n",
              "agent_toolkits.github.toolkit.NoInput\n",
              "Schema for operations that do not require any input.\n",
              "agent_toolkits.github.toolkit.ReadFile\n",
              "Schema for operations that require a file path as input.\n",
              "agent_toolkits.github.toolkit.SearchCode\n",
              "Schema for operations that require a search query as input.\n",
              "agent_toolkits.github.toolkit.SearchIssuesAndPRs\n",
              "Schema for operations that require a search query as input.\n",
              "agent_toolkits.github.toolkit.UpdateFile\n",
              "Schema for operations that require a file path and content as input.\n",
              "agent_toolkits.gitlab.toolkit.GitLabToolkit\n",
              "GitLab Toolkit.\n",
              "agent_toolkits.gmail.toolkit.GmailToolkit\n",
              "Toolkit for interacting with Gmail.\n",
              "agent_toolkits.jira.toolkit.JiraToolkit\n",
              "Jira Toolkit.\n",
              "agent_toolkits.json.toolkit.JsonToolkit\n",
              "Toolkit for interacting with a JSON spec.\n",
              "agent_toolkits.multion.toolkit.MultionToolkit\n",
              "Toolkit for interacting with the Browser Agent.\n",
              "agent_toolkits.nasa.toolkit.NasaToolkit\n",
              "Nasa Toolkit.\n",
              "agent_toolkits.nla.tool.NLATool\n",
              "Natural Language API Tool.\n",
              "agent_toolkits.nla.toolkit.NLAToolkit\n",
              "Natural Language API Toolkit.\n",
              "agent_toolkits.office365.toolkit.O365Toolkit\n",
              "Toolkit for interacting with Office 365.\n",
              "agent_toolkits.openapi.planner.RequestsDeleteToolWithParsing\n",
              "Tool that sends a DELETE request and parses the response.\n",
              "agent_toolkits.openapi.planner.RequestsGetToolWithParsing\n",
              "Requests GET tool with LLM-instructed extraction of truncated responses.\n",
              "agent_toolkits.openapi.planner.RequestsPatchToolWithParsing\n",
              "Requests PATCH tool with LLM-instructed extraction of truncated responses.\n",
              "agent_toolkits.openapi.planner.RequestsPostToolWithParsing\n",
              "Requests POST tool with LLM-instructed extraction of truncated responses.\n",
              "agent_toolkits.openapi.planner.RequestsPutToolWithParsing\n",
              "Requests PUT tool with LLM-instructed extraction of truncated responses.\n",
              "agent_toolkits.openapi.spec.ReducedOpenAPISpec(...)\n",
              "A reduced OpenAPI spec.\n",
              "agent_toolkits.openapi.toolkit.OpenAPIToolkit\n",
              "Toolkit for interacting with an OpenAPI API.\n",
              "agent_toolkits.openapi.toolkit.RequestsToolkit\n",
              "Toolkit for making REST requests.\n",
              "agent_toolkits.playwright.toolkit.PlayWrightBrowserToolkit\n",
              "Toolkit for PlayWright browser tools.\n",
              "agent_toolkits.polygon.toolkit.PolygonToolkit\n",
              "Polygon Toolkit.\n",
              "agent_toolkits.powerbi.toolkit.PowerBIToolkit\n",
              "Toolkit for interacting with Power BI dataset.\n",
              "agent_toolkits.slack.toolkit.SlackToolkit\n",
              "Toolkit for interacting with Slack.\n",
              "agent_toolkits.spark_sql.toolkit.SparkSQLToolkit\n",
              "Toolkit for interacting with Spark SQL.\n",
              "agent_toolkits.sql.toolkit.SQLDatabaseToolkit\n",
              "Toolkit for interacting with SQL databases.\n",
              "agent_toolkits.steam.toolkit.SteamToolkit\n",
              "Steam Toolkit.\n",
              "agent_toolkits.zapier.toolkit.ZapierToolkit\n",
              "Zapier Toolkit.\n",
              "Functions¶\n",
              "agent_toolkits.json.base.create_json_agent(...)\n",
              "Construct a json agent from an LLM and tools.\n",
              "agent_toolkits.openapi.base.create_openapi_agent(...)\n",
              "Construct an OpenAPI agent from an LLM and tools.\n",
              "agent_toolkits.openapi.planner.create_openapi_agent(...)\n",
              "Construct an OpenAI API planner and controller for a given spec.\n",
              "agent_toolkits.openapi.spec.reduce_openapi_spec(spec)\n",
              "Simplify/distill/minify a spec somehow.\n",
              "agent_toolkits.powerbi.base.create_pbi_agent(llm)\n",
              "Construct a Power BI agent from an LLM and tools.\n",
              "agent_toolkits.powerbi.chat_base.create_pbi_chat_agent(llm)\n",
              "Construct a Power BI agent from a Chat LLM and tools.\n",
              "agent_toolkits.spark_sql.base.create_spark_sql_agent(...)\n",
              "Construct a Spark SQL agent from an LLM and tools.\n",
              "agent_toolkits.sql.base.create_sql_agent(llm)\n",
              "Construct a SQL agent from an LLM and toolkit or database.\n",
              "langchain_community.cache¶\n",
              "Warning\n",
              "Beta Feature!\n",
              "Cache provides an optional caching layer for LLMs.\n",
              "Cache is useful for two reasons:\n",
              "It can save you money by reducing the number of API calls you make to the LLM\n",
              "provider if you’re often requesting the same completion multiple times.\n",
              "It can speed up your application by reducing the number of API calls you make\n",
              "to the LLM provider.\n",
              "Cache directly competes with Memory. See documentation for Pros and Cons.\n",
              "Class hierarchy:\n",
              "BaseCache --> <name>Cache  # Examples: InMemoryCache, RedisCache, GPTCache\n",
              "Classes¶\n",
              "cache.AstraDBCache(*[, collection_name, ...])\n",
              "[Deprecated]\n",
              "cache.AstraDBSemanticCache(*[, ...])\n",
              "[Deprecated]\n",
              "cache.AsyncRedisCache(redis_, *[, ttl])\n",
              "Cache that uses Redis as a backend.\n",
              "cache.AzureCosmosDBSemanticCache(...[, ...])\n",
              "Cache that uses Cosmos DB Mongo vCore vector-store backend\n",
              "cache.CassandraCache([session, keyspace, ...])\n",
              "Cache that uses Cassandra / Astra DB as a backend.\n",
              "cache.CassandraSemanticCache(session, ...[, ...])\n",
              "Cache that uses Cassandra as a vector-store backend for semantic (i.e.\n",
              "cache.FullLLMCache(**kwargs)\n",
              "SQLite table for full LLM Cache (all generations).\n",
              "cache.FullMd5LLMCache(**kwargs)\n",
              "SQLite table for full LLM Cache (all generations).\n",
              "cache.GPTCache([init_func])\n",
              "Cache that uses GPTCache as a backend.\n",
              "cache.InMemoryCache()\n",
              "Cache that stores things in memory.\n",
              "cache.MomentoCache(cache_client, cache_name, *)\n",
              "Cache that uses Momento as a backend.\n",
              "cache.RedisCache(redis_, *[, ttl])\n",
              "Cache that uses Redis as a backend.\n",
              "cache.RedisSemanticCache(redis_url, embedding)\n",
              "Cache that uses Redis as a vector-store backend.\n",
              "cache.SQLAlchemyCache(engine, cache_schema)\n",
              "Cache that uses SQAlchemy as a backend.\n",
              "cache.SQLAlchemyMd5Cache(engine, cache_schema)\n",
              "Cache that uses SQAlchemy as a backend.\n",
              "cache.SQLiteCache([database_path])\n",
              "Cache that uses SQLite as a backend.\n",
              "cache.UpstashRedisCache(redis_, *[, ttl])\n",
              "Cache that uses Upstash Redis as a backend.\n",
              "langchain_community.callbacks¶\n",
              "Callback handlers allow listening to events in LangChain.\n",
              "Class hierarchy:\n",
              "BaseCallbackHandler --> <name>CallbackHandler  # Example: AimCallbackHandler\n",
              "Classes¶\n",
              "callbacks.aim_callback.AimCallbackHandler([...])\n",
              "Callback Handler that logs to Aim.\n",
              "callbacks.aim_callback.BaseMetadataCallbackHandler()\n",
              "This class handles the metadata and associated function states for callbacks.\n",
              "callbacks.argilla_callback.ArgillaCallbackHandler(...)\n",
              "Callback Handler that logs into Argilla.\n",
              "callbacks.arize_callback.ArizeCallbackHandler([...])\n",
              "Callback Handler that logs to Arize.\n",
              "callbacks.arthur_callback.ArthurCallbackHandler(...)\n",
              "Callback Handler that logs to Arthur platform.\n",
              "callbacks.bedrock_anthropic_callback.BedrockAnthropicTokenUsageCallbackHandler()\n",
              "Callback Handler that tracks bedrock anthropic info.\n",
              "callbacks.clearml_callback.ClearMLCallbackHandler([...])\n",
              "Callback Handler that logs to ClearML.\n",
              "callbacks.comet_ml_callback.CometCallbackHandler([...])\n",
              "Callback Handler that logs to Comet.\n",
              "callbacks.confident_callback.DeepEvalCallbackHandler(metrics)\n",
              "Callback Handler that logs into deepeval.\n",
              "callbacks.context_callback.ContextCallbackHandler([...])\n",
              "Callback Handler that records transcripts to the Context service.\n",
              "callbacks.fiddler_callback.FiddlerCallbackHandler(...)\n",
              "Initialize Fiddler callback handler.\n",
              "callbacks.flyte_callback.FlyteCallbackHandler()\n",
              "Callback handler that is used within a Flyte task.\n",
              "callbacks.human.AsyncHumanApprovalCallbackHandler(...)\n",
              "Asynchronous callback for manually validating values.\n",
              "callbacks.human.HumanApprovalCallbackHandler(...)\n",
              "Callback for manually validating values.\n",
              "callbacks.human.HumanRejectedException\n",
              "Exception to raise when a person manually review and rejects a value.\n",
              "callbacks.infino_callback.InfinoCallbackHandler([...])\n",
              "Callback Handler that logs to Infino.\n",
              "callbacks.labelstudio_callback.LabelStudioCallbackHandler([...])\n",
              "Label Studio callback handler.\n",
              "callbacks.labelstudio_callback.LabelStudioMode(value)\n",
              "Label Studio mode enumerator.\n",
              "callbacks.llmonitor_callback.LLMonitorCallbackHandler([...])\n",
              "Callback Handler for LLMonitor`.\n",
              "callbacks.llmonitor_callback.UserContextManager(user_id)\n",
              "Context manager for LLMonitor user context.\n",
              "callbacks.mlflow_callback.MlflowCallbackHandler([...])\n",
              "Callback Handler that logs metrics and artifacts to mlflow server.\n",
              "callbacks.mlflow_callback.MlflowLogger(**kwargs)\n",
              "Callback Handler that logs metrics and artifacts to mlflow server.\n",
              "callbacks.openai_info.OpenAICallbackHandler()\n",
              "Callback Handler that tracks OpenAI info.\n",
              "callbacks.promptlayer_callback.PromptLayerCallbackHandler([...])\n",
              "Callback handler for promptlayer.\n",
              "callbacks.sagemaker_callback.SageMakerCallbackHandler(run)\n",
              "Callback Handler that logs prompt artifacts and metrics to SageMaker Experiments.\n",
              "callbacks.streamlit.mutable_expander.ChildRecord(...)\n",
              "Child record as a NamedTuple.\n",
              "callbacks.streamlit.mutable_expander.ChildType(value)\n",
              "Enumerator of the child type.\n",
              "callbacks.streamlit.mutable_expander.MutableExpander(...)\n",
              "Streamlit expander that can be renamed and dynamically expanded/collapsed.\n",
              "callbacks.streamlit.streamlit_callback_handler.LLMThought(...)\n",
              "A thought in the LLM's thought stream.\n",
              "callbacks.streamlit.streamlit_callback_handler.LLMThoughtLabeler()\n",
              "Generates markdown labels for LLMThought containers.\n",
              "callbacks.streamlit.streamlit_callback_handler.LLMThoughtState(value)\n",
              "Enumerator of the LLMThought state.\n",
              "callbacks.streamlit.streamlit_callback_handler.StreamlitCallbackHandler(...)\n",
              "Callback handler that writes to a Streamlit app.\n",
              "callbacks.streamlit.streamlit_callback_handler.ToolRecord(...)\n",
              "Tool record as a NamedTuple.\n",
              "callbacks.tracers.comet.CometTracer(**kwargs)\n",
              "Comet Tracer.\n",
              "callbacks.tracers.wandb.RunProcessor(...)\n",
              "Handles the conversion of a LangChain Runs into a WBTraceTree.\n",
              "callbacks.tracers.wandb.WandbRunArgs\n",
              "Arguments for the WandbTracer.\n",
              "callbacks.tracers.wandb.WandbTracer([run_args])\n",
              "Callback Handler that logs to Weights and Biases.\n",
              "callbacks.trubrics_callback.TrubricsCallbackHandler([...])\n",
              "Callback handler for Trubrics.\n",
              "callbacks.utils.BaseMetadataCallbackHandler()\n",
              "This class handles the metadata and associated function states for callbacks.\n",
              "callbacks.wandb_callback.WandbCallbackHandler([...])\n",
              "Callback Handler that logs to Weights and Biases.\n",
              "callbacks.whylabs_callback.WhyLabsCallbackHandler(...)\n",
              "Callback Handler for logging to WhyLabs.\n",
              "Functions¶\n",
              "callbacks.aim_callback.import_aim()\n",
              "Import the aim python package and raise an error if it is not installed.\n",
              "callbacks.clearml_callback.import_clearml()\n",
              "Import the clearml python package and raise an error if it is not installed.\n",
              "callbacks.comet_ml_callback.import_comet_ml()\n",
              "Import comet_ml and raise an error if it is not installed.\n",
              "callbacks.context_callback.import_context()\n",
              "Import the getcontext package.\n",
              "callbacks.fiddler_callback.import_fiddler()\n",
              "Import the fiddler python package and raise an error if it is not installed.\n",
              "callbacks.flyte_callback.analyze_text(text)\n",
              "Analyze text using textstat and spacy.\n",
              "callbacks.flyte_callback.import_flytekit()\n",
              "Import flytekit and flytekitplugins-deck-standard.\n",
              "callbacks.infino_callback.get_num_tokens(...)\n",
              "Calculate num tokens for OpenAI with tiktoken package.\n",
              "callbacks.infino_callback.import_infino()\n",
              "Import the infino client.\n",
              "callbacks.infino_callback.import_tiktoken()\n",
              "Import tiktoken for counting tokens for OpenAI models.\n",
              "callbacks.labelstudio_callback.get_default_label_configs(mode)\n",
              "Get default Label Studio configs for the given mode.\n",
              "callbacks.llmonitor_callback.identify(user_id)\n",
              "Builds an LLMonitor UserContextManager\n",
              "callbacks.manager.get_bedrock_anthropic_callback()\n",
              "Get the Bedrock anthropic callback handler in a context manager.\n",
              "callbacks.manager.get_openai_callback()\n",
              "Get the OpenAI callback handler in a context manager.\n",
              "callbacks.manager.wandb_tracing_enabled([...])\n",
              "Get the WandbTracer in a context manager.\n",
              "callbacks.mlflow_callback.analyze_text(text)\n",
              "Analyze text using textstat and spacy.\n",
              "callbacks.mlflow_callback.construct_html_from_prompt_and_generation(...)\n",
              "Construct an html element from a prompt and a generation.\n",
              "callbacks.mlflow_callback.get_text_complexity_metrics()\n",
              "Get the text complexity metrics from textstat.\n",
              "callbacks.mlflow_callback.import_mlflow()\n",
              "Import the mlflow python package and raise an error if it is not installed.\n",
              "callbacks.mlflow_callback.mlflow_callback_metrics()\n",
              "Get the metrics to log to MLFlow.\n",
              "callbacks.openai_info.get_openai_token_cost_for_model(...)\n",
              "Get the cost in USD for a given model and number of tokens.\n",
              "callbacks.openai_info.standardize_model_name(...)\n",
              "Standardize the model name to a format that can be used in the OpenAI API.\n",
              "callbacks.sagemaker_callback.save_json(data, ...)\n",
              "Save dict to local file path.\n",
              "callbacks.tracers.comet.import_comet_llm_api()\n",
              "Import comet_llm api and raise an error if it is not installed.\n",
              "callbacks.utils.flatten_dict(nested_dict[, ...])\n",
              "Flattens a nested dictionary into a flat dictionary.\n",
              "callbacks.utils.hash_string(s)\n",
              "Hash a string using sha1.\n",
              "callbacks.utils.import_pandas()\n",
              "Import the pandas python package and raise an error if it is not installed.\n",
              "callbacks.utils.import_spacy()\n",
              "Import the spacy python package and raise an error if it is not installed.\n",
              "callbacks.utils.import_textstat()\n",
              "Import the textstat python package and raise an error if it is not installed.\n",
              "callbacks.utils.load_json(json_path)\n",
              "Load json file to a string.\n",
              "callbacks.wandb_callback.analyze_text(text)\n",
              "Analyze text using textstat and spacy.\n",
              "callbacks.wandb_callback.construct_html_from_prompt_and_generation(...)\n",
              "Construct an html element from a prompt and a generation.\n",
              "callbacks.wandb_callback.import_wandb()\n",
              "Import the wandb python package and raise an error if it is not installed.\n",
              "callbacks.wandb_callback.load_json_to_dict(...)\n",
              "Load json file to a dictionary.\n",
              "callbacks.whylabs_callback.import_langkit([...])\n",
              "Import the langkit python package and raise an error if it is not installed.\n",
              "langchain_community.chat_loaders¶\n",
              "Chat Loaders load chat messages from common communications platforms.\n",
              "Load chat messages from various\n",
              "communications platforms such as Facebook Messenger, Telegram, and\n",
              "WhatsApp. The loaded chat messages can be used for fine-tuning models.\n",
              "Class hierarchy:\n",
              "BaseChatLoader --> <name>ChatLoader  # Examples: WhatsAppChatLoader, IMessageChatLoader\n",
              "Main helpers:\n",
              "ChatSession\n",
              "Classes¶\n",
              "chat_loaders.base.BaseChatLoader()\n",
              "Base class for chat loaders.\n",
              "chat_loaders.facebook_messenger.FolderFacebookMessengerChatLoader(path)\n",
              "Load Facebook Messenger chat data from a folder.\n",
              "chat_loaders.facebook_messenger.SingleFileFacebookMessengerChatLoader(path)\n",
              "Load Facebook Messenger chat data from a single file.\n",
              "chat_loaders.gmail.GMailLoader(creds[, n, ...])\n",
              "[Deprecated] Load data from GMail.\n",
              "chat_loaders.imessage.IMessageChatLoader([path])\n",
              "Load chat sessions from the iMessage chat.db SQLite file.\n",
              "chat_loaders.langsmith.LangSmithDatasetChatLoader(*, ...)\n",
              "Load chat sessions from a LangSmith dataset with the \"chat\" data type.\n",
              "chat_loaders.langsmith.LangSmithRunChatLoader(runs)\n",
              "Load chat sessions from a list of LangSmith \"llm\" runs.\n",
              "chat_loaders.slack.SlackChatLoader(path)\n",
              "Load Slack conversations from a dump zip file.\n",
              "chat_loaders.telegram.TelegramChatLoader(path)\n",
              "Load telegram conversations to LangChain chat messages.\n",
              "chat_loaders.whatsapp.WhatsAppChatLoader(path)\n",
              "Load WhatsApp conversations from a dump zip file or directory.\n",
              "Functions¶\n",
              "chat_loaders.imessage.nanoseconds_from_2001_to_datetime(...)\n",
              "chat_loaders.utils.map_ai_messages(...)\n",
              "Convert messages from the specified 'sender' to AI messages.\n",
              "chat_loaders.utils.map_ai_messages_in_session(...)\n",
              "Convert messages from the specified 'sender' to AI messages.\n",
              "chat_loaders.utils.merge_chat_runs(chat_sessions)\n",
              "Merge chat runs together.\n",
              "chat_loaders.utils.merge_chat_runs_in_session(...)\n",
              "Merge chat runs together in a chat session.\n",
              "langchain_community.chat_message_histories¶\n",
              "Chat message history stores a history of the message interactions in a chat.\n",
              "Class hierarchy:\n",
              "BaseChatMessageHistory --> <name>ChatMessageHistory  # Examples: FileChatMessageHistory, PostgresChatMessageHistory\n",
              "Main helpers:\n",
              "AIMessage, HumanMessage, BaseMessage\n",
              "Classes¶\n",
              "chat_message_histories.astradb.AstraDBChatMessageHistory(*, ...)\n",
              "[Deprecated]\n",
              "chat_message_histories.cassandra.CassandraChatMessageHistory(...)\n",
              "Chat message history that stores history in Cassandra.\n",
              "chat_message_histories.cosmos_db.CosmosDBChatMessageHistory(...)\n",
              "Chat message history backed by Azure CosmosDB.\n",
              "chat_message_histories.dynamodb.DynamoDBChatMessageHistory(...)\n",
              "Chat message history that stores history in AWS DynamoDB.\n",
              "chat_message_histories.elasticsearch.ElasticsearchChatMessageHistory(...)\n",
              "[Deprecated] Chat message history that stores history in Elasticsearch.\n",
              "chat_message_histories.file.FileChatMessageHistory(...)\n",
              "Chat message history that stores history in a local file.\n",
              "chat_message_histories.firestore.FirestoreChatMessageHistory(...)\n",
              "Chat message history backed by Google Firestore.\n",
              "chat_message_histories.in_memory.ChatMessageHistory\n",
              "In memory implementation of chat message history.\n",
              "chat_message_histories.momento.MomentoChatMessageHistory(...)\n",
              "Chat message history cache that uses Momento as a backend.\n",
              "chat_message_histories.mongodb.MongoDBChatMessageHistory(...)\n",
              "[Deprecated] Chat message history that stores history in MongoDB.\n",
              "chat_message_histories.neo4j.Neo4jChatMessageHistory(...)\n",
              "Chat message history stored in a Neo4j database.\n",
              "chat_message_histories.postgres.PostgresChatMessageHistory(...)\n",
              "[Deprecated] Chat message history stored in a Postgres database.\n",
              "chat_message_histories.redis.RedisChatMessageHistory(...)\n",
              "Chat message history stored in a Redis database.\n",
              "chat_message_histories.rocksetdb.RocksetChatMessageHistory(...)\n",
              "Uses Rockset to store chat messages.\n",
              "chat_message_histories.singlestoredb.SingleStoreDBChatMessageHistory(...)\n",
              "Chat message history stored in a SingleStoreDB database.\n",
              "chat_message_histories.sql.BaseMessageConverter()\n",
              "Convert BaseMessage to the SQLAlchemy model.\n",
              "chat_message_histories.sql.DefaultMessageConverter(...)\n",
              "The default message converter for SQLChatMessageHistory.\n",
              "chat_message_histories.sql.SQLChatMessageHistory(...)\n",
              "Chat message history stored in an SQL database.\n",
              "chat_message_histories.streamlit.StreamlitChatMessageHistory([key])\n",
              "Chat message history that stores messages in Streamlit session state.\n",
              "chat_message_histories.tidb.TiDBChatMessageHistory(...)\n",
              "Represents a chat message history stored in a TiDB database.\n",
              "chat_message_histories.upstash_redis.UpstashRedisChatMessageHistory(...)\n",
              "Chat message history stored in an Upstash Redis database.\n",
              "chat_message_histories.xata.XataChatMessageHistory(...)\n",
              "Chat message history stored in a Xata database.\n",
              "chat_message_histories.zep.SearchScope(value)\n",
              "Which documents to search.\n",
              "chat_message_histories.zep.SearchType(value)\n",
              "Enumerator of the types of search to perform.\n",
              "chat_message_histories.zep.ZepChatMessageHistory(...)\n",
              "Chat message history that uses Zep as a backend.\n",
              "Functions¶\n",
              "chat_message_histories.sql.create_message_model(...)\n",
              "Create a message model for a given table name.\n",
              "langchain_community.chat_models¶\n",
              "Chat Models are a variation on language models.\n",
              "While Chat Models use language models under the hood, the interface they expose\n",
              "is a bit different. Rather than expose a “text in, text out” API, they expose\n",
              "an interface where “chat messages” are the inputs and outputs.\n",
              "Class hierarchy:\n",
              "BaseLanguageModel --> BaseChatModel --> <name>  # Examples: ChatOpenAI, ChatGooglePalm\n",
              "Main helpers:\n",
              "AIMessage, BaseMessage, HumanMessage\n",
              "Classes¶\n",
              "chat_models.anthropic.ChatAnthropic\n",
              "[Deprecated] Anthropic chat large language models.\n",
              "chat_models.anyscale.ChatAnyscale\n",
              "Anyscale Chat large language models.\n",
              "chat_models.azure_openai.AzureChatOpenAI\n",
              "[Deprecated] Azure OpenAI Chat Completion API.\n",
              "chat_models.azureml_endpoint.AzureMLChatOnlineEndpoint\n",
              "Azure ML Online Endpoint chat models.\n",
              "chat_models.azureml_endpoint.CustomOpenAIChatContentFormatter()\n",
              "Chat Content formatter for models with OpenAI like API scheme.\n",
              "chat_models.azureml_endpoint.LlamaChatContentFormatter()\n",
              "Deprecated: Kept for backwards compatibility\n",
              "chat_models.azureml_endpoint.LlamaContentFormatter()\n",
              "Content formatter for LLaMA.\n",
              "chat_models.azureml_endpoint.MistralChatContentFormatter()\n",
              "Content formatter for Mistral.\n",
              "chat_models.baichuan.ChatBaichuan\n",
              "Baichuan chat models API by Baichuan Intelligent Technology.\n",
              "chat_models.baidu_qianfan_endpoint.QianfanChatEndpoint\n",
              "Baidu Qianfan chat models.\n",
              "chat_models.bedrock.BedrockChat\n",
              "Chat model that uses the Bedrock API.\n",
              "chat_models.bedrock.ChatPromptAdapter()\n",
              "Adapter class to prepare the inputs from Langchain to prompt format that Chat model expects.\n",
              "chat_models.cohere.ChatCohere\n",
              "[Deprecated] Cohere chat large language models.\n",
              "chat_models.dappier.ChatDappierAI\n",
              "Dappier chat large language models.\n",
              "chat_models.databricks.ChatDatabricks\n",
              "Databricks chat models API.\n",
              "chat_models.deepinfra.ChatDeepInfra\n",
              "A chat model that uses the DeepInfra API.\n",
              "chat_models.deepinfra.ChatDeepInfraException\n",
              "Exception raised when the DeepInfra API returns an error.\n",
              "chat_models.edenai.ChatEdenAI\n",
              "EdenAI chat large language models.\n",
              "chat_models.ernie.ErnieBotChat\n",
              "[Deprecated] ERNIE-Bot large language model.\n",
              "chat_models.everlyai.ChatEverlyAI\n",
              "EverlyAI Chat large language models.\n",
              "chat_models.fake.FakeListChatModel\n",
              "Fake ChatModel for testing purposes.\n",
              "chat_models.fake.FakeMessagesListChatModel\n",
              "Fake ChatModel for testing purposes.\n",
              "chat_models.fireworks.ChatFireworks\n",
              "[Deprecated] Fireworks Chat models.\n",
              "chat_models.friendli.ChatFriendli\n",
              "Friendli LLM for chat.\n",
              "chat_models.gigachat.GigaChat\n",
              "GigaChat large language models API.\n",
              "chat_models.google_palm.ChatGooglePalm\n",
              "Google PaLM Chat models API.\n",
              "chat_models.google_palm.ChatGooglePalmError\n",
              "Error with the Google PaLM API.\n",
              "chat_models.gpt_router.GPTRouter\n",
              "GPTRouter by Writesonic Inc.\n",
              "chat_models.gpt_router.GPTRouterException\n",
              "Error with the GPTRouter APIs\n",
              "chat_models.gpt_router.GPTRouterModel\n",
              "GPTRouter model.\n",
              "chat_models.huggingface.ChatHuggingFace\n",
              "Hugging Face LLMs as ChatModels.\n",
              "chat_models.human.HumanInputChatModel\n",
              "ChatModel which returns user input as the response.\n",
              "chat_models.hunyuan.ChatHunyuan\n",
              "Tencent Hunyuan chat models API by Tencent.\n",
              "chat_models.javelin_ai_gateway.ChatJavelinAIGateway\n",
              "Javelin AI Gateway chat models API.\n",
              "chat_models.javelin_ai_gateway.ChatParams\n",
              "Parameters for the Javelin AI Gateway LLM.\n",
              "chat_models.jinachat.JinaChat\n",
              "Jina AI Chat models API.\n",
              "chat_models.kinetica.ChatKinetica\n",
              "Kinetica LLM Chat Model API.\n",
              "chat_models.kinetica.KineticaSqlOutputParser\n",
              "Fetch and return data from the Kinetica LLM.\n",
              "chat_models.kinetica.KineticaSqlResponse\n",
              "Response containing SQL and the fetched data.\n",
              "chat_models.kinetica.KineticaUtil()\n",
              "Kinetica utility functions.\n",
              "chat_models.konko.ChatKonko\n",
              "ChatKonko Chat large language models API.\n",
              "chat_models.litellm.ChatLiteLLM\n",
              "Chat model that uses the LiteLLM API.\n",
              "chat_models.litellm.ChatLiteLLMException\n",
              "Error with the LiteLLM I/O library\n",
              "chat_models.litellm_router.ChatLiteLLMRouter\n",
              "LiteLLM Router as LangChain Model.\n",
              "chat_models.llama_edge.LlamaEdgeChatService\n",
              "Chat with LLMs via llama-api-server\n",
              "chat_models.maritalk.ChatMaritalk\n",
              "MariTalk Chat models API.\n",
              "chat_models.maritalk.MaritalkHTTPError(...)\n",
              "Initialize RequestException with request and response objects.\n",
              "chat_models.minimax.MiniMaxChat\n",
              "MiniMax large language models.\n",
              "chat_models.mlflow.ChatMlflow\n",
              "MLflow chat models API.\n",
              "chat_models.mlflow_ai_gateway.ChatMLflowAIGateway\n",
              "MLflow AI Gateway chat models API.\n",
              "chat_models.mlflow_ai_gateway.ChatParams\n",
              "Parameters for the MLflow AI Gateway LLM.\n",
              "chat_models.mlx.ChatMLX\n",
              "Wrapper for using MLX LLM's as ChatModels.\n",
              "chat_models.moonshot.MoonshotChat\n",
              "Moonshot large language models.\n",
              "chat_models.ollama.ChatOllama\n",
              "Ollama locally runs large language models.\n",
              "chat_models.openai.ChatOpenAI\n",
              "[Deprecated] OpenAI Chat large language models API.\n",
              "chat_models.pai_eas_endpoint.PaiEasChatEndpoint\n",
              "Alibaba Cloud PAI-EAS LLM Service chat model API.\n",
              "chat_models.perplexity.ChatPerplexity\n",
              "Perplexity AI Chat models API.\n",
              "chat_models.premai.ChatPremAI\n",
              "PremAI Chat models.\n",
              "chat_models.premai.ChatPremAPIError\n",
              "Error with the PremAI API.\n",
              "chat_models.promptlayer_openai.PromptLayerChatOpenAI\n",
              "PromptLayer and OpenAI Chat large language models API.\n",
              "chat_models.solar.SolarChat\n",
              "Solar large language models.\n",
              "chat_models.sparkllm.ChatSparkLLM\n",
              "iFlyTek Spark large language model.\n",
              "chat_models.tongyi.ChatTongyi\n",
              "Alibaba Tongyi Qwen chat models API.\n",
              "chat_models.vertexai.ChatVertexAI\n",
              "[Deprecated] Vertex AI Chat large language models API.\n",
              "chat_models.volcengine_maas.VolcEngineMaasChat\n",
              "Volc Engine Maas hosts a plethora of models.\n",
              "chat_models.yandex.ChatYandexGPT\n",
              "YandexGPT large language models.\n",
              "chat_models.yuan2.ChatYuan2\n",
              "Yuan2.0 Chat models API.\n",
              "chat_models.zhipuai.ChatZhipuAI\n",
              "ZhipuAI large language chat models API.\n",
              "Functions¶\n",
              "chat_models.anthropic.convert_messages_to_prompt_anthropic(...)\n",
              "Format a list of messages into a full prompt for the Anthropic model\n",
              "chat_models.baidu_qianfan_endpoint.convert_message_to_dict(message)\n",
              "Convert a message to a dictionary that can be passed to the API.\n",
              "chat_models.bedrock.convert_messages_to_prompt_mistral(...)\n",
              "Convert a list of messages to a prompt for mistral.\n",
              "chat_models.cohere.get_cohere_chat_request(...)\n",
              "Get the request for the Cohere chat API.\n",
              "chat_models.cohere.get_role(message)\n",
              "Get the role of the message.\n",
              "chat_models.fireworks.acompletion_with_retry(...)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.fireworks.acompletion_with_retry_streaming(...)\n",
              "Use tenacity to retry the completion call for streaming.\n",
              "chat_models.fireworks.completion_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "chat_models.fireworks.conditional_decorator(...)\n",
              "Define conditional decorator.\n",
              "chat_models.fireworks.convert_dict_to_message(_dict)\n",
              "Convert a dict response to a message.\n",
              "chat_models.friendli.get_chat_request(messages)\n",
              "Get a request of the Friendli chat API.\n",
              "chat_models.friendli.get_role(message)\n",
              "Get role of the message.\n",
              "chat_models.google_palm.achat_with_retry(...)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.google_palm.chat_with_retry(llm, ...)\n",
              "Use tenacity to retry the completion call.\n",
              "chat_models.gpt_router.acompletion_with_retry(...)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.gpt_router.completion_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "chat_models.gpt_router.get_ordered_generation_requests(...)\n",
              "Return the body for the model router input.\n",
              "chat_models.jinachat.acompletion_with_retry(...)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.litellm.acompletion_with_retry(llm)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.litellm_router.get_llm_output(...)\n",
              "Get llm output from usage and params.\n",
              "chat_models.meta.convert_messages_to_prompt_llama(...)\n",
              "Convert a list of messages to a prompt for llama.\n",
              "chat_models.openai.acompletion_with_retry(llm)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.premai.chat_with_retry(llm, ...)\n",
              "Using tenacity for retry in completion call\n",
              "chat_models.premai.create_prem_retry_decorator(llm, *)\n",
              "Create a retry decorator for PremAI API errors.\n",
              "chat_models.tongyi.convert_dict_to_message(_dict)\n",
              "Convert a dict to a message.\n",
              "chat_models.tongyi.convert_message_chunk_to_message(...)\n",
              "Convert a message chunk to a message.\n",
              "chat_models.tongyi.convert_message_to_dict(message)\n",
              "Convert a message to a dict.\n",
              "chat_models.volcengine_maas.convert_dict_to_message(_dict)\n",
              "Convert a dict to a message.\n",
              "chat_models.yandex.acompletion_with_retry(...)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.yandex.completion_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "chat_models.yuan2.acompletion_with_retry(...)\n",
              "Use tenacity to retry the async completion call.\n",
              "chat_models.zhipuai.aconnect_sse(client, ...)\n",
              "Async connect to a server-sent event stream.\n",
              "chat_models.zhipuai.connect_sse(client, ...)\n",
              "Connect to a server-sent event stream.\n",
              "langchain_community.cross_encoders¶\n",
              "Cross encoders are wrappers around cross encoder models from different APIs andservices.\n",
              "Cross encoder models can be LLMs or not.\n",
              "Class hierarchy:\n",
              "BaseCrossEncoder --> <name>CrossEncoder  # Examples: SagemakerEndpointCrossEncoder\n",
              "Classes¶\n",
              "cross_encoders.base.BaseCrossEncoder()\n",
              "Interface for cross encoder models.\n",
              "cross_encoders.fake.FakeCrossEncoder\n",
              "Fake cross encoder model.\n",
              "cross_encoders.huggingface.HuggingFaceCrossEncoder\n",
              "HuggingFace cross encoder models.\n",
              "cross_encoders.sagemaker_endpoint.CrossEncoderContentHandler()\n",
              "Content handler for CrossEncoder class.\n",
              "cross_encoders.sagemaker_endpoint.SagemakerEndpointCrossEncoder\n",
              "SageMaker Inference CrossEncoder endpoint.\n",
              "langchain_community.docstore¶\n",
              "Docstores are classes to store and load Documents.\n",
              "The Docstore is a simplified version of the Document Loader.\n",
              "Class hierarchy:\n",
              "Docstore --> <name> # Examples: InMemoryDocstore, Wikipedia\n",
              "Main helpers:\n",
              "Document, AddableMixin\n",
              "Classes¶\n",
              "docstore.arbitrary_fn.DocstoreFn(lookup_fn)\n",
              "Docstore via arbitrary lookup function.\n",
              "docstore.base.AddableMixin()\n",
              "Mixin class that supports adding texts.\n",
              "docstore.base.Docstore()\n",
              "Interface to access to place that stores documents.\n",
              "docstore.in_memory.InMemoryDocstore([_dict])\n",
              "Simple in memory docstore in the form of a dict.\n",
              "docstore.wikipedia.Wikipedia()\n",
              "Wikipedia API.\n",
              "langchain_community.document_compressors¶\n",
              "Classes¶\n",
              "document_compressors.llmlingua_filter.LLMLinguaCompressor\n",
              "Compress using LLMLingua Project.\n",
              "document_compressors.openvino_rerank.OpenVINOReranker\n",
              "OpenVINO rerank models.\n",
              "document_compressors.openvino_rerank.RerankRequest([...])\n",
              "Request for reranking.\n",
              "langchain_community.document_loaders¶\n",
              "Document Loaders  are classes to load Documents.\n",
              "Document Loaders are usually used to load a lot of Documents in a single run.\n",
              "Class hierarchy:\n",
              "BaseLoader --> <name>Loader  # Examples: TextLoader, UnstructuredFileLoader\n",
              "Main helpers:\n",
              "Document, <name>TextSplitter\n",
              "Classes¶\n",
              "document_loaders.acreom.AcreomLoader(path[, ...])\n",
              "Load acreom vault from a directory.\n",
              "document_loaders.airbyte.AirbyteCDKLoader(...)\n",
              "Load with an Airbyte source connector implemented using the CDK.\n",
              "document_loaders.airbyte.AirbyteGongLoader(...)\n",
              "Load from Gong using an Airbyte source connector.\n",
              "document_loaders.airbyte.AirbyteHubspotLoader(...)\n",
              "Load from Hubspot using an Airbyte source connector.\n",
              "document_loaders.airbyte.AirbyteSalesforceLoader(...)\n",
              "Load from Salesforce using an Airbyte source connector.\n",
              "document_loaders.airbyte.AirbyteShopifyLoader(...)\n",
              "Load from Shopify using an Airbyte source connector.\n",
              "document_loaders.airbyte.AirbyteStripeLoader(...)\n",
              "Load from Stripe using an Airbyte source connector.\n",
              "document_loaders.airbyte.AirbyteTypeformLoader(...)\n",
              "Load from Typeform using an Airbyte source connector.\n",
              "document_loaders.airbyte.AirbyteZendeskSupportLoader(...)\n",
              "Load from Zendesk Support using an Airbyte source connector.\n",
              "document_loaders.airbyte_json.AirbyteJSONLoader(...)\n",
              "Load local Airbyte json files.\n",
              "document_loaders.airtable.AirtableLoader(...)\n",
              "Load the Airtable tables.\n",
              "document_loaders.apify_dataset.ApifyDatasetLoader\n",
              "Load datasets from Apify web scraping, crawling, and data extraction platform.\n",
              "document_loaders.arcgis_loader.ArcGISLoader(layer)\n",
              "Load records from an ArcGIS FeatureLayer.\n",
              "document_loaders.arxiv.ArxivLoader(query[, ...])\n",
              "Load a query result from Arxiv.\n",
              "document_loaders.assemblyai.AssemblyAIAudioLoaderById(...)\n",
              "Load AssemblyAI audio transcripts.\n",
              "document_loaders.assemblyai.AssemblyAIAudioTranscriptLoader(...)\n",
              "Load AssemblyAI audio transcripts.\n",
              "document_loaders.assemblyai.TranscriptFormat(value)\n",
              "Transcript format to use for the document loader.\n",
              "document_loaders.astradb.AstraDBLoader(...)\n",
              "[Deprecated]\n",
              "document_loaders.async_html.AsyncHtmlLoader(...)\n",
              "Load HTML asynchronously.\n",
              "document_loaders.athena.AthenaLoader(query, ...)\n",
              "Load documents from AWS Athena.\n",
              "document_loaders.azlyrics.AZLyricsLoader([...])\n",
              "Load AZLyrics webpages.\n",
              "document_loaders.azure_ai_data.AzureAIDataLoader(url)\n",
              "Load from Azure AI Data.\n",
              "document_loaders.azure_blob_storage_container.AzureBlobStorageContainerLoader(...)\n",
              "Load from Azure Blob Storage container.\n",
              "document_loaders.azure_blob_storage_file.AzureBlobStorageFileLoader(...)\n",
              "Load from Azure Blob Storage files.\n",
              "document_loaders.baiducloud_bos_directory.BaiduBOSDirectoryLoader(...)\n",
              "Load from Baidu BOS directory.\n",
              "document_loaders.baiducloud_bos_file.BaiduBOSFileLoader(...)\n",
              "Load from Baidu Cloud BOS file.\n",
              "document_loaders.base_o365.O365BaseLoader\n",
              "Base class for all loaders that uses O365 Package\n",
              "document_loaders.bibtex.BibtexLoader(...[, ...])\n",
              "Load a bibtex file.\n",
              "document_loaders.bigquery.BigQueryLoader(query)\n",
              "[Deprecated] Load from the Google Cloud Platform BigQuery.\n",
              "document_loaders.bilibili.BiliBiliLoader(...)\n",
              "Load fetching transcripts from BiliBili videos.\n",
              "document_loaders.blackboard.BlackboardLoader(...)\n",
              "Load a Blackboard course.\n",
              "document_loaders.blob_loaders.file_system.FileSystemBlobLoader(path, *)\n",
              "Load blobs in the local file system.\n",
              "document_loaders.blob_loaders.youtube_audio.YoutubeAudioLoader(...)\n",
              "Load YouTube urls as audio file(s).\n",
              "document_loaders.blockchain.BlockchainDocumentLoader(...)\n",
              "Load elements from a blockchain smart contract.\n",
              "document_loaders.blockchain.BlockchainType(value)\n",
              "Enumerator of the supported blockchains.\n",
              "document_loaders.brave_search.BraveSearchLoader(...)\n",
              "Load with Brave Search engine.\n",
              "document_loaders.browserless.BrowserlessLoader(...)\n",
              "Load webpages with Browserless /content endpoint.\n",
              "document_loaders.cassandra.CassandraLoader(...)\n",
              "Document Loader for Apache Cassandra.\n",
              "document_loaders.chatgpt.ChatGPTLoader(log_file)\n",
              "Load conversations from exported ChatGPT data.\n",
              "document_loaders.chm.CHMParser(path)\n",
              "Microsoft Compiled HTML Help (CHM) Parser.\n",
              "document_loaders.chm.UnstructuredCHMLoader(...)\n",
              "Load CHM files using Unstructured.\n",
              "document_loaders.chromium.AsyncChromiumLoader(urls)\n",
              "Scrape HTML pages from URLs using a headless instance of the Chromium.\n",
              "document_loaders.college_confidential.CollegeConfidentialLoader([...])\n",
              "Load College Confidential webpages.\n",
              "document_loaders.concurrent.ConcurrentLoader(...)\n",
              "Load and pars Documents concurrently.\n",
              "document_loaders.confluence.ConfluenceLoader(url)\n",
              "Load Confluence pages.\n",
              "document_loaders.confluence.ContentFormat(value)\n",
              "Enumerator of the content formats of Confluence page.\n",
              "document_loaders.conllu.CoNLLULoader(file_path)\n",
              "Load CoNLL-U files.\n",
              "document_loaders.couchbase.CouchbaseLoader(...)\n",
              "Load documents from Couchbase.\n",
              "document_loaders.csv_loader.CSVLoader(file_path)\n",
              "Load a CSV file into a list of Documents.\n",
              "document_loaders.csv_loader.UnstructuredCSVLoader(...)\n",
              "Load CSV files using Unstructured.\n",
              "document_loaders.cube_semantic.CubeSemanticLoader(...)\n",
              "Load Cube semantic layer metadata.\n",
              "document_loaders.datadog_logs.DatadogLogsLoader(...)\n",
              "Load Datadog logs.\n",
              "document_loaders.dataframe.BaseDataFrameLoader(...)\n",
              "Initialize with dataframe object.\n",
              "document_loaders.dataframe.DataFrameLoader(...)\n",
              "Load Pandas DataFrame.\n",
              "document_loaders.diffbot.DiffbotLoader(...)\n",
              "Load Diffbot json file.\n",
              "document_loaders.directory.DirectoryLoader(...)\n",
              "Load from a directory.\n",
              "document_loaders.discord.DiscordChatLoader(...)\n",
              "Load Discord chat logs.\n",
              "document_loaders.doc_intelligence.AzureAIDocumentIntelligenceLoader(...)\n",
              "Loads a PDF with Azure Document Intelligence\n",
              "document_loaders.docugami.DocugamiLoader\n",
              "[Deprecated] Load from Docugami.\n",
              "document_loaders.docusaurus.DocusaurusLoader(url)\n",
              "Load from Docusaurus Documentation.\n",
              "document_loaders.dropbox.DropboxLoader\n",
              "Load files from Dropbox.\n",
              "document_loaders.duckdb_loader.DuckDBLoader(query)\n",
              "Load from DuckDB.\n",
              "document_loaders.email.OutlookMessageLoader(...)\n",
              "Loads Outlook Message files using extract_msg.\n",
              "document_loaders.email.UnstructuredEmailLoader(...)\n",
              "Load email files using Unstructured.\n",
              "document_loaders.epub.UnstructuredEPubLoader(...)\n",
              "Load EPub files using Unstructured.\n",
              "document_loaders.etherscan.EtherscanLoader(...)\n",
              "Load transactions from Ethereum mainnet.\n",
              "document_loaders.evernote.EverNoteLoader(...)\n",
              "Load from EverNote.\n",
              "document_loaders.excel.UnstructuredExcelLoader(...)\n",
              "Load Microsoft Excel files using Unstructured.\n",
              "document_loaders.facebook_chat.FacebookChatLoader(path)\n",
              "Load Facebook Chat messages directory dump.\n",
              "document_loaders.fauna.FaunaLoader(query, ...)\n",
              "Load from FaunaDB.\n",
              "document_loaders.figma.FigmaFileLoader(...)\n",
              "Load Figma file.\n",
              "document_loaders.firecrawl.FireCrawlLoader(url, *)\n",
              "Load web pages as Documents using FireCrawl.\n",
              "document_loaders.gcs_directory.GCSDirectoryLoader(...)\n",
              "[Deprecated] Load from GCS directory.\n",
              "document_loaders.gcs_file.GCSFileLoader(...)\n",
              "[Deprecated] Load from GCS file.\n",
              "document_loaders.generic.GenericLoader(...)\n",
              "Generic Document Loader.\n",
              "document_loaders.geodataframe.GeoDataFrameLoader(...)\n",
              "Load geopandas Dataframe.\n",
              "document_loaders.git.GitLoader(repo_path[, ...])\n",
              "Load Git repository files.\n",
              "document_loaders.gitbook.GitbookLoader(web_page)\n",
              "Load GitBook data.\n",
              "document_loaders.github.BaseGitHubLoader\n",
              "Load GitHub repository Issues.\n",
              "document_loaders.github.GitHubIssuesLoader\n",
              "Load issues of a GitHub repository.\n",
              "document_loaders.github.GithubFileLoader\n",
              "Load GitHub File\n",
              "document_loaders.google_speech_to_text.GoogleSpeechToTextLoader(...)\n",
              "[Deprecated] Loader for Google Cloud Speech-to-Text audio transcripts.\n",
              "document_loaders.googledrive.GoogleDriveLoader\n",
              "[Deprecated] Load Google Docs from Google Drive.\n",
              "document_loaders.gutenberg.GutenbergLoader(...)\n",
              "Load from Gutenberg.org.\n",
              "document_loaders.helpers.FileEncoding(...)\n",
              "File encoding as the NamedTuple.\n",
              "document_loaders.hn.HNLoader([web_path, ...])\n",
              "Load Hacker News data.\n",
              "document_loaders.html.UnstructuredHTMLLoader(...)\n",
              "Load HTML files using Unstructured.\n",
              "document_loaders.html_bs.BSHTMLLoader(file_path)\n",
              "Load HTML files and parse them with beautiful soup.\n",
              "document_loaders.hugging_face_dataset.HuggingFaceDatasetLoader(path)\n",
              "Load from Hugging Face Hub datasets.\n",
              "document_loaders.hugging_face_model.HuggingFaceModelLoader(*)\n",
              "Load model information from Hugging Face Hub, including README content.\n",
              "document_loaders.ifixit.IFixitLoader(web_path)\n",
              "Load iFixit repair guides, device wikis and answers.\n",
              "document_loaders.image.UnstructuredImageLoader(...)\n",
              "Load PNG and JPG files using Unstructured.\n",
              "document_loaders.image_captions.ImageCaptionLoader(images)\n",
              "Load image captions.\n",
              "document_loaders.imsdb.IMSDbLoader([...])\n",
              "Load IMSDb webpages.\n",
              "document_loaders.iugu.IuguLoader(resource[, ...])\n",
              "Load from IUGU.\n",
              "document_loaders.joplin.JoplinLoader([...])\n",
              "Load notes from Joplin.\n",
              "document_loaders.json_loader.JSONLoader(...)\n",
              "Load a JSON file using a jq schema.\n",
              "document_loaders.lakefs.LakeFSClient(...)\n",
              "Client for lakeFS.\n",
              "document_loaders.lakefs.LakeFSLoader(...[, ...])\n",
              "Load from lakeFS.\n",
              "document_loaders.lakefs.UnstructuredLakeFSLoader(...)\n",
              "Load from lakeFS as unstructured data.\n",
              "document_loaders.larksuite.LarkSuiteDocLoader(...)\n",
              "Load from LarkSuite (FeiShu).\n",
              "document_loaders.llmsherpa.LLMSherpaFileLoader(...)\n",
              "Load Documents using LLMSherpa.\n",
              "document_loaders.markdown.UnstructuredMarkdownLoader(...)\n",
              "Load Markdown files using Unstructured.\n",
              "document_loaders.mastodon.MastodonTootsLoader(...)\n",
              "Load the Mastodon 'toots'.\n",
              "document_loaders.max_compute.MaxComputeLoader(...)\n",
              "Load from Alibaba Cloud MaxCompute table.\n",
              "document_loaders.mediawikidump.MWDumpLoader(...)\n",
              "Load MediaWiki dump from an XML file.\n",
              "document_loaders.merge.MergedDataLoader(loaders)\n",
              "Merge documents from a list of loaders\n",
              "document_loaders.mhtml.MHTMLLoader(file_path)\n",
              "Parse MHTML files with BeautifulSoup.\n",
              "document_loaders.modern_treasury.ModernTreasuryLoader(...)\n",
              "Load from Modern Treasury.\n",
              "document_loaders.mongodb.MongodbLoader(...)\n",
              "Load MongoDB documents.\n",
              "document_loaders.news.NewsURLLoader(urls[, ...])\n",
              "Load news articles from URLs using Unstructured.\n",
              "document_loaders.notebook.NotebookLoader(path)\n",
              "Load Jupyter notebook (.ipynb) files.\n",
              "document_loaders.notion.NotionDirectoryLoader(path, *)\n",
              "Load Notion directory dump.\n",
              "document_loaders.notiondb.NotionDBLoader(...)\n",
              "Load from Notion DB.\n",
              "document_loaders.nuclia.NucliaLoader(path, ...)\n",
              "Load from any file type using Nuclia Understanding API.\n",
              "document_loaders.obs_directory.OBSDirectoryLoader(...)\n",
              "Load from Huawei OBS directory.\n",
              "document_loaders.obs_file.OBSFileLoader(...)\n",
              "Load from the Huawei OBS file.\n",
              "document_loaders.obsidian.ObsidianLoader(path)\n",
              "Load Obsidian files from directory.\n",
              "document_loaders.odt.UnstructuredODTLoader(...)\n",
              "Load OpenOffice ODT files using Unstructured.\n",
              "document_loaders.onedrive.OneDriveLoader\n",
              "Load from Microsoft OneDrive.\n",
              "document_loaders.onedrive_file.OneDriveFileLoader\n",
              "Load a file from Microsoft OneDrive.\n",
              "document_loaders.onenote.OneNoteLoader\n",
              "Load pages from OneNote notebooks.\n",
              "document_loaders.open_city_data.OpenCityDataLoader(...)\n",
              "Load from Open City.\n",
              "document_loaders.oracleadb_loader.OracleAutonomousDatabaseLoader(...)\n",
              "Load from oracle adb\n",
              "document_loaders.org_mode.UnstructuredOrgModeLoader(...)\n",
              "Load Org-Mode files using Unstructured.\n",
              "document_loaders.parsers.audio.OpenAIWhisperParser([...])\n",
              "Transcribe and parse audio files.\n",
              "document_loaders.parsers.audio.OpenAIWhisperParserLocal([...])\n",
              "Transcribe and parse audio files with OpenAI Whisper model.\n",
              "document_loaders.parsers.audio.YandexSTTParser(*)\n",
              "Transcribe and parse audio files.\n",
              "document_loaders.parsers.doc_intelligence.AzureAIDocumentIntelligenceParser(...)\n",
              "Loads a PDF with Azure Document Intelligence (formerly Forms Recognizer).\n",
              "document_loaders.parsers.docai.DocAIParser(*)\n",
              "[Deprecated] Google Cloud Document AI parser.\n",
              "document_loaders.parsers.docai.DocAIParsingResults(...)\n",
              "A dataclass to store Document AI parsing results.\n",
              "document_loaders.parsers.generic.MimeTypeBasedParser(...)\n",
              "Parser that uses mime-types to parse a blob.\n",
              "document_loaders.parsers.grobid.GrobidParser(...)\n",
              "Load  article PDF files using Grobid.\n",
              "document_loaders.parsers.grobid.ServerUnavailableException\n",
              "Exception raised when the Grobid server is unavailable.\n",
              "document_loaders.parsers.html.bs4.BS4HTMLParser(*)\n",
              "Pparse HTML files using Beautiful Soup.\n",
              "document_loaders.parsers.language.c.CSegmenter(code)\n",
              "Code segmenter for C.\n",
              "document_loaders.parsers.language.cobol.CobolSegmenter(code)\n",
              "Code segmenter for COBOL.\n",
              "document_loaders.parsers.language.code_segmenter.CodeSegmenter(code)\n",
              "Abstract class for the code segmenter.\n",
              "document_loaders.parsers.language.cpp.CPPSegmenter(code)\n",
              "Code segmenter for C++.\n",
              "document_loaders.parsers.language.csharp.CSharpSegmenter(code)\n",
              "Code segmenter for C#.\n",
              "document_loaders.parsers.language.go.GoSegmenter(code)\n",
              "Code segmenter for Go.\n",
              "document_loaders.parsers.language.java.JavaSegmenter(code)\n",
              "Code segmenter for Java.\n",
              "document_loaders.parsers.language.javascript.JavaScriptSegmenter(code)\n",
              "Code segmenter for JavaScript.\n",
              "document_loaders.parsers.language.kotlin.KotlinSegmenter(code)\n",
              "Code segmenter for Kotlin.\n",
              "document_loaders.parsers.language.language_parser.LanguageParser([...])\n",
              "Parse using the respective programming language syntax.\n",
              "document_loaders.parsers.language.lua.LuaSegmenter(code)\n",
              "Code segmenter for Lua.\n",
              "document_loaders.parsers.language.perl.PerlSegmenter(code)\n",
              "Code segmenter for Perl.\n",
              "document_loaders.parsers.language.php.PHPSegmenter(code)\n",
              "Code segmenter for PHP.\n",
              "document_loaders.parsers.language.python.PythonSegmenter(code)\n",
              "Code segmenter for Python.\n",
              "document_loaders.parsers.language.ruby.RubySegmenter(code)\n",
              "Code segmenter for Ruby.\n",
              "document_loaders.parsers.language.rust.RustSegmenter(code)\n",
              "Code segmenter for Rust.\n",
              "document_loaders.parsers.language.scala.ScalaSegmenter(code)\n",
              "Code segmenter for Scala.\n",
              "document_loaders.parsers.language.tree_sitter_segmenter.TreeSitterSegmenter(code)\n",
              "Abstract class for `CodeSegmenter`s that use the tree-sitter library.\n",
              "document_loaders.parsers.language.typescript.TypeScriptSegmenter(code)\n",
              "Code segmenter for TypeScript.\n",
              "document_loaders.parsers.msword.MsWordParser()\n",
              "Parse the Microsoft Word documents from a blob.\n",
              "document_loaders.parsers.pdf.AmazonTextractPDFParser([...])\n",
              "Send PDF files to Amazon Textract and parse them.\n",
              "document_loaders.parsers.pdf.DocumentIntelligenceParser(...)\n",
              "Loads a PDF with Azure Document Intelligence (formerly Form Recognizer) and chunks at character level.\n",
              "document_loaders.parsers.pdf.PDFMinerParser([...])\n",
              "Parse PDF using PDFMiner.\n",
              "document_loaders.parsers.pdf.PDFPlumberParser([...])\n",
              "Parse PDF with PDFPlumber.\n",
              "document_loaders.parsers.pdf.PyMuPDFParser([...])\n",
              "Parse PDF using PyMuPDF.\n",
              "document_loaders.parsers.pdf.PyPDFParser([...])\n",
              "Load PDF using pypdf\n",
              "document_loaders.parsers.pdf.PyPDFium2Parser([...])\n",
              "Parse PDF with PyPDFium2.\n",
              "document_loaders.parsers.txt.TextParser()\n",
              "Parser for text blobs.\n",
              "document_loaders.parsers.vsdx.VsdxParser()\n",
              "Parser for vsdx files.\n",
              "document_loaders.pdf.AmazonTextractPDFLoader(...)\n",
              "Load PDF files from a local file system, HTTP or S3.\n",
              "document_loaders.pdf.BasePDFLoader(file_path, *)\n",
              "Base Loader class for PDF files.\n",
              "document_loaders.pdf.DocumentIntelligenceLoader(...)\n",
              "Loads a PDF with Azure Document Intelligence\n",
              "document_loaders.pdf.MathpixPDFLoader(file_path)\n",
              "Load PDF files using Mathpix service.\n",
              "document_loaders.pdf.OnlinePDFLoader(...[, ...])\n",
              "Load online PDF.\n",
              "document_loaders.pdf.PDFMinerLoader(file_path, *)\n",
              "Load PDF files using PDFMiner.\n",
              "document_loaders.pdf.PDFMinerPDFasHTMLLoader(...)\n",
              "Load PDF files as HTML content using PDFMiner.\n",
              "document_loaders.pdf.PDFPlumberLoader(file_path)\n",
              "Load PDF files using pdfplumber.\n",
              "document_loaders.pdf.PagedPDFSplitter\n",
              "alias of PyPDFLoader\n",
              "document_loaders.pdf.PyMuPDFLoader(file_path, *)\n",
              "Load PDF files using PyMuPDF.\n",
              "document_loaders.pdf.PyPDFDirectoryLoader(path)\n",
              "Load a directory with PDF files using pypdf and chunks at character level.\n",
              "document_loaders.pdf.PyPDFLoader(file_path)\n",
              "Load PDF using pypdf into list of documents.\n",
              "document_loaders.pdf.PyPDFium2Loader(...[, ...])\n",
              "Load PDF using pypdfium2 and chunks at character level.\n",
              "document_loaders.pdf.UnstructuredPDFLoader(...)\n",
              "Load PDF files using Unstructured.\n",
              "document_loaders.pebblo.PebbloSafeLoader(...)\n",
              "Pebblo Safe Loader class is a wrapper around document loaders enabling the data to be scrutinized.\n",
              "document_loaders.polars_dataframe.PolarsDataFrameLoader(...)\n",
              "Load Polars DataFrame.\n",
              "document_loaders.powerpoint.UnstructuredPowerPointLoader(...)\n",
              "Load Microsoft PowerPoint files using Unstructured.\n",
              "document_loaders.psychic.PsychicLoader(...)\n",
              "Load from Psychic.dev.\n",
              "document_loaders.pubmed.PubMedLoader(query)\n",
              "Load from the PubMed biomedical library.\n",
              "document_loaders.pyspark_dataframe.PySparkDataFrameLoader([...])\n",
              "Load PySpark DataFrames.\n",
              "document_loaders.python.PythonLoader(file_path)\n",
              "Load Python files, respecting any non-default encoding if specified.\n",
              "document_loaders.quip.QuipLoader(api_url, ...)\n",
              "Load Quip pages.\n",
              "document_loaders.readthedocs.ReadTheDocsLoader(path)\n",
              "Load ReadTheDocs documentation directory.\n",
              "document_loaders.recursive_url_loader.RecursiveUrlLoader(url)\n",
              "Load all child links from a URL page.\n",
              "document_loaders.reddit.RedditPostsLoader(...)\n",
              "Load Reddit posts.\n",
              "document_loaders.roam.RoamLoader(path)\n",
              "Load Roam files from a directory.\n",
              "document_loaders.rocksetdb.ColumnNotFoundError(...)\n",
              "Column not found error.\n",
              "document_loaders.rocksetdb.RocksetLoader(...)\n",
              "Load from a Rockset database.\n",
              "document_loaders.rspace.RSpaceLoader(global_id)\n",
              "Load content from RSpace notebooks, folders, documents or PDF Gallery files.\n",
              "document_loaders.rss.RSSFeedLoader([urls, ...])\n",
              "Load news articles from RSS feeds using Unstructured.\n",
              "document_loaders.rst.UnstructuredRSTLoader(...)\n",
              "Load RST files using Unstructured.\n",
              "document_loaders.rtf.UnstructuredRTFLoader(...)\n",
              "Load RTF files using Unstructured.\n",
              "document_loaders.s3_directory.S3DirectoryLoader(bucket)\n",
              "Load from Amazon AWS S3 directory.\n",
              "document_loaders.s3_file.S3FileLoader(...[, ...])\n",
              "Load from Amazon AWS S3 file.\n",
              "document_loaders.sharepoint.SharePointLoader\n",
              "Load  from SharePoint.\n",
              "document_loaders.sitemap.SitemapLoader(web_path)\n",
              "Load a sitemap and its URLs.\n",
              "document_loaders.slack_directory.SlackDirectoryLoader(...)\n",
              "Load from a Slack directory dump.\n",
              "document_loaders.snowflake_loader.SnowflakeLoader(...)\n",
              "Load from Snowflake API.\n",
              "document_loaders.spreedly.SpreedlyLoader(...)\n",
              "Load from Spreedly API.\n",
              "document_loaders.sql_database.SQLDatabaseLoader(...)\n",
              "Load documents by querying database tables supported by SQLAlchemy.\n",
              "document_loaders.srt.SRTLoader(file_path)\n",
              "Load .srt (subtitle) files.\n",
              "document_loaders.stripe.StripeLoader(resource)\n",
              "Load from Stripe API.\n",
              "document_loaders.surrealdb.SurrealDBLoader([...])\n",
              "Load SurrealDB documents.\n",
              "document_loaders.telegram.TelegramChatApiLoader([...])\n",
              "Load Telegram chat json directory dump.\n",
              "document_loaders.telegram.TelegramChatFileLoader(path)\n",
              "Load from Telegram chat dump.\n",
              "document_loaders.telegram.TelegramChatLoader\n",
              "alias of TelegramChatFileLoader\n",
              "document_loaders.tencent_cos_directory.TencentCOSDirectoryLoader(...)\n",
              "Load from Tencent Cloud COS directory.\n",
              "document_loaders.tencent_cos_file.TencentCOSFileLoader(...)\n",
              "Load from Tencent Cloud COS file.\n",
              "document_loaders.tensorflow_datasets.TensorflowDatasetLoader(...)\n",
              "Load from TensorFlow Dataset.\n",
              "document_loaders.text.TextLoader(file_path)\n",
              "Load text file.\n",
              "document_loaders.tidb.TiDBLoader(...[, ...])\n",
              "Load documents from TiDB.\n",
              "document_loaders.tomarkdown.ToMarkdownLoader(...)\n",
              "Load HTML using 2markdown API.\n",
              "document_loaders.toml.TomlLoader(source)\n",
              "Load TOML files.\n",
              "document_loaders.trello.TrelloLoader(client, ...)\n",
              "Load cards from a Trello board.\n",
              "document_loaders.tsv.UnstructuredTSVLoader(...)\n",
              "Load TSV files using Unstructured.\n",
              "document_loaders.twitter.TwitterTweetLoader(...)\n",
              "Load Twitter tweets.\n",
              "document_loaders.unstructured.UnstructuredAPIFileIOLoader(file)\n",
              "Load files using Unstructured API.\n",
              "document_loaders.unstructured.UnstructuredAPIFileLoader([...])\n",
              "Load files using Unstructured API.\n",
              "document_loaders.unstructured.UnstructuredBaseLoader([...])\n",
              "Base Loader that uses Unstructured.\n",
              "document_loaders.unstructured.UnstructuredFileIOLoader(file)\n",
              "Load files using Unstructured.\n",
              "document_loaders.unstructured.UnstructuredFileLoader(...)\n",
              "Load files using Unstructured.\n",
              "document_loaders.url.UnstructuredURLLoader(urls)\n",
              "Load files from remote URLs using Unstructured.\n",
              "document_loaders.url_playwright.PlaywrightEvaluator()\n",
              "Abstract base class for all evaluators.\n",
              "document_loaders.url_playwright.PlaywrightURLLoader(urls)\n",
              "Load HTML pages with Playwright and parse with Unstructured.\n",
              "document_loaders.url_playwright.UnstructuredHtmlEvaluator([...])\n",
              "Evaluates the page HTML content using the unstructured library.\n",
              "document_loaders.url_selenium.SeleniumURLLoader(urls)\n",
              "Load HTML pages with Selenium and parse with Unstructured.\n",
              "document_loaders.vsdx.VsdxLoader(file_path)\n",
              "Initialize with file path.\n",
              "document_loaders.weather.WeatherDataLoader(...)\n",
              "Load weather data with Open Weather Map API.\n",
              "document_loaders.web_base.WebBaseLoader([...])\n",
              "Load HTML pages using urllib and parse them with `BeautifulSoup'.\n",
              "document_loaders.whatsapp_chat.WhatsAppChatLoader(path)\n",
              "Load WhatsApp messages text file.\n",
              "document_loaders.wikipedia.WikipediaLoader(query)\n",
              "Load from Wikipedia.\n",
              "document_loaders.word_document.Docx2txtLoader(...)\n",
              "Load DOCX file using docx2txt and chunks at character level.\n",
              "document_loaders.word_document.UnstructuredWordDocumentLoader(...)\n",
              "Load Microsoft Word file using Unstructured.\n",
              "document_loaders.xml.UnstructuredXMLLoader(...)\n",
              "Load XML file using Unstructured.\n",
              "document_loaders.xorbits.XorbitsLoader(...)\n",
              "Load Xorbits DataFrame.\n",
              "document_loaders.youtube.GoogleApiClient([...])\n",
              "Generic Google API Client.\n",
              "document_loaders.youtube.GoogleApiYoutubeLoader(...)\n",
              "Load all Videos from a YouTube Channel.\n",
              "document_loaders.youtube.TranscriptFormat(value)\n",
              "Transcript format.\n",
              "document_loaders.youtube.YoutubeLoader(video_id)\n",
              "Load YouTube transcripts.\n",
              "document_loaders.yuque.YuqueLoader(access_token)\n",
              "Load documents from Yuque.\n",
              "Functions¶\n",
              "document_loaders.base_o365.fetch_mime_types(...)\n",
              "Fetch the mime types for the specified file types.\n",
              "document_loaders.chatgpt.concatenate_rows(...)\n",
              "Combine message information in a readable format ready to be used.\n",
              "document_loaders.facebook_chat.concatenate_rows(row)\n",
              "Combine message information in a readable format ready to be used.\n",
              "document_loaders.helpers.detect_file_encodings(...)\n",
              "Try to detect the file encoding.\n",
              "document_loaders.notebook.concatenate_cells(...)\n",
              "Combine cells information in a readable format ready to be used.\n",
              "document_loaders.notebook.remove_newlines(x)\n",
              "Recursively remove newlines, no matter the data structure they are stored in.\n",
              "document_loaders.parsers.pdf.extract_from_images_with_rapidocr(images)\n",
              "Extract text from images with RapidOCR.\n",
              "document_loaders.parsers.registry.get_parser(...)\n",
              "Get a parser by parser name.\n",
              "document_loaders.rocksetdb.default_joiner(docs)\n",
              "Default joiner for content columns.\n",
              "document_loaders.telegram.concatenate_rows(row)\n",
              "Combine message information in a readable format ready to be used.\n",
              "document_loaders.telegram.text_to_docs(text)\n",
              "Convert a string or list of strings to a list of Documents with metadata.\n",
              "document_loaders.unstructured.get_elements_from_api([...])\n",
              "Retrieve a list of elements from the Unstructured API.\n",
              "document_loaders.unstructured.satisfies_min_unstructured_version(...)\n",
              "Check if the installed Unstructured version exceeds the minimum version for the feature in question.\n",
              "document_loaders.unstructured.validate_unstructured_version(...)\n",
              "Raise an error if the Unstructured version does not exceed the specified minimum.\n",
              "document_loaders.whatsapp_chat.concatenate_rows(...)\n",
              "Combine message information in a readable format ready to be used.\n",
              "langchain_community.document_transformers¶\n",
              "Document Transformers are classes to transform Documents.\n",
              "Document Transformers usually used to transform a lot of Documents in a single run.\n",
              "Class hierarchy:\n",
              "BaseDocumentTransformer --> <name>  # Examples: DoctranQATransformer, DoctranTextTranslator\n",
              "Main helpers:\n",
              "Document\n",
              "Classes¶\n",
              "document_transformers.beautiful_soup_transformer.BeautifulSoupTransformer()\n",
              "Transform HTML content by extracting specific tags and removing unwanted ones.\n",
              "document_transformers.doctran_text_extract.DoctranPropertyExtractor(...)\n",
              "Extract properties from text documents using doctran.\n",
              "document_transformers.doctran_text_qa.DoctranQATransformer([...])\n",
              "Extract QA from text documents using doctran.\n",
              "document_transformers.doctran_text_translate.DoctranTextTranslator([...])\n",
              "Translate text documents using doctran.\n",
              "document_transformers.embeddings_redundant_filter.EmbeddingsClusteringFilter\n",
              "Perform K-means clustering on document vectors.\n",
              "document_transformers.embeddings_redundant_filter.EmbeddingsRedundantFilter\n",
              "Filter that drops redundant documents by comparing their embeddings.\n",
              "document_transformers.google_translate.GoogleTranslateTransformer(...)\n",
              "[Deprecated] Translate text documents using Google Cloud Translation.\n",
              "document_transformers.html2text.Html2TextTransformer([...])\n",
              "Replace occurrences of a particular search pattern with a replacement string\n",
              "document_transformers.long_context_reorder.LongContextReorder\n",
              "Reorder long context.\n",
              "document_transformers.nuclia_text_transform.NucliaTextTransformer(nua)\n",
              "Nuclia Text Transformer.\n",
              "document_transformers.openai_functions.OpenAIMetadataTagger\n",
              "Extract metadata tags from document contents using OpenAI functions.\n",
              "Functions¶\n",
              "document_transformers.beautiful_soup_transformer.get_navigable_strings(...)\n",
              "Get all navigable strings from a BeautifulSoup element.\n",
              "document_transformers.embeddings_redundant_filter.get_stateful_documents(...)\n",
              "Convert a list of documents to a list of documents with state.\n",
              "document_transformers.openai_functions.create_metadata_tagger(...)\n",
              "Create a DocumentTransformer that uses an OpenAI function chain to automatically\n",
              "langchain_community.embeddings¶\n",
              "Embedding models  are wrappers around embedding models\n",
              "from different APIs and services.\n",
              "Embedding models can be LLMs or not.\n",
              "Class hierarchy:\n",
              "Embeddings --> <name>Embeddings  # Examples: OpenAIEmbeddings, HuggingFaceEmbeddings\n",
              "Classes¶\n",
              "embeddings.aleph_alpha.AlephAlphaAsymmetricSemanticEmbedding\n",
              "Aleph Alpha's asymmetric semantic embedding.\n",
              "embeddings.aleph_alpha.AlephAlphaSymmetricSemanticEmbedding\n",
              "Symmetric version of the Aleph Alpha's semantic embeddings.\n",
              "embeddings.anyscale.AnyscaleEmbeddings\n",
              "Anyscale Embeddings API.\n",
              "embeddings.awa.AwaEmbeddings\n",
              "Embedding documents and queries with Awa DB.\n",
              "embeddings.azure_openai.AzureOpenAIEmbeddings\n",
              "[Deprecated] Azure OpenAI Embeddings API.\n",
              "embeddings.baichuan.BaichuanTextEmbeddings\n",
              "Baichuan Text Embedding models.\n",
              "embeddings.baidu_qianfan_endpoint.QianfanEmbeddingsEndpoint\n",
              "Baidu Qianfan Embeddings embedding models.\n",
              "embeddings.bedrock.BedrockEmbeddings\n",
              "Bedrock embedding models.\n",
              "embeddings.bookend.BookendEmbeddings\n",
              "Bookend AI sentence_transformers embedding models.\n",
              "embeddings.clarifai.ClarifaiEmbeddings\n",
              "Clarifai embedding models.\n",
              "embeddings.cloudflare_workersai.CloudflareWorkersAIEmbeddings\n",
              "Cloudflare Workers AI embedding model.\n",
              "embeddings.cohere.CohereEmbeddings\n",
              "[Deprecated] Cohere embedding models.\n",
              "embeddings.dashscope.DashScopeEmbeddings\n",
              "DashScope embedding models.\n",
              "embeddings.databricks.DatabricksEmbeddings\n",
              "Databricks embeddings.\n",
              "embeddings.deepinfra.DeepInfraEmbeddings\n",
              "Deep Infra's embedding inference service.\n",
              "embeddings.edenai.EdenAiEmbeddings\n",
              "EdenAI embedding.\n",
              "embeddings.elasticsearch.ElasticsearchEmbeddings(...)\n",
              "[Deprecated] Elasticsearch embedding models.\n",
              "embeddings.embaas.EmbaasEmbeddings\n",
              "Embaas's embedding service.\n",
              "embeddings.embaas.EmbaasEmbeddingsPayload\n",
              "Payload for the Embaas embeddings API.\n",
              "embeddings.ernie.ErnieEmbeddings\n",
              "[Deprecated] Ernie Embeddings V1 embedding models.\n",
              "embeddings.fake.DeterministicFakeEmbedding\n",
              "Fake embedding model that always returns the same embedding vector for the same text.\n",
              "embeddings.fake.FakeEmbeddings\n",
              "Fake embedding model.\n",
              "embeddings.fastembed.FastEmbedEmbeddings\n",
              "Qdrant FastEmbedding models.\n",
              "embeddings.gigachat.GigaChatEmbeddings\n",
              "GigaChat Embeddings models.\n",
              "embeddings.google_palm.GooglePalmEmbeddings\n",
              "Google's PaLM Embeddings APIs.\n",
              "embeddings.gpt4all.GPT4AllEmbeddings\n",
              "GPT4All embedding models.\n",
              "embeddings.gradient_ai.GradientEmbeddings\n",
              "Gradient.ai Embedding models.\n",
              "embeddings.gradient_ai.TinyAsyncGradientEmbeddingClient(...)\n",
              "Deprecated, TinyAsyncGradientEmbeddingClient was removed.\n",
              "embeddings.huggingface.HuggingFaceBgeEmbeddings\n",
              "HuggingFace sentence_transformers embedding models.\n",
              "embeddings.huggingface.HuggingFaceEmbeddings\n",
              "HuggingFace sentence_transformers embedding models.\n",
              "embeddings.huggingface.HuggingFaceInferenceAPIEmbeddings\n",
              "Embed texts using the HuggingFace API.\n",
              "embeddings.huggingface.HuggingFaceInstructEmbeddings\n",
              "Wrapper around sentence_transformers embedding models.\n",
              "embeddings.huggingface_hub.HuggingFaceHubEmbeddings\n",
              "HuggingFaceHub embedding models.\n",
              "embeddings.infinity.InfinityEmbeddings\n",
              "Embedding models for self-hosted https://github.com/michaelfeil/infinity This should also work for text-embeddings-inference and other self-hosted openai-compatible servers.\n",
              "embeddings.infinity.TinyAsyncOpenAIInfinityEmbeddingClient([...])\n",
              "A helper tool to embed Infinity.\n",
              "embeddings.infinity_local.InfinityEmbeddingsLocal\n",
              "Optimized Infinity embedding models.\n",
              "embeddings.itrex.QuantizedBgeEmbeddings\n",
              "Leverage Itrex runtime to unlock the performance of compressed NLP models.\n",
              "embeddings.javelin_ai_gateway.JavelinAIGatewayEmbeddings\n",
              "Javelin AI Gateway embeddings.\n",
              "embeddings.jina.JinaEmbeddings\n",
              "Jina embedding models.\n",
              "embeddings.johnsnowlabs.JohnSnowLabsEmbeddings\n",
              "JohnSnowLabs embedding models\n",
              "embeddings.laser.LaserEmbeddings\n",
              "LASER Language-Agnostic SEntence Representations.\n",
              "embeddings.llamacpp.LlamaCppEmbeddings\n",
              "llama.cpp embedding models.\n",
              "embeddings.llamafile.LlamafileEmbeddings\n",
              "Llamafile lets you distribute and run large language models with a single file.\n",
              "embeddings.llm_rails.LLMRailsEmbeddings\n",
              "LLMRails embedding models.\n",
              "embeddings.localai.LocalAIEmbeddings\n",
              "LocalAI embedding models.\n",
              "embeddings.minimax.MiniMaxEmbeddings\n",
              "MiniMax's embedding service.\n",
              "embeddings.mlflow.MlflowCohereEmbeddings\n",
              "Cohere embedding LLMs in MLflow.\n",
              "embeddings.mlflow.MlflowEmbeddings\n",
              "Embedding LLMs in MLflow.\n",
              "embeddings.mlflow_gateway.MlflowAIGatewayEmbeddings\n",
              "MLflow AI Gateway embeddings.\n",
              "embeddings.modelscope_hub.ModelScopeEmbeddings\n",
              "ModelScopeHub embedding models.\n",
              "embeddings.mosaicml.MosaicMLInstructorEmbeddings\n",
              "MosaicML embedding service.\n",
              "embeddings.nemo.NeMoEmbeddings\n",
              "NeMo embedding models.\n",
              "embeddings.nlpcloud.NLPCloudEmbeddings\n",
              "NLP Cloud embedding models.\n",
              "embeddings.oci_generative_ai.OCIAuthType(value)\n",
              "OCI authentication types as enumerator.\n",
              "embeddings.oci_generative_ai.OCIGenAIEmbeddings\n",
              "OCI embedding models.\n",
              "embeddings.octoai_embeddings.OctoAIEmbeddings\n",
              "OctoAI Compute Service embedding models.\n",
              "embeddings.ollama.OllamaEmbeddings\n",
              "Ollama locally runs large language models.\n",
              "embeddings.openai.OpenAIEmbeddings\n",
              "[Deprecated] OpenAI embedding models.\n",
              "embeddings.openvino.OpenVINOBgeEmbeddings\n",
              "OpenVNO BGE embedding models.\n",
              "embeddings.openvino.OpenVINOEmbeddings\n",
              "OpenVINO embedding models.\n",
              "embeddings.optimum_intel.QuantizedBiEncoderEmbeddings\n",
              "Quantized bi-encoders embedding models.\n",
              "embeddings.premai.PremAIEmbeddings\n",
              "Prem's Embedding APIs\n",
              "embeddings.sagemaker_endpoint.EmbeddingsContentHandler()\n",
              "Content handler for LLM class.\n",
              "embeddings.sagemaker_endpoint.SagemakerEndpointEmbeddings\n",
              "Custom Sagemaker Inference Endpoints.\n",
              "embeddings.self_hosted.SelfHostedEmbeddings\n",
              "Custom embedding models on self-hosted remote hardware.\n",
              "embeddings.self_hosted_hugging_face.SelfHostedHuggingFaceEmbeddings\n",
              "HuggingFace embedding models on self-hosted remote hardware.\n",
              "embeddings.self_hosted_hugging_face.SelfHostedHuggingFaceInstructEmbeddings\n",
              "HuggingFace InstructEmbedding models on self-hosted remote hardware.\n",
              "embeddings.solar.SolarEmbeddings\n",
              "Solar's embedding service.\n",
              "embeddings.spacy_embeddings.SpacyEmbeddings\n",
              "Embeddings by spaCy models.\n",
              "embeddings.sparkllm.AssembleHeaderException(msg)\n",
              "embeddings.sparkllm.SparkLLMTextEmbeddings\n",
              "SparkLLM Text Embedding models.\n",
              "embeddings.sparkllm.Url(host, path, schema)\n",
              "embeddings.tensorflow_hub.TensorflowHubEmbeddings\n",
              "TensorflowHub embedding models.\n",
              "embeddings.text2vec.Text2vecEmbeddings\n",
              "text2vec embedding models.\n",
              "embeddings.vertexai.VertexAIEmbeddings\n",
              "[Deprecated] Google Cloud VertexAI embedding models.\n",
              "embeddings.volcengine.VolcanoEmbeddings\n",
              "Volcengine Embeddings embedding models.\n",
              "embeddings.voyageai.VoyageEmbeddings\n",
              "[Deprecated] Voyage embedding models.\n",
              "embeddings.xinference.XinferenceEmbeddings([...])\n",
              "Xinference embedding models.\n",
              "embeddings.yandex.YandexGPTEmbeddings\n",
              "YandexGPT Embeddings models.\n",
              "Functions¶\n",
              "embeddings.dashscope.embed_with_retry(...)\n",
              "Use tenacity to retry the embedding call.\n",
              "embeddings.google_palm.embed_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "embeddings.localai.async_embed_with_retry(...)\n",
              "Use tenacity to retry the embedding call.\n",
              "embeddings.localai.embed_with_retry(...)\n",
              "Use tenacity to retry the embedding call.\n",
              "embeddings.minimax.embed_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "embeddings.nemo.is_endpoint_live(url, ...)\n",
              "Check if an endpoint is live by sending a GET request to the specified URL.\n",
              "embeddings.openai.async_embed_with_retry(...)\n",
              "Use tenacity to retry the embedding call.\n",
              "embeddings.openai.embed_with_retry(...)\n",
              "Use tenacity to retry the embedding call.\n",
              "embeddings.premai.create_prem_retry_decorator(...)\n",
              "embeddings.premai.embed_with_retry(embedder, ...)\n",
              "Using tenacity for retry in embedding calls\n",
              "embeddings.self_hosted_hugging_face.load_embedding_model(...)\n",
              "Load the embedding model.\n",
              "embeddings.solar.embed_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "embeddings.voyageai.embed_with_retry(...)\n",
              "Use tenacity to retry the embedding call.\n",
              "langchain_community.example_selectors¶\n",
              "Example selector implements logic for selecting examples to include them\n",
              "in prompts.\n",
              "This allows us to select examples that are most relevant to the input.\n",
              "There could be multiple strategies for selecting examples. For example, one could\n",
              "select examples based on the similarity of the input to the examples. Another\n",
              "strategy could be to select examples based on the diversity of the examples.\n",
              "Classes¶\n",
              "example_selectors.ngram_overlap.NGramOverlapExampleSelector\n",
              "Select and order examples based on ngram overlap score (sentence_bleu score from NLTK package).\n",
              "Functions¶\n",
              "example_selectors.ngram_overlap.ngram_overlap_score(...)\n",
              "Compute ngram overlap score of source and example as sentence_bleu score from NLTK package.\n",
              "langchain_community.graphs¶\n",
              "Graphs provide a natural language interface to graph databases.\n",
              "Classes¶\n",
              "graphs.arangodb_graph.ArangoGraph(db)\n",
              "ArangoDB wrapper for graph operations.\n",
              "graphs.falkordb_graph.FalkorDBGraph(database)\n",
              "FalkorDB wrapper for graph operations.\n",
              "graphs.graph_document.GraphDocument\n",
              "Represents a graph document consisting of nodes and relationships.\n",
              "graphs.graph_document.Node\n",
              "Represents a node in a graph with associated properties.\n",
              "graphs.graph_document.Relationship\n",
              "Represents a directed relationship between two nodes in a graph.\n",
              "graphs.graph_store.GraphStore()\n",
              "An abstract class wrapper for graph operations.\n",
              "graphs.gremlin_graph.GremlinGraph([url, ...])\n",
              "Gremlin wrapper for graph operations. Parameters: url (Optional[str]): The URL of the Gremlin database server or env GREMLIN_URI username (Optional[str]): The collection-identifier like '/dbs/database/colls/graph'                            or env GREMLIN_USERNAME if none provided password (Optional[str]): The connection-key for database authentication                           or env GREMLIN_PASSWORD if none provided traversal_source (str): The traversal source to use for queries. Defaults to 'g'. message_serializer (Optional[Any]): The message serializer to use for requests. Defaults to serializer.GraphSONSerializersV2d0() Security note: Make sure that the database connection uses credentials     that are narrowly-scoped to only include necessary permissions. Failure to do so may result in data corruption or loss, since the calling     code may attempt commands that would result in deletion, mutation     of data if appropriately prompted or reading sensitive data if such     data is present in the database. The best way to guard against such negative outcomes is to (as appropriate)     limit the permissions granted to the credentials used with this tool.\n",
              "graphs.hugegraph.HugeGraph([username, ...])\n",
              "HugeGraph wrapper for graph operations.\n",
              "graphs.kuzu_graph.KuzuGraph(db[, database])\n",
              "Kùzu wrapper for graph operations.\n",
              "graphs.memgraph_graph.MemgraphGraph(url, ...)\n",
              "Memgraph wrapper for graph operations.\n",
              "graphs.nebula_graph.NebulaGraph(space[, ...])\n",
              "NebulaGraph wrapper for graph operations.\n",
              "graphs.neo4j_graph.Neo4jGraph([url, ...])\n",
              "Neo4j database wrapper for various graph operations.\n",
              "graphs.neptune_graph.BaseNeptuneGraph()\n",
              "graphs.neptune_graph.NeptuneAnalyticsGraph(...)\n",
              "Neptune Analytics wrapper for graph operations.\n",
              "graphs.neptune_graph.NeptuneGraph(host[, ...])\n",
              "Neptune wrapper for graph operations.\n",
              "graphs.neptune_graph.NeptuneQueryException(...)\n",
              "Exception for the Neptune queries.\n",
              "graphs.neptune_rdf_graph.NeptuneRdfGraph(host)\n",
              "Neptune wrapper for RDF graph operations.\n",
              "graphs.networkx_graph.KnowledgeTriple(...)\n",
              "Knowledge triple in the graph.\n",
              "graphs.networkx_graph.NetworkxEntityGraph([graph])\n",
              "Networkx wrapper for entity graph operations.\n",
              "graphs.ontotext_graphdb_graph.OntotextGraphDBGraph(...)\n",
              "Ontotext GraphDB https://graphdb.ontotext.com/ wrapper for graph operations.\n",
              "graphs.rdf_graph.RdfGraph([source_file, ...])\n",
              "RDFlib wrapper for graph operations.\n",
              "graphs.tigergraph_graph.TigerGraph(conn)\n",
              "TigerGraph wrapper for graph operations.\n",
              "Functions¶\n",
              "graphs.arangodb_graph.get_arangodb_client([...])\n",
              "Get the Arango DB client from credentials.\n",
              "graphs.neo4j_graph.value_sanitize(d)\n",
              "Sanitize the input dictionary or list.\n",
              "graphs.networkx_graph.get_entities(entity_str)\n",
              "Extract entities from entity string.\n",
              "graphs.networkx_graph.parse_triples(...)\n",
              "Parse knowledge triples from the knowledge string.\n",
              "langchain_community.indexes¶\n",
              "Index is used to avoid writing duplicated content\n",
              "into the vectostore and to avoid over-writing content if it’s unchanged.\n",
              "Indexes also :\n",
              "Create knowledge graphs from data.\n",
              "Support indexing workflows from LangChain data loaders to vectorstores.\n",
              "Importantly, Index keeps on working even if the content being written is derived\n",
              "via a set of transformations from some source content (e.g., indexing children\n",
              "documents that were derived from parent documents by chunking.)\n",
              "Classes¶\n",
              "indexes.base.RecordManager(namespace)\n",
              "Abstract base class for a record manager.\n",
              "langchain_community.llms¶\n",
              "LLM classes provide\n",
              "access to the large language model (LLM) APIs and services.\n",
              "Class hierarchy:\n",
              "BaseLanguageModel --> BaseLLM --> LLM --> <name>  # Examples: AI21, HuggingFaceHub, OpenAI\n",
              "Main helpers:\n",
              "LLMResult, PromptValue,\n",
              "CallbackManagerForLLMRun, AsyncCallbackManagerForLLMRun,\n",
              "CallbackManager, AsyncCallbackManager,\n",
              "AIMessage, BaseMessage\n",
              "Classes¶\n",
              "llms.ai21.AI21\n",
              "AI21 large language models.\n",
              "llms.ai21.AI21PenaltyData\n",
              "Parameters for AI21 penalty data.\n",
              "llms.aleph_alpha.AlephAlpha\n",
              "Aleph Alpha large language models.\n",
              "llms.amazon_api_gateway.AmazonAPIGateway\n",
              "Amazon API Gateway to access LLM models hosted on AWS.\n",
              "llms.amazon_api_gateway.ContentHandlerAmazonAPIGateway()\n",
              "Adapter to prepare the inputs from Langchain to a format that LLM model expects.\n",
              "llms.anthropic.Anthropic\n",
              "[Deprecated] Anthropic large language models.\n",
              "llms.anyscale.Anyscale\n",
              "Anyscale large language models.\n",
              "llms.aphrodite.Aphrodite\n",
              "Aphrodite language model.\n",
              "llms.arcee.Arcee\n",
              "Arcee's Domain Adapted Language Models (DALMs).\n",
              "llms.aviary.Aviary\n",
              "Aviary hosted models.\n",
              "llms.aviary.AviaryBackend(backend_url, bearer)\n",
              "Aviary backend.\n",
              "llms.azureml_endpoint.AzureMLBaseEndpoint\n",
              "Azure ML Online Endpoint models.\n",
              "llms.azureml_endpoint.AzureMLEndpointApiType(value)\n",
              "Azure ML endpoints API types.\n",
              "llms.azureml_endpoint.AzureMLEndpointClient(...)\n",
              "AzureML Managed Endpoint client.\n",
              "llms.azureml_endpoint.AzureMLOnlineEndpoint\n",
              "Azure ML Online Endpoint models.\n",
              "llms.azureml_endpoint.ContentFormatterBase()\n",
              "Transform request and response of AzureML endpoint to match with required schema.\n",
              "llms.azureml_endpoint.CustomOpenAIContentFormatter()\n",
              "Content formatter for models that use the OpenAI like API scheme.\n",
              "llms.azureml_endpoint.DollyContentFormatter()\n",
              "Content handler for the Dolly-v2-12b model\n",
              "llms.azureml_endpoint.GPT2ContentFormatter()\n",
              "Content handler for GPT2\n",
              "llms.azureml_endpoint.HFContentFormatter()\n",
              "Content handler for LLMs from the HuggingFace catalog.\n",
              "llms.azureml_endpoint.LlamaContentFormatter()\n",
              "Deprecated: Kept for backwards compatibility\n",
              "llms.azureml_endpoint.OSSContentFormatter()\n",
              "Deprecated: Kept for backwards compatibility\n",
              "llms.baichuan.BaichuanLLM\n",
              "Wrapper around Baichuan large language models.\n",
              "llms.baidu_qianfan_endpoint.QianfanLLMEndpoint\n",
              "Baidu Qianfan hosted open source or customized models.\n",
              "llms.bananadev.Banana\n",
              "Banana large language models.\n",
              "llms.baseten.Baseten\n",
              "Baseten model\n",
              "llms.beam.Beam\n",
              "Beam API for gpt2 large language model.\n",
              "llms.bedrock.Bedrock\n",
              "Bedrock models.\n",
              "llms.bedrock.BedrockBase\n",
              "Base class for Bedrock models.\n",
              "llms.bedrock.LLMInputOutputAdapter()\n",
              "Adapter class to prepare the inputs from Langchain to a format that LLM model expects.\n",
              "llms.bigdl_llm.BigdlLLM\n",
              "Wrapper around the BigdlLLM model\n",
              "llms.bittensor.NIBittensorLLM\n",
              "NIBittensor LLMs\n",
              "llms.cerebriumai.CerebriumAI\n",
              "CerebriumAI large language models.\n",
              "llms.chatglm.ChatGLM\n",
              "ChatGLM LLM service.\n",
              "llms.chatglm3.ChatGLM3\n",
              "ChatGLM3 LLM service.\n",
              "llms.clarifai.Clarifai\n",
              "Clarifai large language models.\n",
              "llms.cloudflare_workersai.CloudflareWorkersAI\n",
              "Cloudflare Workers AI service.\n",
              "llms.cohere.BaseCohere\n",
              "[Deprecated] Base class for Cohere models.\n",
              "llms.cohere.Cohere\n",
              "[Deprecated] Cohere large language models.\n",
              "llms.ctransformers.CTransformers\n",
              "C Transformers LLM models.\n",
              "llms.ctranslate2.CTranslate2\n",
              "CTranslate2 language model.\n",
              "llms.databricks.Databricks\n",
              "Databricks serving endpoint or a cluster driver proxy app for LLM.\n",
              "llms.deepinfra.DeepInfra\n",
              "DeepInfra models.\n",
              "llms.deepsparse.DeepSparse\n",
              "Neural Magic DeepSparse LLM interface.\n",
              "llms.edenai.EdenAI\n",
              "EdenAI models.\n",
              "llms.fake.FakeListLLM\n",
              "Fake LLM for testing purposes.\n",
              "llms.fake.FakeStreamingListLLM\n",
              "Fake streaming list LLM for testing purposes.\n",
              "llms.fireworks.Fireworks\n",
              "[Deprecated] Fireworks models.\n",
              "llms.forefrontai.ForefrontAI\n",
              "ForefrontAI large language models.\n",
              "llms.friendli.BaseFriendli\n",
              "Base class of Friendli.\n",
              "llms.friendli.Friendli\n",
              "Friendli LLM.\n",
              "llms.gigachat.GigaChat\n",
              "GigaChat large language models API.\n",
              "llms.google_palm.GooglePalm\n",
              "[Deprecated] DEPRECATED: Use langchain_google_genai.GoogleGenerativeAI instead.\n",
              "llms.gooseai.GooseAI\n",
              "GooseAI large language models.\n",
              "llms.gpt4all.GPT4All\n",
              "GPT4All language models.\n",
              "llms.gradient_ai.GradientLLM\n",
              "Gradient.ai LLM Endpoints.\n",
              "llms.gradient_ai.TrainResult\n",
              "Train result.\n",
              "llms.huggingface_endpoint.HuggingFaceEndpoint\n",
              "HuggingFace Endpoint.\n",
              "llms.huggingface_hub.HuggingFaceHub\n",
              "[Deprecated] HuggingFaceHub  models.\n",
              "llms.huggingface_pipeline.HuggingFacePipeline\n",
              "HuggingFace Pipeline API.\n",
              "llms.huggingface_text_gen_inference.HuggingFaceTextGenInference\n",
              "[Deprecated] HuggingFace text generation API.\n",
              "llms.human.HumanInputLLM\n",
              "User input as the response.\n",
              "llms.ipex_llm.IpexLLM\n",
              "IpexLLM model.\n",
              "llms.javelin_ai_gateway.JavelinAIGateway\n",
              "Javelin AI Gateway LLMs.\n",
              "llms.javelin_ai_gateway.Params\n",
              "Parameters for the Javelin AI Gateway LLM.\n",
              "llms.koboldai.KoboldApiLLM\n",
              "Kobold API language model.\n",
              "llms.konko.Konko\n",
              "Konko AI models.\n",
              "llms.layerup_security.LayerupSecurity\n",
              "Layerup Security LLM service.\n",
              "llms.llamacpp.LlamaCpp\n",
              "llama.cpp model.\n",
              "llms.llamafile.Llamafile\n",
              "Llamafile lets you distribute and run large language models with a single file.\n",
              "llms.manifest.ManifestWrapper\n",
              "HazyResearch's Manifest library.\n",
              "llms.minimax.Minimax\n",
              "Wrapper around Minimax large language models.\n",
              "llms.minimax.MinimaxCommon\n",
              "Common parameters for Minimax large language models.\n",
              "llms.mlflow.Mlflow\n",
              "MLflow LLM service.\n",
              "llms.mlflow_ai_gateway.MlflowAIGateway\n",
              "MLflow AI Gateway LLMs.\n",
              "llms.mlflow_ai_gateway.Params\n",
              "Parameters for the MLflow AI Gateway LLM.\n",
              "llms.mlx_pipeline.MLXPipeline\n",
              "MLX Pipeline API.\n",
              "llms.modal.Modal\n",
              "Modal large language models.\n",
              "llms.moonshot.Moonshot\n",
              "Moonshot large language models.\n",
              "llms.moonshot.MoonshotCommon\n",
              "Common parameters for Moonshot LLMs.\n",
              "llms.mosaicml.MosaicML\n",
              "MosaicML LLM service.\n",
              "llms.nlpcloud.NLPCloud\n",
              "NLPCloud large language models.\n",
              "llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentLLM\n",
              "Base class for LLM deployed on OCI Data Science Model Deployment.\n",
              "llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI\n",
              "OCI Data Science Model Deployment TGI Endpoint.\n",
              "llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentVLLM\n",
              "VLLM deployed on OCI Data Science Model Deployment\n",
              "llms.oci_generative_ai.OCIAuthType(value)\n",
              "OCI authentication types as enumerator.\n",
              "llms.oci_generative_ai.OCIGenAI\n",
              "OCI large language models.\n",
              "llms.oci_generative_ai.OCIGenAIBase\n",
              "Base class for OCI GenAI models\n",
              "llms.octoai_endpoint.OctoAIEndpoint\n",
              "OctoAI LLM Endpoints.\n",
              "llms.ollama.Ollama\n",
              "Ollama locally runs large language models.\n",
              "llms.ollama.OllamaEndpointNotFoundError\n",
              "Raised when the Ollama endpoint is not found.\n",
              "llms.opaqueprompts.OpaquePrompts\n",
              "LLM that uses OpaquePrompts to sanitize prompts.\n",
              "llms.openai.AzureOpenAI\n",
              "[Deprecated] Azure-specific OpenAI large language models.\n",
              "llms.openai.BaseOpenAI\n",
              "Base OpenAI large language model class.\n",
              "llms.openai.OpenAI\n",
              "[Deprecated] OpenAI large language models.\n",
              "llms.openai.OpenAIChat\n",
              "[Deprecated] OpenAI Chat large language models.\n",
              "llms.openllm.IdentifyingParams\n",
              "Parameters for identifying a model as a typed dict.\n",
              "llms.openllm.OpenLLM\n",
              "OpenLLM, supporting both in-process model instance and remote OpenLLM servers.\n",
              "llms.openlm.OpenLM\n",
              "OpenLM models.\n",
              "llms.pai_eas_endpoint.PaiEasEndpoint\n",
              "Langchain LLM class to help to access eass llm service.\n",
              "llms.petals.Petals\n",
              "Petals Bloom models.\n",
              "llms.pipelineai.PipelineAI\n",
              "PipelineAI large language models.\n",
              "llms.predibase.Predibase\n",
              "Use your Predibase models with Langchain.\n",
              "llms.predictionguard.PredictionGuard\n",
              "Prediction Guard large language models.\n",
              "llms.promptlayer_openai.PromptLayerOpenAI\n",
              "PromptLayer OpenAI large language models.\n",
              "llms.promptlayer_openai.PromptLayerOpenAIChat\n",
              "PromptLayer OpenAI large language models.\n",
              "llms.replicate.Replicate\n",
              "Replicate models.\n",
              "llms.rwkv.RWKV\n",
              "RWKV language models.\n",
              "llms.sagemaker_endpoint.ContentHandlerBase()\n",
              "Handler class to transform input from LLM to a format that SageMaker endpoint expects.\n",
              "llms.sagemaker_endpoint.LLMContentHandler()\n",
              "Content handler for LLM class.\n",
              "llms.sagemaker_endpoint.LineIterator(stream)\n",
              "Parse the byte stream input.\n",
              "llms.sagemaker_endpoint.SagemakerEndpoint\n",
              "Sagemaker Inference Endpoint models.\n",
              "llms.self_hosted.SelfHostedPipeline\n",
              "Model inference on self-hosted remote hardware.\n",
              "llms.self_hosted_hugging_face.SelfHostedHuggingFaceLLM\n",
              "HuggingFace Pipeline API to run on self-hosted remote hardware.\n",
              "llms.solar.Solar\n",
              "Solar large language models.\n",
              "llms.solar.SolarCommon\n",
              "Common configuration for Solar LLMs.\n",
              "llms.sparkllm.SparkLLM\n",
              "iFlyTek Spark large language model.\n",
              "llms.stochasticai.StochasticAI\n",
              "StochasticAI large language models.\n",
              "llms.symblai_nebula.Nebula\n",
              "Nebula Service models.\n",
              "llms.textgen.TextGen\n",
              "Text generation models from WebUI.\n",
              "llms.titan_takeoff.TitanTakeoff\n",
              "Titan Takeoff API LLMs.\n",
              "llms.titan_takeoff_pro.TitanTakeoffPro\n",
              "Titan Takeoff Pro is a language model that can be used to generate text.\n",
              "llms.together.Together\n",
              "[Deprecated] LLM models from Together.\n",
              "llms.tongyi.Tongyi\n",
              "Tongyi Qwen large language models.\n",
              "llms.vertexai.VertexAI\n",
              "[Deprecated] Google Vertex AI large language models.\n",
              "llms.vertexai.VertexAIModelGarden\n",
              "[Deprecated] Vertex AI Model Garden large language models.\n",
              "llms.vllm.VLLM\n",
              "VLLM language model.\n",
              "llms.vllm.VLLMOpenAI\n",
              "vLLM OpenAI-compatible API client\n",
              "llms.volcengine_maas.VolcEngineMaasBase\n",
              "Base class for VolcEngineMaas models.\n",
              "llms.volcengine_maas.VolcEngineMaasLLM\n",
              "volc engine maas hosts a plethora of models.\n",
              "llms.watsonxllm.WatsonxLLM\n",
              "[Deprecated] IBM watsonx.ai large language models.\n",
              "llms.weight_only_quantization.WeightOnlyQuantPipeline\n",
              "Weight only quantized model.\n",
              "llms.writer.Writer\n",
              "Writer large language models.\n",
              "llms.xinference.Xinference\n",
              "Xinference large-scale model inference service.\n",
              "llms.yandex.YandexGPT\n",
              "Yandex large language models.\n",
              "llms.yuan2.Yuan2\n",
              "Yuan2.0 language models.\n",
              "Functions¶\n",
              "llms.anyscale.create_llm_result(choices, ...)\n",
              "Create the LLMResult from the choices and prompts.\n",
              "llms.anyscale.update_token_usage(keys, ...)\n",
              "Update token usage.\n",
              "llms.aviary.get_completions(model, prompt[, ...])\n",
              "Get completions from Aviary models.\n",
              "llms.aviary.get_models()\n",
              "List available models\n",
              "llms.cohere.acompletion_with_retry(llm, **kwargs)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.cohere.completion_with_retry(llm, **kwargs)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.databricks.get_default_api_token()\n",
              "Get the default Databricks personal access token.\n",
              "llms.databricks.get_default_host()\n",
              "Get the default Databricks workspace hostname.\n",
              "llms.databricks.get_repl_context()\n",
              "Get the notebook REPL context if running inside a Databricks notebook.\n",
              "llms.fireworks.acompletion_with_retry(llm, ...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.fireworks.acompletion_with_retry_batching(...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.fireworks.acompletion_with_retry_streaming(...)\n",
              "Use tenacity to retry the completion call for streaming.\n",
              "llms.fireworks.completion_with_retry(llm, ...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.fireworks.completion_with_retry_batching(...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.fireworks.conditional_decorator(...)\n",
              "Conditionally apply a decorator.\n",
              "llms.google_palm.completion_with_retry(llm, ...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.koboldai.clean_url(url)\n",
              "Remove trailing slash and /api from url if present.\n",
              "llms.layerup_security.default_guardrail_violation_handler(...)\n",
              "Default guardrail violation handler.\n",
              "llms.loading.load_llm(file, **kwargs)\n",
              "Load LLM from a file.\n",
              "llms.loading.load_llm_from_config(config, ...)\n",
              "Load LLM from Config Dict.\n",
              "llms.openai.acompletion_with_retry(llm[, ...])\n",
              "Use tenacity to retry the async completion call.\n",
              "llms.openai.completion_with_retry(llm[, ...])\n",
              "Use tenacity to retry the completion call.\n",
              "llms.openai.update_token_usage(keys, ...)\n",
              "Update token usage.\n",
              "llms.symblai_nebula.completion_with_retry(...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.symblai_nebula.make_request(self, prompt)\n",
              "Generate text from the model.\n",
              "llms.tongyi.agenerate_with_last_element_mark(...)\n",
              "Generate elements from an async iterable, and a boolean indicating if it is the last element.\n",
              "llms.tongyi.astream_generate_with_retry(llm, ...)\n",
              "Async version of stream_generate_with_retry.\n",
              "llms.tongyi.check_response(resp)\n",
              "Check the response from the completion call.\n",
              "llms.tongyi.generate_with_last_element_mark(...)\n",
              "Generate elements from an iterable, and a boolean indicating if it is the last element.\n",
              "llms.tongyi.generate_with_retry(llm, **kwargs)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.tongyi.stream_generate_with_retry(llm, ...)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.utils.enforce_stop_tokens(text, stop)\n",
              "Cut off the text as soon as any stop words occur.\n",
              "llms.vertexai.acompletion_with_retry(llm, prompt)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.vertexai.completion_with_retry(llm, prompt)\n",
              "Use tenacity to retry the completion call.\n",
              "llms.vertexai.is_codey_model(model_name)\n",
              "Return True if the model name is a Codey model.\n",
              "llms.vertexai.is_gemini_model(model_name)\n",
              "Return True if the model name is a Gemini model.\n",
              "llms.yandex.acompletion_with_retry(llm, **kwargs)\n",
              "Use tenacity to retry the async completion call.\n",
              "llms.yandex.completion_with_retry(llm, **kwargs)\n",
              "Use tenacity to retry the completion call.\n",
              "langchain_community.output_parsers¶\n",
              "OutputParser classes parse the output of an LLM call.\n",
              "Class hierarchy:\n",
              "BaseLLMOutputParser --> BaseOutputParser --> <name>OutputParser  # GuardrailsOutputParser\n",
              "Main helpers:\n",
              "Serializable, Generation, PromptValue\n",
              "Classes¶\n",
              "output_parsers.ernie_functions.JsonKeyOutputFunctionsParser\n",
              "Parse an output as the element of the Json object.\n",
              "output_parsers.ernie_functions.JsonOutputFunctionsParser\n",
              "Parse an output as the Json object.\n",
              "output_parsers.ernie_functions.OutputFunctionsParser\n",
              "Parse an output that is one of sets of values.\n",
              "output_parsers.ernie_functions.PydanticAttrOutputFunctionsParser\n",
              "Parse an output as an attribute of a pydantic object.\n",
              "output_parsers.ernie_functions.PydanticOutputFunctionsParser\n",
              "Parse an output as a pydantic object.\n",
              "output_parsers.rail_parser.GuardrailsOutputParser\n",
              "Parse the output of an LLM call using Guardrails.\n",
              "langchain_community.retrievers¶\n",
              "Retriever class returns Documents given a text query.\n",
              "It is more general than a vector store. A retriever does not need to be able to\n",
              "store documents, only to return (or retrieve) it. Vector stores can be used as\n",
              "the backbone of a retriever, but there are other types of retrievers as well.\n",
              "Class hierarchy:\n",
              "BaseRetriever --> <name>Retriever  # Examples: ArxivRetriever, MergerRetriever\n",
              "Main helpers:\n",
              "Document, Serializable, Callbacks,\n",
              "CallbackManagerForRetrieverRun, AsyncCallbackManagerForRetrieverRun\n",
              "Classes¶\n",
              "retrievers.arcee.ArceeRetriever\n",
              "Arcee Domain Adapted Language Models (DALMs) retriever.\n",
              "retrievers.arxiv.ArxivRetriever\n",
              "Arxiv retriever.\n",
              "retrievers.azure_ai_search.AzureAISearchRetriever\n",
              "Azure AI Search service retriever.\n",
              "retrievers.azure_ai_search.AzureCognitiveSearchRetriever\n",
              "Azure Cognitive Search service retriever.\n",
              "retrievers.bedrock.AmazonKnowledgeBasesRetriever\n",
              "Amazon Bedrock Knowledge Bases retrieval.\n",
              "retrievers.bedrock.RetrievalConfig\n",
              "Configuration for retrieval.\n",
              "retrievers.bedrock.VectorSearchConfig\n",
              "Configuration for vector search.\n",
              "retrievers.bm25.BM25Retriever\n",
              "BM25 retriever without Elasticsearch.\n",
              "retrievers.breebs.BreebsRetriever\n",
              "A retriever class for Breebs.\n",
              "retrievers.chaindesk.ChaindeskRetriever\n",
              "Chaindesk API retriever.\n",
              "retrievers.chatgpt_plugin_retriever.ChatGPTPluginRetriever\n",
              "ChatGPT plugin retriever.\n",
              "retrievers.cohere_rag_retriever.CohereRagRetriever\n",
              "[Deprecated] Cohere Chat API with RAG.\n",
              "retrievers.databerry.DataberryRetriever\n",
              "Databerry API retriever.\n",
              "retrievers.docarray.DocArrayRetriever\n",
              "DocArray Document Indices retriever.\n",
              "retrievers.docarray.SearchType(value)\n",
              "Enumerator of the types of search to perform.\n",
              "retrievers.dria_index.DriaRetriever\n",
              "Dria retriever using the DriaAPIWrapper.\n",
              "retrievers.elastic_search_bm25.ElasticSearchBM25Retriever\n",
              "Elasticsearch retriever that uses BM25.\n",
              "retrievers.embedchain.EmbedchainRetriever\n",
              "Embedchain retriever.\n",
              "retrievers.google_cloud_documentai_warehouse.GoogleDocumentAIWarehouseRetriever\n",
              "[Deprecated] A retriever based on Document AI Warehouse.\n",
              "retrievers.google_vertex_ai_search.GoogleCloudEnterpriseSearchRetriever\n",
              "Google Vertex Search API retriever alias for backwards compatibility.\n",
              "retrievers.google_vertex_ai_search.GoogleVertexAIMultiTurnSearchRetriever\n",
              "Google Vertex AI Search retriever for multi-turn conversations.\n",
              "retrievers.google_vertex_ai_search.GoogleVertexAISearchRetriever\n",
              "Google Vertex AI Search retriever.\n",
              "retrievers.kay.KayAiRetriever\n",
              "Retriever for Kay.ai datasets.\n",
              "retrievers.kendra.AdditionalResultAttribute\n",
              "Additional result attribute.\n",
              "retrievers.kendra.AdditionalResultAttributeValue\n",
              "Value of an additional result attribute.\n",
              "retrievers.kendra.AmazonKendraRetriever\n",
              "Amazon Kendra Index retriever.\n",
              "retrievers.kendra.DocumentAttribute\n",
              "Document attribute.\n",
              "retrievers.kendra.DocumentAttributeValue\n",
              "Value of a document attribute.\n",
              "retrievers.kendra.Highlight\n",
              "Information that highlights the keywords in the excerpt.\n",
              "retrievers.kendra.QueryResult\n",
              "Amazon Kendra Query API search result.\n",
              "retrievers.kendra.QueryResultItem\n",
              "Query API result item.\n",
              "retrievers.kendra.ResultItem\n",
              "Base class of a result item.\n",
              "retrievers.kendra.RetrieveResult\n",
              "Amazon Kendra Retrieve API search result.\n",
              "retrievers.kendra.RetrieveResultItem\n",
              "Retrieve API result item.\n",
              "retrievers.kendra.TextWithHighLights\n",
              "Text with highlights.\n",
              "retrievers.knn.KNNRetriever\n",
              "KNN retriever.\n",
              "retrievers.llama_index.LlamaIndexGraphRetriever\n",
              "LlamaIndex graph data structure retriever.\n",
              "retrievers.llama_index.LlamaIndexRetriever\n",
              "LlamaIndex retriever.\n",
              "retrievers.metal.MetalRetriever\n",
              "Metal API retriever.\n",
              "retrievers.milvus.MilvusRetriever\n",
              "Milvus API retriever.\n",
              "retrievers.outline.OutlineRetriever\n",
              "Retriever for Outline API.\n",
              "retrievers.pinecone_hybrid_search.PineconeHybridSearchRetriever\n",
              "Pinecone Hybrid Search retriever.\n",
              "retrievers.pubmed.PubMedRetriever\n",
              "PubMed API retriever.\n",
              "retrievers.qdrant_sparse_vector_retriever.QdrantSparseVectorRetriever\n",
              "Qdrant sparse vector retriever.\n",
              "retrievers.remote_retriever.RemoteLangChainRetriever\n",
              "LangChain API retriever.\n",
              "retrievers.svm.SVMRetriever\n",
              "SVM retriever.\n",
              "retrievers.tavily_search_api.SearchDepth(value)\n",
              "Search depth as enumerator.\n",
              "retrievers.tavily_search_api.TavilySearchAPIRetriever\n",
              "Tavily Search API retriever.\n",
              "retrievers.tfidf.TFIDFRetriever\n",
              "TF-IDF retriever.\n",
              "retrievers.vespa_retriever.VespaRetriever\n",
              "Vespa retriever.\n",
              "retrievers.weaviate_hybrid_search.WeaviateHybridSearchRetriever\n",
              "Weaviate hybrid search retriever.\n",
              "retrievers.wikipedia.WikipediaRetriever\n",
              "Wikipedia API retriever.\n",
              "retrievers.you.YouRetriever\n",
              "You.com Search API retriever.\n",
              "retrievers.zep.SearchScope(value)\n",
              "Which documents to search.\n",
              "retrievers.zep.SearchType(value)\n",
              "Enumerator of the types of search to perform.\n",
              "retrievers.zep.ZepRetriever\n",
              "Zep MemoryStore Retriever.\n",
              "retrievers.zilliz.ZillizRetriever\n",
              "Zilliz API retriever.\n",
              "Functions¶\n",
              "retrievers.bm25.default_preprocessing_func(text)\n",
              "retrievers.kendra.clean_excerpt(excerpt)\n",
              "Clean an excerpt from Kendra.\n",
              "retrievers.kendra.combined_text(item)\n",
              "Combine a ResultItem title and excerpt into a single string.\n",
              "retrievers.knn.create_index(contexts, embeddings)\n",
              "Create an index of embeddings for a list of contexts.\n",
              "retrievers.milvus.MilvusRetreiver(*args, ...)\n",
              "Deprecated MilvusRetreiver.\n",
              "retrievers.pinecone_hybrid_search.create_index(...)\n",
              "Create an index from a list of contexts.\n",
              "retrievers.pinecone_hybrid_search.hash_text(text)\n",
              "Hash a text using SHA256.\n",
              "retrievers.svm.create_index(contexts, embeddings)\n",
              "Create an index of embeddings for a list of contexts.\n",
              "retrievers.zilliz.ZillizRetreiver(*args, ...)\n",
              "Deprecated ZillizRetreiver.\n",
              "langchain_community.storage¶\n",
              "Storage is an implementation of key-value store.\n",
              "Storage module provides implementations of various key-value stores that conform\n",
              "to a simple key-value interface.\n",
              "The primary goal of these storages is to support caching.\n",
              "Class hierarchy:\n",
              "BaseStore --> <name>Store  # Examples: MongoDBStore, RedisStore\n",
              "Classes¶\n",
              "storage.astradb.AstraDBBaseStore(*args, **kwargs)\n",
              "Base class for the DataStax AstraDB data store.\n",
              "storage.astradb.AstraDBByteStore(collection_name)\n",
              "[Deprecated]\n",
              "storage.astradb.AstraDBStore(collection_name)\n",
              "[Deprecated]\n",
              "storage.exceptions.InvalidKeyException\n",
              "Raised when a key is invalid; e.g., uses incorrect characters.\n",
              "storage.mongodb.MongoDBStore(...[, ...])\n",
              "BaseStore implementation using MongoDB as the underlying store.\n",
              "storage.redis.RedisStore(*[, client, ...])\n",
              "BaseStore implementation using Redis as the underlying store.\n",
              "storage.upstash_redis.UpstashRedisByteStore(*)\n",
              "BaseStore implementation using Upstash Redis as the underlying store to store raw bytes.\n",
              "storage.upstash_redis.UpstashRedisStore(*[, ...])\n",
              "[Deprecated] BaseStore implementation using Upstash Redis as the underlying store to store strings.\n",
              "langchain_community.tools¶\n",
              "Tools are classes that an Agent uses to interact with the world.\n",
              "Each tool has a description. Agent uses the description to choose the right\n",
              "tool for the job.\n",
              "Class hierarchy:\n",
              "ToolMetaclass --> BaseTool --> <name>Tool  # Examples: AIPluginTool, BaseGraphQLTool\n",
              "                               <name>      # Examples: BraveSearch, HumanInputRun\n",
              "Main helpers:\n",
              "CallbackManagerForToolRun, AsyncCallbackManagerForToolRun\n",
              "Classes¶\n",
              "tools.ainetwork.app.AINAppOps\n",
              "Tool for app operations.\n",
              "tools.ainetwork.app.AppOperationType(value)\n",
              "Type of app operation as enumerator.\n",
              "tools.ainetwork.app.AppSchema\n",
              "Schema for app operations.\n",
              "tools.ainetwork.base.AINBaseTool\n",
              "Base class for the AINetwork tools.\n",
              "tools.ainetwork.base.OperationType(value)\n",
              "Type of operation as enumerator.\n",
              "tools.ainetwork.owner.AINOwnerOps\n",
              "Tool for owner operations.\n",
              "tools.ainetwork.owner.RuleSchema\n",
              "Schema for owner operations.\n",
              "tools.ainetwork.rule.AINRuleOps\n",
              "Tool for owner operations.\n",
              "tools.ainetwork.rule.RuleSchema\n",
              "Schema for owner operations.\n",
              "tools.ainetwork.transfer.AINTransfer\n",
              "Tool for transfer operations.\n",
              "tools.ainetwork.transfer.TransferSchema\n",
              "Schema for transfer operations.\n",
              "tools.ainetwork.value.AINValueOps\n",
              "Tool for value operations.\n",
              "tools.ainetwork.value.ValueSchema\n",
              "Schema for value operations.\n",
              "tools.amadeus.base.AmadeusBaseTool\n",
              "Base Tool for Amadeus.\n",
              "tools.amadeus.closest_airport.AmadeusClosestAirport\n",
              "Tool for finding the closest airport to a particular location.\n",
              "tools.amadeus.closest_airport.ClosestAirportSchema\n",
              "Schema for the AmadeusClosestAirport tool.\n",
              "tools.amadeus.flight_search.AmadeusFlightSearch\n",
              "Tool for searching for a single flight between two airports.\n",
              "tools.amadeus.flight_search.FlightSearchSchema\n",
              "Schema for the AmadeusFlightSearch tool.\n",
              "tools.arxiv.tool.ArxivInput\n",
              "Input for the Arxiv tool.\n",
              "tools.arxiv.tool.ArxivQueryRun\n",
              "Tool that searches the Arxiv API.\n",
              "tools.audio.huggingface_text_to_speech_inference.HuggingFaceTextToSpeechModelInference\n",
              "HuggingFace Text-to-Speech Model Inference.\n",
              "tools.azure_ai_services.document_intelligence.AzureAiServicesDocumentIntelligenceTool\n",
              "Tool that queries the Azure AI Services Document Intelligence API.\n",
              "tools.azure_ai_services.image_analysis.AzureAiServicesImageAnalysisTool\n",
              "Tool that queries the Azure AI Services Image Analysis API.\n",
              "tools.azure_ai_services.speech_to_text.AzureAiServicesSpeechToTextTool\n",
              "Tool that queries the Azure AI Services Speech to Text API.\n",
              "tools.azure_ai_services.text_analytics_for_health.AzureAiServicesTextAnalyticsForHealthTool\n",
              "Tool that queries the Azure AI Services Text Analytics for Health API.\n",
              "tools.azure_ai_services.text_to_speech.AzureAiServicesTextToSpeechTool\n",
              "Tool that queries the Azure AI Services Text to Speech API.\n",
              "tools.azure_cognitive_services.form_recognizer.AzureCogsFormRecognizerTool\n",
              "Tool that queries the Azure Cognitive Services Form Recognizer API.\n",
              "tools.azure_cognitive_services.image_analysis.AzureCogsImageAnalysisTool\n",
              "Tool that queries the Azure Cognitive Services Image Analysis API.\n",
              "tools.azure_cognitive_services.speech2text.AzureCogsSpeech2TextTool\n",
              "Tool that queries the Azure Cognitive Services Speech2Text API.\n",
              "tools.azure_cognitive_services.text2speech.AzureCogsText2SpeechTool\n",
              "Tool that queries the Azure Cognitive Services Text2Speech API.\n",
              "tools.azure_cognitive_services.text_analytics_health.AzureCogsTextAnalyticsHealthTool\n",
              "Tool that queries the Azure Cognitive Services Text Analytics for Health API.\n",
              "tools.bearly.tool.BearlyInterpreterTool(api_key)\n",
              "Tool for evaluating python code in a sandbox environment.\n",
              "tools.bearly.tool.BearlyInterpreterToolArguments\n",
              "Arguments for the BearlyInterpreterTool.\n",
              "tools.bearly.tool.FileInfo\n",
              "Information about a file to be uploaded.\n",
              "tools.bing_search.tool.BingSearchResults\n",
              "Tool that queries the Bing Search API and gets back json.\n",
              "tools.bing_search.tool.BingSearchRun\n",
              "Tool that queries the Bing search API.\n",
              "tools.brave_search.tool.BraveSearch\n",
              "Tool that queries the BraveSearch.\n",
              "tools.clickup.tool.ClickupAction\n",
              "Tool that queries the  Clickup API.\n",
              "tools.cogniswitch.tool.CogniswitchKnowledgeRequest\n",
              "Tool that uses the Cogniswitch service to answer questions.\n",
              "tools.cogniswitch.tool.CogniswitchKnowledgeSourceFile\n",
              "Tool that uses the Cogniswitch services to store data from file.\n",
              "tools.cogniswitch.tool.CogniswitchKnowledgeSourceURL\n",
              "Tool that uses the Cogniswitch services to store data from a URL.\n",
              "tools.cogniswitch.tool.CogniswitchKnowledgeStatus\n",
              "Tool that uses the Cogniswitch services to get the\n",
              "tools.connery.models.Action\n",
              "Connery Action model.\n",
              "tools.connery.models.Parameter\n",
              "Connery Action parameter model.\n",
              "tools.connery.models.Validation\n",
              "Connery Action parameter validation model.\n",
              "tools.connery.service.ConneryService\n",
              "Service for interacting with the Connery Runner API.\n",
              "tools.connery.tool.ConneryAction\n",
              "Connery Action tool.\n",
              "tools.dataforseo_api_search.tool.DataForSeoAPISearchResults\n",
              "Tool that queries the DataForSeo Google Search API and get back json.\n",
              "tools.dataforseo_api_search.tool.DataForSeoAPISearchRun\n",
              "Tool that queries the DataForSeo Google search API.\n",
              "tools.ddg_search.tool.DDGInput\n",
              "Input for the DuckDuckGo search tool.\n",
              "tools.ddg_search.tool.DuckDuckGoSearchResults\n",
              "Tool that queries the DuckDuckGo search API and gets back json.\n",
              "tools.ddg_search.tool.DuckDuckGoSearchRun\n",
              "Tool that queries the DuckDuckGo search API.\n",
              "tools.e2b_data_analysis.tool.E2BDataAnalysisTool\n",
              "Tool for running python code in a sandboxed environment for data analysis.\n",
              "tools.e2b_data_analysis.tool.E2BDataAnalysisToolArguments\n",
              "Arguments for the E2BDataAnalysisTool.\n",
              "tools.e2b_data_analysis.tool.UploadedFile\n",
              "Description of the uploaded path with its remote path.\n",
              "tools.e2b_data_analysis.unparse.Unparser(tree)\n",
              "Methods in this class recursively traverse an AST and output source code for the abstract syntax; original formatting is disregarded.\n",
              "tools.edenai.audio_speech_to_text.EdenAiSpeechToTextTool\n",
              "Tool that queries the Eden AI Speech To Text API.\n",
              "tools.edenai.audio_text_to_speech.EdenAiTextToSpeechTool\n",
              "Tool that queries the Eden AI Text to speech API.\n",
              "tools.edenai.edenai_base_tool.EdenaiTool\n",
              "the base tool for all the EdenAI Tools .\n",
              "tools.edenai.image_explicitcontent.EdenAiExplicitImageTool\n",
              "Tool that queries the Eden AI Explicit image detection.\n",
              "tools.edenai.image_objectdetection.EdenAiObjectDetectionTool\n",
              "Tool that queries the Eden AI Object detection API.\n",
              "tools.edenai.ocr_identityparser.EdenAiParsingIDTool\n",
              "Tool that queries the Eden AI  Identity parsing API.\n",
              "tools.edenai.ocr_invoiceparser.EdenAiParsingInvoiceTool\n",
              "Tool that queries the Eden AI Invoice parsing API.\n",
              "tools.edenai.text_moderation.EdenAiTextModerationTool\n",
              "Tool that queries the Eden AI Explicit text detection.\n",
              "tools.eleven_labs.models.ElevenLabsModel(value)\n",
              "Models available for Eleven Labs Text2Speech.\n",
              "tools.eleven_labs.text2speech.ElevenLabsModel(value)\n",
              "Models available for Eleven Labs Text2Speech.\n",
              "tools.eleven_labs.text2speech.ElevenLabsText2SpeechTool\n",
              "Tool that queries the Eleven Labs Text2Speech API.\n",
              "tools.file_management.copy.CopyFileTool\n",
              "Tool that copies a file.\n",
              "tools.file_management.copy.FileCopyInput\n",
              "Input for CopyFileTool.\n",
              "tools.file_management.delete.DeleteFileTool\n",
              "Tool that deletes a file.\n",
              "tools.file_management.delete.FileDeleteInput\n",
              "Input for DeleteFileTool.\n",
              "tools.file_management.file_search.FileSearchInput\n",
              "Input for FileSearchTool.\n",
              "tools.file_management.file_search.FileSearchTool\n",
              "Tool that searches for files in a subdirectory that match a regex pattern.\n",
              "tools.file_management.list_dir.DirectoryListingInput\n",
              "Input for ListDirectoryTool.\n",
              "tools.file_management.list_dir.ListDirectoryTool\n",
              "Tool that lists files and directories in a specified folder.\n",
              "tools.file_management.move.FileMoveInput\n",
              "Input for MoveFileTool.\n",
              "tools.file_management.move.MoveFileTool\n",
              "Tool that moves a file.\n",
              "tools.file_management.read.ReadFileInput\n",
              "Input for ReadFileTool.\n",
              "tools.file_management.read.ReadFileTool\n",
              "Tool that reads a file.\n",
              "tools.file_management.utils.BaseFileToolMixin\n",
              "Mixin for file system tools.\n",
              "tools.file_management.utils.FileValidationError\n",
              "Error for paths outside the root directory.\n",
              "tools.file_management.write.WriteFileInput\n",
              "Input for WriteFileTool.\n",
              "tools.file_management.write.WriteFileTool\n",
              "Tool that writes a file to disk.\n",
              "tools.github.tool.GitHubAction\n",
              "Tool for interacting with the GitHub API.\n",
              "tools.gitlab.tool.GitLabAction\n",
              "Tool for interacting with the GitLab API.\n",
              "tools.gmail.base.GmailBaseTool\n",
              "Base class for Gmail tools.\n",
              "tools.gmail.create_draft.CreateDraftSchema\n",
              "Input for CreateDraftTool.\n",
              "tools.gmail.create_draft.GmailCreateDraft\n",
              "Tool that creates a draft email for Gmail.\n",
              "tools.gmail.get_message.GmailGetMessage\n",
              "Tool that gets a message by ID from Gmail.\n",
              "tools.gmail.get_message.SearchArgsSchema\n",
              "Input for GetMessageTool.\n",
              "tools.gmail.get_thread.GetThreadSchema\n",
              "Input for GetMessageTool.\n",
              "tools.gmail.get_thread.GmailGetThread\n",
              "Tool that gets a thread by ID from Gmail.\n",
              "tools.gmail.search.GmailSearch\n",
              "Tool that searches for messages or threads in Gmail.\n",
              "tools.gmail.search.Resource(value)\n",
              "Enumerator of Resources to search.\n",
              "tools.gmail.search.SearchArgsSchema\n",
              "Input for SearchGmailTool.\n",
              "tools.gmail.send_message.GmailSendMessage\n",
              "Tool that sends a message to Gmail.\n",
              "tools.gmail.send_message.SendMessageSchema\n",
              "Input for SendMessageTool.\n",
              "tools.golden_query.tool.GoldenQueryRun\n",
              "Tool that adds the capability to query using the Golden API and get back JSON.\n",
              "tools.google_cloud.texttospeech.GoogleCloudTextToSpeechTool\n",
              "Tool that queries the Google Cloud Text to Speech API.\n",
              "tools.google_finance.tool.GoogleFinanceQueryRun\n",
              "Tool that queries the Google Finance API.\n",
              "tools.google_jobs.tool.GoogleJobsQueryRun\n",
              "Tool that queries the Google Jobs API.\n",
              "tools.google_lens.tool.GoogleLensQueryRun\n",
              "Tool that queries the Google Lens API.\n",
              "tools.google_places.tool.GooglePlacesSchema\n",
              "Input for GooglePlacesTool.\n",
              "tools.google_places.tool.GooglePlacesTool\n",
              "Tool that queries the Google places API.\n",
              "tools.google_scholar.tool.GoogleScholarQueryRun\n",
              "Tool that queries the Google search API.\n",
              "tools.google_search.tool.GoogleSearchResults\n",
              "Tool that queries the Google Search API and gets back json.\n",
              "tools.google_search.tool.GoogleSearchRun\n",
              "Tool that queries the Google search API.\n",
              "tools.google_serper.tool.GoogleSerperResults\n",
              "Tool that queries the Serper.dev Google Search API and get back json.\n",
              "tools.google_serper.tool.GoogleSerperRun\n",
              "Tool that queries the Serper.dev Google search API.\n",
              "tools.google_trends.tool.GoogleTrendsQueryRun\n",
              "Tool that queries the Google trends API.\n",
              "tools.graphql.tool.BaseGraphQLTool\n",
              "Base tool for querying a GraphQL API.\n",
              "tools.human.tool.HumanInputRun\n",
              "Tool that asks user for input.\n",
              "tools.ifttt.IFTTTWebhook\n",
              "IFTTT Webhook.\n",
              "tools.jira.tool.JiraAction\n",
              "Tool that queries the Atlassian Jira API.\n",
              "tools.json.tool.JsonGetValueTool\n",
              "Tool for getting a value in a JSON spec.\n",
              "tools.json.tool.JsonListKeysTool\n",
              "Tool for listing keys in a JSON spec.\n",
              "tools.json.tool.JsonSpec\n",
              "Base class for JSON spec.\n",
              "tools.memorize.tool.Memorize\n",
              "Tool that trains a language model.\n",
              "tools.memorize.tool.TrainableLLM(*args, **kwargs)\n",
              "Protocol for trainable language models.\n",
              "tools.merriam_webster.tool.MerriamWebsterQueryRun\n",
              "Tool that searches the Merriam-Webster API.\n",
              "tools.metaphor_search.tool.MetaphorSearchResults\n",
              "[Deprecated] Tool that queries the Metaphor Search API and gets back json.\n",
              "tools.multion.close_session.CloseSessionSchema\n",
              "Input for UpdateSessionTool.\n",
              "tools.multion.close_session.MultionCloseSession\n",
              "Tool that closes an existing Multion Browser Window with provided fields.\n",
              "tools.multion.create_session.CreateSessionSchema\n",
              "Input for CreateSessionTool.\n",
              "tools.multion.create_session.MultionCreateSession\n",
              "Tool that creates a new Multion Browser Window with provided fields.\n",
              "tools.multion.update_session.MultionUpdateSession\n",
              "Tool that updates an existing Multion Browser Window with provided fields.\n",
              "tools.multion.update_session.UpdateSessionSchema\n",
              "Input for UpdateSessionTool.\n",
              "tools.nasa.tool.NasaAction\n",
              "Tool that queries the Atlassian Jira API.\n",
              "tools.nuclia.tool.NUASchema\n",
              "Input for Nuclia Understanding API.\n",
              "tools.nuclia.tool.NucliaUnderstandingAPI\n",
              "Tool to process files with the Nuclia Understanding API.\n",
              "tools.office365.base.O365BaseTool\n",
              "Base class for the Office 365 tools.\n",
              "tools.office365.create_draft_message.CreateDraftMessageSchema\n",
              "Input for SendMessageTool.\n",
              "tools.office365.create_draft_message.O365CreateDraftMessage\n",
              "Tool for creating a draft email in Office 365.\n",
              "tools.office365.events_search.O365SearchEvents\n",
              "Search calendar events in Office 365.\n",
              "tools.office365.events_search.SearchEventsInput\n",
              "Input for SearchEmails Tool.\n",
              "tools.office365.messages_search.O365SearchEmails\n",
              "Search email messages in Office 365.\n",
              "tools.office365.messages_search.SearchEmailsInput\n",
              "Input for SearchEmails Tool.\n",
              "tools.office365.send_event.O365SendEvent\n",
              "Tool for sending calendar events in Office 365.\n",
              "tools.office365.send_event.SendEventSchema\n",
              "Input for CreateEvent Tool.\n",
              "tools.office365.send_message.O365SendMessage\n",
              "Send an email in Office 365.\n",
              "tools.office365.send_message.SendMessageSchema\n",
              "Input for SendMessageTool.\n",
              "tools.openai_dalle_image_generation.tool.OpenAIDALLEImageGenerationTool\n",
              "Tool that generates an image using OpenAI DALLE.\n",
              "tools.openapi.utils.api_models.APIOperation\n",
              "A model for a single API operation.\n",
              "tools.openapi.utils.api_models.APIProperty\n",
              "A model for a property in the query, path, header, or cookie params.\n",
              "tools.openapi.utils.api_models.APIPropertyBase\n",
              "Base model for an API property.\n",
              "tools.openapi.utils.api_models.APIPropertyLocation(value)\n",
              "The location of the property.\n",
              "tools.openapi.utils.api_models.APIRequestBody\n",
              "A model for a request body.\n",
              "tools.openapi.utils.api_models.APIRequestBodyProperty\n",
              "A model for a request body property.\n",
              "tools.openweathermap.tool.OpenWeatherMapQueryRun\n",
              "Tool that queries the OpenWeatherMap API.\n",
              "tools.passio_nutrition_ai.tool.NutritionAI\n",
              "Tool that queries the Passio Nutrition AI API.\n",
              "tools.passio_nutrition_ai.tool.NutritionAIInputs\n",
              "Inputs to the Passio Nutrition AI tool.\n",
              "tools.playwright.base.BaseBrowserTool\n",
              "Base class for browser tools.\n",
              "tools.playwright.click.ClickTool\n",
              "Tool for clicking on an element with the given CSS selector.\n",
              "tools.playwright.click.ClickToolInput\n",
              "Input for ClickTool.\n",
              "tools.playwright.current_page.CurrentWebPageTool\n",
              "Tool for getting the URL of the current webpage.\n",
              "tools.playwright.extract_hyperlinks.ExtractHyperlinksTool\n",
              "Extract all hyperlinks on the page.\n",
              "tools.playwright.extract_hyperlinks.ExtractHyperlinksToolInput\n",
              "Input for ExtractHyperlinksTool.\n",
              "tools.playwright.extract_text.ExtractTextTool\n",
              "Tool for extracting all the text on the current webpage.\n",
              "tools.playwright.get_elements.GetElementsTool\n",
              "Tool for getting elements in the current web page matching a CSS selector.\n",
              "tools.playwright.get_elements.GetElementsToolInput\n",
              "Input for GetElementsTool.\n",
              "tools.playwright.navigate.NavigateTool\n",
              "Tool for navigating a browser to a URL.\n",
              "tools.playwright.navigate.NavigateToolInput\n",
              "Input for NavigateToolInput.\n",
              "tools.playwright.navigate_back.NavigateBackTool\n",
              "Navigate back to the previous page in the browser history.\n",
              "tools.plugin.AIPlugin\n",
              "AI Plugin Definition.\n",
              "tools.plugin.AIPluginTool\n",
              "Tool for getting the OpenAPI spec for an AI Plugin.\n",
              "tools.plugin.AIPluginToolSchema\n",
              "Schema for AIPluginTool.\n",
              "tools.plugin.ApiConfig\n",
              "API Configuration.\n",
              "tools.polygon.aggregates.PolygonAggregates\n",
              "Tool that gets aggregate bars (stock prices) over a given date range for a given ticker from Polygon.\n",
              "tools.polygon.aggregates.PolygonAggregatesSchema\n",
              "Input for PolygonAggregates.\n",
              "tools.polygon.financials.Inputs\n",
              "Inputs for Polygon's Financials API\n",
              "tools.polygon.financials.PolygonFinancials\n",
              "Tool that gets the financials of a ticker from Polygon\n",
              "tools.polygon.last_quote.Inputs\n",
              "Inputs for Polygon's Last Quote API\n",
              "tools.polygon.last_quote.PolygonLastQuote\n",
              "Tool that gets the last quote of a ticker from Polygon\n",
              "tools.polygon.ticker_news.Inputs\n",
              "Inputs for Polygon's Ticker News API\n",
              "tools.polygon.ticker_news.PolygonTickerNews\n",
              "Tool that gets the latest news for a given ticker from Polygon\n",
              "tools.powerbi.tool.InfoPowerBITool\n",
              "Tool for getting metadata about a PowerBI Dataset.\n",
              "tools.powerbi.tool.ListPowerBITool\n",
              "Tool for getting tables names.\n",
              "tools.powerbi.tool.QueryPowerBITool\n",
              "Tool for querying a Power BI Dataset.\n",
              "tools.pubmed.tool.PubmedQueryRun\n",
              "Tool that searches the PubMed API.\n",
              "tools.reddit_search.tool.RedditSearchRun\n",
              "Tool that queries for posts on a subreddit.\n",
              "tools.reddit_search.tool.RedditSearchSchema\n",
              "Input for Reddit search.\n",
              "tools.requests.tool.BaseRequestsTool\n",
              "Base class for requests tools.\n",
              "tools.requests.tool.RequestsDeleteTool\n",
              "Tool for making a DELETE request to an API endpoint.\n",
              "tools.requests.tool.RequestsGetTool\n",
              "Tool for making a GET request to an API endpoint.\n",
              "tools.requests.tool.RequestsPatchTool\n",
              "Tool for making a PATCH request to an API endpoint.\n",
              "tools.requests.tool.RequestsPostTool\n",
              "Tool for making a POST request to an API endpoint.\n",
              "tools.requests.tool.RequestsPutTool\n",
              "Tool for making a PUT request to an API endpoint.\n",
              "tools.scenexplain.tool.SceneXplainInput\n",
              "Input for SceneXplain.\n",
              "tools.scenexplain.tool.SceneXplainTool\n",
              "Tool that explains images.\n",
              "tools.searchapi.tool.SearchAPIResults\n",
              "Tool that queries the SearchApi.io search API and returns JSON.\n",
              "tools.searchapi.tool.SearchAPIRun\n",
              "Tool that queries the SearchApi.io search API.\n",
              "tools.searx_search.tool.SearxSearchResults\n",
              "Tool that queries a Searx instance and gets back json.\n",
              "tools.searx_search.tool.SearxSearchRun\n",
              "Tool that queries a Searx instance.\n",
              "tools.semanticscholar.tool.SemanticScholarQueryRun\n",
              "Tool that searches the semanticscholar API.\n",
              "tools.semanticscholar.tool.SemantscholarInput\n",
              "Input for the SemanticScholar tool.\n",
              "tools.shell.tool.ShellInput\n",
              "Commands for the Bash Shell tool.\n",
              "tools.shell.tool.ShellTool\n",
              "Tool to run shell commands.\n",
              "tools.slack.base.SlackBaseTool\n",
              "Base class for Slack tools.\n",
              "tools.slack.get_channel.SlackGetChannel\n",
              "Tool that gets Slack channel information.\n",
              "tools.slack.get_message.SlackGetMessage\n",
              "Tool that gets Slack messages.\n",
              "tools.slack.get_message.SlackGetMessageSchema\n",
              "Input schema for SlackGetMessages.\n",
              "tools.slack.schedule_message.ScheduleMessageSchema\n",
              "Input for ScheduleMessageTool.\n",
              "tools.slack.schedule_message.SlackScheduleMessage\n",
              "Tool for scheduling a message in Slack.\n",
              "tools.slack.send_message.SendMessageSchema\n",
              "Input for SendMessageTool.\n",
              "tools.slack.send_message.SlackSendMessage\n",
              "Tool for sending a message in Slack.\n",
              "tools.sleep.tool.SleepInput\n",
              "Input for CopyFileTool.\n",
              "tools.sleep.tool.SleepTool\n",
              "Tool that adds the capability to sleep.\n",
              "tools.spark_sql.tool.BaseSparkSQLTool\n",
              "Base tool for interacting with Spark SQL.\n",
              "tools.spark_sql.tool.InfoSparkSQLTool\n",
              "Tool for getting metadata about a Spark SQL.\n",
              "tools.spark_sql.tool.ListSparkSQLTool\n",
              "Tool for getting tables names.\n",
              "tools.spark_sql.tool.QueryCheckerTool\n",
              "Use an LLM to check if a query is correct.\n",
              "tools.spark_sql.tool.QuerySparkSQLTool\n",
              "Tool for querying a Spark SQL.\n",
              "tools.sql_database.tool.BaseSQLDatabaseTool\n",
              "Base tool for interacting with a SQL database.\n",
              "tools.sql_database.tool.InfoSQLDatabaseTool\n",
              "Tool for getting metadata about a SQL database.\n",
              "tools.sql_database.tool.ListSQLDatabaseTool\n",
              "Tool for getting tables names.\n",
              "tools.sql_database.tool.QuerySQLCheckerTool\n",
              "Use an LLM to check if a query is correct.\n",
              "tools.sql_database.tool.QuerySQLDataBaseTool\n",
              "Tool for querying a SQL database.\n",
              "tools.stackexchange.tool.StackExchangeTool\n",
              "Tool that uses StackExchange\n",
              "tools.steam.tool.SteamWebAPIQueryRun\n",
              "Tool that searches the Steam Web API.\n",
              "tools.steamship_image_generation.tool.ModelName(value)\n",
              "Supported Image Models for generation.\n",
              "tools.steamship_image_generation.tool.SteamshipImageGenerationTool\n",
              "Tool used to generate images from a text-prompt.\n",
              "tools.tavily_search.tool.TavilyAnswer\n",
              "Tool that queries the Tavily Search API and gets back an answer.\n",
              "tools.tavily_search.tool.TavilyInput\n",
              "Input for the Tavily tool.\n",
              "tools.tavily_search.tool.TavilySearchResults\n",
              "Tool that queries the Tavily Search API and gets back json.\n",
              "tools.vectorstore.tool.BaseVectorStoreTool\n",
              "Base class for tools that use a VectorStore.\n",
              "tools.vectorstore.tool.VectorStoreQATool\n",
              "Tool for the VectorDBQA chain.\n",
              "tools.vectorstore.tool.VectorStoreQAWithSourcesTool\n",
              "Tool for the VectorDBQAWithSources chain.\n",
              "tools.wikidata.tool.WikidataQueryRun\n",
              "Tool that searches the Wikidata API.\n",
              "tools.wikipedia.tool.WikipediaQueryRun\n",
              "Tool that searches the Wikipedia API.\n",
              "tools.wolfram_alpha.tool.WolframAlphaQueryRun\n",
              "Tool that queries using the Wolfram Alpha SDK.\n",
              "tools.yahoo_finance_news.YahooFinanceNewsTool\n",
              "Tool that searches financial news on Yahoo Finance.\n",
              "tools.you.tool.YouInput\n",
              "Input schema for the you.com tool.\n",
              "tools.you.tool.YouSearchTool\n",
              "Tool that searches the you.com API.\n",
              "tools.youtube.search.YouTubeSearchTool\n",
              "Tool that queries YouTube.\n",
              "tools.zapier.tool.ZapierNLAListActions\n",
              "Returns a list of all exposed (enabled) actions associated with current user (associated with the set api_key).\n",
              "tools.zapier.tool.ZapierNLARunAction\n",
              "Executes an action that is identified by action_id, must be exposed\n",
              "Functions¶\n",
              "tools.ainetwork.utils.authenticate([network])\n",
              "Authenticate using the AIN Blockchain\n",
              "tools.amadeus.utils.authenticate()\n",
              "Authenticate using the Amadeus API\n",
              "tools.azure_ai_services.utils.detect_file_src_type(...)\n",
              "Detect if the file is local or remote.\n",
              "tools.azure_ai_services.utils.download_audio_from_url(...)\n",
              "Download audio from url to local.\n",
              "tools.azure_cognitive_services.utils.detect_file_src_type(...)\n",
              "Detect if the file is local or remote.\n",
              "tools.azure_cognitive_services.utils.download_audio_from_url(...)\n",
              "Download audio from url to local.\n",
              "tools.bearly.tool.file_to_base64(path)\n",
              "Convert a file to base64.\n",
              "tools.bearly.tool.head_file(path, n)\n",
              "Get the first n lines of a file.\n",
              "tools.bearly.tool.strip_markdown_code(md_string)\n",
              "Strip markdown code from a string.\n",
              "tools.ddg_search.tool.DuckDuckGoSearchTool(...)\n",
              "Deprecated.\n",
              "tools.e2b_data_analysis.tool.add_last_line_print(code)\n",
              "Add print statement to the last line if it's missing.\n",
              "tools.e2b_data_analysis.unparse.interleave(...)\n",
              "Call f on each item in seq, calling inter() in between.\n",
              "tools.e2b_data_analysis.unparse.roundtrip(...)\n",
              "Parse a file and pretty-print it to output.\n",
              "tools.file_management.utils.get_validated_relative_path(...)\n",
              "Resolve a relative path, raising an error if not within the root directory.\n",
              "tools.file_management.utils.is_relative_to(...)\n",
              "Check if path is relative to root.\n",
              "tools.gmail.utils.build_resource_service([...])\n",
              "Build a Gmail service.\n",
              "tools.gmail.utils.clean_email_body(body)\n",
              "Clean email body.\n",
              "tools.gmail.utils.get_gmail_credentials([...])\n",
              "Get credentials.\n",
              "tools.gmail.utils.import_google()\n",
              "Import google libraries.\n",
              "tools.gmail.utils.import_googleapiclient_resource_builder()\n",
              "Import googleapiclient.discovery.build function.\n",
              "tools.gmail.utils.import_installed_app_flow()\n",
              "Import InstalledAppFlow class.\n",
              "tools.interaction.tool.StdInInquireTool(...)\n",
              "Tool for asking the user for input.\n",
              "tools.office365.utils.authenticate()\n",
              "Authenticate using the Microsoft Graph API\n",
              "tools.office365.utils.clean_body(body)\n",
              "Clean body of a message or event.\n",
              "tools.playwright.base.lazy_import_playwright_browsers()\n",
              "Lazy import playwright browsers.\n",
              "tools.playwright.utils.aget_current_page(browser)\n",
              "Asynchronously get the current page of the browser.\n",
              "tools.playwright.utils.create_async_playwright_browser([...])\n",
              "Create an async playwright browser.\n",
              "tools.playwright.utils.create_sync_playwright_browser([...])\n",
              "Create a playwright browser.\n",
              "tools.playwright.utils.get_current_page(browser)\n",
              "Get the current page of the browser.\n",
              "tools.playwright.utils.run_async(coro)\n",
              "Run an async coroutine.\n",
              "tools.plugin.marshal_spec(txt)\n",
              "Convert the yaml or json serialized spec to a dict.\n",
              "tools.slack.utils.login()\n",
              "Authenticate using the Slack API.\n",
              "tools.steamship_image_generation.utils.make_image_public(...)\n",
              "Upload a block to a signed URL and return the public URL.\n",
              "langchain_community.utilities¶\n",
              "Utilities are the integrations with third-part systems and packages.\n",
              "Other LangChain classes use Utilities to interact with third-part systems\n",
              "and packages.\n",
              "Classes¶\n",
              "utilities.alpha_vantage.AlphaVantageAPIWrapper\n",
              "Wrapper for AlphaVantage API for Currency Exchange Rate.\n",
              "utilities.apify.ApifyWrapper\n",
              "Wrapper around Apify.\n",
              "utilities.arcee.ArceeDocument\n",
              "Arcee document.\n",
              "utilities.arcee.ArceeDocumentAdapter()\n",
              "Adapter for Arcee documents\n",
              "utilities.arcee.ArceeDocumentSource\n",
              "Source of an Arcee document.\n",
              "utilities.arcee.ArceeRoute(value)\n",
              "Routes available for the Arcee API as enumerator.\n",
              "utilities.arcee.ArceeWrapper(arcee_api_key, ...)\n",
              "Wrapper for Arcee API.\n",
              "utilities.arcee.DALMFilter\n",
              "Filters available for a DALM retrieval and generation.\n",
              "utilities.arcee.DALMFilterType(value)\n",
              "Filter types available for a DALM retrieval as enumerator.\n",
              "utilities.arxiv.ArxivAPIWrapper\n",
              "Wrapper around ArxivAPI.\n",
              "utilities.astradb.SetupMode(value)\n",
              "Setup mode for AstraDBEnvironment as enumerator.\n",
              "utilities.awslambda.LambdaWrapper\n",
              "Wrapper for AWS Lambda SDK.\n",
              "utilities.bibtex.BibtexparserWrapper\n",
              "Wrapper around bibtexparser.\n",
              "utilities.bing_search.BingSearchAPIWrapper\n",
              "Wrapper for Bing Search API.\n",
              "utilities.brave_search.BraveSearchWrapper\n",
              "Wrapper around the Brave search engine.\n",
              "utilities.clickup.CUList(folder_id, name[, ...])\n",
              "Component class for a list.\n",
              "utilities.clickup.ClickupAPIWrapper\n",
              "Wrapper for Clickup API.\n",
              "utilities.clickup.Component()\n",
              "Base class for all components.\n",
              "utilities.clickup.Member(id, username, ...)\n",
              "Component class for a member.\n",
              "utilities.clickup.Space(id, name, private, ...)\n",
              "Component class for a space.\n",
              "utilities.clickup.Task(id, name, ...)\n",
              "Class for a task.\n",
              "utilities.clickup.Team(id, name, members)\n",
              "Component class for a team.\n",
              "utilities.dalle_image_generator.DallEAPIWrapper\n",
              "Wrapper for OpenAI's DALL-E Image Generator.\n",
              "utilities.dataforseo_api_search.DataForSeoAPIWrapper\n",
              "Wrapper around the DataForSeo API.\n",
              "utilities.dria_index.DriaAPIWrapper(api_key)\n",
              "Wrapper around Dria API.\n",
              "utilities.duckduckgo_search.DuckDuckGoSearchAPIWrapper\n",
              "Wrapper for DuckDuckGo Search API.\n",
              "utilities.github.GitHubAPIWrapper\n",
              "Wrapper for GitHub API.\n",
              "utilities.gitlab.GitLabAPIWrapper\n",
              "Wrapper for GitLab API.\n",
              "utilities.golden_query.GoldenQueryAPIWrapper\n",
              "Wrapper for Golden.\n",
              "utilities.google_finance.GoogleFinanceAPIWrapper\n",
              "Wrapper for SerpApi's Google Finance API\n",
              "utilities.google_jobs.GoogleJobsAPIWrapper\n",
              "Wrapper for SerpApi's Google Scholar API\n",
              "utilities.google_lens.GoogleLensAPIWrapper\n",
              "Wrapper for SerpApi's Google Lens API\n",
              "utilities.google_places_api.GooglePlacesAPIWrapper\n",
              "Wrapper around Google Places API.\n",
              "utilities.google_scholar.GoogleScholarAPIWrapper\n",
              "Wrapper for Google Scholar API\n",
              "utilities.google_search.GoogleSearchAPIWrapper\n",
              "Wrapper for Google Search API.\n",
              "utilities.google_serper.GoogleSerperAPIWrapper\n",
              "Wrapper around the Serper.dev Google Search API.\n",
              "utilities.google_trends.GoogleTrendsAPIWrapper\n",
              "Wrapper for SerpApi's Google Scholar API\n",
              "utilities.graphql.GraphQLAPIWrapper\n",
              "Wrapper around GraphQL API.\n",
              "utilities.infobip.InfobipAPIWrapper\n",
              "Wrapper for Infobip API for messaging.\n",
              "utilities.jira.JiraAPIWrapper\n",
              "Wrapper for Jira API.\n",
              "utilities.max_compute.MaxComputeAPIWrapper(client)\n",
              "Interface for querying Alibaba Cloud MaxCompute tables.\n",
              "utilities.merriam_webster.MerriamWebsterAPIWrapper\n",
              "Wrapper for Merriam-Webster.\n",
              "utilities.metaphor_search.MetaphorSearchAPIWrapper\n",
              "Wrapper for Metaphor Search API.\n",
              "utilities.nasa.NasaAPIWrapper\n",
              "Wrapper for NASA API.\n",
              "utilities.nvidia_riva.ASRInputType\n",
              "alias of AudioStream\n",
              "utilities.nvidia_riva.AudioStream([maxsize])\n",
              "A message containing streaming audio.\n",
              "utilities.nvidia_riva.NVIDIARivaASR\n",
              "alias of RivaASR\n",
              "utilities.nvidia_riva.NVIDIARivaStream\n",
              "alias of AudioStream\n",
              "utilities.nvidia_riva.NVIDIARivaTTS\n",
              "alias of RivaTTS\n",
              "utilities.nvidia_riva.RivaASR\n",
              "A runnable that performs Automatic Speech Recognition (ASR) using NVIDIA Riva.\n",
              "utilities.nvidia_riva.RivaAudioEncoding(value)\n",
              "An enum of the possible choices for Riva audio encoding.\n",
              "utilities.nvidia_riva.RivaAuthMixin\n",
              "Configuration for the authentication to a Riva service connection.\n",
              "utilities.nvidia_riva.RivaCommonConfigMixin\n",
              "A collection of common Riva settings.\n",
              "utilities.nvidia_riva.RivaTTS\n",
              "A runnable that performs Text-to-Speech (TTS) with NVIDIA Riva.\n",
              "utilities.nvidia_riva.SentinelT()\n",
              "An empty Sentinel type.\n",
              "utilities.openapi.HTTPVerb(value)\n",
              "Enumerator of the HTTP verbs.\n",
              "utilities.openapi.OpenAPISpec()\n",
              "OpenAPI Model that removes mis-formatted parts of the spec.\n",
              "utilities.openweathermap.OpenWeatherMapAPIWrapper\n",
              "Wrapper for OpenWeatherMap API using PyOWM.\n",
              "utilities.outline.OutlineAPIWrapper\n",
              "Wrapper around OutlineAPI.\n",
              "utilities.passio_nutrition_ai.ManagedPassioLifeAuth(...)\n",
              "Manages the token for the NutritionAI API.\n",
              "utilities.passio_nutrition_ai.NoDiskStorage()\n",
              "utilities.passio_nutrition_ai.NutritionAIAPI\n",
              "Wrapper for the Passio Nutrition AI API.\n",
              "utilities.pebblo.App\n",
              "Pebblo AI application.\n",
              "utilities.pebblo.Doc\n",
              "Pebblo document.\n",
              "utilities.pebblo.Framework\n",
              "Pebblo Framework instance.\n",
              "utilities.pebblo.Runtime\n",
              "Pebblo Runtime.\n",
              "utilities.polygon.PolygonAPIWrapper\n",
              "Wrapper for Polygon API.\n",
              "utilities.portkey.Portkey()\n",
              "Portkey configuration.\n",
              "utilities.powerbi.PowerBIDataset\n",
              "Create PowerBI engine from dataset ID and credential or token.\n",
              "utilities.pubmed.PubMedAPIWrapper\n",
              "Wrapper around PubMed API.\n",
              "utilities.python.PythonREPL\n",
              "Simulates a standalone Python REPL.\n",
              "utilities.reddit_search.RedditSearchAPIWrapper\n",
              "Wrapper for Reddit API\n",
              "utilities.redis.TokenEscaper([escape_chars_re])\n",
              "Escape punctuation within an input string.\n",
              "utilities.requests.GenericRequestsWrapper\n",
              "Lightweight wrapper around requests library.\n",
              "utilities.requests.JsonRequestsWrapper\n",
              "Lightweight wrapper around requests library, with async support.\n",
              "utilities.requests.Requests\n",
              "Wrapper around requests to handle auth and async.\n",
              "utilities.requests.RequestsWrapper\n",
              "alias of TextRequestsWrapper\n",
              "utilities.requests.TextRequestsWrapper\n",
              "Lightweight wrapper around requests library, with async support.\n",
              "utilities.scenexplain.SceneXplainAPIWrapper\n",
              "Wrapper for SceneXplain API.\n",
              "utilities.searchapi.SearchApiAPIWrapper\n",
              "Wrapper around SearchApi API.\n",
              "utilities.searx_search.SearxResults(data)\n",
              "Dict like wrapper around search api results.\n",
              "utilities.searx_search.SearxSearchWrapper\n",
              "Wrapper for Searx API.\n",
              "utilities.semanticscholar.SemanticScholarAPIWrapper\n",
              "Wrapper around semanticscholar.org API.\n",
              "utilities.serpapi.HiddenPrints()\n",
              "Context manager to hide prints.\n",
              "utilities.serpapi.SerpAPIWrapper\n",
              "Wrapper around SerpAPI.\n",
              "utilities.spark_sql.SparkSQL([...])\n",
              "SparkSQL is a utility class for interacting with Spark SQL.\n",
              "utilities.sql_database.SQLDatabase(engine[, ...])\n",
              "SQLAlchemy wrapper around a database.\n",
              "utilities.stackexchange.StackExchangeAPIWrapper\n",
              "Wrapper for Stack Exchange API.\n",
              "utilities.steam.SteamWebAPIWrapper\n",
              "Wrapper for Steam API.\n",
              "utilities.tavily_search.TavilySearchAPIWrapper\n",
              "Wrapper for Tavily Search API.\n",
              "utilities.tensorflow_datasets.TensorflowDatasets\n",
              "Access to the TensorFlow Datasets.\n",
              "utilities.twilio.TwilioAPIWrapper\n",
              "Messaging Client using Twilio.\n",
              "utilities.wikidata.WikidataAPIWrapper\n",
              "Wrapper around the Wikidata API.\n",
              "utilities.wikipedia.WikipediaAPIWrapper\n",
              "Wrapper around WikipediaAPI.\n",
              "utilities.wolfram_alpha.WolframAlphaAPIWrapper\n",
              "Wrapper for Wolfram Alpha.\n",
              "utilities.you.YouAPIOutput\n",
              "Output from you.com API.\n",
              "utilities.you.YouDocument\n",
              "Output of parsing one snippet.\n",
              "utilities.you.YouHit\n",
              "A single hit from you.com, which may contain multiple snippets\n",
              "utilities.you.YouHitMetadata\n",
              "Metadata on a single hit from you.com\n",
              "utilities.you.YouSearchAPIWrapper\n",
              "Wrapper for you.com Search API.\n",
              "utilities.zapier.ZapierNLAWrapper\n",
              "Wrapper for Zapier NLA.\n",
              "Functions¶\n",
              "utilities.anthropic.get_num_tokens_anthropic(text)\n",
              "Get the number of tokens in a string of text.\n",
              "utilities.anthropic.get_token_ids_anthropic(text)\n",
              "Get the token ids for a string of text.\n",
              "utilities.clickup.extract_dict_elements_from_component_fields(...)\n",
              "Extract elements from a dictionary.\n",
              "utilities.clickup.fetch_data(url, access_token)\n",
              "Fetch data from a URL.\n",
              "utilities.clickup.fetch_first_id(data, key)\n",
              "Fetch the first id from a dictionary.\n",
              "utilities.clickup.fetch_folder_id(space_id, ...)\n",
              "Fetch the folder id.\n",
              "utilities.clickup.fetch_list_id(space_id, ...)\n",
              "Fetch the list id.\n",
              "utilities.clickup.fetch_space_id(team_id, ...)\n",
              "Fetch the space id.\n",
              "utilities.clickup.fetch_team_id(access_token)\n",
              "Fetch the team id.\n",
              "utilities.clickup.load_query(query[, ...])\n",
              "Attempts to parse a JSON string and return the parsed object.\n",
              "utilities.clickup.parse_dict_through_component(...)\n",
              "Parse a dictionary by creating a component and then turning it back into a dictionary.\n",
              "utilities.opaqueprompts.desanitize(...)\n",
              "Restore the original sensitive data from the sanitized text.\n",
              "utilities.opaqueprompts.sanitize(input)\n",
              "Sanitize input string or dict of strings by replacing sensitive data with placeholders.\n",
              "utilities.passio_nutrition_ai.is_http_retryable(rsp)\n",
              "utilities.pebblo.get_full_path(path)\n",
              "Return an absolute local path for a local file/directory, for a network related path, return as is.\n",
              "utilities.pebblo.get_ip()\n",
              "Fetch local runtime ip address.\n",
              "utilities.pebblo.get_loader_full_path(loader)\n",
              "Return an absolute source path of source of loader based on the keys present in Document object from loader.\n",
              "utilities.pebblo.get_loader_type(loader)\n",
              "Return loader type among, file, dir or in-memory.\n",
              "utilities.pebblo.get_runtime()\n",
              "Fetch the current Framework and Runtime details.\n",
              "utilities.powerbi.fix_table_name(table)\n",
              "Add single quotes around table names that contain spaces.\n",
              "utilities.powerbi.json_to_md(json_contents)\n",
              "Converts a JSON object to a markdown table.\n",
              "utilities.redis.check_redis_module_exist(...)\n",
              "Check if the correct Redis modules are installed.\n",
              "utilities.redis.get_client(redis_url, **kwargs)\n",
              "Get a redis client from the connection url given.\n",
              "utilities.sql_database.truncate_word(...[, ...])\n",
              "Truncate a string to a certain number of words, based on the max string length.\n",
              "utilities.vertexai.create_retry_decorator(llm, *)\n",
              "Create a retry decorator for Vertex / Palm LLMs.\n",
              "utilities.vertexai.get_client_info([module])\n",
              "Return a custom user agent header.\n",
              "utilities.vertexai.init_vertexai([project, ...])\n",
              "Init Vertex AI.\n",
              "utilities.vertexai.load_image_from_gcs(path)\n",
              "Load an image from Google Cloud Storage.\n",
              "utilities.vertexai.raise_vertex_import_error([...])\n",
              "Raise ImportError related to Vertex SDK being not available.\n",
              "langchain_community.utils¶\n",
              "Utility functions for LangChain.\n",
              "Classes¶\n",
              "utils.ernie_functions.FunctionDescription\n",
              "Representation of a callable function to the Ernie API.\n",
              "utils.ernie_functions.ToolDescription\n",
              "Representation of a callable function to the Ernie API.\n",
              "Functions¶\n",
              "utils.ernie_functions.convert_pydantic_to_ernie_function(...)\n",
              "Convert a Pydantic model to a function description for the Ernie API.\n",
              "utils.ernie_functions.convert_pydantic_to_ernie_tool(...)\n",
              "Convert a Pydantic model to a function description for the Ernie API.\n",
              "utils.google.get_client_info([module])\n",
              "Return a custom user agent header.\n",
              "utils.math.cosine_similarity(X, Y)\n",
              "Row-wise cosine similarity between two equal-width matrices.\n",
              "utils.math.cosine_similarity_top_k(X, Y[, ...])\n",
              "Row-wise cosine similarity with optional top-k and score threshold filtering.\n",
              "utils.openai.is_openai_v1()\n",
              "Return whether OpenAI API is v1 or more.\n",
              "langchain_community.vectorstores¶\n",
              "Vector store stores embedded data and performs vector search.\n",
              "One of the most common ways to store and search over unstructured data is to\n",
              "embed it and store the resulting embedding vectors, and then query the store\n",
              "and retrieve the data that are ‘most similar’ to the embedded query.\n",
              "Class hierarchy:\n",
              "VectorStore --> <name>  # Examples: Annoy, FAISS, Milvus\n",
              "BaseRetriever --> VectorStoreRetriever --> <name>Retriever  # Example: VespaRetriever\n",
              "Main helpers:\n",
              "Embeddings, Document\n",
              "Classes¶\n",
              "vectorstores.alibabacloud_opensearch.AlibabaCloudOpenSearch(...)\n",
              "Alibaba Cloud OpenSearch vector store.\n",
              "vectorstores.alibabacloud_opensearch.AlibabaCloudOpenSearchSettings(...)\n",
              "Alibaba Cloud Opensearch` client configuration.\n",
              "vectorstores.analyticdb.AnalyticDB(...[, ...])\n",
              "AnalyticDB (distributed PostgreSQL) vector store.\n",
              "vectorstores.annoy.Annoy(embedding_function, ...)\n",
              "Annoy vector store.\n",
              "vectorstores.apache_doris.ApacheDoris(...[, ...])\n",
              "Apache Doris vector store.\n",
              "vectorstores.apache_doris.ApacheDorisSettings\n",
              "Apache Doris client configuration.\n",
              "vectorstores.astradb.AstraDB(*, embedding, ...)\n",
              "[Deprecated]\n",
              "vectorstores.atlas.AtlasDB(name[, ...])\n",
              "Atlas vector store.\n",
              "vectorstores.awadb.AwaDB([table_name, ...])\n",
              "AwaDB vector store.\n",
              "vectorstores.azure_cosmos_db.AzureCosmosDBVectorSearch(...)\n",
              "Azure Cosmos DB for MongoDB vCore vector store.\n",
              "vectorstores.azure_cosmos_db.CosmosDBSimilarityType(value)\n",
              "Cosmos DB Similarity Type as enumerator.\n",
              "vectorstores.azure_cosmos_db.CosmosDBVectorSearchType(value)\n",
              "Cosmos DB Vector Search Type as enumerator.\n",
              "vectorstores.azuresearch.AzureSearch(...[, ...])\n",
              "Azure Cognitive Search vector store.\n",
              "vectorstores.azuresearch.AzureSearchVectorStoreRetriever\n",
              "Retriever that uses Azure Cognitive Search.\n",
              "vectorstores.bageldb.Bagel([cluster_name, ...])\n",
              "BagelDB.ai vector store.\n",
              "vectorstores.baiducloud_vector_search.BESVectorStore(...)\n",
              "Baidu Elasticsearch vector store.\n",
              "vectorstores.baiduvectordb.BaiduVectorDB(...)\n",
              "Baidu VectorDB as a vector store.\n",
              "vectorstores.baiduvectordb.ConnectionParams(...)\n",
              "Baidu VectorDB Connection params.\n",
              "vectorstores.baiduvectordb.TableParams(dimension)\n",
              "Baidu VectorDB table params.\n",
              "vectorstores.bigquery_vector_search.BigQueryVectorSearch(...)\n",
              "Google Cloud BigQuery vector store.\n",
              "vectorstores.cassandra.Cassandra(embedding, ...)\n",
              "Wrapper around Apache Cassandra(R) for vector-store workloads.\n",
              "vectorstores.chroma.Chroma([...])\n",
              "ChromaDB vector store.\n",
              "vectorstores.clarifai.Clarifai([user_id, ...])\n",
              "Clarifai AI vector store.\n",
              "vectorstores.clickhouse.Clickhouse(embedding)\n",
              "ClickHouse VectorSearch vector store.\n",
              "vectorstores.clickhouse.ClickhouseSettings\n",
              "ClickHouse client configuration.\n",
              "vectorstores.couchbase.CouchbaseVectorStore(...)\n",
              "Couchbase Vector Store vector store.\n",
              "vectorstores.dashvector.DashVector(...)\n",
              "DashVector vector store.\n",
              "vectorstores.databricks_vector_search.DatabricksVectorSearch(...)\n",
              "Databricks Vector Search vector store.\n",
              "vectorstores.deeplake.DeepLake([...])\n",
              "Activeloop Deep Lake vector store.\n",
              "vectorstores.dingo.Dingo(embedding, text_key, *)\n",
              "Dingo vector store.\n",
              "vectorstores.docarray.base.DocArrayIndex(...)\n",
              "Base class for DocArray based vector stores.\n",
              "vectorstores.docarray.hnsw.DocArrayHnswSearch(...)\n",
              "HnswLib storage using DocArray package.\n",
              "vectorstores.docarray.in_memory.DocArrayInMemorySearch(...)\n",
              "In-memory DocArray storage for exact search.\n",
              "vectorstores.documentdb.DocumentDBSimilarityType(value)\n",
              "DocumentDB Similarity Type as enumerator.\n",
              "vectorstores.documentdb.DocumentDBVectorSearch(...)\n",
              "Amazon DocumentDB (with MongoDB compatibility) vector store.\n",
              "vectorstores.duckdb.DuckDB(*[, connection, ...])\n",
              "DuckDB vector store.\n",
              "vectorstores.ecloud_vector_search.EcloudESVectorStore(...)\n",
              "ecloud Elasticsearch vector store.\n",
              "vectorstores.elastic_vector_search.ElasticKnnSearch(...)\n",
              "[Deprecated] [DEPRECATED] Elasticsearch with k-nearest neighbor search (k-NN) vector store.\n",
              "vectorstores.elastic_vector_search.ElasticVectorSearch(...)\n",
              "[Deprecated] ElasticVectorSearch uses the brute force method of searching on vectors.\n",
              "vectorstores.elasticsearch.ApproxRetrievalStrategy([...])\n",
              "[Deprecated] Approximate retrieval strategy using the HNSW algorithm.\n",
              "vectorstores.elasticsearch.BaseRetrievalStrategy()\n",
              "Base class for Elasticsearch retrieval strategies.\n",
              "vectorstores.elasticsearch.ElasticsearchStore(...)\n",
              "[Deprecated] Elasticsearch vector store.\n",
              "vectorstores.elasticsearch.ExactRetrievalStrategy(...)\n",
              "[Deprecated] Exact retrieval strategy using the script_score query.\n",
              "vectorstores.elasticsearch.SparseRetrievalStrategy([...])\n",
              "[Deprecated] Sparse retrieval strategy using the text_expansion processor.\n",
              "vectorstores.epsilla.Epsilla(client, embeddings)\n",
              "Wrapper around Epsilla vector database.\n",
              "vectorstores.faiss.FAISS(embedding_function, ...)\n",
              "Meta Faiss vector store.\n",
              "vectorstores.hanavector.HanaDB(connection, ...)\n",
              "SAP HANA Cloud Vector Engine\n",
              "vectorstores.hippo.Hippo(embedding_function)\n",
              "Hippo vector store.\n",
              "vectorstores.hologres.Hologres(...[, ndims, ...])\n",
              "Hologres API vector store.\n",
              "vectorstores.infinispanvs.Infinispan(**kwargs)\n",
              "Helper class for Infinispan REST interface.\n",
              "vectorstores.infinispanvs.InfinispanVS([...])\n",
              "Infinispan VectorStore interface.\n",
              "vectorstores.inmemory.InMemoryVectorStore(...)\n",
              "In-memory implementation of VectorStore using a dictionary.\n",
              "vectorstores.jaguar.Jaguar(pod, store, ...)\n",
              "Jaguar API vector store.\n",
              "vectorstores.kdbai.KDBAI(table, embedding[, ...])\n",
              "KDB.AI vector store.\n",
              "vectorstores.kinetica.Dimension(value)\n",
              "Some default dimensions for known embeddings.\n",
              "vectorstores.kinetica.DistanceStrategy(value)\n",
              "Enumerator of the Distance strategies.\n",
              "vectorstores.kinetica.Kinetica(config, ...)\n",
              "Kinetica vector store.\n",
              "vectorstores.kinetica.KineticaSettings\n",
              "Kinetica client configuration.\n",
              "vectorstores.lancedb.LanceDB([connection, ...])\n",
              "LanceDB vector store.\n",
              "vectorstores.lantern.BaseEmbeddingStore()\n",
              "Base class for the Lantern embedding store.\n",
              "vectorstores.lantern.DistanceStrategy(value)\n",
              "Enumerator of the Distance strategies.\n",
              "vectorstores.lantern.Lantern(...[, ...])\n",
              "Postgres with the lantern extension as a vector store.\n",
              "vectorstores.lantern.QueryResult()\n",
              "Result from a query.\n",
              "vectorstores.llm_rails.LLMRails([...])\n",
              "Implementation of Vector Store using LLMRails.\n",
              "vectorstores.llm_rails.LLMRailsRetriever\n",
              "Retriever for LLMRails.\n",
              "vectorstores.marqo.Marqo(client, index_name)\n",
              "Marqo vector store.\n",
              "vectorstores.matching_engine.MatchingEngine(...)\n",
              "[Deprecated] Google Vertex AI Vector Search (previously Matching Engine) vector store.\n",
              "vectorstores.meilisearch.Meilisearch(embedding)\n",
              "Meilisearch vector store.\n",
              "vectorstores.milvus.Milvus(embedding_function)\n",
              "Milvus vector store.\n",
              "vectorstores.momento_vector_index.MomentoVectorIndex(...)\n",
              "Momento Vector Index (MVI) vector store.\n",
              "vectorstores.mongodb_atlas.MongoDBAtlasVectorSearch(...)\n",
              "[Deprecated] MongoDB Atlas Vector Search vector store.\n",
              "vectorstores.myscale.MyScale(embedding[, config])\n",
              "MyScale vector store.\n",
              "vectorstores.myscale.MyScaleSettings\n",
              "MyScale client configuration.\n",
              "vectorstores.myscale.MyScaleWithoutJSON(...)\n",
              "MyScale vector store without metadata column\n",
              "vectorstores.neo4j_vector.Neo4jVector(...[, ...])\n",
              "Neo4j vector index.\n",
              "vectorstores.neo4j_vector.SearchType(value)\n",
              "Enumerator of the Distance strategies.\n",
              "vectorstores.nucliadb.NucliaDB(...[, ...])\n",
              "NucliaDB vector store.\n",
              "vectorstores.opensearch_vector_search.OpenSearchVectorSearch(...)\n",
              "Amazon OpenSearch Vector Engine vector store.\n",
              "vectorstores.pathway.PathwayVectorClient([...])\n",
              "VectorStore connecting to Pathway Vector Store.\n",
              "vectorstores.pgembedding.BaseModel(**kwargs)\n",
              "Base model for all SQL stores.\n",
              "vectorstores.pgembedding.CollectionStore(...)\n",
              "Collection store.\n",
              "vectorstores.pgembedding.EmbeddingStore(**kwargs)\n",
              "Embedding store.\n",
              "vectorstores.pgembedding.PGEmbedding(...[, ...])\n",
              "Postgres with the pg_embedding extension as a vector store.\n",
              "vectorstores.pgembedding.QueryResult()\n",
              "Result from a query.\n",
              "vectorstores.pgvecto_rs.PGVecto_rs(...[, ...])\n",
              "VectorStore backed by pgvecto_rs.\n",
              "vectorstores.pgvector.BaseModel(**kwargs)\n",
              "Base model for the SQL stores.\n",
              "vectorstores.pgvector.DistanceStrategy(value)\n",
              "Enumerator of the Distance strategies.\n",
              "vectorstores.pgvector.PGVector(...[, ...])\n",
              "[Deprecated] Postgres/PGVector vector store.\n",
              "vectorstores.pinecone.Pinecone(index, ...[, ...])\n",
              "[Deprecated] Pinecone vector store.\n",
              "vectorstores.qdrant.Qdrant(client, ...[, ...])\n",
              "Qdrant vector store.\n",
              "vectorstores.qdrant.QdrantException\n",
              "Qdrant related exceptions.\n",
              "vectorstores.redis.base.Redis(redis_url, ...)\n",
              "Redis vector database.\n",
              "vectorstores.redis.base.RedisVectorStoreRetriever\n",
              "Retriever for Redis VectorStore.\n",
              "vectorstores.redis.filters.RedisFilter()\n",
              "Collection of RedisFilterFields.\n",
              "vectorstores.redis.filters.RedisFilterExpression([...])\n",
              "Logical expression of RedisFilterFields.\n",
              "vectorstores.redis.filters.RedisFilterField(field)\n",
              "Base class for RedisFilterFields.\n",
              "vectorstores.redis.filters.RedisFilterOperator(value)\n",
              "RedisFilterOperator enumerator is used to create RedisFilterExpressions.\n",
              "vectorstores.redis.filters.RedisNum(field)\n",
              "RedisFilterField representing a numeric field in a Redis index.\n",
              "vectorstores.redis.filters.RedisTag(field)\n",
              "RedisFilterField representing a tag in a Redis index.\n",
              "vectorstores.redis.filters.RedisText(field)\n",
              "RedisFilterField representing a text field in a Redis index.\n",
              "vectorstores.redis.schema.FlatVectorField\n",
              "Schema for flat vector fields in Redis.\n",
              "vectorstores.redis.schema.HNSWVectorField\n",
              "Schema for HNSW vector fields in Redis.\n",
              "vectorstores.redis.schema.NumericFieldSchema\n",
              "Schema for numeric fields in Redis.\n",
              "vectorstores.redis.schema.RedisDistanceMetric(value)\n",
              "Distance metrics for Redis vector fields.\n",
              "vectorstores.redis.schema.RedisField\n",
              "Base class for Redis fields.\n",
              "vectorstores.redis.schema.RedisModel\n",
              "Schema for Redis index.\n",
              "vectorstores.redis.schema.RedisVectorField\n",
              "Base class for Redis vector fields.\n",
              "vectorstores.redis.schema.TagFieldSchema\n",
              "Schema for tag fields in Redis.\n",
              "vectorstores.redis.schema.TextFieldSchema\n",
              "Schema for text fields in Redis.\n",
              "vectorstores.rocksetdb.Rockset(client, ...)\n",
              "Rockset vector store.\n",
              "vectorstores.scann.ScaNN(embedding, index, ...)\n",
              "ScaNN vector store.\n",
              "vectorstores.semadb.SemaDB(collection_name, ...)\n",
              "SemaDB vector store.\n",
              "vectorstores.singlestoredb.SingleStoreDB(...)\n",
              "SingleStore DB vector store.\n",
              "vectorstores.sklearn.BaseSerializer(persist_path)\n",
              "Base class for serializing data.\n",
              "vectorstores.sklearn.BsonSerializer(persist_path)\n",
              "Serialize data in Binary JSON using the bson python package.\n",
              "vectorstores.sklearn.JsonSerializer(persist_path)\n",
              "Serialize data in JSON using the json package from python standard library.\n",
              "vectorstores.sklearn.ParquetSerializer(...)\n",
              "Serialize data in Apache Parquet format using the pyarrow package.\n",
              "vectorstores.sklearn.SKLearnVectorStore(...)\n",
              "Simple in-memory vector store based on the scikit-learn library NearestNeighbors.\n",
              "vectorstores.sklearn.SKLearnVectorStoreException\n",
              "Exception raised by SKLearnVectorStore.\n",
              "vectorstores.sqlitevss.SQLiteVSS(table, ...)\n",
              "SQLite with VSS extension as a vector database.\n",
              "vectorstores.starrocks.StarRocks(embedding)\n",
              "StarRocks vector store.\n",
              "vectorstores.starrocks.StarRocksSettings\n",
              "StarRocks client configuration.\n",
              "vectorstores.supabase.SupabaseVectorStore(...)\n",
              "Supabase Postgres vector store.\n",
              "vectorstores.surrealdb.SurrealDBStore(...)\n",
              "SurrealDB as Vector Store.\n",
              "vectorstores.tair.Tair(embedding_function, ...)\n",
              "Tair vector store.\n",
              "vectorstores.tencentvectordb.ConnectionParams(...)\n",
              "Tencent vector DB Connection params.\n",
              "vectorstores.tencentvectordb.IndexParams(...)\n",
              "Tencent vector DB Index params.\n",
              "vectorstores.tencentvectordb.MetaField\n",
              "MetaData Field for Tencent vector DB.\n",
              "vectorstores.tencentvectordb.TencentVectorDB(...)\n",
              "Tencent VectorDB as a vector store.\n",
              "vectorstores.thirdai_neuraldb.NeuralDBVectorStore(db)\n",
              "Vectorstore that uses ThirdAI's NeuralDB.\n",
              "vectorstores.tidb_vector.TiDBVectorStore(...)\n",
              "TiDB Vector Store.\n",
              "vectorstores.tigris.Tigris(client, ...)\n",
              "Tigris vector store.\n",
              "vectorstores.tiledb.TileDB(embedding, ...[, ...])\n",
              "TileDB vector store.\n",
              "vectorstores.timescalevector.TimescaleVector(...)\n",
              "Timescale Postgres vector store\n",
              "vectorstores.typesense.Typesense(...[, ...])\n",
              "Typesense vector store.\n",
              "vectorstores.usearch.USearch(embedding, ...)\n",
              "USearch vector store.\n",
              "vectorstores.utils.DistanceStrategy(value)\n",
              "Enumerator of the Distance strategies for calculating distances between vectors.\n",
              "vectorstores.vald.Vald(embedding[, host, ...])\n",
              "Vald vector database.\n",
              "vectorstores.vdms.VDMS(client, *[, ...])\n",
              "Intel Lab's VDMS for vector-store workloads.\n",
              "vectorstores.vearch.Vearch(embedding_function)\n",
              "Initialize vearch vector store flag 1 for cluster,0 for standalone\n",
              "vectorstores.vectara.MMRConfig([is_enabled, ...])\n",
              "Configuration for Maximal Marginal Relevance (MMR) search.\n",
              "vectorstores.vectara.SummaryConfig([...])\n",
              "Configuration for summary generation.\n",
              "vectorstores.vectara.Vectara([...])\n",
              "Vectara API vector store.\n",
              "vectorstores.vectara.VectaraQueryConfig(k, ...)\n",
              "Configuration for Vectara query.\n",
              "vectorstores.vectara.VectaraRetriever\n",
              "Retriever for Vectara.\n",
              "vectorstores.vespa.VespaStore(app[, ...])\n",
              "Vespa vector store.\n",
              "vectorstores.vikingdb.VikingDB(...[, ...])\n",
              "vikingdb as a vector store\n",
              "vectorstores.vikingdb.VikingDBConfig([host, ...])\n",
              "vikingdb connection config\n",
              "vectorstores.weaviate.Weaviate(client, ...)\n",
              "Weaviate vector store.\n",
              "vectorstores.xata.XataVectorStore(api_key, ...)\n",
              "Xata vector store.\n",
              "vectorstores.yellowbrick.Yellowbrick(...)\n",
              "Yellowbrick as a vector database.\n",
              "vectorstores.zep.CollectionConfig(name, ...)\n",
              "Configuration for a Zep Collection.\n",
              "vectorstores.zep.ZepVectorStore(...[, ...])\n",
              "Zep vector store.\n",
              "vectorstores.zilliz.Zilliz(embedding_function)\n",
              "Zilliz vector store.\n",
              "Functions¶\n",
              "vectorstores.alibabacloud_opensearch.create_metadata(fields)\n",
              "Create metadata from fields.\n",
              "vectorstores.annoy.dependable_annoy_import()\n",
              "Import annoy if available, otherwise raise error.\n",
              "vectorstores.clickhouse.has_mul_sub_str(s, *args)\n",
              "Check if a string contains multiple substrings.\n",
              "vectorstores.faiss.dependable_faiss_import([...])\n",
              "Import faiss if available, otherwise raise error.\n",
              "vectorstores.lantern.get_embedding_store(...)\n",
              "Get the embedding store class.\n",
              "vectorstores.myscale.has_mul_sub_str(s, *args)\n",
              "Check if a string contains multiple substrings.\n",
              "vectorstores.neo4j_vector.check_if_not_null(...)\n",
              "Check if the values are not None or empty string\n",
              "vectorstores.neo4j_vector.collect_params(...)\n",
              "Transform the input data into the desired format.\n",
              "vectorstores.neo4j_vector.combine_queries(...)\n",
              "Combine multiple queries with an operator.\n",
              "vectorstores.neo4j_vector.construct_metadata_filter(filter)\n",
              "Construct a metadata filter.\n",
              "vectorstores.neo4j_vector.dict_to_yaml_str(...)\n",
              "Convert a dictionary to a YAML-like string without using external libraries.\n",
              "vectorstores.neo4j_vector.remove_lucene_chars(text)\n",
              "Remove Lucene special characters\n",
              "vectorstores.neo4j_vector.sort_by_index_name(...)\n",
              "Sort first element to match the index_name if exists\n",
              "vectorstores.qdrant.sync_call_fallback(method)\n",
              "Decorator to call the synchronous method of the class if the async method is not implemented.\n",
              "vectorstores.redis.base.check_index_exists(...)\n",
              "Check if Redis index exists.\n",
              "vectorstores.redis.filters.check_operator_misuse(func)\n",
              "Decorator to check for misuse of equality operators.\n",
              "vectorstores.redis.schema.read_schema(...)\n",
              "Read in the index schema from a dict or yaml file.\n",
              "vectorstores.scann.dependable_scann_import()\n",
              "Import scann if available, otherwise raise error.\n",
              "vectorstores.scann.normalize(x)\n",
              "Normalize vectors to unit length.\n",
              "vectorstores.starrocks.debug_output(s)\n",
              "Print a debug message if DEBUG is True.\n",
              "vectorstores.starrocks.get_named_result(...)\n",
              "Get a named result from a query.\n",
              "vectorstores.starrocks.has_mul_sub_str(s, *args)\n",
              "Check if a string has multiple substrings.\n",
              "vectorstores.tencentvectordb.translate_filter(...)\n",
              "vectorstores.tiledb.dependable_tiledb_import()\n",
              "Import tiledb-vector-search if available, otherwise raise error.\n",
              "vectorstores.tiledb.get_documents_array_uri(uri)\n",
              "Get the URI of the documents array.\n",
              "vectorstores.tiledb.get_documents_array_uri_from_group(group)\n",
              "Get the URI of the documents array from group.\n",
              "vectorstores.tiledb.get_vector_index_uri(uri)\n",
              "Get the URI of the vector index.\n",
              "vectorstores.tiledb.get_vector_index_uri_from_group(group)\n",
              "Get the URI of the vector index.\n",
              "vectorstores.usearch.dependable_usearch_import()\n",
              "Import usearch if available, otherwise raise error.\n",
              "vectorstores.utils.filter_complex_metadata(...)\n",
              "Filter out metadata types that are not supported for a vector store.\n",
              "vectorstores.utils.maximal_marginal_relevance(...)\n",
              "Calculate maximal marginal relevance.\n",
              "vectorstores.vdms.VDMS_Client([host, port])\n",
              "VDMS client for the VDMS server.\n",
              "vectorstores.vdms.embedding2bytes(embedding)\n",
              "Convert embedding to bytes.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[834]==================</br><pre><code class=\"python\">langchain.smith.evaluation.config.RunEvalConfig¶\n",
              "class langchain.smith.evaluation.config.RunEvalConfig[source]¶\n",
              "Bases: BaseModel\n",
              "Configuration for a run evaluation.\n",
              "Parameters\n",
              "evaluators (List[Union[EvaluatorType, EvalConfig, RunEvaluator, Callable]]) – Configurations for which evaluators to apply to the dataset run.\n",
              "Each can be the string of an EvaluatorType, such\n",
              "as EvaluatorType.QA, the evaluator type string (“qa”), or a configuration for a\n",
              "given evaluator (e.g., RunEvalConfig.QA).\n",
              "custom_evaluators (Optional[List[Union[RunEvaluator, StringEvaluator]]]) – Custom evaluators to apply to the dataset run.\n",
              "reference_key (Optional[str]) – The key in the dataset run to use as the reference string.\n",
              "If not provided, it will be inferred automatically.\n",
              "prediction_key (Optional[str]) – The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "input_key (Optional[str]) – The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "eval_llm (Optional[BaseLanguageModel]) – The language model to pass to any evaluators that use a language model.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param batch_evaluators: Optional[List[Callable[[Sequence[Run], Optional[Sequence[Example]]], Union[EvaluationResult, EvaluationResults, dict]]]] = None¶\n",
              "Evaluators that run on an aggregate/batch level.\n",
              "These generate 1 or more metrics that are assigned to the full test run.\n",
              "As a result, they are not associated with individual traces.\n",
              "param custom_evaluators: Optional[List[Union[Callable[[Run, Optional[Example]], Union[EvaluationResult, EvaluationResults, dict]], RunEvaluator, StringEvaluator]]] = None¶\n",
              "Custom evaluators to apply to the dataset run.\n",
              "param eval_llm: Optional[BaseLanguageModel] = None¶\n",
              "The language model to pass to any evaluators that require one.\n",
              "param evaluators: List[Union[EvaluatorType, str, EvalConfig, Callable[[Run, Optional[Example]], Union[EvaluationResult, EvaluationResults, dict]], RunEvaluator, StringEvaluator]] [Optional]¶\n",
              "Configurations for which evaluators to apply to the dataset run.\n",
              "Each can be the string of an\n",
              "EvaluatorType, such\n",
              "as EvaluatorType.QA, the evaluator type string (“qa”), or a configuration for a\n",
              "given evaluator\n",
              "(e.g.,\n",
              "RunEvalConfig.QA).\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "class CoTQA[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a context-based QA evaluator.\n",
              "Parameters\n",
              "prompt (Optional[BasePromptTemplate]) – The prompt template to use for generating the question.\n",
              "llm (Optional[BaseLanguageModel]) – The language model to use for the evaluation chain.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.CONTEXT_QA¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param prompt: Optional[BasePromptTemplate] = None¶\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class ContextQA[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a context-based QA evaluator.\n",
              "Parameters\n",
              "prompt (Optional[BasePromptTemplate]) – The prompt template to use for generating the question.\n",
              "llm (Optional[BaseLanguageModel]) – The language model to use for the evaluation chain.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.CONTEXT_QA¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param prompt: Optional[BasePromptTemplate] = None¶\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class Criteria[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a reference-free criteria evaluator.\n",
              "Parameters\n",
              "criteria (Optional[CRITERIA_TYPE]) – The criteria to evaluate.\n",
              "llm (Optional[BaseLanguageModel]) – The language model to use for the evaluation chain.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param criteria: Optional[Union[Mapping[str, str], Criteria, ConstitutionalPrinciple]] = None¶\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.CRITERIA¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class EmbeddingDistance[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for an embedding distance evaluator.\n",
              "Parameters\n",
              "embeddings (Optional[Embeddings]) – The embeddings to use for computing the distance.\n",
              "distance_metric (Optional[EmbeddingDistanceEnum]) – The distance metric to use for computing the distance.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param distance_metric: Optional[EmbeddingDistance] = None¶\n",
              "param embeddings: Optional[Embeddings] = None¶\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.EMBEDDING_DISTANCE¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class ExactMatch[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for an exact match string evaluator.\n",
              "Parameters\n",
              "ignore_case (bool) – Whether to ignore case when comparing strings.\n",
              "ignore_punctuation (bool) – Whether to ignore punctuation when comparing strings.\n",
              "ignore_numbers (bool) – Whether to ignore numbers when comparing strings.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.EXACT_MATCH¶\n",
              "param ignore_case: bool = False¶\n",
              "param ignore_numbers: bool = False¶\n",
              "param ignore_punctuation: bool = False¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class JsonEqualityEvaluator[source]¶\n",
              "Bases: EvalConfig\n",
              "Configuration for a json equality evaluator.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.JSON_EQUALITY¶\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class JsonValidity[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a json validity evaluator.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.JSON_VALIDITY¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class LabeledCriteria[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a labeled (with references) criteria evaluator.\n",
              "Parameters\n",
              "criteria (Optional[CRITERIA_TYPE]) – The criteria to evaluate.\n",
              "llm (Optional[BaseLanguageModel]) – The language model to use for the evaluation chain.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param criteria: Optional[Union[Mapping[str, str], Criteria, ConstitutionalPrinciple]] = None¶\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.LABELED_CRITERIA¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class LabeledScoreString[source]¶\n",
              "Bases: ScoreString\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param criteria: Optional[Union[Mapping[str, str], Criteria, ConstitutionalPrinciple]] = None¶\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.LABELED_SCORE_STRING¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param normalize_by: Optional[float] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param prompt: Optional[BasePromptTemplate] = None¶\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class QA[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a QA evaluator.\n",
              "Parameters\n",
              "prompt (Optional[BasePromptTemplate]) – The prompt template to use for generating the question.\n",
              "llm (Optional[BaseLanguageModel]) – The language model to use for the evaluation chain.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.QA¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param prompt: Optional[BasePromptTemplate] = None¶\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class RegexMatch[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a regex match string evaluator.\n",
              "Parameters\n",
              "flags (int) – The flags to pass to the regex. Example: re.IGNORECASE.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.REGEX_MATCH¶\n",
              "param flags: int = 0¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class ScoreString[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a score string evaluator.\n",
              "This is like the criteria evaluator but it is configured by\n",
              "default to return a score on the scale from 1-10.\n",
              "It is recommended to normalize these scores\n",
              "by setting normalize_by to 10.\n",
              "Parameters\n",
              "criteria (Optional[CRITERIA_TYPE]) – The criteria to evaluate.\n",
              "llm (Optional[BaseLanguageModel]) – The language model to use for the evaluation chain.\n",
              "normalize_by (Optional[int] = None) – If you want to normalize the score, the denominator to use.\n",
              "If not provided, the score will be between 1 and 10 (by default).\n",
              "prompt (Optional[BasePromptTemplate]) – \n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param criteria: Optional[Union[Mapping[str, str], Criteria, ConstitutionalPrinciple]] = None¶\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.SCORE_STRING¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param llm: Optional[BaseLanguageModel] = None¶\n",
              "param normalize_by: Optional[float] = None¶\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param prompt: Optional[BasePromptTemplate] = None¶\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "class StringDistance[source]¶\n",
              "Bases: SingleKeyEvalConfig\n",
              "Configuration for a string distance evaluator.\n",
              "Parameters\n",
              "distance (Optional[StringDistanceEnum]) – The string distance metric to use.\n",
              "Create a new model by parsing and validating input data from keyword arguments.\n",
              "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
              "param distance: Optional[StringDistance] = None¶\n",
              "The string distance metric to use.\n",
              "damerau_levenshtein: The Damerau-Levenshtein distance.\n",
              "levenshtein: The Levenshtein distance.\n",
              "jaro: The Jaro distance.\n",
              "jaro_winkler: The Jaro-Winkler distance.\n",
              "param evaluator_type: EvaluatorType = EvaluatorType.STRING_DISTANCE¶\n",
              "param input_key: Optional[str] = None¶\n",
              "The key from the traced run’s inputs dictionary to use to represent the\n",
              "input. If not provided, it will be inferred automatically.\n",
              "param normalize_score: bool = True¶\n",
              "Whether to normalize the distance to between 0 and 1.\n",
              "Applies only to the Levenshtein and Damerau-Levenshtein distances.\n",
              "param prediction_key: Optional[str] = None¶\n",
              "The key from the traced run’s outputs dictionary to use to\n",
              "represent the prediction. If not provided, it will be inferred\n",
              "automatically.\n",
              "param reference_key: Optional[str] = None¶\n",
              "The key in the dataset run to use as the reference string.\n",
              "If not provided, we will attempt to infer automatically.\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "get_kwargs() → Dict[str, Any]¶\n",
              "Get the keyword arguments for the load_evaluator call.\n",
              "Returns\n",
              "The keyword arguments for the load_evaluator call.\n",
              "Return type\n",
              "Dict[str, Any]\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\n",
              "Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
              "Default values are respected, but no other validation is performed.\n",
              "Behaves as if Config.extra = ‘allow’ was set since it adds all passed values\n",
              "Parameters\n",
              "_fields_set (Optional[SetStr]) – \n",
              "values (Any) – \n",
              "Return type\n",
              "Model\n",
              "copy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\n",
              "Duplicate a model, optionally choose which fields to include, exclude and change.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\n",
              "update (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\n",
              "the new model: you should trust this data\n",
              "deep (bool) – set to True to make a deep copy of the model\n",
              "self (Model) – \n",
              "Returns\n",
              "new model instance\n",
              "Return type\n",
              "Model\n",
              "dict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\n",
              "Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod from_orm(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "json(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\n",
              "Generate a JSON representation of the model, include and exclude arguments as per dict().\n",
              "encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\n",
              "Parameters\n",
              "include (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "exclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \n",
              "by_alias (bool) – \n",
              "skip_defaults (Optional[bool]) – \n",
              "exclude_unset (bool) – \n",
              "exclude_defaults (bool) – \n",
              "exclude_none (bool) – \n",
              "encoder (Optional[Callable[[Any], Any]]) – \n",
              "models_as_dict (bool) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "path (Union[str, Path]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_obj(obj: Any) → Model¶\n",
              "Parameters\n",
              "obj (Any) – \n",
              "Return type\n",
              "Model\n",
              "classmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\n",
              "Parameters\n",
              "b (Union[str, bytes]) – \n",
              "content_type (unicode) – \n",
              "encoding (unicode) – \n",
              "proto (Protocol) – \n",
              "allow_pickle (bool) – \n",
              "Return type\n",
              "Model\n",
              "classmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "Return type\n",
              "DictStrAny\n",
              "classmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\n",
              "Parameters\n",
              "by_alias (bool) – \n",
              "ref_template (unicode) – \n",
              "dumps_kwargs (Any) – \n",
              "Return type\n",
              "unicode\n",
              "classmethod update_forward_refs(**localns: Any) → None¶\n",
              "Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
              "Parameters\n",
              "localns (Any) – \n",
              "Return type\n",
              "None\n",
              "classmethod validate(value: Any) → Model¶\n",
              "Parameters\n",
              "value (Any) – \n",
              "Return type\n",
              "Model\n",
              "Examples using RunEvalConfig¶\n",
              "LangSmith Walkthrough</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[2747]=================</br><pre><code class=\"python\">Source code for typing\n",
              "\"\"\"\n",
              "The typing module: Support for gradual typing as defined by PEP 484.\n",
              "At large scale, the structure of the module is following:\n",
              "* Imports and exports, all public names should be explicitly added to __all__.\n",
              "* Internal helper functions: these should never be used in code outside this module.\n",
              "* _SpecialForm and its instances (special forms):\n",
              "  Any, NoReturn, ClassVar, Union, Optional, Concatenate\n",
              "* Classes whose instances can be type arguments in addition to types:\n",
              "  ForwardRef, TypeVar and ParamSpec\n",
              "* The core of internal generics API: _GenericAlias and _VariadicGenericAlias, the latter is\n",
              "  currently only used by Tuple and Callable. All subscripted types like X[int], Union[int, str],\n",
              "  etc., are instances of either of these classes.\n",
              "* The public counterpart of the generics API consists of two classes: Generic and Protocol.\n",
              "* Public helper functions: get_type_hints, overload, cast, no_type_check,\n",
              "  no_type_check_decorator.\n",
              "* Generic aliases for collections.abc ABCs and few additional protocols.\n",
              "* Special types: NewType, NamedTuple, TypedDict.\n",
              "* Wrapper submodules for re and io related types.\n",
              "\"\"\"\n",
              "from abc import abstractmethod, ABCMeta\n",
              "import collections\n",
              "import collections.abc\n",
              "import contextlib\n",
              "import functools\n",
              "import operator\n",
              "import re as stdlib_re  # Avoid confusion with the re we export.\n",
              "import sys\n",
              "import types\n",
              "from types import WrapperDescriptorType, MethodWrapperType, MethodDescriptorType, GenericAlias\n",
              "# Please keep __all__ alphabetized within each category.\n",
              "__all__ = [\n",
              "    # Super-special typing primitives.\n",
              "    'Annotated',\n",
              "    'Any',\n",
              "    'Callable',\n",
              "    'ClassVar',\n",
              "    'Concatenate',\n",
              "    'Final',\n",
              "    'ForwardRef',\n",
              "    'Generic',\n",
              "    'Literal',\n",
              "    'Optional',\n",
              "    'ParamSpec',\n",
              "    'Protocol',\n",
              "    'Tuple',\n",
              "    'Type',\n",
              "    'TypeVar',\n",
              "    'Union',\n",
              "    # ABCs (from collections.abc).\n",
              "    'AbstractSet',  # collections.abc.Set.\n",
              "    'ByteString',\n",
              "    'Container',\n",
              "    'ContextManager',\n",
              "    'Hashable',\n",
              "    'ItemsView',\n",
              "    'Iterable',\n",
              "    'Iterator',\n",
              "    'KeysView',\n",
              "    'Mapping',\n",
              "    'MappingView',\n",
              "    'MutableMapping',\n",
              "    'MutableSequence',\n",
              "    'MutableSet',\n",
              "    'Sequence',\n",
              "    'Sized',\n",
              "    'ValuesView',\n",
              "    'Awaitable',\n",
              "    'AsyncIterator',\n",
              "    'AsyncIterable',\n",
              "    'Coroutine',\n",
              "    'Collection',\n",
              "    'AsyncGenerator',\n",
              "    'AsyncContextManager',\n",
              "    # Structural checks, a.k.a. protocols.\n",
              "    'Reversible',\n",
              "    'SupportsAbs',\n",
              "    'SupportsBytes',\n",
              "    'SupportsComplex',\n",
              "    'SupportsFloat',\n",
              "    'SupportsIndex',\n",
              "    'SupportsInt',\n",
              "    'SupportsRound',\n",
              "    # Concrete collection types.\n",
              "    'ChainMap',\n",
              "    'Counter',\n",
              "    'Deque',\n",
              "    'Dict',\n",
              "    'DefaultDict',\n",
              "    'List',\n",
              "    'OrderedDict',\n",
              "    'Set',\n",
              "    'FrozenSet',\n",
              "    'NamedTuple',  # Not really a type.\n",
              "    'TypedDict',  # Not really a type.\n",
              "    'Generator',\n",
              "    # Other concrete types.\n",
              "    'BinaryIO',\n",
              "    'IO',\n",
              "    'Match',\n",
              "    'Pattern',\n",
              "    'TextIO',\n",
              "    # One-off things.\n",
              "    'AnyStr',\n",
              "    'cast',\n",
              "    'final',\n",
              "    'get_args',\n",
              "    'get_origin',\n",
              "    'get_type_hints',\n",
              "    'is_typeddict',\n",
              "    'NewType',\n",
              "    'no_type_check',\n",
              "    'no_type_check_decorator',\n",
              "    'NoReturn',\n",
              "    'overload',\n",
              "    'ParamSpecArgs',\n",
              "    'ParamSpecKwargs',\n",
              "    'runtime_checkable',\n",
              "    'Text',\n",
              "    'TYPE_CHECKING',\n",
              "    'TypeAlias',\n",
              "    'TypeGuard',\n",
              "]\n",
              "# The pseudo-submodules 're' and 'io' are part of the public\n",
              "# namespace, but excluded from __all__ because they might stomp on\n",
              "# legitimate imports of those modules.\n",
              "def _type_convert(arg, module=None, *, allow_special_forms=False):\n",
              "    \"\"\"For converting None to type(None), and strings to ForwardRef.\"\"\"\n",
              "    if arg is None:\n",
              "        return type(None)\n",
              "    if isinstance(arg, str):\n",
              "        return ForwardRef(arg, module=module, is_class=allow_special_forms)\n",
              "    return arg\n",
              "def _type_check(arg, msg, is_argument=True, module=None, *, allow_special_forms=False):\n",
              "    \"\"\"Check that the argument is a type, and return it (internal helper).\n",
              "    As a special case, accept None and return type(None) instead. Also wrap strings\n",
              "    into ForwardRef instances. Consider several corner cases, for example plain\n",
              "    special forms like Union are not valid, while Union[int, str] is OK, etc.\n",
              "    The msg argument is a human-readable error message, e.g::\n",
              "        \"Union[arg, ...]: arg should be a type.\"\n",
              "    We append the repr() of the actual value (truncated to 100 chars).\n",
              "    \"\"\"\n",
              "    invalid_generic_forms = (Generic, Protocol)\n",
              "    if not allow_special_forms:\n",
              "        invalid_generic_forms += (ClassVar,)\n",
              "        if is_argument:\n",
              "            invalid_generic_forms += (Final,)\n",
              "    arg = _type_convert(arg, module=module, allow_special_forms=allow_special_forms)\n",
              "    if (isinstance(arg, _GenericAlias) and\n",
              "            arg.__origin__ in invalid_generic_forms):\n",
              "        raise TypeError(f\"{arg} is not valid as type argument\")\n",
              "    if arg in (Any, NoReturn, Final, TypeAlias):\n",
              "        return arg\n",
              "    if isinstance(arg, _SpecialForm) or arg in (Generic, Protocol):\n",
              "        raise TypeError(f\"Plain {arg} is not valid as type argument\")\n",
              "    if isinstance(arg, (type, TypeVar, ForwardRef, types.UnionType, ParamSpec,\n",
              "                        ParamSpecArgs, ParamSpecKwargs)):\n",
              "        return arg\n",
              "    if not callable(arg):\n",
              "        raise TypeError(f\"{msg} Got {arg!r:.100}.\")\n",
              "    return arg\n",
              "def _is_param_expr(arg):\n",
              "    return arg is ... or isinstance(arg,\n",
              "            (tuple, list, ParamSpec, _ConcatenateGenericAlias))\n",
              "def _type_repr(obj):\n",
              "    \"\"\"Return the repr() of an object, special-casing types (internal helper).\n",
              "    If obj is a type, we return a shorter version than the default\n",
              "    type.__repr__, based on the module and qualified name, which is\n",
              "    typically enough to uniquely identify a type.  For everything\n",
              "    else, we fall back on repr(obj).\n",
              "    \"\"\"\n",
              "    if isinstance(obj, types.GenericAlias):\n",
              "        return repr(obj)\n",
              "    if isinstance(obj, type):\n",
              "        if obj.__module__ == 'builtins':\n",
              "            return obj.__qualname__\n",
              "        return f'{obj.__module__}.{obj.__qualname__}'\n",
              "    if obj is ...:\n",
              "        return('...')\n",
              "    if isinstance(obj, types.FunctionType):\n",
              "        return obj.__name__\n",
              "    return repr(obj)\n",
              "def _collect_type_vars(types_, typevar_types=None):\n",
              "    \"\"\"Collect all type variable contained\n",
              "    in types in order of first appearance (lexicographic order). For example::\n",
              "        _collect_type_vars((T, List[S, T])) == (T, S)\n",
              "    \"\"\"\n",
              "    if typevar_types is None:\n",
              "        typevar_types = TypeVar\n",
              "    tvars = []\n",
              "    for t in types_:\n",
              "        if isinstance(t, typevar_types) and t not in tvars:\n",
              "            tvars.append(t)\n",
              "        if isinstance(t, (_GenericAlias, GenericAlias, types.UnionType)):\n",
              "            tvars.extend([t for t in t.__parameters__ if t not in tvars])\n",
              "    return tuple(tvars)\n",
              "def _check_generic(cls, parameters, elen):\n",
              "    \"\"\"Check correct count for parameters of a generic cls (internal helper).\n",
              "    This gives a nice error message in case of count mismatch.\n",
              "    \"\"\"\n",
              "    if not elen:\n",
              "        raise TypeError(f\"{cls} is not a generic class\")\n",
              "    alen = len(parameters)\n",
              "    if alen != elen:\n",
              "        raise TypeError(f\"Too {'many' if alen > elen else 'few'} arguments for {cls};\"\n",
              "                        f\" actual {alen}, expected {elen}\")\n",
              "def _prepare_paramspec_params(cls, params):\n",
              "    \"\"\"Prepares the parameters for a Generic containing ParamSpec\n",
              "    variables (internal helper).\n",
              "    \"\"\"\n",
              "    # Special case where Z[[int, str, bool]] == Z[int, str, bool] in PEP 612.\n",
              "    if (len(cls.__parameters__) == 1\n",
              "            and params and not _is_param_expr(params[0])):\n",
              "        assert isinstance(cls.__parameters__[0], ParamSpec)\n",
              "        return (params,)\n",
              "    else:\n",
              "        _check_generic(cls, params, len(cls.__parameters__))\n",
              "        _params = []\n",
              "        # Convert lists to tuples to help other libraries cache the results.\n",
              "        for p, tvar in zip(params, cls.__parameters__):\n",
              "            if isinstance(tvar, ParamSpec) and isinstance(p, list):\n",
              "                p = tuple(p)\n",
              "            _params.append(p)\n",
              "        return tuple(_params)\n",
              "def _deduplicate(params):\n",
              "    # Weed out strict duplicates, preserving the first of each occurrence.\n",
              "    all_params = set(params)\n",
              "    if len(all_params) < len(params):\n",
              "        new_params = []\n",
              "        for t in params:\n",
              "            if t in all_params:\n",
              "                new_params.append(t)\n",
              "                all_params.remove(t)\n",
              "        params = new_params\n",
              "        assert not all_params, all_params\n",
              "    return params\n",
              "def _remove_dups_flatten(parameters):\n",
              "    \"\"\"An internal helper for Union creation and substitution: flatten Unions\n",
              "    among parameters, then remove duplicates.\n",
              "    \"\"\"\n",
              "    # Flatten out Union[Union[...], ...].\n",
              "    params = []\n",
              "    for p in parameters:\n",
              "        if isinstance(p, (_UnionGenericAlias, types.UnionType)):\n",
              "            params.extend(p.__args__)\n",
              "        elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:\n",
              "            params.extend(p[1:])\n",
              "        else:\n",
              "            params.append(p)\n",
              "    return tuple(_deduplicate(params))\n",
              "def _flatten_literal_params(parameters):\n",
              "    \"\"\"An internal helper for Literal creation: flatten Literals among parameters\"\"\"\n",
              "    params = []\n",
              "    for p in parameters:\n",
              "        if isinstance(p, _LiteralGenericAlias):\n",
              "            params.extend(p.__args__)\n",
              "        else:\n",
              "            params.append(p)\n",
              "    return tuple(params)\n",
              "_cleanups = []\n",
              "def _tp_cache(func=None, /, *, typed=False):\n",
              "    \"\"\"Internal wrapper caching __getitem__ of generic types with a fallback to\n",
              "    original function for non-hashable arguments.\n",
              "    \"\"\"\n",
              "    def decorator(func):\n",
              "        cached = functools.lru_cache(typed=typed)(func)\n",
              "        _cleanups.append(cached.cache_clear)\n",
              "        @functools.wraps(func)\n",
              "        def inner(*args, **kwds):\n",
              "            try:\n",
              "                return cached(*args, **kwds)\n",
              "            except TypeError:\n",
              "                pass  # All real errors (not unhashable args) are raised below.\n",
              "            return func(*args, **kwds)\n",
              "        return inner\n",
              "    if func is not None:\n",
              "        return decorator(func)\n",
              "    return decorator\n",
              "def _eval_type(t, globalns, localns, recursive_guard=frozenset()):\n",
              "    \"\"\"Evaluate all forward references in the given type t.\n",
              "    For use of globalns and localns see the docstring for get_type_hints().\n",
              "    recursive_guard is used to prevent infinite recursion with a recursive\n",
              "    ForwardRef.\n",
              "    \"\"\"\n",
              "    if isinstance(t, ForwardRef):\n",
              "        return t._evaluate(globalns, localns, recursive_guard)\n",
              "    if isinstance(t, (_GenericAlias, GenericAlias, types.UnionType)):\n",
              "        ev_args = tuple(_eval_type(a, globalns, localns, recursive_guard) for a in t.__args__)\n",
              "        if ev_args == t.__args__:\n",
              "            return t\n",
              "        if isinstance(t, GenericAlias):\n",
              "            return GenericAlias(t.__origin__, ev_args)\n",
              "        if isinstance(t, types.UnionType):\n",
              "            return functools.reduce(operator.or_, ev_args)\n",
              "        else:\n",
              "            return t.copy_with(ev_args)\n",
              "    return t\n",
              "class _Final:\n",
              "    \"\"\"Mixin to prohibit subclassing\"\"\"\n",
              "    __slots__ = ('__weakref__',)\n",
              "    def __init_subclass__(self, /, *args, **kwds):\n",
              "        if '_root' not in kwds:\n",
              "            raise TypeError(\"Cannot subclass special typing classes\")\n",
              "class _Immutable:\n",
              "    \"\"\"Mixin to indicate that object should not be copied.\"\"\"\n",
              "    __slots__ = ()\n",
              "    def __copy__(self):\n",
              "        return self\n",
              "    def __deepcopy__(self, memo):\n",
              "        return self\n",
              "# Internal indicator of special typing constructs.\n",
              "# See __doc__ instance attribute for specific docs.\n",
              "class _SpecialForm(_Final, _root=True):\n",
              "    __slots__ = ('_name', '__doc__', '_getitem')\n",
              "    def __init__(self, getitem):\n",
              "        self._getitem = getitem\n",
              "        self._name = getitem.__name__\n",
              "        self.__doc__ = getitem.__doc__\n",
              "    def __getattr__(self, item):\n",
              "        if item in {'__name__', '__qualname__'}:\n",
              "            return self._name\n",
              "        raise AttributeError(item)\n",
              "    def __mro_entries__(self, bases):\n",
              "        raise TypeError(f\"Cannot subclass {self!r}\")\n",
              "    def __repr__(self):\n",
              "        return 'typing.' + self._name\n",
              "    def __reduce__(self):\n",
              "        return self._name\n",
              "    def __call__(self, *args, **kwds):\n",
              "        raise TypeError(f\"Cannot instantiate {self!r}\")\n",
              "    def __or__(self, other):\n",
              "        return Union[self, other]\n",
              "    def __ror__(self, other):\n",
              "        return Union[other, self]\n",
              "    def __instancecheck__(self, obj):\n",
              "        raise TypeError(f\"{self} cannot be used with isinstance()\")\n",
              "    def __subclasscheck__(self, cls):\n",
              "        raise TypeError(f\"{self} cannot be used with issubclass()\")\n",
              "    @_tp_cache\n",
              "    def __getitem__(self, parameters):\n",
              "        return self._getitem(self, parameters)\n",
              "class _LiteralSpecialForm(_SpecialForm, _root=True):\n",
              "    def __getitem__(self, parameters):\n",
              "        if not isinstance(parameters, tuple):\n",
              "            parameters = (parameters,)\n",
              "        return self._getitem(self, *parameters)\n",
              "@_SpecialForm\n",
              "def Any(self, parameters):\n",
              "    \"\"\"Special type indicating an unconstrained type.\n",
              "    - Any is compatible with every type.\n",
              "    - Any assumed to have all methods.\n",
              "    - All values assumed to be instances of Any.\n",
              "    Note that all the above statements are true from the point of view of\n",
              "    static type checkers. At runtime, Any should not be used with instance\n",
              "    or class checks.\n",
              "    \"\"\"\n",
              "    raise TypeError(f\"{self} is not subscriptable\")\n",
              "@_SpecialForm\n",
              "def NoReturn(self, parameters):\n",
              "    \"\"\"Special type indicating functions that never return.\n",
              "    Example::\n",
              "      from typing import NoReturn\n",
              "      def stop() -> NoReturn:\n",
              "          raise Exception('no way')\n",
              "    This type is invalid in other positions, e.g., ``List[NoReturn]``\n",
              "    will fail in static type checkers.\n",
              "    \"\"\"\n",
              "    raise TypeError(f\"{self} is not subscriptable\")\n",
              "@_SpecialForm\n",
              "def ClassVar(self, parameters):\n",
              "    \"\"\"Special type construct to mark class variables.\n",
              "    An annotation wrapped in ClassVar indicates that a given\n",
              "    attribute is intended to be used as a class variable and\n",
              "    should not be set on instances of that class. Usage::\n",
              "      class Starship:\n",
              "          stats: ClassVar[Dict[str, int]] = {} # class variable\n",
              "          damage: int = 10                     # instance variable\n",
              "    ClassVar accepts only types and cannot be further subscribed.\n",
              "    Note that ClassVar is not a class itself, and should not\n",
              "    be used with isinstance() or issubclass().\n",
              "    \"\"\"\n",
              "    item = _type_check(parameters, f'{self} accepts only single type.')\n",
              "    return _GenericAlias(self, (item,))\n",
              "@_SpecialForm\n",
              "def Final(self, parameters):\n",
              "    \"\"\"Special typing construct to indicate final names to type checkers.\n",
              "    A final name cannot be re-assigned or overridden in a subclass.\n",
              "    For example:\n",
              "      MAX_SIZE: Final = 9000\n",
              "      MAX_SIZE += 1  # Error reported by type checker\n",
              "      class Connection:\n",
              "          TIMEOUT: Final[int] = 10\n",
              "      class FastConnector(Connection):\n",
              "          TIMEOUT = 1  # Error reported by type checker\n",
              "    There is no runtime checking of these properties.\n",
              "    \"\"\"\n",
              "    item = _type_check(parameters, f'{self} accepts only single type.')\n",
              "    return _GenericAlias(self, (item,))\n",
              "@_SpecialForm\n",
              "def Union(self, parameters):\n",
              "    \"\"\"Union type; Union[X, Y] means either X or Y.\n",
              "    To define a union, use e.g. Union[int, str].  Details:\n",
              "    - The arguments must be types and there must be at least one.\n",
              "    - None as an argument is a special case and is replaced by\n",
              "      type(None).\n",
              "    - Unions of unions are flattened, e.g.::\n",
              "        Union[Union[int, str], float] == Union[int, str, float]\n",
              "    - Unions of a single argument vanish, e.g.::\n",
              "        Union[int] == int  # The constructor actually returns int\n",
              "    - Redundant arguments are skipped, e.g.::\n",
              "        Union[int, str, int] == Union[int, str]\n",
              "    - When comparing unions, the argument order is ignored, e.g.::\n",
              "        Union[int, str] == Union[str, int]\n",
              "    - You cannot subclass or instantiate a union.\n",
              "    - You can use Optional[X] as a shorthand for Union[X, None].\n",
              "    \"\"\"\n",
              "    if parameters == ():\n",
              "        raise TypeError(\"Cannot take a Union of no types.\")\n",
              "    if not isinstance(parameters, tuple):\n",
              "        parameters = (parameters,)\n",
              "    msg = \"Union[arg, ...]: each arg must be a type.\"\n",
              "    parameters = tuple(_type_check(p, msg) for p in parameters)\n",
              "    parameters = _remove_dups_flatten(parameters)\n",
              "    if len(parameters) == 1:\n",
              "        return parameters[0]\n",
              "    if len(parameters) == 2 and type(None) in parameters:\n",
              "        return _UnionGenericAlias(self, parameters, name=\"Optional\")\n",
              "    return _UnionGenericAlias(self, parameters)\n",
              "@_SpecialForm\n",
              "def Optional(self, parameters):\n",
              "    \"\"\"Optional type.\n",
              "    Optional[X] is equivalent to Union[X, None].\n",
              "    \"\"\"\n",
              "    arg = _type_check(parameters, f\"{self} requires a single type.\")\n",
              "    return Union[arg, type(None)]\n",
              "@_LiteralSpecialForm\n",
              "@_tp_cache(typed=True)\n",
              "def Literal(self, *parameters):\n",
              "    \"\"\"Special typing form to define literal types (a.k.a. value types).\n",
              "    This form can be used to indicate to type checkers that the corresponding\n",
              "    variable or function parameter has a value equivalent to the provided\n",
              "    literal (or one of several literals):\n",
              "      def validate_simple(data: Any) -> Literal[True]:  # always returns True\n",
              "          ...\n",
              "      MODE = Literal['r', 'rb', 'w', 'wb']\n",
              "      def open_helper(file: str, mode: MODE) -> str:\n",
              "          ...\n",
              "      open_helper('/some/path', 'r')  # Passes type check\n",
              "      open_helper('/other/path', 'typo')  # Error in type checker\n",
              "    Literal[...] cannot be subclassed. At runtime, an arbitrary value\n",
              "    is allowed as type argument to Literal[...], but type checkers may\n",
              "    impose restrictions.\n",
              "    \"\"\"\n",
              "    # There is no '_type_check' call because arguments to Literal[...] are\n",
              "    # values, not types.\n",
              "    parameters = _flatten_literal_params(parameters)\n",
              "    try:\n",
              "        parameters = tuple(p for p, _ in _deduplicate(list(_value_and_type_iter(parameters))))\n",
              "    except TypeError:  # unhashable parameters\n",
              "        pass\n",
              "    return _LiteralGenericAlias(self, parameters)\n",
              "@_SpecialForm\n",
              "def TypeAlias(self, parameters):\n",
              "    \"\"\"Special marker indicating that an assignment should\n",
              "    be recognized as a proper type alias definition by type\n",
              "    checkers.\n",
              "    For example::\n",
              "        Predicate: TypeAlias = Callable[..., bool]\n",
              "    It's invalid when used anywhere except as in the example above.\n",
              "    \"\"\"\n",
              "    raise TypeError(f\"{self} is not subscriptable\")\n",
              "@_SpecialForm\n",
              "def Concatenate(self, parameters):\n",
              "    \"\"\"Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a\n",
              "    higher order function which adds, removes or transforms parameters of a\n",
              "    callable.\n",
              "    For example::\n",
              "       Callable[Concatenate[int, P], int]\n",
              "    See PEP 612 for detailed information.\n",
              "    \"\"\"\n",
              "    if parameters == ():\n",
              "        raise TypeError(\"Cannot take a Concatenate of no types.\")\n",
              "    if not isinstance(parameters, tuple):\n",
              "        parameters = (parameters,)\n",
              "    if not isinstance(parameters[-1], ParamSpec):\n",
              "        raise TypeError(\"The last parameter to Concatenate should be a \"\n",
              "                        \"ParamSpec variable.\")\n",
              "    msg = \"Concatenate[arg, ...]: each arg must be a type.\"\n",
              "    parameters = (*(_type_check(p, msg) for p in parameters[:-1]), parameters[-1])\n",
              "    return _ConcatenateGenericAlias(self, parameters,\n",
              "                                    _typevar_types=(TypeVar, ParamSpec),\n",
              "                                    _paramspec_tvars=True)\n",
              "@_SpecialForm\n",
              "def TypeGuard(self, parameters):\n",
              "    \"\"\"Special typing form used to annotate the return type of a user-defined\n",
              "    type guard function.  ``TypeGuard`` only accepts a single type argument.\n",
              "    At runtime, functions marked this way should return a boolean.\n",
              "    ``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static\n",
              "    type checkers to determine a more precise type of an expression within a\n",
              "    program's code flow.  Usually type narrowing is done by analyzing\n",
              "    conditional code flow and applying the narrowing to a block of code.  The\n",
              "    conditional expression here is sometimes referred to as a \"type guard\".\n",
              "    Sometimes it would be convenient to use a user-defined boolean function\n",
              "    as a type guard.  Such a function should use ``TypeGuard[...]`` as its\n",
              "    return type to alert static type checkers to this intention.\n",
              "    Using  ``-> TypeGuard`` tells the static type checker that for a given\n",
              "    function:\n",
              "    1. The return value is a boolean.\n",
              "    2. If the return value is ``True``, the type of its argument\n",
              "       is the type inside ``TypeGuard``.\n",
              "       For example::\n",
              "          def is_str(val: Union[str, float]):\n",
              "              # \"isinstance\" type guard\n",
              "              if isinstance(val, str):\n",
              "                  # Type of ``val`` is narrowed to ``str``\n",
              "                  ...\n",
              "              else:\n",
              "                  # Else, type of ``val`` is narrowed to ``float``.\n",
              "                  ...\n",
              "    Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower\n",
              "    form of ``TypeA`` (it can even be a wider form) and this may lead to\n",
              "    type-unsafe results.  The main reason is to allow for things like\n",
              "    narrowing ``List[object]`` to ``List[str]`` even though the latter is not\n",
              "    a subtype of the former, since ``List`` is invariant.  The responsibility of\n",
              "    writing type-safe type guards is left to the user.\n",
              "    ``TypeGuard`` also works with type variables.  For more information, see\n",
              "    PEP 647 (User-Defined Type Guards).\n",
              "    \"\"\"\n",
              "    item = _type_check(parameters, f'{self} accepts only single type.')\n",
              "    return _GenericAlias(self, (item,))\n",
              "class ForwardRef(_Final, _root=True):\n",
              "    \"\"\"Internal wrapper to hold a forward reference.\"\"\"\n",
              "    __slots__ = ('__forward_arg__', '__forward_code__',\n",
              "                 '__forward_evaluated__', '__forward_value__',\n",
              "                 '__forward_is_argument__', '__forward_is_class__',\n",
              "                 '__forward_module__')\n",
              "    def __init__(self, arg, is_argument=True, module=None, *, is_class=False):\n",
              "        if not isinstance(arg, str):\n",
              "            raise TypeError(f\"Forward reference must be a string -- got {arg!r}\")\n",
              "        try:\n",
              "            code = compile(arg, '<string>', 'eval')\n",
              "        except SyntaxError:\n",
              "            raise SyntaxError(f\"Forward reference must be an expression -- got {arg!r}\")\n",
              "        self.__forward_arg__ = arg\n",
              "        self.__forward_code__ = code\n",
              "        self.__forward_evaluated__ = False\n",
              "        self.__forward_value__ = None\n",
              "        self.__forward_is_argument__ = is_argument\n",
              "        self.__forward_is_class__ = is_class\n",
              "        self.__forward_module__ = module\n",
              "    def _evaluate(self, globalns, localns, recursive_guard):\n",
              "        if self.__forward_arg__ in recursive_guard:\n",
              "            return self\n",
              "        if not self.__forward_evaluated__ or localns is not globalns:\n",
              "            if globalns is None and localns is None:\n",
              "                globalns = localns = {}\n",
              "            elif globalns is None:\n",
              "                globalns = localns\n",
              "            elif localns is None:\n",
              "                localns = globalns\n",
              "            if self.__forward_module__ is not None:\n",
              "                globalns = getattr(\n",
              "                    sys.modules.get(self.__forward_module__, None), '__dict__', globalns\n",
              "                )\n",
              "            type_ = _type_check(\n",
              "                eval(self.__forward_code__, globalns, localns),\n",
              "                \"Forward references must evaluate to types.\",\n",
              "                is_argument=self.__forward_is_argument__,\n",
              "                allow_special_forms=self.__forward_is_class__,\n",
              "            )\n",
              "            self.__forward_value__ = _eval_type(\n",
              "                type_, globalns, localns, recursive_guard | {self.__forward_arg__}\n",
              "            )\n",
              "            self.__forward_evaluated__ = True\n",
              "        return self.__forward_value__\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, ForwardRef):\n",
              "            return NotImplemented\n",
              "        if self.__forward_evaluated__ and other.__forward_evaluated__:\n",
              "            return (self.__forward_arg__ == other.__forward_arg__ and\n",
              "                    self.__forward_value__ == other.__forward_value__)\n",
              "        return (self.__forward_arg__ == other.__forward_arg__ and\n",
              "                self.__forward_module__ == other.__forward_module__)\n",
              "    def __hash__(self):\n",
              "        return hash((self.__forward_arg__, self.__forward_module__))\n",
              "    def __repr__(self):\n",
              "        return f'ForwardRef({self.__forward_arg__!r})'\n",
              "class _TypeVarLike:\n",
              "    \"\"\"Mixin for TypeVar-like types (TypeVar and ParamSpec).\"\"\"\n",
              "    def __init__(self, bound, covariant, contravariant):\n",
              "        \"\"\"Used to setup TypeVars and ParamSpec's bound, covariant and\n",
              "        contravariant attributes.\n",
              "        \"\"\"\n",
              "        if covariant and contravariant:\n",
              "            raise ValueError(\"Bivariant types are not supported.\")\n",
              "        self.__covariant__ = bool(covariant)\n",
              "        self.__contravariant__ = bool(contravariant)\n",
              "        if bound:\n",
              "            self.__bound__ = _type_check(bound, \"Bound must be a type.\")\n",
              "        else:\n",
              "            self.__bound__ = None\n",
              "    def __or__(self, right):\n",
              "        return Union[self, right]\n",
              "    def __ror__(self, left):\n",
              "        return Union[left, self]\n",
              "    def __repr__(self):\n",
              "        if self.__covariant__:\n",
              "            prefix = '+'\n",
              "        elif self.__contravariant__:\n",
              "            prefix = '-'\n",
              "        else:\n",
              "            prefix = '~'\n",
              "        return prefix + self.__name__\n",
              "    def __reduce__(self):\n",
              "        return self.__name__\n",
              "class TypeVar( _Final, _Immutable, _TypeVarLike, _root=True):\n",
              "    \"\"\"Type variable.\n",
              "    Usage::\n",
              "      T = TypeVar('T')  # Can be anything\n",
              "      A = TypeVar('A', str, bytes)  # Must be str or bytes\n",
              "    Type variables exist primarily for the benefit of static type\n",
              "    checkers.  They serve as the parameters for generic types as well\n",
              "    as for generic function definitions.  See class Generic for more\n",
              "    information on generic types.  Generic functions work as follows:\n",
              "      def repeat(x: T, n: int) -> List[T]:\n",
              "          '''Return a list containing n references to x.'''\n",
              "          return [x]*n\n",
              "      def longest(x: A, y: A) -> A:\n",
              "          '''Return the longest of two strings.'''\n",
              "          return x if len(x) >= len(y) else y\n",
              "    The latter example's signature is essentially the overloading\n",
              "    of (str, str) -> str and (bytes, bytes) -> bytes.  Also note\n",
              "    that if the arguments are instances of some subclass of str,\n",
              "    the return type is still plain str.\n",
              "    At runtime, isinstance(x, T) and issubclass(C, T) will raise TypeError.\n",
              "    Type variables defined with covariant=True or contravariant=True\n",
              "    can be used to declare covariant or contravariant generic types.\n",
              "    See PEP 484 for more details. By default generic types are invariant\n",
              "    in all type variables.\n",
              "    Type variables can be introspected. e.g.:\n",
              "      T.__name__ == 'T'\n",
              "      T.__constraints__ == ()\n",
              "      T.__covariant__ == False\n",
              "      T.__contravariant__ = False\n",
              "      A.__constraints__ == (str, bytes)\n",
              "    Note that only type variables defined in global scope can be pickled.\n",
              "    \"\"\"\n",
              "    __slots__ = ('__name__', '__bound__', '__constraints__',\n",
              "                 '__covariant__', '__contravariant__', '__dict__')\n",
              "    def __init__(self, name, *constraints, bound=None,\n",
              "                 covariant=False, contravariant=False):\n",
              "        self.__name__ = name\n",
              "        super().__init__(bound, covariant, contravariant)\n",
              "        if constraints and bound is not None:\n",
              "            raise TypeError(\"Constraints cannot be combined with bound=...\")\n",
              "        if constraints and len(constraints) == 1:\n",
              "            raise TypeError(\"A single constraint is not allowed\")\n",
              "        msg = \"TypeVar(name, constraint, ...): constraints must be types.\"\n",
              "        self.__constraints__ = tuple(_type_check(t, msg) for t in constraints)\n",
              "        try:\n",
              "            def_mod = sys._getframe(1).f_globals.get('__name__', '__main__')  # for pickling\n",
              "        except (AttributeError, ValueError):\n",
              "            def_mod = None\n",
              "        if def_mod != 'typing':\n",
              "            self.__module__ = def_mod\n",
              "class ParamSpecArgs(_Final, _Immutable, _root=True):\n",
              "    \"\"\"The args for a ParamSpec object.\n",
              "    Given a ParamSpec object P, P.args is an instance of ParamSpecArgs.\n",
              "    ParamSpecArgs objects have a reference back to their ParamSpec:\n",
              "       P.args.__origin__ is P\n",
              "    This type is meant for runtime introspection and has no special meaning to\n",
              "    static type checkers.\n",
              "    \"\"\"\n",
              "    def __init__(self, origin):\n",
              "        self.__origin__ = origin\n",
              "    def __repr__(self):\n",
              "        return f\"{self.__origin__.__name__}.args\"\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, ParamSpecArgs):\n",
              "            return NotImplemented\n",
              "        return self.__origin__ == other.__origin__\n",
              "class ParamSpecKwargs(_Final, _Immutable, _root=True):\n",
              "    \"\"\"The kwargs for a ParamSpec object.\n",
              "    Given a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.\n",
              "    ParamSpecKwargs objects have a reference back to their ParamSpec:\n",
              "       P.kwargs.__origin__ is P\n",
              "    This type is meant for runtime introspection and has no special meaning to\n",
              "    static type checkers.\n",
              "    \"\"\"\n",
              "    def __init__(self, origin):\n",
              "        self.__origin__ = origin\n",
              "    def __repr__(self):\n",
              "        return f\"{self.__origin__.__name__}.kwargs\"\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, ParamSpecKwargs):\n",
              "            return NotImplemented\n",
              "        return self.__origin__ == other.__origin__\n",
              "class ParamSpec(_Final, _Immutable, _TypeVarLike, _root=True):\n",
              "    \"\"\"Parameter specification variable.\n",
              "    Usage::\n",
              "       P = ParamSpec('P')\n",
              "    Parameter specification variables exist primarily for the benefit of static\n",
              "    type checkers.  They are used to forward the parameter types of one\n",
              "    callable to another callable, a pattern commonly found in higher order\n",
              "    functions and decorators.  They are only valid when used in ``Concatenate``,\n",
              "    or as the first argument to ``Callable``, or as parameters for user-defined\n",
              "    Generics.  See class Generic for more information on generic types.  An\n",
              "    example for annotating a decorator::\n",
              "       T = TypeVar('T')\n",
              "       P = ParamSpec('P')\n",
              "       def add_logging(f: Callable[P, T]) -> Callable[P, T]:\n",
              "           '''A type-safe decorator to add logging to a function.'''\n",
              "           def inner(*args: P.args, **kwargs: P.kwargs) -> T:\n",
              "               logging.info(f'{f.__name__} was called')\n",
              "               return f(*args, **kwargs)\n",
              "           return inner\n",
              "       @add_logging\n",
              "       def add_two(x: float, y: float) -> float:\n",
              "           '''Add two numbers together.'''\n",
              "           return x + y\n",
              "    Parameter specification variables defined with covariant=True or\n",
              "    contravariant=True can be used to declare covariant or contravariant\n",
              "    generic types.  These keyword arguments are valid, but their actual semantics\n",
              "    are yet to be decided.  See PEP 612 for details.\n",
              "    Parameter specification variables can be introspected. e.g.:\n",
              "       P.__name__ == 'P'\n",
              "       P.__bound__ == None\n",
              "       P.__covariant__ == False\n",
              "       P.__contravariant__ == False\n",
              "    Note that only parameter specification variables defined in global scope can\n",
              "    be pickled.\n",
              "    \"\"\"\n",
              "    __slots__ = ('__name__', '__bound__', '__covariant__', '__contravariant__',\n",
              "                 '__dict__')\n",
              "    @property\n",
              "    def args(self):\n",
              "        return ParamSpecArgs(self)\n",
              "    @property\n",
              "    def kwargs(self):\n",
              "        return ParamSpecKwargs(self)\n",
              "    def __init__(self, name, *, bound=None, covariant=False, contravariant=False):\n",
              "        self.__name__ = name\n",
              "        super().__init__(bound, covariant, contravariant)\n",
              "        try:\n",
              "            def_mod = sys._getframe(1).f_globals.get('__name__', '__main__')\n",
              "        except (AttributeError, ValueError):\n",
              "            def_mod = None\n",
              "        if def_mod != 'typing':\n",
              "            self.__module__ = def_mod\n",
              "def _is_dunder(attr):\n",
              "    return attr.startswith('__') and attr.endswith('__')\n",
              "class _BaseGenericAlias(_Final, _root=True):\n",
              "    \"\"\"The central part of internal API.\n",
              "    This represents a generic version of type 'origin' with type arguments 'params'.\n",
              "    There are two kind of these aliases: user defined and special. The special ones\n",
              "    are wrappers around builtin collections and ABCs in collections.abc. These must\n",
              "    have 'name' always set. If 'inst' is False, then the alias can't be instantiated,\n",
              "    this is used by e.g. typing.List and typing.Dict.\n",
              "    \"\"\"\n",
              "    def __init__(self, origin, *, inst=True, name=None):\n",
              "        self._inst = inst\n",
              "        self._name = name\n",
              "        self.__origin__ = origin\n",
              "        self.__slots__ = None  # This is not documented.\n",
              "    def __call__(self, *args, **kwargs):\n",
              "        if not self._inst:\n",
              "            raise TypeError(f\"Type {self._name} cannot be instantiated; \"\n",
              "                            f\"use {self.__origin__.__name__}() instead\")\n",
              "        result = self.__origin__(*args, **kwargs)\n",
              "        try:\n",
              "            result.__orig_class__ = self\n",
              "        except AttributeError:\n",
              "            pass\n",
              "        return result\n",
              "    def __mro_entries__(self, bases):\n",
              "        res = []\n",
              "        if self.__origin__ not in bases:\n",
              "            res.append(self.__origin__)\n",
              "        i = bases.index(self)\n",
              "        for b in bases[i+1:]:\n",
              "            if isinstance(b, _BaseGenericAlias) or issubclass(b, Generic):\n",
              "                break\n",
              "        else:\n",
              "            res.append(Generic)\n",
              "        return tuple(res)\n",
              "    def __getattr__(self, attr):\n",
              "        if attr in {'__name__', '__qualname__'}:\n",
              "            return self._name or self.__origin__.__name__\n",
              "        # We are careful for copy and pickle.\n",
              "        # Also for simplicity we don't relay any dunder names\n",
              "        if '__origin__' in self.__dict__ and not _is_dunder(attr):\n",
              "            return getattr(self.__origin__, attr)\n",
              "        raise AttributeError(attr)\n",
              "    def __setattr__(self, attr, val):\n",
              "        if _is_dunder(attr) or attr in {'_name', '_inst', '_nparams',\n",
              "                                        '_typevar_types', '_paramspec_tvars'}:\n",
              "            super().__setattr__(attr, val)\n",
              "        else:\n",
              "            setattr(self.__origin__, attr, val)\n",
              "    def __instancecheck__(self, obj):\n",
              "        return self.__subclasscheck__(type(obj))\n",
              "    def __subclasscheck__(self, cls):\n",
              "        raise TypeError(\"Subscripted generics cannot be used with\"\n",
              "                        \" class and instance checks\")\n",
              "    def __dir__(self):\n",
              "        return list(set(super().__dir__()\n",
              "                + [attr for attr in dir(self.__origin__) if not _is_dunder(attr)]))\n",
              "# Special typing constructs Union, Optional, Generic, Callable and Tuple\n",
              "# use three special attributes for internal bookkeeping of generic types:\n",
              "# * __parameters__ is a tuple of unique free type parameters of a generic\n",
              "#   type, for example, Dict[T, T].__parameters__ == (T,);\n",
              "# * __origin__ keeps a reference to a type that was subscripted,\n",
              "#   e.g., Union[T, int].__origin__ == Union, or the non-generic version of\n",
              "#   the type.\n",
              "# * __args__ is a tuple of all arguments used in subscripting,\n",
              "#   e.g., Dict[T, int].__args__ == (T, int).\n",
              "class _GenericAlias(_BaseGenericAlias, _root=True):\n",
              "    def __init__(self, origin, params, *, inst=True, name=None,\n",
              "                 _typevar_types=TypeVar,\n",
              "                 _paramspec_tvars=False):\n",
              "        super().__init__(origin, inst=inst, name=name)\n",
              "        if not isinstance(params, tuple):\n",
              "            params = (params,)\n",
              "        self.__args__ = tuple(... if a is _TypingEllipsis else\n",
              "                              () if a is _TypingEmpty else\n",
              "                              a for a in params)\n",
              "        self.__parameters__ = _collect_type_vars(params, typevar_types=_typevar_types)\n",
              "        self._typevar_types = _typevar_types\n",
              "        self._paramspec_tvars = _paramspec_tvars\n",
              "        if not name:\n",
              "            self.__module__ = origin.__module__\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, _GenericAlias):\n",
              "            return NotImplemented\n",
              "        return (self.__origin__ == other.__origin__\n",
              "                and self.__args__ == other.__args__)\n",
              "    def __hash__(self):\n",
              "        return hash((self.__origin__, self.__args__))\n",
              "    def __or__(self, right):\n",
              "        return Union[self, right]\n",
              "    def __ror__(self, left):\n",
              "        return Union[left, self]\n",
              "    @_tp_cache\n",
              "    def __getitem__(self, params):\n",
              "        if self.__origin__ in (Generic, Protocol):\n",
              "            # Can't subscript Generic[...] or Protocol[...].\n",
              "            raise TypeError(f\"Cannot subscript already-subscripted {self}\")\n",
              "        if not isinstance(params, tuple):\n",
              "            params = (params,)\n",
              "        params = tuple(_type_convert(p) for p in params)\n",
              "        if (self._paramspec_tvars\n",
              "                and any(isinstance(t, ParamSpec) for t in self.__parameters__)):\n",
              "            params = _prepare_paramspec_params(self, params)\n",
              "        else:\n",
              "            _check_generic(self, params, len(self.__parameters__))\n",
              "        subst = dict(zip(self.__parameters__, params))\n",
              "        new_args = []\n",
              "        for arg in self.__args__:\n",
              "            if isinstance(arg, self._typevar_types):\n",
              "                if isinstance(arg, ParamSpec):\n",
              "                    arg = subst[arg]\n",
              "                    if not _is_param_expr(arg):\n",
              "                        raise TypeError(f\"Expected a list of types, an ellipsis, \"\n",
              "                                        f\"ParamSpec, or Concatenate. Got {arg}\")\n",
              "                else:\n",
              "                    arg = subst[arg]\n",
              "            elif isinstance(arg, (_GenericAlias, GenericAlias, types.UnionType)):\n",
              "                subparams = arg.__parameters__\n",
              "                if subparams:\n",
              "                    subargs = tuple(subst[x] for x in subparams)\n",
              "                    arg = arg[subargs]\n",
              "            # Required to flatten out the args for CallableGenericAlias\n",
              "            if self.__origin__ == collections.abc.Callable and isinstance(arg, tuple):\n",
              "                new_args.extend(arg)\n",
              "            else:\n",
              "                new_args.append(arg)\n",
              "        return self.copy_with(tuple(new_args))\n",
              "    def copy_with(self, params):\n",
              "        return self.__class__(self.__origin__, params, name=self._name, inst=self._inst,\n",
              "                              _typevar_types=self._typevar_types,\n",
              "                              _paramspec_tvars=self._paramspec_tvars)\n",
              "    def __repr__(self):\n",
              "        if self._name:\n",
              "            name = 'typing.' + self._name\n",
              "        else:\n",
              "            name = _type_repr(self.__origin__)\n",
              "        args = \", \".join([_type_repr(a) for a in self.__args__])\n",
              "        return f'{name}[{args}]'\n",
              "    def __reduce__(self):\n",
              "        if self._name:\n",
              "            origin = globals()[self._name]\n",
              "        else:\n",
              "            origin = self.__origin__\n",
              "        args = tuple(self.__args__)\n",
              "        if len(args) == 1 and (not isinstance(args[0], tuple) or\n",
              "                               origin is Tuple and not args[0]):\n",
              "            args, = args\n",
              "        return operator.getitem, (origin, args)\n",
              "    def __mro_entries__(self, bases):\n",
              "        if isinstance(self.__origin__, _SpecialForm):\n",
              "            raise TypeError(f\"Cannot subclass {self!r}\")\n",
              "        if self._name:  # generic version of an ABC or built-in class\n",
              "            return super().__mro_entries__(bases)\n",
              "        if self.__origin__ is Generic:\n",
              "            if Protocol in bases:\n",
              "                return ()\n",
              "            i = bases.index(self)\n",
              "            for b in bases[i+1:]:\n",
              "                if isinstance(b, _BaseGenericAlias) and b is not self:\n",
              "                    return ()\n",
              "        return (self.__origin__,)\n",
              "# _nparams is the number of accepted parameters, e.g. 0 for Hashable,\n",
              "# 1 for List and 2 for Dict.  It may be -1 if variable number of\n",
              "# parameters are accepted (needs custom __getitem__).\n",
              "class _SpecialGenericAlias(_BaseGenericAlias, _root=True):\n",
              "    def __init__(self, origin, nparams, *, inst=True, name=None):\n",
              "        if name is None:\n",
              "            name = origin.__name__\n",
              "        super().__init__(origin, inst=inst, name=name)\n",
              "        self._nparams = nparams\n",
              "        if origin.__module__ == 'builtins':\n",
              "            self.__doc__ = f'A generic version of {origin.__qualname__}.'\n",
              "        else:\n",
              "            self.__doc__ = f'A generic version of {origin.__module__}.{origin.__qualname__}.'\n",
              "    @_tp_cache\n",
              "    def __getitem__(self, params):\n",
              "        if not isinstance(params, tuple):\n",
              "            params = (params,)\n",
              "        msg = \"Parameters to generic types must be types.\"\n",
              "        params = tuple(_type_check(p, msg) for p in params)\n",
              "        _check_generic(self, params, self._nparams)\n",
              "        return self.copy_with(params)\n",
              "    def copy_with(self, params):\n",
              "        return _GenericAlias(self.__origin__, params,\n",
              "                             name=self._name, inst=self._inst)\n",
              "    def __repr__(self):\n",
              "        return 'typing.' + self._name\n",
              "    def __subclasscheck__(self, cls):\n",
              "        if isinstance(cls, _SpecialGenericAlias):\n",
              "            return issubclass(cls.__origin__, self.__origin__)\n",
              "        if not isinstance(cls, _GenericAlias):\n",
              "            return issubclass(cls, self.__origin__)\n",
              "        return super().__subclasscheck__(cls)\n",
              "    def __reduce__(self):\n",
              "        return self._name\n",
              "    def __or__(self, right):\n",
              "        return Union[self, right]\n",
              "    def __ror__(self, left):\n",
              "        return Union[left, self]\n",
              "class _CallableGenericAlias(_GenericAlias, _root=True):\n",
              "    def __repr__(self):\n",
              "        assert self._name == 'Callable'\n",
              "        args = self.__args__\n",
              "        if len(args) == 2 and _is_param_expr(args[0]):\n",
              "            return super().__repr__()\n",
              "        return (f'typing.Callable'\n",
              "                f'[[{\", \".join([_type_repr(a) for a in args[:-1]])}], '\n",
              "                f'{_type_repr(args[-1])}]')\n",
              "    def __reduce__(self):\n",
              "        args = self.__args__\n",
              "        if not (len(args) == 2 and _is_param_expr(args[0])):\n",
              "            args = list(args[:-1]), args[-1]\n",
              "        return operator.getitem, (Callable, args)\n",
              "class _CallableType(_SpecialGenericAlias, _root=True):\n",
              "    def copy_with(self, params):\n",
              "        return _CallableGenericAlias(self.__origin__, params,\n",
              "                                     name=self._name, inst=self._inst,\n",
              "                                     _typevar_types=(TypeVar, ParamSpec),\n",
              "                                     _paramspec_tvars=True)\n",
              "    def __getitem__(self, params):\n",
              "        if not isinstance(params, tuple) or len(params) != 2:\n",
              "            raise TypeError(\"Callable must be used as \"\n",
              "                            \"Callable[[arg, ...], result].\")\n",
              "        args, result = params\n",
              "        # This relaxes what args can be on purpose to allow things like\n",
              "        # PEP 612 ParamSpec.  Responsibility for whether a user is using\n",
              "        # Callable[...] properly is deferred to static type checkers.\n",
              "        if isinstance(args, list):\n",
              "            params = (tuple(args), result)\n",
              "        else:\n",
              "            params = (args, result)\n",
              "        return self.__getitem_inner__(params)\n",
              "    @_tp_cache\n",
              "    def __getitem_inner__(self, params):\n",
              "        args, result = params\n",
              "        msg = \"Callable[args, result]: result must be a type.\"\n",
              "        result = _type_check(result, msg)\n",
              "        if args is Ellipsis:\n",
              "            return self.copy_with((_TypingEllipsis, result))\n",
              "        if not isinstance(args, tuple):\n",
              "            args = (args,)\n",
              "        args = tuple(_type_convert(arg) for arg in args)\n",
              "        params = args + (result,)\n",
              "        return self.copy_with(params)\n",
              "class _TupleType(_SpecialGenericAlias, _root=True):\n",
              "    @_tp_cache\n",
              "    def __getitem__(self, params):\n",
              "        if params == ():\n",
              "            return self.copy_with((_TypingEmpty,))\n",
              "        if not isinstance(params, tuple):\n",
              "            params = (params,)\n",
              "        if len(params) == 2 and params[1] is ...:\n",
              "            msg = \"Tuple[t, ...]: t must be a type.\"\n",
              "            p = _type_check(params[0], msg)\n",
              "            return self.copy_with((p, _TypingEllipsis))\n",
              "        msg = \"Tuple[t0, t1, ...]: each t must be a type.\"\n",
              "        params = tuple(_type_check(p, msg) for p in params)\n",
              "        return self.copy_with(params)\n",
              "class _UnionGenericAlias(_GenericAlias, _root=True):\n",
              "    def copy_with(self, params):\n",
              "        return Union[params]\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, (_UnionGenericAlias, types.UnionType)):\n",
              "            return NotImplemented\n",
              "        return set(self.__args__) == set(other.__args__)\n",
              "    def __hash__(self):\n",
              "        return hash(frozenset(self.__args__))\n",
              "    def __repr__(self):\n",
              "        args = self.__args__\n",
              "        if len(args) == 2:\n",
              "            if args[0] is type(None):\n",
              "                return f'typing.Optional[{_type_repr(args[1])}]'\n",
              "            elif args[1] is type(None):\n",
              "                return f'typing.Optional[{_type_repr(args[0])}]'\n",
              "        return super().__repr__()\n",
              "    def __instancecheck__(self, obj):\n",
              "        return self.__subclasscheck__(type(obj))\n",
              "    def __subclasscheck__(self, cls):\n",
              "        for arg in self.__args__:\n",
              "            if issubclass(cls, arg):\n",
              "                return True\n",
              "    def __reduce__(self):\n",
              "        func, (origin, args) = super().__reduce__()\n",
              "        return func, (Union, args)\n",
              "def _value_and_type_iter(parameters):\n",
              "    return ((p, type(p)) for p in parameters)\n",
              "class _LiteralGenericAlias(_GenericAlias, _root=True):\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, _LiteralGenericAlias):\n",
              "            return NotImplemented\n",
              "        return set(_value_and_type_iter(self.__args__)) == set(_value_and_type_iter(other.__args__))\n",
              "    def __hash__(self):\n",
              "        return hash(frozenset(_value_and_type_iter(self.__args__)))\n",
              "class _ConcatenateGenericAlias(_GenericAlias, _root=True):\n",
              "    def copy_with(self, params):\n",
              "        if isinstance(params[-1], (list, tuple)):\n",
              "            return (*params[:-1], *params[-1])\n",
              "        if isinstance(params[-1], _ConcatenateGenericAlias):\n",
              "            params = (*params[:-1], *params[-1].__args__)\n",
              "        elif not isinstance(params[-1], ParamSpec):\n",
              "            raise TypeError(\"The last parameter to Concatenate should be a \"\n",
              "                            \"ParamSpec variable.\")\n",
              "        return super().copy_with(params)\n",
              "class Generic:\n",
              "    \"\"\"Abstract base class for generic types.\n",
              "    A generic type is typically declared by inheriting from\n",
              "    this class parameterized with one or more type variables.\n",
              "    For example, a generic mapping type might be defined as::\n",
              "      class Mapping(Generic[KT, VT]):\n",
              "          def __getitem__(self, key: KT) -> VT:\n",
              "              ...\n",
              "          # Etc.\n",
              "    This class can then be used as follows::\n",
              "      def lookup_name(mapping: Mapping[KT, VT], key: KT, default: VT) -> VT:\n",
              "          try:\n",
              "              return mapping[key]\n",
              "          except KeyError:\n",
              "              return default\n",
              "    \"\"\"\n",
              "    __slots__ = ()\n",
              "    _is_protocol = False\n",
              "    @_tp_cache\n",
              "    def __class_getitem__(cls, params):\n",
              "        if not isinstance(params, tuple):\n",
              "            params = (params,)\n",
              "        if not params and cls is not Tuple:\n",
              "            raise TypeError(\n",
              "                f\"Parameter list to {cls.__qualname__}[...] cannot be empty\")\n",
              "        params = tuple(_type_convert(p) for p in params)\n",
              "        if cls in (Generic, Protocol):\n",
              "            # Generic and Protocol can only be subscripted with unique type variables.\n",
              "            if not all(isinstance(p, (TypeVar, ParamSpec)) for p in params):\n",
              "                raise TypeError(\n",
              "                    f\"Parameters to {cls.__name__}[...] must all be type variables \"\n",
              "                    f\"or parameter specification variables.\")\n",
              "            if len(set(params)) != len(params):\n",
              "                raise TypeError(\n",
              "                    f\"Parameters to {cls.__name__}[...] must all be unique\")\n",
              "        else:\n",
              "            # Subscripting a regular Generic subclass.\n",
              "            if any(isinstance(t, ParamSpec) for t in cls.__parameters__):\n",
              "                params = _prepare_paramspec_params(cls, params)\n",
              "            else:\n",
              "                _check_generic(cls, params, len(cls.__parameters__))\n",
              "        return _GenericAlias(cls, params,\n",
              "                             _typevar_types=(TypeVar, ParamSpec),\n",
              "                             _paramspec_tvars=True)\n",
              "    def __init_subclass__(cls, *args, **kwargs):\n",
              "        super().__init_subclass__(*args, **kwargs)\n",
              "        tvars = []\n",
              "        if '__orig_bases__' in cls.__dict__:\n",
              "            error = Generic in cls.__orig_bases__\n",
              "        else:\n",
              "            error = Generic in cls.__bases__ and cls.__name__ != 'Protocol'\n",
              "        if error:\n",
              "            raise TypeError(\"Cannot inherit from plain Generic\")\n",
              "        if '__orig_bases__' in cls.__dict__:\n",
              "            tvars = _collect_type_vars(cls.__orig_bases__, (TypeVar, ParamSpec))\n",
              "            # Look for Generic[T1, ..., Tn].\n",
              "            # If found, tvars must be a subset of it.\n",
              "            # If not found, tvars is it.\n",
              "            # Also check for and reject plain Generic,\n",
              "            # and reject multiple Generic[...].\n",
              "            gvars = None\n",
              "            for base in cls.__orig_bases__:\n",
              "                if (isinstance(base, _GenericAlias) and\n",
              "                        base.__origin__ is Generic):\n",
              "                    if gvars is not None:\n",
              "                        raise TypeError(\n",
              "                            \"Cannot inherit from Generic[...] multiple types.\")\n",
              "                    gvars = base.__parameters__\n",
              "            if gvars is not None:\n",
              "                tvarset = set(tvars)\n",
              "                gvarset = set(gvars)\n",
              "                if not tvarset <= gvarset:\n",
              "                    s_vars = ', '.join(str(t) for t in tvars if t not in gvarset)\n",
              "                    s_args = ', '.join(str(g) for g in gvars)\n",
              "                    raise TypeError(f\"Some type variables ({s_vars}) are\"\n",
              "                                    f\" not listed in Generic[{s_args}]\")\n",
              "                tvars = gvars\n",
              "        cls.__parameters__ = tuple(tvars)\n",
              "class _TypingEmpty:\n",
              "    \"\"\"Internal placeholder for () or []. Used by TupleMeta and CallableMeta\n",
              "    to allow empty list/tuple in specific places, without allowing them\n",
              "    to sneak in where prohibited.\n",
              "    \"\"\"\n",
              "class _TypingEllipsis:\n",
              "    \"\"\"Internal placeholder for ... (ellipsis).\"\"\"\n",
              "_TYPING_INTERNALS = ['__parameters__', '__orig_bases__',  '__orig_class__',\n",
              "                     '_is_protocol', '_is_runtime_protocol']\n",
              "_SPECIAL_NAMES = ['__abstractmethods__', '__annotations__', '__dict__', '__doc__',\n",
              "                  '__init__', '__module__', '__new__', '__slots__',\n",
              "                  '__subclasshook__', '__weakref__', '__class_getitem__']\n",
              "# These special attributes will be not collected as protocol members.\n",
              "EXCLUDED_ATTRIBUTES = _TYPING_INTERNALS + _SPECIAL_NAMES + ['_MutableMapping__marker']\n",
              "def _get_protocol_attrs(cls):\n",
              "    \"\"\"Collect protocol members from a protocol class objects.\n",
              "    This includes names actually defined in the class dictionary, as well\n",
              "    as names that appear in annotations. Special names (above) are skipped.\n",
              "    \"\"\"\n",
              "    attrs = set()\n",
              "    for base in cls.__mro__[:-1]:  # without object\n",
              "        if base.__name__ in ('Protocol', 'Generic'):\n",
              "            continue\n",
              "        annotations = getattr(base, '__annotations__', {})\n",
              "        for attr in list(base.__dict__.keys()) + list(annotations.keys()):\n",
              "            if not attr.startswith('_abc_') and attr not in EXCLUDED_ATTRIBUTES:\n",
              "                attrs.add(attr)\n",
              "    return attrs\n",
              "def _is_callable_members_only(cls):\n",
              "    # PEP 544 prohibits using issubclass() with protocols that have non-method members.\n",
              "    return all(callable(getattr(cls, attr, None)) for attr in _get_protocol_attrs(cls))\n",
              "def _no_init_or_replace_init(self, *args, **kwargs):\n",
              "    cls = type(self)\n",
              "    if cls._is_protocol:\n",
              "        raise TypeError('Protocols cannot be instantiated')\n",
              "    # Already using a custom `__init__`. No need to calculate correct\n",
              "    # `__init__` to call. This can lead to RecursionError. See bpo-45121.\n",
              "    if cls.__init__ is not _no_init_or_replace_init:\n",
              "        return\n",
              "    # Initially, `__init__` of a protocol subclass is set to `_no_init_or_replace_init`.\n",
              "    # The first instantiation of the subclass will call `_no_init_or_replace_init` which\n",
              "    # searches for a proper new `__init__` in the MRO. The new `__init__`\n",
              "    # replaces the subclass' old `__init__` (ie `_no_init_or_replace_init`). Subsequent\n",
              "    # instantiation of the protocol subclass will thus use the new\n",
              "    # `__init__` and no longer call `_no_init_or_replace_init`.\n",
              "    for base in cls.__mro__:\n",
              "        init = base.__dict__.get('__init__', _no_init_or_replace_init)\n",
              "        if init is not _no_init_or_replace_init:\n",
              "            cls.__init__ = init\n",
              "            break\n",
              "    else:\n",
              "        # should not happen\n",
              "        cls.__init__ = object.__init__\n",
              "    cls.__init__(self, *args, **kwargs)\n",
              "def _caller(depth=1, default='__main__'):\n",
              "    try:\n",
              "        return sys._getframe(depth + 1).f_globals.get('__name__', default)\n",
              "    except (AttributeError, ValueError):  # For platforms without _getframe()\n",
              "        return None\n",
              "def _allow_reckless_class_checks(depth=3):\n",
              "    \"\"\"Allow instance and class checks for special stdlib modules.\n",
              "    The abc and functools modules indiscriminately call isinstance() and\n",
              "    issubclass() on the whole MRO of a user class, which may contain protocols.\n",
              "    \"\"\"\n",
              "    try:\n",
              "        return sys._getframe(depth).f_globals['__name__'] in ['abc', 'functools']\n",
              "    except (AttributeError, ValueError):  # For platforms without _getframe().\n",
              "        return True\n",
              "_PROTO_ALLOWLIST = {\n",
              "    'collections.abc': [\n",
              "        'Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',\n",
              "        'Hashable', 'Sized', 'Container', 'Collection', 'Reversible',\n",
              "    ],\n",
              "    'contextlib': ['AbstractContextManager', 'AbstractAsyncContextManager'],\n",
              "}\n",
              "class _ProtocolMeta(ABCMeta):\n",
              "    # This metaclass is really unfortunate and exists only because of\n",
              "    # the lack of __instancehook__.\n",
              "    def __instancecheck__(cls, instance):\n",
              "        # We need this method for situations where attributes are\n",
              "        # assigned in __init__.\n",
              "        if (\n",
              "            getattr(cls, '_is_protocol', False) and\n",
              "            not getattr(cls, '_is_runtime_protocol', False) and\n",
              "            not _allow_reckless_class_checks(depth=2)\n",
              "        ):\n",
              "            raise TypeError(\"Instance and class checks can only be used with\"\n",
              "                            \" @runtime_checkable protocols\")\n",
              "        if ((not getattr(cls, '_is_protocol', False) or\n",
              "                _is_callable_members_only(cls)) and\n",
              "                issubclass(instance.__class__, cls)):\n",
              "            return True\n",
              "        if cls._is_protocol:\n",
              "            if all(hasattr(instance, attr) and\n",
              "                    # All *methods* can be blocked by setting them to None.\n",
              "                    (not callable(getattr(cls, attr, None)) or\n",
              "                     getattr(instance, attr) is not None)\n",
              "                    for attr in _get_protocol_attrs(cls)):\n",
              "                return True\n",
              "        return super().__instancecheck__(instance)\n",
              "class Protocol(Generic, metaclass=_ProtocolMeta):\n",
              "    \"\"\"Base class for protocol classes.\n",
              "    Protocol classes are defined as::\n",
              "        class Proto(Protocol):\n",
              "            def meth(self) -> int:\n",
              "                ...\n",
              "    Such classes are primarily used with static type checkers that recognize\n",
              "    structural subtyping (static duck-typing), for example::\n",
              "        class C:\n",
              "            def meth(self) -> int:\n",
              "                return 0\n",
              "        def func(x: Proto) -> int:\n",
              "            return x.meth()\n",
              "        func(C())  # Passes static type check\n",
              "    See PEP 544 for details. Protocol classes decorated with\n",
              "    @typing.runtime_checkable act as simple-minded runtime protocols that check\n",
              "    only the presence of given attributes, ignoring their type signatures.\n",
              "    Protocol classes can be generic, they are defined as::\n",
              "        class GenProto(Protocol[T]):\n",
              "            def meth(self) -> T:\n",
              "                ...\n",
              "    \"\"\"\n",
              "    __slots__ = ()\n",
              "    _is_protocol = True\n",
              "    _is_runtime_protocol = False\n",
              "    def __init_subclass__(cls, *args, **kwargs):\n",
              "        super().__init_subclass__(*args, **kwargs)\n",
              "        # Determine if this is a protocol or a concrete subclass.\n",
              "        if not cls.__dict__.get('_is_protocol', False):\n",
              "            cls._is_protocol = any(b is Protocol for b in cls.__bases__)\n",
              "        # Set (or override) the protocol subclass hook.\n",
              "        def _proto_hook(other):\n",
              "            if not cls.__dict__.get('_is_protocol', False):\n",
              "                return NotImplemented\n",
              "            # First, perform various sanity checks.\n",
              "            if not getattr(cls, '_is_runtime_protocol', False):\n",
              "                if _allow_reckless_class_checks():\n",
              "                    return NotImplemented\n",
              "                raise TypeError(\"Instance and class checks can only be used with\"\n",
              "                                \" @runtime_checkable protocols\")\n",
              "            if not _is_callable_members_only(cls):\n",
              "                if _allow_reckless_class_checks():\n",
              "                    return NotImplemented\n",
              "                raise TypeError(\"Protocols with non-method members\"\n",
              "                                \" don't support issubclass()\")\n",
              "            if not isinstance(other, type):\n",
              "                # Same error message as for issubclass(1, int).\n",
              "                raise TypeError('issubclass() arg 1 must be a class')\n",
              "            # Second, perform the actual structural compatibility check.\n",
              "            for attr in _get_protocol_attrs(cls):\n",
              "                for base in other.__mro__:\n",
              "                    # Check if the members appears in the class dictionary...\n",
              "                    if attr in base.__dict__:\n",
              "                        if base.__dict__[attr] is None:\n",
              "                            return NotImplemented\n",
              "                        break\n",
              "                    # ...or in annotations, if it is a sub-protocol.\n",
              "                    annotations = getattr(base, '__annotations__', {})\n",
              "                    if (isinstance(annotations, collections.abc.Mapping) and\n",
              "                            attr in annotations and\n",
              "                            issubclass(other, Generic) and other._is_protocol):\n",
              "                        break\n",
              "                else:\n",
              "                    return NotImplemented\n",
              "            return True\n",
              "        if '__subclasshook__' not in cls.__dict__:\n",
              "            cls.__subclasshook__ = _proto_hook\n",
              "        # We have nothing more to do for non-protocols...\n",
              "        if not cls._is_protocol:\n",
              "            return\n",
              "        # ... otherwise check consistency of bases, and prohibit instantiation.\n",
              "        for base in cls.__bases__:\n",
              "            if not (base in (object, Generic) or\n",
              "                    base.__module__ in _PROTO_ALLOWLIST and\n",
              "                    base.__name__ in _PROTO_ALLOWLIST[base.__module__] or\n",
              "                    issubclass(base, Generic) and base._is_protocol):\n",
              "                raise TypeError('Protocols can only inherit from other'\n",
              "                                ' protocols, got %r' % base)\n",
              "        cls.__init__ = _no_init_or_replace_init\n",
              "class _AnnotatedAlias(_GenericAlias, _root=True):\n",
              "    \"\"\"Runtime representation of an annotated type.\n",
              "    At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'\n",
              "    with extra annotations. The alias behaves like a normal typing alias,\n",
              "    instantiating is the same as instantiating the underlying type, binding\n",
              "    it to types is also the same.\n",
              "    \"\"\"\n",
              "    def __init__(self, origin, metadata):\n",
              "        if isinstance(origin, _AnnotatedAlias):\n",
              "            metadata = origin.__metadata__ + metadata\n",
              "            origin = origin.__origin__\n",
              "        super().__init__(origin, origin)\n",
              "        self.__metadata__ = metadata\n",
              "    def copy_with(self, params):\n",
              "        assert len(params) == 1\n",
              "        new_type = params[0]\n",
              "        return _AnnotatedAlias(new_type, self.__metadata__)\n",
              "    def __repr__(self):\n",
              "        return \"typing.Annotated[{}, {}]\".format(\n",
              "            _type_repr(self.__origin__),\n",
              "            \", \".join(repr(a) for a in self.__metadata__)\n",
              "        )\n",
              "    def __reduce__(self):\n",
              "        return operator.getitem, (\n",
              "            Annotated, (self.__origin__,) + self.__metadata__\n",
              "        )\n",
              "    def __eq__(self, other):\n",
              "        if not isinstance(other, _AnnotatedAlias):\n",
              "            return NotImplemented\n",
              "        return (self.__origin__ == other.__origin__\n",
              "                and self.__metadata__ == other.__metadata__)\n",
              "    def __hash__(self):\n",
              "        return hash((self.__origin__, self.__metadata__))\n",
              "    def __getattr__(self, attr):\n",
              "        if attr in {'__name__', '__qualname__'}:\n",
              "            return 'Annotated'\n",
              "        return super().__getattr__(attr)\n",
              "class Annotated:\n",
              "    \"\"\"Add context specific metadata to a type.\n",
              "    Example: Annotated[int, runtime_check.Unsigned] indicates to the\n",
              "    hypothetical runtime_check module that this type is an unsigned int.\n",
              "    Every other consumer of this type can ignore this metadata and treat\n",
              "    this type as int.\n",
              "    The first argument to Annotated must be a valid type.\n",
              "    Details:\n",
              "    - It's an error to call `Annotated` with less than two arguments.\n",
              "    - Nested Annotated are flattened::\n",
              "        Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]\n",
              "    - Instantiating an annotated type is equivalent to instantiating the\n",
              "    underlying type::\n",
              "        Annotated[C, Ann1](5) == C(5)\n",
              "    - Annotated can be used as a generic type alias::\n",
              "        Optimized = Annotated[T, runtime.Optimize()]\n",
              "        Optimized[int] == Annotated[int, runtime.Optimize()]\n",
              "        OptimizedList = Annotated[List[T], runtime.Optimize()]\n",
              "        OptimizedList[int] == Annotated[List[int], runtime.Optimize()]\n",
              "    \"\"\"\n",
              "    __slots__ = ()\n",
              "    def __new__(cls, *args, **kwargs):\n",
              "        raise TypeError(\"Type Annotated cannot be instantiated.\")\n",
              "    @_tp_cache\n",
              "    def __class_getitem__(cls, params):\n",
              "        if not isinstance(params, tuple) or len(params) < 2:\n",
              "            raise TypeError(\"Annotated[...] should be used \"\n",
              "                            \"with at least two arguments (a type and an \"\n",
              "                            \"annotation).\")\n",
              "        msg = \"Annotated[t, ...]: t must be a type.\"\n",
              "        origin = _type_check(params[0], msg, allow_special_forms=True)\n",
              "        metadata = tuple(params[1:])\n",
              "        return _AnnotatedAlias(origin, metadata)\n",
              "    def __init_subclass__(cls, *args, **kwargs):\n",
              "        raise TypeError(\n",
              "            \"Cannot subclass {}.Annotated\".format(cls.__module__)\n",
              "        )\n",
              "def runtime_checkable(cls):\n",
              "    \"\"\"Mark a protocol class as a runtime protocol.\n",
              "    Such protocol can be used with isinstance() and issubclass().\n",
              "    Raise TypeError if applied to a non-protocol class.\n",
              "    This allows a simple-minded structural check very similar to\n",
              "    one trick ponies in collections.abc such as Iterable.\n",
              "    For example::\n",
              "        @runtime_checkable\n",
              "        class Closable(Protocol):\n",
              "            def close(self): ...\n",
              "        assert isinstance(open('/some/file'), Closable)\n",
              "    Warning: this will check only the presence of the required methods,\n",
              "    not their type signatures!\n",
              "    \"\"\"\n",
              "    if not issubclass(cls, Generic) or not cls._is_protocol:\n",
              "        raise TypeError('@runtime_checkable can be only applied to protocol classes,'\n",
              "                        ' got %r' % cls)\n",
              "    cls._is_runtime_protocol = True\n",
              "    return cls\n",
              "def cast(typ, val):\n",
              "    \"\"\"Cast a value to a type.\n",
              "    This returns the value unchanged.  To the type checker this\n",
              "    signals that the return value has the designated type, but at\n",
              "    runtime we intentionally don't check anything (we want this\n",
              "    to be as fast as possible).\n",
              "    \"\"\"\n",
              "    return val\n",
              "def _get_defaults(func):\n",
              "    \"\"\"Internal helper to extract the default arguments, by name.\"\"\"\n",
              "    try:\n",
              "        code = func.__code__\n",
              "    except AttributeError:\n",
              "        # Some built-in functions don't have __code__, __defaults__, etc.\n",
              "        return {}\n",
              "    pos_count = code.co_argcount\n",
              "    arg_names = code.co_varnames\n",
              "    arg_names = arg_names[:pos_count]\n",
              "    defaults = func.__defaults__ or ()\n",
              "    kwdefaults = func.__kwdefaults__\n",
              "    res = dict(kwdefaults) if kwdefaults else {}\n",
              "    pos_offset = pos_count - len(defaults)\n",
              "    for name, value in zip(arg_names[pos_offset:], defaults):\n",
              "        assert name not in res\n",
              "        res[name] = value\n",
              "    return res\n",
              "_allowed_types = (types.FunctionType, types.BuiltinFunctionType,\n",
              "                  types.MethodType, types.ModuleType,\n",
              "                  WrapperDescriptorType, MethodWrapperType, MethodDescriptorType)\n",
              "def get_type_hints(obj, globalns=None, localns=None, include_extras=False):\n",
              "    \"\"\"Return type hints for an object.\n",
              "    This is often the same as obj.__annotations__, but it handles\n",
              "    forward references encoded as string literals, adds Optional[t] if a\n",
              "    default value equal to None is set and recursively replaces all\n",
              "    'Annotated[T, ...]' with 'T' (unless 'include_extras=True').\n",
              "    The argument may be a module, class, method, or function. The annotations\n",
              "    are returned as a dictionary. For classes, annotations include also\n",
              "    inherited members.\n",
              "    TypeError is raised if the argument is not of a type that can contain\n",
              "    annotations, and an empty dictionary is returned if no annotations are\n",
              "    present.\n",
              "    BEWARE -- the behavior of globalns and localns is counterintuitive\n",
              "    (unless you are familiar with how eval() and exec() work).  The\n",
              "    search order is locals first, then globals.\n",
              "    - If no dict arguments are passed, an attempt is made to use the\n",
              "      globals from obj (or the respective module's globals for classes),\n",
              "      and these are also used as the locals.  If the object does not appear\n",
              "      to have globals, an empty dictionary is used.  For classes, the search\n",
              "      order is globals first then locals.\n",
              "    - If one dict argument is passed, it is used for both globals and\n",
              "      locals.\n",
              "    - If two dict arguments are passed, they specify globals and\n",
              "      locals, respectively.\n",
              "    \"\"\"\n",
              "    if getattr(obj, '__no_type_check__', None):\n",
              "        return {}\n",
              "    # Classes require a special treatment.\n",
              "    if isinstance(obj, type):\n",
              "        hints = {}\n",
              "        for base in reversed(obj.__mro__):\n",
              "            if globalns is None:\n",
              "                base_globals = getattr(sys.modules.get(base.__module__, None), '__dict__', {})\n",
              "            else:\n",
              "                base_globals = globalns\n",
              "            ann = base.__dict__.get('__annotations__', {})\n",
              "            if isinstance(ann, types.GetSetDescriptorType):\n",
              "                ann = {}\n",
              "            base_locals = dict(vars(base)) if localns is None else localns\n",
              "            if localns is None and globalns is None:\n",
              "                # This is surprising, but required.  Before Python 3.10,\n",
              "                # get_type_hints only evaluated the globalns of\n",
              "                # a class.  To maintain backwards compatibility, we reverse\n",
              "                # the globalns and localns order so that eval() looks into\n",
              "                # *base_globals* first rather than *base_locals*.\n",
              "                # This only affects ForwardRefs.\n",
              "                base_globals, base_locals = base_locals, base_globals\n",
              "            for name, value in ann.items():\n",
              "                if value is None:\n",
              "                    value = type(None)\n",
              "                if isinstance(value, str):\n",
              "                    value = ForwardRef(value, is_argument=False, is_class=True)\n",
              "                value = _eval_type(value, base_globals, base_locals)\n",
              "                hints[name] = value\n",
              "        return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}\n",
              "    if globalns is None:\n",
              "        if isinstance(obj, types.ModuleType):\n",
              "            globalns = obj.__dict__\n",
              "        else:\n",
              "            nsobj = obj\n",
              "            # Find globalns for the unwrapped object.\n",
              "            while hasattr(nsobj, '__wrapped__'):\n",
              "                nsobj = nsobj.__wrapped__\n",
              "            globalns = getattr(nsobj, '__globals__', {})\n",
              "        if localns is None:\n",
              "            localns = globalns\n",
              "    elif localns is None:\n",
              "        localns = globalns\n",
              "    hints = getattr(obj, '__annotations__', None)\n",
              "    if hints is None:\n",
              "        # Return empty annotations for something that _could_ have them.\n",
              "        if isinstance(obj, _allowed_types):\n",
              "            return {}\n",
              "        else:\n",
              "            raise TypeError('{!r} is not a module, class, method, '\n",
              "                            'or function.'.format(obj))\n",
              "    defaults = _get_defaults(obj)\n",
              "    hints = dict(hints)\n",
              "    for name, value in hints.items():\n",
              "        if value is None:\n",
              "            value = type(None)\n",
              "        if isinstance(value, str):\n",
              "            # class-level forward refs were handled above, this must be either\n",
              "            # a module-level annotation or a function argument annotation\n",
              "            value = ForwardRef(\n",
              "                value,\n",
              "                is_argument=not isinstance(obj, types.ModuleType),\n",
              "                is_class=False,\n",
              "            )\n",
              "        value = _eval_type(value, globalns, localns)\n",
              "        if name in defaults and defaults[name] is None:\n",
              "            value = Optional[value]\n",
              "        hints[name] = value\n",
              "    return hints if include_extras else {k: _strip_annotations(t) for k, t in hints.items()}\n",
              "def _strip_annotations(t):\n",
              "    \"\"\"Strips the annotations from a given type.\n",
              "    \"\"\"\n",
              "    if isinstance(t, _AnnotatedAlias):\n",
              "        return _strip_annotations(t.__origin__)\n",
              "    if isinstance(t, _GenericAlias):\n",
              "        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n",
              "        if stripped_args == t.__args__:\n",
              "            return t\n",
              "        return t.copy_with(stripped_args)\n",
              "    if isinstance(t, GenericAlias):\n",
              "        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n",
              "        if stripped_args == t.__args__:\n",
              "            return t\n",
              "        return GenericAlias(t.__origin__, stripped_args)\n",
              "    if isinstance(t, types.UnionType):\n",
              "        stripped_args = tuple(_strip_annotations(a) for a in t.__args__)\n",
              "        if stripped_args == t.__args__:\n",
              "            return t\n",
              "        return functools.reduce(operator.or_, stripped_args)\n",
              "    return t\n",
              "def get_origin(tp):\n",
              "    \"\"\"Get the unsubscripted version of a type.\n",
              "    This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar\n",
              "    and Annotated. Return None for unsupported types. Examples::\n",
              "        get_origin(Literal[42]) is Literal\n",
              "        get_origin(int) is None\n",
              "        get_origin(ClassVar[int]) is ClassVar\n",
              "        get_origin(Generic) is Generic\n",
              "        get_origin(Generic[T]) is Generic\n",
              "        get_origin(Union[T, int]) is Union\n",
              "        get_origin(List[Tuple[T, T]][int]) == list\n",
              "        get_origin(P.args) is P\n",
              "    \"\"\"\n",
              "    if isinstance(tp, _AnnotatedAlias):\n",
              "        return Annotated\n",
              "    if isinstance(tp, (_BaseGenericAlias, GenericAlias,\n",
              "                       ParamSpecArgs, ParamSpecKwargs)):\n",
              "        return tp.__origin__\n",
              "    if tp is Generic:\n",
              "        return Generic\n",
              "    if isinstance(tp, types.UnionType):\n",
              "        return types.UnionType\n",
              "    return None\n",
              "def get_args(tp):\n",
              "    \"\"\"Get type arguments with all substitutions performed.\n",
              "    For unions, basic simplifications used by Union constructor are performed.\n",
              "    Examples::\n",
              "        get_args(Dict[str, int]) == (str, int)\n",
              "        get_args(int) == ()\n",
              "        get_args(Union[int, Union[T, int], str][int]) == (int, str)\n",
              "        get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])\n",
              "        get_args(Callable[[], T][int]) == ([], int)\n",
              "    \"\"\"\n",
              "    if isinstance(tp, _AnnotatedAlias):\n",
              "        return (tp.__origin__,) + tp.__metadata__\n",
              "    if isinstance(tp, (_GenericAlias, GenericAlias)):\n",
              "        res = tp.__args__\n",
              "        if (tp.__origin__ is collections.abc.Callable\n",
              "                and not (len(res) == 2 and _is_param_expr(res[0]))):\n",
              "            res = (list(res[:-1]), res[-1])\n",
              "        return res\n",
              "    if isinstance(tp, types.UnionType):\n",
              "        return tp.__args__\n",
              "    return ()\n",
              "def is_typeddict(tp):\n",
              "    \"\"\"Check if an annotation is a TypedDict class\n",
              "    For example::\n",
              "        class Film(TypedDict):\n",
              "            title: str\n",
              "            year: int\n",
              "        is_typeddict(Film)  # => True\n",
              "        is_typeddict(Union[list, str])  # => False\n",
              "    \"\"\"\n",
              "    return isinstance(tp, _TypedDictMeta)\n",
              "def no_type_check(arg):\n",
              "    \"\"\"Decorator to indicate that annotations are not type hints.\n",
              "    The argument must be a class or function; if it is a class, it\n",
              "    applies recursively to all methods and classes defined in that class\n",
              "    (but not to methods defined in its superclasses or subclasses).\n",
              "    This mutates the function(s) or class(es) in place.\n",
              "    \"\"\"\n",
              "    if isinstance(arg, type):\n",
              "        arg_attrs = arg.__dict__.copy()\n",
              "        for attr, val in arg.__dict__.items():\n",
              "            if val in arg.__bases__ + (arg,):\n",
              "                arg_attrs.pop(attr)\n",
              "        for obj in arg_attrs.values():\n",
              "            if isinstance(obj, types.FunctionType):\n",
              "                obj.__no_type_check__ = True\n",
              "            if isinstance(obj, type):\n",
              "                no_type_check(obj)\n",
              "    try:\n",
              "        arg.__no_type_check__ = True\n",
              "    except TypeError:  # built-in classes\n",
              "        pass\n",
              "    return arg\n",
              "def no_type_check_decorator(decorator):\n",
              "    \"\"\"Decorator to give another decorator the @no_type_check effect.\n",
              "    This wraps the decorator with something that wraps the decorated\n",
              "    function in @no_type_check.\n",
              "    \"\"\"\n",
              "    @functools.wraps(decorator)\n",
              "    def wrapped_decorator(*args, **kwds):\n",
              "        func = decorator(*args, **kwds)\n",
              "        func = no_type_check(func)\n",
              "        return func\n",
              "    return wrapped_decorator\n",
              "def _overload_dummy(*args, **kwds):\n",
              "    \"\"\"Helper for @overload to raise when called.\"\"\"\n",
              "    raise NotImplementedError(\n",
              "        \"You should not call an overloaded function. \"\n",
              "        \"A series of @overload-decorated functions \"\n",
              "        \"outside a stub module should always be followed \"\n",
              "        \"by an implementation that is not @overload-ed.\")\n",
              "def overload(func):\n",
              "    \"\"\"Decorator for overloaded functions/methods.\n",
              "    In a stub file, place two or more stub definitions for the same\n",
              "    function in a row, each decorated with @overload.  For example:\n",
              "      @overload\n",
              "      def utf8(value: None) -> None: ...\n",
              "      @overload\n",
              "      def utf8(value: bytes) -> bytes: ...\n",
              "      @overload\n",
              "      def utf8(value: str) -> bytes: ...\n",
              "    In a non-stub file (i.e. a regular .py file), do the same but\n",
              "    follow it with an implementation.  The implementation should *not*\n",
              "    be decorated with @overload.  For example:\n",
              "      @overload\n",
              "      def utf8(value: None) -> None: ...\n",
              "      @overload\n",
              "      def utf8(value: bytes) -> bytes: ...\n",
              "      @overload\n",
              "      def utf8(value: str) -> bytes: ...\n",
              "      def utf8(value):\n",
              "          # implementation goes here\n",
              "    \"\"\"\n",
              "    return _overload_dummy\n",
              "def final(f):\n",
              "    \"\"\"A decorator to indicate final methods and final classes.\n",
              "    Use this decorator to indicate to type checkers that the decorated\n",
              "    method cannot be overridden, and decorated class cannot be subclassed.\n",
              "    For example:\n",
              "      class Base:\n",
              "          @final\n",
              "          def done(self) -> None:\n",
              "              ...\n",
              "      class Sub(Base):\n",
              "          def done(self) -> None:  # Error reported by type checker\n",
              "                ...\n",
              "      @final\n",
              "      class Leaf:\n",
              "          ...\n",
              "      class Other(Leaf):  # Error reported by type checker\n",
              "          ...\n",
              "    There is no runtime checking of these properties.\n",
              "    \"\"\"\n",
              "    return f\n",
              "# Some unconstrained type variables.  These are used by the container types.\n",
              "# (These are not for export.)\n",
              "T = TypeVar('T')  # Any type.\n",
              "KT = TypeVar('KT')  # Key type.\n",
              "VT = TypeVar('VT')  # Value type.\n",
              "T_co = TypeVar('T_co', covariant=True)  # Any type covariant containers.\n",
              "V_co = TypeVar('V_co', covariant=True)  # Any type covariant containers.\n",
              "VT_co = TypeVar('VT_co', covariant=True)  # Value type covariant containers.\n",
              "T_contra = TypeVar('T_contra', contravariant=True)  # Ditto contravariant.\n",
              "# Internal type variable used for Type[].\n",
              "CT_co = TypeVar('CT_co', covariant=True, bound=type)\n",
              "# A useful type variable with constraints.  This represents string types.\n",
              "# (This one *is* for export!)\n",
              "AnyStr = TypeVar('AnyStr', bytes, str)\n",
              "# Various ABCs mimicking those in collections.abc.\n",
              "_alias = _SpecialGenericAlias\n",
              "Hashable = _alias(collections.abc.Hashable, 0)  # Not generic.\n",
              "Awaitable = _alias(collections.abc.Awaitable, 1)\n",
              "Coroutine = _alias(collections.abc.Coroutine, 3)\n",
              "AsyncIterable = _alias(collections.abc.AsyncIterable, 1)\n",
              "AsyncIterator = _alias(collections.abc.AsyncIterator, 1)\n",
              "Iterable = _alias(collections.abc.Iterable, 1)\n",
              "Iterator = _alias(collections.abc.Iterator, 1)\n",
              "Reversible = _alias(collections.abc.Reversible, 1)\n",
              "Sized = _alias(collections.abc.Sized, 0)  # Not generic.\n",
              "Container = _alias(collections.abc.Container, 1)\n",
              "Collection = _alias(collections.abc.Collection, 1)\n",
              "Callable = _CallableType(collections.abc.Callable, 2)\n",
              "Callable.__doc__ = \\\n",
              "    \"\"\"Callable type; Callable[[int], str] is a function of (int) -> str.\n",
              "    The subscription syntax must always be used with exactly two\n",
              "    values: the argument list and the return type.  The argument list\n",
              "    must be a list of types or ellipsis; the return type must be a single type.\n",
              "    There is no syntax to indicate optional or keyword arguments,\n",
              "    such function types are rarely used as callback types.\n",
              "    \"\"\"\n",
              "AbstractSet = _alias(collections.abc.Set, 1, name='AbstractSet')\n",
              "MutableSet = _alias(collections.abc.MutableSet, 1)\n",
              "# NOTE: Mapping is only covariant in the value type.\n",
              "Mapping = _alias(collections.abc.Mapping, 2)\n",
              "MutableMapping = _alias(collections.abc.MutableMapping, 2)\n",
              "Sequence = _alias(collections.abc.Sequence, 1)\n",
              "MutableSequence = _alias(collections.abc.MutableSequence, 1)\n",
              "ByteString = _alias(collections.abc.ByteString, 0)  # Not generic\n",
              "# Tuple accepts variable number of parameters.\n",
              "Tuple = _TupleType(tuple, -1, inst=False, name='Tuple')\n",
              "Tuple.__doc__ = \\\n",
              "    \"\"\"Tuple type; Tuple[X, Y] is the cross-product type of X and Y.\n",
              "    Example: Tuple[T1, T2] is a tuple of two elements corresponding\n",
              "    to type variables T1 and T2.  Tuple[int, float, str] is a tuple\n",
              "    of an int, a float and a string.\n",
              "    To specify a variable-length tuple of homogeneous type, use Tuple[T, ...].\n",
              "    \"\"\"\n",
              "List = _alias(list, 1, inst=False, name='List')\n",
              "Deque = _alias(collections.deque, 1, name='Deque')\n",
              "Set = _alias(set, 1, inst=False, name='Set')\n",
              "FrozenSet = _alias(frozenset, 1, inst=False, name='FrozenSet')\n",
              "MappingView = _alias(collections.abc.MappingView, 1)\n",
              "KeysView = _alias(collections.abc.KeysView, 1)\n",
              "ItemsView = _alias(collections.abc.ItemsView, 2)\n",
              "ValuesView = _alias(collections.abc.ValuesView, 1)\n",
              "ContextManager = _alias(contextlib.AbstractContextManager, 1, name='ContextManager')\n",
              "AsyncContextManager = _alias(contextlib.AbstractAsyncContextManager, 1, name='AsyncContextManager')\n",
              "Dict = _alias(dict, 2, inst=False, name='Dict')\n",
              "DefaultDict = _alias(collections.defaultdict, 2, name='DefaultDict')\n",
              "OrderedDict = _alias(collections.OrderedDict, 2)\n",
              "Counter = _alias(collections.Counter, 1)\n",
              "ChainMap = _alias(collections.ChainMap, 2)\n",
              "Generator = _alias(collections.abc.Generator, 3)\n",
              "AsyncGenerator = _alias(collections.abc.AsyncGenerator, 2)\n",
              "Type = _alias(type, 1, inst=False, name='Type')\n",
              "Type.__doc__ = \\\n",
              "    \"\"\"A special construct usable to annotate class objects.\n",
              "    For example, suppose we have the following classes::\n",
              "      class User: ...  # Abstract base for User classes\n",
              "      class BasicUser(User): ...\n",
              "      class ProUser(User): ...\n",
              "      class TeamUser(User): ...\n",
              "    And a function that takes a class argument that's a subclass of\n",
              "    User and returns an instance of the corresponding class::\n",
              "      U = TypeVar('U', bound=User)\n",
              "      def new_user(user_class: Type[U]) -> U:\n",
              "          user = user_class()\n",
              "          # (Here we could write the user object to a database)\n",
              "          return user\n",
              "      joe = new_user(BasicUser)\n",
              "    At this point the type checker knows that joe has type BasicUser.\n",
              "    \"\"\"\n",
              "@runtime_checkable\n",
              "class SupportsInt(Protocol):\n",
              "    \"\"\"An ABC with one abstract method __int__.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __int__(self) -> int:\n",
              "        pass\n",
              "@runtime_checkable\n",
              "class SupportsFloat(Protocol):\n",
              "    \"\"\"An ABC with one abstract method __float__.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __float__(self) -> float:\n",
              "        pass\n",
              "@runtime_checkable\n",
              "class SupportsComplex(Protocol):\n",
              "    \"\"\"An ABC with one abstract method __complex__.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __complex__(self) -> complex:\n",
              "        pass\n",
              "@runtime_checkable\n",
              "class SupportsBytes(Protocol):\n",
              "    \"\"\"An ABC with one abstract method __bytes__.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __bytes__(self) -> bytes:\n",
              "        pass\n",
              "@runtime_checkable\n",
              "class SupportsIndex(Protocol):\n",
              "    \"\"\"An ABC with one abstract method __index__.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __index__(self) -> int:\n",
              "        pass\n",
              "@runtime_checkable\n",
              "class SupportsAbs(Protocol[T_co]):\n",
              "    \"\"\"An ABC with one abstract method __abs__ that is covariant in its return type.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __abs__(self) -> T_co:\n",
              "        pass\n",
              "@runtime_checkable\n",
              "class SupportsRound(Protocol[T_co]):\n",
              "    \"\"\"An ABC with one abstract method __round__ that is covariant in its return type.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def __round__(self, ndigits: int = 0) -> T_co:\n",
              "        pass\n",
              "def _make_nmtuple(name, types, module, defaults = ()):\n",
              "    fields = [n for n, t in types]\n",
              "    types = {n: _type_check(t, f\"field {n} annotation must be a type\")\n",
              "             for n, t in types}\n",
              "    nm_tpl = collections.namedtuple(name, fields,\n",
              "                                    defaults=defaults, module=module)\n",
              "    nm_tpl.__annotations__ = nm_tpl.__new__.__annotations__ = types\n",
              "    return nm_tpl\n",
              "# attributes prohibited to set in NamedTuple class syntax\n",
              "_prohibited = frozenset({'__new__', '__init__', '__slots__', '__getnewargs__',\n",
              "                         '_fields', '_field_defaults',\n",
              "                         '_make', '_replace', '_asdict', '_source'})\n",
              "_special = frozenset({'__module__', '__name__', '__annotations__'})\n",
              "class NamedTupleMeta(type):\n",
              "    def __new__(cls, typename, bases, ns):\n",
              "        assert bases[0] is _NamedTuple\n",
              "        types = ns.get('__annotations__', {})\n",
              "        default_names = []\n",
              "        for field_name in types:\n",
              "            if field_name in ns:\n",
              "                default_names.append(field_name)\n",
              "            elif default_names:\n",
              "                raise TypeError(f\"Non-default namedtuple field {field_name} \"\n",
              "                                f\"cannot follow default field\"\n",
              "                                f\"{'s' if len(default_names) > 1 else ''} \"\n",
              "                                f\"{', '.join(default_names)}\")\n",
              "        nm_tpl = _make_nmtuple(typename, types.items(),\n",
              "                               defaults=[ns[n] for n in default_names],\n",
              "                               module=ns['__module__'])\n",
              "        # update from user namespace without overriding special namedtuple attributes\n",
              "        for key in ns:\n",
              "            if key in _prohibited:\n",
              "                raise AttributeError(\"Cannot overwrite NamedTuple attribute \" + key)\n",
              "            elif key not in _special and key not in nm_tpl._fields:\n",
              "                setattr(nm_tpl, key, ns[key])\n",
              "        return nm_tpl\n",
              "def NamedTuple(typename, fields=None, /, **kwargs):\n",
              "    \"\"\"Typed version of namedtuple.\n",
              "    Usage in Python versions >= 3.6::\n",
              "        class Employee(NamedTuple):\n",
              "            name: str\n",
              "            id: int\n",
              "    This is equivalent to::\n",
              "        Employee = collections.namedtuple('Employee', ['name', 'id'])\n",
              "    The resulting class has an extra __annotations__ attribute, giving a\n",
              "    dict that maps field names to types.  (The field names are also in\n",
              "    the _fields attribute, which is part of the namedtuple API.)\n",
              "    Alternative equivalent keyword syntax is also accepted::\n",
              "        Employee = NamedTuple('Employee', name=str, id=int)\n",
              "    In Python versions <= 3.5 use::\n",
              "        Employee = NamedTuple('Employee', [('name', str), ('id', int)])\n",
              "    \"\"\"\n",
              "    if fields is None:\n",
              "        fields = kwargs.items()\n",
              "    elif kwargs:\n",
              "        raise TypeError(\"Either list of fields or keywords\"\n",
              "                        \" can be provided to NamedTuple, not both\")\n",
              "    try:\n",
              "        module = sys._getframe(1).f_globals.get('__name__', '__main__')\n",
              "    except (AttributeError, ValueError):\n",
              "        module = None\n",
              "    return _make_nmtuple(typename, fields, module=module)\n",
              "_NamedTuple = type.__new__(NamedTupleMeta, 'NamedTuple', (), {})\n",
              "def _namedtuple_mro_entries(bases):\n",
              "    if len(bases) > 1:\n",
              "        raise TypeError(\"Multiple inheritance with NamedTuple is not supported\")\n",
              "    assert bases[0] is NamedTuple\n",
              "    return (_NamedTuple,)\n",
              "NamedTuple.__mro_entries__ = _namedtuple_mro_entries\n",
              "class _TypedDictMeta(type):\n",
              "    def __new__(cls, name, bases, ns, total=True):\n",
              "        \"\"\"Create new typed dict class object.\n",
              "        This method is called when TypedDict is subclassed,\n",
              "        or when TypedDict is instantiated. This way\n",
              "        TypedDict supports all three syntax forms described in its docstring.\n",
              "        Subclasses and instances of TypedDict return actual dictionaries.\n",
              "        \"\"\"\n",
              "        for base in bases:\n",
              "            if type(base) is not _TypedDictMeta:\n",
              "                raise TypeError('cannot inherit from both a TypedDict type '\n",
              "                                'and a non-TypedDict base class')\n",
              "        tp_dict = type.__new__(_TypedDictMeta, name, (dict,), ns)\n",
              "        annotations = {}\n",
              "        own_annotations = ns.get('__annotations__', {})\n",
              "        own_annotation_keys = set(own_annotations.keys())\n",
              "        msg = \"TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type\"\n",
              "        own_annotations = {\n",
              "            n: _type_check(tp, msg, module=tp_dict.__module__)\n",
              "            for n, tp in own_annotations.items()\n",
              "        }\n",
              "        required_keys = set()\n",
              "        optional_keys = set()\n",
              "        for base in bases:\n",
              "            annotations.update(base.__dict__.get('__annotations__', {}))\n",
              "            required_keys.update(base.__dict__.get('__required_keys__', ()))\n",
              "            optional_keys.update(base.__dict__.get('__optional_keys__', ()))\n",
              "        annotations.update(own_annotations)\n",
              "        if total:\n",
              "            required_keys.update(own_annotation_keys)\n",
              "        else:\n",
              "            optional_keys.update(own_annotation_keys)\n",
              "        tp_dict.__annotations__ = annotations\n",
              "        tp_dict.__required_keys__ = frozenset(required_keys)\n",
              "        tp_dict.__optional_keys__ = frozenset(optional_keys)\n",
              "        if not hasattr(tp_dict, '__total__'):\n",
              "            tp_dict.__total__ = total\n",
              "        return tp_dict\n",
              "    __call__ = dict  # static method\n",
              "    def __subclasscheck__(cls, other):\n",
              "        # Typed dicts are only for static structural subtyping.\n",
              "        raise TypeError('TypedDict does not support instance and class checks')\n",
              "    __instancecheck__ = __subclasscheck__\n",
              "def TypedDict(typename, fields=None, /, *, total=True, **kwargs):\n",
              "    \"\"\"A simple typed namespace. At runtime it is equivalent to a plain dict.\n",
              "    TypedDict creates a dictionary type that expects all of its\n",
              "    instances to have a certain set of keys, where each key is\n",
              "    associated with a value of a consistent type. This expectation\n",
              "    is not checked at runtime but is only enforced by type checkers.\n",
              "    Usage::\n",
              "        class Point2D(TypedDict):\n",
              "            x: int\n",
              "            y: int\n",
              "            label: str\n",
              "        a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK\n",
              "        b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check\n",
              "        assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')\n",
              "    The type info can be accessed via the Point2D.__annotations__ dict, and\n",
              "    the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.\n",
              "    TypedDict supports two additional equivalent forms::\n",
              "        Point2D = TypedDict('Point2D', x=int, y=int, label=str)\n",
              "        Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})\n",
              "    By default, all keys must be present in a TypedDict. It is possible\n",
              "    to override this by specifying totality.\n",
              "    Usage::\n",
              "        class point2D(TypedDict, total=False):\n",
              "            x: int\n",
              "            y: int\n",
              "    This means that a point2D TypedDict can have any of the keys omitted.A type\n",
              "    checker is only expected to support a literal False or True as the value of\n",
              "    the total argument. True is the default, and makes all items defined in the\n",
              "    class body be required.\n",
              "    The class syntax is only supported in Python 3.6+, while two other\n",
              "    syntax forms work for Python 2.7 and 3.2+\n",
              "    \"\"\"\n",
              "    if fields is None:\n",
              "        fields = kwargs\n",
              "    elif kwargs:\n",
              "        raise TypeError(\"TypedDict takes either a dict or keyword arguments,\"\n",
              "                        \" but not both\")\n",
              "    ns = {'__annotations__': dict(fields)}\n",
              "    try:\n",
              "        # Setting correct module is necessary to make typed dict classes pickleable.\n",
              "        ns['__module__'] = sys._getframe(1).f_globals.get('__name__', '__main__')\n",
              "    except (AttributeError, ValueError):\n",
              "        pass\n",
              "    return _TypedDictMeta(typename, (), ns, total=total)\n",
              "_TypedDict = type.__new__(_TypedDictMeta, 'TypedDict', (), {})\n",
              "TypedDict.__mro_entries__ = lambda bases: (_TypedDict,)\n",
              "class NewType:\n",
              "    \"\"\"NewType creates simple unique types with almost zero\n",
              "    runtime overhead. NewType(name, tp) is considered a subtype of tp\n",
              "    by static type checkers. At runtime, NewType(name, tp) returns\n",
              "    a dummy callable that simply returns its argument. Usage::\n",
              "        UserId = NewType('UserId', int)\n",
              "        def name_by_id(user_id: UserId) -> str:\n",
              "            ...\n",
              "        UserId('user')          # Fails type check\n",
              "        name_by_id(42)          # Fails type check\n",
              "        name_by_id(UserId(42))  # OK\n",
              "        num = UserId(5) + 1     # type: int\n",
              "    \"\"\"\n",
              "    def __init__(self, name, tp):\n",
              "        self.__qualname__ = name\n",
              "        if '.' in name:\n",
              "            name = name.rpartition('.')[-1]\n",
              "        self.__name__ = name\n",
              "        self.__supertype__ = tp\n",
              "        def_mod = _caller()\n",
              "        if def_mod != 'typing':\n",
              "            self.__module__ = def_mod\n",
              "    def __repr__(self):\n",
              "        return f'{self.__module__}.{self.__qualname__}'\n",
              "    def __call__(self, x):\n",
              "        return x\n",
              "    def __reduce__(self):\n",
              "        return self.__qualname__\n",
              "    def __or__(self, other):\n",
              "        return Union[self, other]\n",
              "    def __ror__(self, other):\n",
              "        return Union[other, self]\n",
              "# Python-version-specific alias (Python 2: unicode; Python 3: str)\n",
              "Text = str\n",
              "# Constant that's True when type checking, but False here.\n",
              "TYPE_CHECKING = False\n",
              "class IO(Generic[AnyStr]):\n",
              "    \"\"\"Generic base class for TextIO and BinaryIO.\n",
              "    This is an abstract, generic version of the return of open().\n",
              "    NOTE: This does not distinguish between the different possible\n",
              "    classes (text vs. binary, read vs. write vs. read/write,\n",
              "    append-only, unbuffered).  The TextIO and BinaryIO subclasses\n",
              "    below capture the distinctions between text vs. binary, which is\n",
              "    pervasive in the interface; however we currently do not offer a\n",
              "    way to track the other distinctions in the type system.\n",
              "    \"\"\"\n",
              "    __slots__ = ()\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def mode(self) -> str:\n",
              "        pass\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def name(self) -> str:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def close(self) -> None:\n",
              "        pass\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def closed(self) -> bool:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def fileno(self) -> int:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def flush(self) -> None:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def isatty(self) -> bool:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def read(self, n: int = -1) -> AnyStr:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def readable(self) -> bool:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def readline(self, limit: int = -1) -> AnyStr:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def readlines(self, hint: int = -1) -> List[AnyStr]:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def seek(self, offset: int, whence: int = 0) -> int:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def seekable(self) -> bool:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def tell(self) -> int:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def truncate(self, size: int = None) -> int:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def writable(self) -> bool:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def write(self, s: AnyStr) -> int:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def writelines(self, lines: List[AnyStr]) -> None:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def __enter__(self) -> 'IO[AnyStr]':\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def __exit__(self, type, value, traceback) -> None:\n",
              "        pass\n",
              "class BinaryIO(IO[bytes]):\n",
              "    \"\"\"Typed version of the return of open() in binary mode.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @abstractmethod\n",
              "    def write(self, s: Union[bytes, bytearray]) -> int:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def __enter__(self) -> 'BinaryIO':\n",
              "        pass\n",
              "class TextIO(IO[str]):\n",
              "    \"\"\"Typed version of the return of open() in text mode.\"\"\"\n",
              "    __slots__ = ()\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def buffer(self) -> BinaryIO:\n",
              "        pass\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def encoding(self) -> str:\n",
              "        pass\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def errors(self) -> Optional[str]:\n",
              "        pass\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def line_buffering(self) -> bool:\n",
              "        pass\n",
              "    @property\n",
              "    @abstractmethod\n",
              "    def newlines(self) -> Any:\n",
              "        pass\n",
              "    @abstractmethod\n",
              "    def __enter__(self) -> 'TextIO':\n",
              "        pass\n",
              "class io:\n",
              "    \"\"\"Wrapper namespace for IO generic classes.\"\"\"\n",
              "    __all__ = ['IO', 'TextIO', 'BinaryIO']\n",
              "    IO = IO\n",
              "    TextIO = TextIO\n",
              "    BinaryIO = BinaryIO\n",
              "io.__name__ = __name__ + '.io'\n",
              "sys.modules[io.__name__] = io\n",
              "Pattern = _alias(stdlib_re.Pattern, 1)\n",
              "Match = _alias(stdlib_re.Match, 1)\n",
              "class re:\n",
              "    \"\"\"Wrapper namespace for re type aliases.\"\"\"\n",
              "    __all__ = ['Pattern', 'Match']\n",
              "    Pattern = Pattern\n",
              "    Match = Match\n",
              "re.__name__ = __name__ + '.re'\n",
              "sys.modules[re.__name__] = re</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[3055]=================</br><pre><code class=\"python\">Source code for langchain_core.runnables.base\n",
              "from __future__ import annotations\n",
              "import asyncio\n",
              "import collections\n",
              "import inspect\n",
              "import threading\n",
              "from abc import ABC, abstractmethod\n",
              "from concurrent.futures import FIRST_COMPLETED, wait\n",
              "from contextvars import copy_context\n",
              "from functools import wraps\n",
              "from itertools import groupby, tee\n",
              "from operator import itemgetter\n",
              "from typing import (\n",
              "    TYPE_CHECKING,\n",
              "    Any,\n",
              "    AsyncIterator,\n",
              "    Awaitable,\n",
              "    Callable,\n",
              "    Coroutine,\n",
              "    Dict,\n",
              "    Generic,\n",
              "    Iterator,\n",
              "    List,\n",
              "    Mapping,\n",
              "    Optional,\n",
              "    Sequence,\n",
              "    Set,\n",
              "    Tuple,\n",
              "    Type,\n",
              "    TypeVar,\n",
              "    Union,\n",
              "    cast,\n",
              "    overload,\n",
              ")\n",
              "from typing_extensions import Literal, get_args\n",
              "from langchain_core._api import beta_decorator\n",
              "from langchain_core.load.dump import dumpd\n",
              "from langchain_core.load.serializable import (\n",
              "    Serializable,\n",
              "    SerializedConstructor,\n",
              "    SerializedNotImplemented,\n",
              ")\n",
              "from langchain_core.pydantic_v1 import BaseModel, Field\n",
              "from langchain_core.runnables.config import (\n",
              "    RunnableConfig,\n",
              "    acall_func_with_variable_args,\n",
              "    call_func_with_variable_args,\n",
              "    ensure_config,\n",
              "    get_async_callback_manager_for_config,\n",
              "    get_callback_manager_for_config,\n",
              "    get_config_list,\n",
              "    get_executor_for_config,\n",
              "    merge_configs,\n",
              "    patch_config,\n",
              "    run_in_executor,\n",
              "    var_child_runnable_config,\n",
              ")\n",
              "from langchain_core.runnables.graph import Graph\n",
              "from langchain_core.runnables.schema import EventData, StreamEvent\n",
              "from langchain_core.runnables.utils import (\n",
              "    AddableDict,\n",
              "    AnyConfigurableField,\n",
              "    ConfigurableField,\n",
              "    ConfigurableFieldSpec,\n",
              "    Input,\n",
              "    Output,\n",
              "    accepts_config,\n",
              "    accepts_context,\n",
              "    accepts_run_manager,\n",
              "    adapt_first_streaming_chunk,\n",
              "    create_model,\n",
              "    gather_with_concurrency,\n",
              "    get_function_first_arg_dict_keys,\n",
              "    get_function_nonlocals,\n",
              "    get_lambda_source,\n",
              "    get_unique_config_specs,\n",
              "    indent_lines_after_first,\n",
              ")\n",
              "from langchain_core.utils.aiter import atee, py_anext\n",
              "from langchain_core.utils.iter import safetee\n",
              "if TYPE_CHECKING:\n",
              "    from langchain_core.callbacks.manager import (\n",
              "        AsyncCallbackManagerForChainRun,\n",
              "        CallbackManagerForChainRun,\n",
              "    )\n",
              "    from langchain_core.prompts.base import BasePromptTemplate\n",
              "    from langchain_core.runnables.fallbacks import (\n",
              "        RunnableWithFallbacks as RunnableWithFallbacksT,\n",
              "    )\n",
              "    from langchain_core.tracers.log_stream import (\n",
              "        LogEntry,\n",
              "        RunLog,\n",
              "        RunLogPatch,\n",
              "    )\n",
              "    from langchain_core.tracers.root_listeners import Listener\n",
              "Other = TypeVar(\"Other\")\n",
              "[docs]class Runnable(Generic[Input, Output], ABC):\n",
              "    \"\"\"A unit of work that can be invoked, batched, streamed, transformed and composed.\n",
              "     Key Methods\n",
              "     ===========\n",
              "    - **invoke/ainvoke**: Transforms a single input into an output.\n",
              "    - **batch/abatch**: Efficiently transforms multiple inputs into outputs.\n",
              "    - **stream/astream**: Streams output from a single input as it's produced.\n",
              "    - **astream_log**: Streams output and selected intermediate results from an input.\n",
              "    Built-in optimizations:\n",
              "    - **Batch**: By default, batch runs invoke() in parallel using a thread pool executor.\n",
              "             Override to optimize batching.\n",
              "    - **Async**: Methods with \"a\" suffix are asynchronous. By default, they execute\n",
              "             the sync counterpart using asyncio's thread pool.\n",
              "             Override for native async.\n",
              "    All methods accept an optional config argument, which can be used to configure\n",
              "    execution, add tags and metadata for tracing and debugging etc.\n",
              "    Runnables expose schematic information about their input, output and config via\n",
              "    the input_schema property, the output_schema property and config_schema method.\n",
              "    LCEL and Composition\n",
              "    ====================\n",
              "    The LangChain Expression Language (LCEL) is a declarative way to compose Runnables\n",
              "    into chains. Any chain constructed this way will automatically have sync, async,\n",
              "    batch, and streaming support.\n",
              "    The main composition primitives are RunnableSequence and RunnableParallel.\n",
              "    RunnableSequence invokes a series of runnables sequentially, with one runnable's\n",
              "    output serving as the next's input. Construct using the `|` operator or by\n",
              "    passing a list of runnables to RunnableSequence.\n",
              "    RunnableParallel invokes runnables concurrently, providing the same input\n",
              "    to each. Construct it using a dict literal within a sequence or by passing a\n",
              "    dict to RunnableParallel.\n",
              "    For example,\n",
              "    .. code-block:: python\n",
              "        from langchain_core.runnables import RunnableLambda\n",
              "        # A RunnableSequence constructed using the `|` operator\n",
              "        sequence = RunnableLambda(lambda x: x + 1) | RunnableLambda(lambda x: x * 2)\n",
              "        sequence.invoke(1) # 4\n",
              "        sequence.batch([1, 2, 3]) # [4, 6, 8]\n",
              "        # A sequence that contains a RunnableParallel constructed using a dict literal\n",
              "        sequence = RunnableLambda(lambda x: x + 1) | {\n",
              "            'mul_2': RunnableLambda(lambda x: x * 2),\n",
              "            'mul_5': RunnableLambda(lambda x: x * 5)\n",
              "        }\n",
              "        sequence.invoke(1) # {'mul_2': 4, 'mul_5': 10}\n",
              "    Standard Methods\n",
              "    ================\n",
              "    All Runnables expose additional methods that can be used to modify their behavior\n",
              "    (e.g., add a retry policy, add lifecycle listeners, make them configurable, etc.).\n",
              "    These methods will work on any Runnable, including Runnable chains constructed\n",
              "    by composing other Runnables. See the individual methods for details.\n",
              "    For example,\n",
              "    .. code-block:: python\n",
              "        from langchain_core.runnables import RunnableLambda\n",
              "        import random\n",
              "        def add_one(x: int) -> int:\n",
              "            return x + 1\n",
              "        def buggy_double(y: int) -> int:\n",
              "            '''Buggy code that will fail 70% of the time'''\n",
              "            if random.random() > 0.3:\n",
              "                print('This code failed, and will probably be retried!')  # noqa: T201\n",
              "                raise ValueError('Triggered buggy code')\n",
              "            return y * 2\n",
              "        sequence = (\n",
              "            RunnableLambda(add_one) |\n",
              "            RunnableLambda(buggy_double).with_retry( # Retry on failure\n",
              "                stop_after_attempt=10,\n",
              "                wait_exponential_jitter=False\n",
              "            )\n",
              "        )\n",
              "        print(sequence.input_schema.schema()) # Show inferred input schema\n",
              "        print(sequence.output_schema.schema()) # Show inferred output schema\n",
              "        print(sequence.invoke(2)) # invoke the sequence (note the retry above!!)\n",
              "    Debugging and tracing\n",
              "    =====================\n",
              "    As the chains get longer, it can be useful to be able to see intermediate results\n",
              "    to debug and trace the chain.\n",
              "    You can set the global debug flag to True to enable debug output for all chains:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.globals import set_debug\n",
              "            set_debug(True)\n",
              "    Alternatively, you can pass existing or custom callbacks to any given chain:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.tracers import ConsoleCallbackHandler\n",
              "            chain.invoke(\n",
              "                ...,\n",
              "                config={'callbacks': [ConsoleCallbackHandler()]}\n",
              "            )\n",
              "    For a UI (and much more) checkout LangSmith: https://docs.smith.langchain.com/\n",
              "    \"\"\"  # noqa: E501\n",
              "    name: Optional[str] = None\n",
              "    \"\"\"The name of the runnable. Used for debugging and tracing.\"\"\"\n",
              "[docs]    def get_name(\n",
              "        self, suffix: Optional[str] = None, *, name: Optional[str] = None\n",
              "    ) -> str:\n",
              "        \"\"\"Get the name of the runnable.\"\"\"\n",
              "        name = name or self.name or self.__class__.__name__\n",
              "        if suffix:\n",
              "            if name[0].isupper():\n",
              "                return name + suffix.title()\n",
              "            else:\n",
              "                return name + \"_\" + suffix.lower()\n",
              "        else:\n",
              "            return name\n",
              "    @property\n",
              "    def InputType(self) -> Type[Input]:\n",
              "        \"\"\"The type of input this runnable accepts specified as a type annotation.\"\"\"\n",
              "        for cls in self.__class__.__orig_bases__:  # type: ignore[attr-defined]\n",
              "            type_args = get_args(cls)\n",
              "            if type_args and len(type_args) == 2:\n",
              "                return type_args[0]\n",
              "        raise TypeError(\n",
              "            f\"Runnable {self.get_name()} doesn't have an inferable InputType. \"\n",
              "            \"Override the InputType property to specify the input type.\"\n",
              "        )\n",
              "    @property\n",
              "    def OutputType(self) -> Type[Output]:\n",
              "        \"\"\"The type of output this runnable produces specified as a type annotation.\"\"\"\n",
              "        for cls in self.__class__.__orig_bases__:  # type: ignore[attr-defined]\n",
              "            type_args = get_args(cls)\n",
              "            if type_args and len(type_args) == 2:\n",
              "                return type_args[1]\n",
              "        raise TypeError(\n",
              "            f\"Runnable {self.get_name()} doesn't have an inferable OutputType. \"\n",
              "            \"Override the OutputType property to specify the output type.\"\n",
              "        )\n",
              "    @property\n",
              "    def input_schema(self) -> Type[BaseModel]:\n",
              "        \"\"\"The type of input this runnable accepts specified as a pydantic model.\"\"\"\n",
              "        return self.get_input_schema()\n",
              "[docs]    def get_input_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        \"\"\"Get a pydantic model that can be used to validate input to the runnable.\n",
              "        Runnables that leverage the configurable_fields and configurable_alternatives\n",
              "        methods will have a dynamic input schema that depends on which\n",
              "        configuration the runnable is invoked with.\n",
              "        This method allows to get an input schema for a specific configuration.\n",
              "        Args:\n",
              "            config: A config to use when generating the schema.\n",
              "        Returns:\n",
              "            A pydantic model that can be used to validate input.\n",
              "        \"\"\"\n",
              "        root_type = self.InputType\n",
              "        if inspect.isclass(root_type) and issubclass(root_type, BaseModel):\n",
              "            return root_type\n",
              "        return create_model(\n",
              "            self.get_name(\"Input\"),\n",
              "            __root__=(root_type, None),\n",
              "        )\n",
              "    @property\n",
              "    def output_schema(self) -> Type[BaseModel]:\n",
              "        \"\"\"The type of output this runnable produces specified as a pydantic model.\"\"\"\n",
              "        return self.get_output_schema()\n",
              "[docs]    def get_output_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        \"\"\"Get a pydantic model that can be used to validate output to the runnable.\n",
              "        Runnables that leverage the configurable_fields and configurable_alternatives\n",
              "        methods will have a dynamic output schema that depends on which\n",
              "        configuration the runnable is invoked with.\n",
              "        This method allows to get an output schema for a specific configuration.\n",
              "        Args:\n",
              "            config: A config to use when generating the schema.\n",
              "        Returns:\n",
              "            A pydantic model that can be used to validate output.\n",
              "        \"\"\"\n",
              "        root_type = self.OutputType\n",
              "        if inspect.isclass(root_type) and issubclass(root_type, BaseModel):\n",
              "            return root_type\n",
              "        return create_model(\n",
              "            self.get_name(\"Output\"),\n",
              "            __root__=(root_type, None),\n",
              "        )\n",
              "    @property\n",
              "    def config_specs(self) -> List[ConfigurableFieldSpec]:\n",
              "        \"\"\"List configurable fields for this runnable.\"\"\"\n",
              "        return []\n",
              "[docs]    def config_schema(\n",
              "        self, *, include: Optional[Sequence[str]] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        \"\"\"The type of config this runnable accepts specified as a pydantic model.\n",
              "        To mark a field as configurable, see the `configurable_fields`\n",
              "        and `configurable_alternatives` methods.\n",
              "        Args:\n",
              "            include: A list of fields to include in the config schema.\n",
              "        Returns:\n",
              "            A pydantic model that can be used to validate config.\n",
              "        \"\"\"\n",
              "        include = include or []\n",
              "        config_specs = self.config_specs\n",
              "        configurable = (\n",
              "            create_model(  # type: ignore[call-overload]\n",
              "                \"Configurable\",\n",
              "                **{\n",
              "                    spec.id: (\n",
              "                        spec.annotation,\n",
              "                        Field(\n",
              "                            spec.default, title=spec.name, description=spec.description\n",
              "                        ),\n",
              "                    )\n",
              "                    for spec in config_specs\n",
              "                },\n",
              "            )\n",
              "            if config_specs\n",
              "            else None\n",
              "        )\n",
              "        return create_model(  # type: ignore[call-overload]\n",
              "            self.get_name(\"Config\"),\n",
              "            **({\"configurable\": (configurable, None)} if configurable else {}),\n",
              "            **{\n",
              "                field_name: (field_type, None)\n",
              "                for field_name, field_type in RunnableConfig.__annotations__.items()\n",
              "                if field_name in [i for i in include if i != \"configurable\"]\n",
              "            },\n",
              "        )\n",
              "[docs]    def get_graph(self, config: Optional[RunnableConfig] = None) -> Graph:\n",
              "        \"\"\"Return a graph representation of this runnable.\"\"\"\n",
              "        from langchain_core.runnables.graph import Graph\n",
              "        graph = Graph()\n",
              "        input_node = graph.add_node(self.get_input_schema(config))\n",
              "        runnable_node = graph.add_node(self)\n",
              "        output_node = graph.add_node(self.get_output_schema(config))\n",
              "        graph.add_edge(input_node, runnable_node)\n",
              "        graph.add_edge(runnable_node, output_node)\n",
              "        return graph\n",
              "[docs]    def get_prompts(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> List[BasePromptTemplate]:\n",
              "        from langchain_core.prompts.base import BasePromptTemplate\n",
              "        prompts = []\n",
              "        for _, node in self.get_graph(config=config).nodes.items():\n",
              "            if isinstance(node.data, BasePromptTemplate):\n",
              "                prompts.append(node.data)\n",
              "        return prompts\n",
              "    def __or__(\n",
              "        self,\n",
              "        other: Union[\n",
              "            Runnable[Any, Other],\n",
              "            Callable[[Any], Other],\n",
              "            Callable[[Iterator[Any]], Iterator[Other]],\n",
              "            Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]],\n",
              "        ],\n",
              "    ) -> RunnableSerializable[Input, Other]:\n",
              "        \"\"\"Compose this runnable with another object to create a RunnableSequence.\"\"\"\n",
              "        return RunnableSequence(self, coerce_to_runnable(other))\n",
              "    def __ror__(\n",
              "        self,\n",
              "        other: Union[\n",
              "            Runnable[Other, Any],\n",
              "            Callable[[Other], Any],\n",
              "            Callable[[Iterator[Other]], Iterator[Any]],\n",
              "            Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]],\n",
              "        ],\n",
              "    ) -> RunnableSerializable[Other, Output]:\n",
              "        \"\"\"Compose this runnable with another object to create a RunnableSequence.\"\"\"\n",
              "        return RunnableSequence(coerce_to_runnable(other), self)\n",
              "[docs]    def pipe(\n",
              "        self,\n",
              "        *others: Union[Runnable[Any, Other], Callable[[Any], Other]],\n",
              "        name: Optional[str] = None,\n",
              "    ) -> RunnableSerializable[Input, Other]:\n",
              "        \"\"\"Compose this Runnable with Runnable-like objects to make a RunnableSequence.\n",
              "        Equivalent to `RunnableSequence(self, *others)` or `self | others[0] | ...`\n",
              "        Example:\n",
              "            .. code-block:: python\n",
              "                from langchain_core.runnables import RunnableLambda\n",
              "                def add_one(x: int) -> int:\n",
              "                    return x + 1\n",
              "                def mul_two(x: int) -> int:\n",
              "                    return x * 2\n",
              "                runnable_1 = RunnableLambda(add_one)\n",
              "                runnable_2 = RunnableLambda(mul_two)\n",
              "                sequence = runnable_1.pipe(runnable_2)\n",
              "                # Or equivalently:\n",
              "                # sequence = runnable_1 | runnable_2\n",
              "                # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
              "                sequence.invoke(1)\n",
              "                await sequence.ainvoke(1)\n",
              "                # -> 4\n",
              "                sequence.batch([1, 2, 3])\n",
              "                await sequence.abatch([1, 2, 3])\n",
              "                # -> [4, 6, 8]\n",
              "        \"\"\"\n",
              "        return RunnableSequence(self, *others, name=name)\n",
              "[docs]    def pick(self, keys: Union[str, List[str]]) -> RunnableSerializable[Any, Any]:\n",
              "        \"\"\"Pick keys from the dict output of this runnable.\n",
              "        Pick single key:\n",
              "            .. code-block:: python\n",
              "                import json\n",
              "                from langchain_core.runnables import RunnableLambda, RunnableMap\n",
              "                as_str = RunnableLambda(str)\n",
              "                as_json = RunnableLambda(json.loads)\n",
              "                chain = RunnableMap(str=as_str, json=as_json)\n",
              "                chain.invoke(\"[1, 2, 3]\")\n",
              "                # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3]}\n",
              "                json_only_chain = chain.pick(\"json\")\n",
              "                json_only_chain.invoke(\"[1, 2, 3]\")\n",
              "                # -> [1, 2, 3]\n",
              "        Pick list of keys:\n",
              "            .. code-block:: python\n",
              "                from typing import Any\n",
              "                import json\n",
              "                from langchain_core.runnables import RunnableLambda, RunnableMap\n",
              "                as_str = RunnableLambda(str)\n",
              "                as_json = RunnableLambda(json.loads)\n",
              "                def as_bytes(x: Any) -> bytes:\n",
              "                    return bytes(x, \"utf-8\")\n",
              "                chain = RunnableMap(\n",
              "                    str=as_str,\n",
              "                    json=as_json,\n",
              "                    bytes=RunnableLambda(as_bytes)\n",
              "                )\n",
              "                chain.invoke(\"[1, 2, 3]\")\n",
              "                # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
              "                json_and_bytes_chain = chain.pick([\"json\", \"bytes\"])\n",
              "                json_and_bytes_chain.invoke(\"[1, 2, 3]\")\n",
              "                # -> {\"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
              "        \"\"\"  # noqa: E501\n",
              "        from langchain_core.runnables.passthrough import RunnablePick\n",
              "        return self | RunnablePick(keys)\n",
              "[docs]    def assign(\n",
              "        self,\n",
              "        **kwargs: Union[\n",
              "            Runnable[Dict[str, Any], Any],\n",
              "            Callable[[Dict[str, Any]], Any],\n",
              "            Mapping[\n",
              "                str,\n",
              "                Union[Runnable[Dict[str, Any], Any], Callable[[Dict[str, Any]], Any]],\n",
              "            ],\n",
              "        ],\n",
              "    ) -> RunnableSerializable[Any, Any]:\n",
              "        \"\"\"Assigns new fields to the dict output of this runnable.\n",
              "        Returns a new runnable.\n",
              "        .. code-block:: python\n",
              "            from langchain_community.llms.fake import FakeStreamingListLLM\n",
              "            from langchain_core.output_parsers import StrOutputParser\n",
              "            from langchain_core.prompts import SystemMessagePromptTemplate\n",
              "            from langchain_core.runnables import Runnable\n",
              "            from operator import itemgetter\n",
              "            prompt = (\n",
              "                SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
              "                + \"{question}\"\n",
              "            )\n",
              "            llm = FakeStreamingListLLM(responses=[\"foo-lish\"])\n",
              "            chain: Runnable = prompt | llm | {\"str\": StrOutputParser()}\n",
              "            chain_with_assign = chain.assign(hello=itemgetter(\"str\") | llm)\n",
              "            print(chain_with_assign.input_schema.schema())\n",
              "            # {'title': 'PromptInput', 'type': 'object', 'properties':\n",
              "            {'question': {'title': 'Question', 'type': 'string'}}}\n",
              "            print(chain_with_assign.output_schema.schema()) #\n",
              "            {'title': 'RunnableSequenceOutput', 'type': 'object', 'properties':\n",
              "            {'str': {'title': 'Str',\n",
              "            'type': 'string'}, 'hello': {'title': 'Hello', 'type': 'string'}}}\n",
              "        \"\"\"\n",
              "        from langchain_core.runnables.passthrough import RunnableAssign\n",
              "        return self | RunnableAssign(RunnableParallel(kwargs))\n",
              "    \"\"\" --- Public API --- \"\"\"\n",
              "[docs]    @abstractmethod\n",
              "    def invoke(self, input: Input, config: Optional[RunnableConfig] = None) -> Output:\n",
              "        \"\"\"Transform a single input into an output. Override to implement.\n",
              "        Args:\n",
              "            input: The input to the runnable.\n",
              "            config: A config to use when invoking the runnable.\n",
              "               The config supports standard keys like 'tags', 'metadata' for tracing\n",
              "               purposes, 'max_concurrency' for controlling how much work to do\n",
              "               in parallel, and other keys. Please refer to the RunnableConfig\n",
              "               for more details.\n",
              "        Returns:\n",
              "            The output of the runnable.\n",
              "        \"\"\"\n",
              "[docs]    async def ainvoke(\n",
              "        self, input: Input, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
              "    ) -> Output:\n",
              "        \"\"\"Default implementation of ainvoke, calls invoke from a thread.\n",
              "        The default implementation allows usage of async code even if\n",
              "        the runnable did not implement a native async version of invoke.\n",
              "        Subclasses should override this method if they can run asynchronously.\n",
              "        \"\"\"\n",
              "        return await run_in_executor(config, self.invoke, input, config, **kwargs)\n",
              "[docs]    def batch(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        \"\"\"Default implementation runs invoke in parallel using a thread pool executor.\n",
              "        The default implementation of batch works well for IO bound runnables.\n",
              "        Subclasses should override this method if they can batch more efficiently;\n",
              "        e.g., if the underlying runnable uses an API which supports a batch mode.\n",
              "        \"\"\"\n",
              "        if not inputs:\n",
              "            return []\n",
              "        configs = get_config_list(config, len(inputs))\n",
              "        def invoke(input: Input, config: RunnableConfig) -> Union[Output, Exception]:\n",
              "            if return_exceptions:\n",
              "                try:\n",
              "                    return self.invoke(input, config, **kwargs)\n",
              "                except Exception as e:\n",
              "                    return e\n",
              "            else:\n",
              "                return self.invoke(input, config, **kwargs)\n",
              "        # If there's only one input, don't bother with the executor\n",
              "        if len(inputs) == 1:\n",
              "            return cast(List[Output], [invoke(inputs[0], configs[0])])\n",
              "        with get_executor_for_config(configs[0]) as executor:\n",
              "            return cast(List[Output], list(executor.map(invoke, inputs, configs)))\n",
              "    @overload\n",
              "    def batch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[False] = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Tuple[int, Output]]:\n",
              "        ...\n",
              "    @overload\n",
              "    def batch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[True],\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        ...\n",
              "[docs]    def batch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        \"\"\"Run invoke in parallel on a list of inputs,\n",
              "        yielding results as they complete.\"\"\"\n",
              "        if not inputs:\n",
              "            return\n",
              "        configs = get_config_list(config, len(inputs))\n",
              "        def invoke(\n",
              "            i: int, input: Input, config: RunnableConfig\n",
              "        ) -> Tuple[int, Union[Output, Exception]]:\n",
              "            if return_exceptions:\n",
              "                try:\n",
              "                    out: Union[Output, Exception] = self.invoke(input, config, **kwargs)\n",
              "                except Exception as e:\n",
              "                    out = e\n",
              "            else:\n",
              "                out = self.invoke(input, config, **kwargs)\n",
              "            return (i, out)\n",
              "        if len(inputs) == 1:\n",
              "            yield invoke(0, inputs[0], configs[0])\n",
              "            return\n",
              "        with get_executor_for_config(configs[0]) as executor:\n",
              "            futures = {\n",
              "                executor.submit(invoke, i, input, config)\n",
              "                for i, (input, config) in enumerate(zip(inputs, configs))\n",
              "            }\n",
              "            try:\n",
              "                while futures:\n",
              "                    done, futures = wait(futures, return_when=FIRST_COMPLETED)\n",
              "                    while done:\n",
              "                        yield done.pop().result()\n",
              "            finally:\n",
              "                for future in futures:\n",
              "                    future.cancel()\n",
              "[docs]    async def abatch(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        \"\"\"Default implementation runs ainvoke in parallel using asyncio.gather.\n",
              "        The default implementation of batch works well for IO bound runnables.\n",
              "        Subclasses should override this method if they can batch more efficiently;\n",
              "        e.g., if the underlying runnable uses an API which supports a batch mode.\n",
              "        \"\"\"\n",
              "        if not inputs:\n",
              "            return []\n",
              "        configs = get_config_list(config, len(inputs))\n",
              "        async def ainvoke(\n",
              "            input: Input, config: RunnableConfig\n",
              "        ) -> Union[Output, Exception]:\n",
              "            if return_exceptions:\n",
              "                try:\n",
              "                    return await self.ainvoke(input, config, **kwargs)\n",
              "                except Exception as e:\n",
              "                    return e\n",
              "            else:\n",
              "                return await self.ainvoke(input, config, **kwargs)\n",
              "        coros = map(ainvoke, inputs, configs)\n",
              "        return await gather_with_concurrency(configs[0].get(\"max_concurrency\"), *coros)\n",
              "    @overload\n",
              "    def abatch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[False] = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Tuple[int, Output]]:\n",
              "        ...\n",
              "    @overload\n",
              "    def abatch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[True],\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        ...\n",
              "[docs]    async def abatch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        \"\"\"Run ainvoke in parallel on a list of inputs,\n",
              "        yielding results as they complete.\"\"\"\n",
              "        if not inputs:\n",
              "            return\n",
              "        configs = get_config_list(config, len(inputs))\n",
              "        async def ainvoke(\n",
              "            i: int, input: Input, config: RunnableConfig\n",
              "        ) -> Tuple[int, Union[Output, Exception]]:\n",
              "            if return_exceptions:\n",
              "                try:\n",
              "                    out: Union[Output, Exception] = await self.ainvoke(\n",
              "                        input, config, **kwargs\n",
              "                    )\n",
              "                except Exception as e:\n",
              "                    out = e\n",
              "            else:\n",
              "                out = await self.ainvoke(input, config, **kwargs)\n",
              "            return (i, out)\n",
              "        coros = map(ainvoke, range(len(inputs)), inputs, configs)\n",
              "        for coro in asyncio.as_completed(coros):\n",
              "            yield await coro\n",
              "[docs]    def stream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        \"\"\"\n",
              "        Default implementation of stream, which calls invoke.\n",
              "        Subclasses should override this method if they support streaming output.\n",
              "        \"\"\"\n",
              "        yield self.invoke(input, config, **kwargs)\n",
              "[docs]    async def astream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        \"\"\"\n",
              "        Default implementation of astream, which calls ainvoke.\n",
              "        Subclasses should override this method if they support streaming output.\n",
              "        \"\"\"\n",
              "        yield await self.ainvoke(input, config, **kwargs)\n",
              "    @overload\n",
              "    def astream_log(\n",
              "        self,\n",
              "        input: Any,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        *,\n",
              "        diff: Literal[True] = True,\n",
              "        with_streamed_output_list: bool = True,\n",
              "        include_names: Optional[Sequence[str]] = None,\n",
              "        include_types: Optional[Sequence[str]] = None,\n",
              "        include_tags: Optional[Sequence[str]] = None,\n",
              "        exclude_names: Optional[Sequence[str]] = None,\n",
              "        exclude_types: Optional[Sequence[str]] = None,\n",
              "        exclude_tags: Optional[Sequence[str]] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[RunLogPatch]:\n",
              "        ...\n",
              "    @overload\n",
              "    def astream_log(\n",
              "        self,\n",
              "        input: Any,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        *,\n",
              "        diff: Literal[False],\n",
              "        with_streamed_output_list: bool = True,\n",
              "        include_names: Optional[Sequence[str]] = None,\n",
              "        include_types: Optional[Sequence[str]] = None,\n",
              "        include_tags: Optional[Sequence[str]] = None,\n",
              "        exclude_names: Optional[Sequence[str]] = None,\n",
              "        exclude_types: Optional[Sequence[str]] = None,\n",
              "        exclude_tags: Optional[Sequence[str]] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[RunLog]:\n",
              "        ...\n",
              "[docs]    async def astream_log(\n",
              "        self,\n",
              "        input: Any,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        *,\n",
              "        diff: bool = True,\n",
              "        with_streamed_output_list: bool = True,\n",
              "        include_names: Optional[Sequence[str]] = None,\n",
              "        include_types: Optional[Sequence[str]] = None,\n",
              "        include_tags: Optional[Sequence[str]] = None,\n",
              "        exclude_names: Optional[Sequence[str]] = None,\n",
              "        exclude_types: Optional[Sequence[str]] = None,\n",
              "        exclude_tags: Optional[Sequence[str]] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> Union[AsyncIterator[RunLogPatch], AsyncIterator[RunLog]]:\n",
              "        \"\"\"\n",
              "        Stream all output from a runnable, as reported to the callback system.\n",
              "        This includes all inner runs of LLMs, Retrievers, Tools, etc.\n",
              "        Output is streamed as Log objects, which include a list of\n",
              "        jsonpatch ops that describe how the state of the run has changed in each\n",
              "        step, and the final state of the run.\n",
              "        The jsonpatch ops can be applied in order to construct state.\n",
              "        Args:\n",
              "            input: The input to the runnable.\n",
              "            config: The config to use for the runnable.\n",
              "            diff: Whether to yield diffs between each step, or the current state.\n",
              "            with_streamed_output_list: Whether to yield the streamed_output list.\n",
              "            include_names: Only include logs with these names.\n",
              "            include_types: Only include logs with these types.\n",
              "            include_tags: Only include logs with these tags.\n",
              "            exclude_names: Exclude logs with these names.\n",
              "            exclude_types: Exclude logs with these types.\n",
              "            exclude_tags: Exclude logs with these tags.\n",
              "        \"\"\"\n",
              "        from langchain_core.tracers.log_stream import (\n",
              "            LogStreamCallbackHandler,\n",
              "            _astream_log_implementation,\n",
              "        )\n",
              "        stream = LogStreamCallbackHandler(\n",
              "            auto_close=False,\n",
              "            include_names=include_names,\n",
              "            include_types=include_types,\n",
              "            include_tags=include_tags,\n",
              "            exclude_names=exclude_names,\n",
              "            exclude_types=exclude_types,\n",
              "            exclude_tags=exclude_tags,\n",
              "            _schema_format=\"original\",\n",
              "        )\n",
              "        # Mypy isn't resolving the overloads here\n",
              "        # Likely an issue b/c `self` is being passed through\n",
              "        # and it's can't map it to Runnable[Input,Output]?\n",
              "        async for item in _astream_log_implementation(  # type: ignore\n",
              "            self,\n",
              "            input,\n",
              "            config,\n",
              "            diff=diff,\n",
              "            stream=stream,\n",
              "            with_streamed_output_list=with_streamed_output_list,\n",
              "            **kwargs,\n",
              "        ):\n",
              "            yield item\n",
              "[docs]    @beta_decorator.beta(message=\"This API is in beta and may change in the future.\")\n",
              "    async def astream_events(\n",
              "        self,\n",
              "        input: Any,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        *,\n",
              "        version: Literal[\"v1\"],\n",
              "        include_names: Optional[Sequence[str]] = None,\n",
              "        include_types: Optional[Sequence[str]] = None,\n",
              "        include_tags: Optional[Sequence[str]] = None,\n",
              "        exclude_names: Optional[Sequence[str]] = None,\n",
              "        exclude_types: Optional[Sequence[str]] = None,\n",
              "        exclude_tags: Optional[Sequence[str]] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[StreamEvent]:\n",
              "        \"\"\"Generate a stream of events.\n",
              "        Use to create an iterator over StreamEvents that provide real-time information\n",
              "        about the progress of the runnable, including StreamEvents from intermediate\n",
              "        results.\n",
              "        A StreamEvent is a dictionary with the following schema:\n",
              "        - ``event``: **str** - Event names are of the\n",
              "            format: on_[runnable_type]_(start|stream|end).\n",
              "        - ``name``: **str** - The name of the runnable that generated the event.\n",
              "        - ``run_id``: **str** - randomly generated ID associated with the given execution of\n",
              "            the runnable that emitted the event.\n",
              "            A child runnable that gets invoked as part of the execution of a\n",
              "            parent runnable is assigned its own unique ID.\n",
              "        - ``tags``: **Optional[List[str]]** - The tags of the runnable that generated\n",
              "            the event.\n",
              "        - ``metadata``: **Optional[Dict[str, Any]]** - The metadata of the runnable\n",
              "            that generated the event.\n",
              "        - ``data``: **Dict[str, Any]**\n",
              "        Below is a table that illustrates some evens that might be emitted by various\n",
              "        chains. Metadata fields have been omitted from the table for brevity.\n",
              "        Chain definitions have been included after the table.\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | event                | name             | chunk                           | input                                         | output                                          |\n",
              "        +======================+==================+=================================+===============================================+=================================================+\n",
              "        | on_chat_model_start  | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_chat_model_stream | [model name]     | AIMessageChunk(content=\"hello\") |                                               |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_chat_model_end    | [model name]     |                                 | {\"messages\": [[SystemMessage, HumanMessage]]} | {\"generations\": [...], \"llm_output\": None, ...} |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_llm_start         | [model name]     |                                 | {'input': 'hello'}                            |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_llm_stream        | [model name]     | 'Hello'                         |                                               |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_llm_end           | [model name]     |                                 | 'Hello human!'                                |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_chain_start       | format_docs      |                                 |                                               |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_chain_stream      | format_docs      | \"hello world!, goodbye world!\"  |                                               |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_chain_end         | format_docs      |                                 | [Document(...)]                               | \"hello world!, goodbye world!\"                  |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_tool_start        | some_tool        |                                 | {\"x\": 1, \"y\": \"2\"}                            |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_tool_stream       | some_tool        | {\"x\": 1, \"y\": \"2\"}              |                                               |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_tool_end          | some_tool        |                                 |                                               | {\"x\": 1, \"y\": \"2\"}                              |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_retriever_start   | [retriever name] |                                 | {\"query\": \"hello\"}                            |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_retriever_chunk   | [retriever name] | {documents: [...]}              |                                               |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_retriever_end     | [retriever name] |                                 | {\"query\": \"hello\"}                            | {documents: [...]}                              |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_prompt_start      | [template_name]  |                                 | {\"question\": \"hello\"}                         |                                                 |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        | on_prompt_end        | [template_name]  |                                 | {\"question\": \"hello\"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |\n",
              "        +----------------------+------------------+---------------------------------+-----------------------------------------------+-------------------------------------------------+\n",
              "        Here are declarations associated with the events shown above:\n",
              "        `format_docs`:\n",
              "        .. code-block:: python\n",
              "            def format_docs(docs: List[Document]) -> str:\n",
              "                '''Format the docs.'''\n",
              "                return \", \".join([doc.page_content for doc in docs])\n",
              "            format_docs = RunnableLambda(format_docs)\n",
              "        `some_tool`:\n",
              "        .. code-block:: python\n",
              "            @tool\n",
              "            def some_tool(x: int, y: str) -> dict:\n",
              "                '''Some_tool.'''\n",
              "                return {\"x\": x, \"y\": y}\n",
              "        `prompt`:\n",
              "        .. code-block:: python\n",
              "            template = ChatPromptTemplate.from_messages(\n",
              "                [(\"system\", \"You are Cat Agent 007\"), (\"human\", \"{question}\")]\n",
              "            ).with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})\n",
              "        Example:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import RunnableLambda\n",
              "            async def reverse(s: str) -> str:\n",
              "                return s[::-1]\n",
              "            chain = RunnableLambda(func=reverse)\n",
              "            events = [\n",
              "                event async for event in chain.astream_events(\"hello\", version=\"v1\")\n",
              "            ]\n",
              "            # will produce the following events (run_id has been omitted for brevity):\n",
              "            [\n",
              "                {\n",
              "                    \"data\": {\"input\": \"hello\"},\n",
              "                    \"event\": \"on_chain_start\",\n",
              "                    \"metadata\": {},\n",
              "                    \"name\": \"reverse\",\n",
              "                    \"tags\": [],\n",
              "                },\n",
              "                {\n",
              "                    \"data\": {\"chunk\": \"olleh\"},\n",
              "                    \"event\": \"on_chain_stream\",\n",
              "                    \"metadata\": {},\n",
              "                    \"name\": \"reverse\",\n",
              "                    \"tags\": [],\n",
              "                },\n",
              "                {\n",
              "                    \"data\": {\"output\": \"olleh\"},\n",
              "                    \"event\": \"on_chain_end\",\n",
              "                    \"metadata\": {},\n",
              "                    \"name\": \"reverse\",\n",
              "                    \"tags\": [],\n",
              "                },\n",
              "            ]\n",
              "        Args:\n",
              "            input: The input to the runnable.\n",
              "            config: The config to use for the runnable.\n",
              "            version: The version of the schema to use.\n",
              "                     Currently only version 1 is available.\n",
              "                     No default will be assigned until the API is stabilized.\n",
              "            include_names: Only include events from runnables with matching names.\n",
              "            include_types: Only include events from runnables with matching types.\n",
              "            include_tags: Only include events from runnables with matching tags.\n",
              "            exclude_names: Exclude events from runnables with matching names.\n",
              "            exclude_types: Exclude events from runnables with matching types.\n",
              "            exclude_tags: Exclude events from runnables with matching tags.\n",
              "            kwargs: Additional keyword arguments to pass to the runnable.\n",
              "                These will be passed to astream_log as this implementation\n",
              "                of astream_events is built on top of astream_log.\n",
              "        Returns:\n",
              "            An async stream of StreamEvents.\n",
              "        \"\"\"  # noqa: E501\n",
              "        if version != \"v1\":\n",
              "            raise NotImplementedError(\n",
              "                'Only version \"v1\" of the schema is currently supported.'\n",
              "            )\n",
              "        from langchain_core.runnables.utils import (\n",
              "            _RootEventFilter,\n",
              "        )\n",
              "        from langchain_core.tracers.log_stream import (\n",
              "            LogStreamCallbackHandler,\n",
              "            RunLog,\n",
              "            _astream_log_implementation,\n",
              "        )\n",
              "        stream = LogStreamCallbackHandler(\n",
              "            auto_close=False,\n",
              "            include_names=include_names,\n",
              "            include_types=include_types,\n",
              "            include_tags=include_tags,\n",
              "            exclude_names=exclude_names,\n",
              "            exclude_types=exclude_types,\n",
              "            exclude_tags=exclude_tags,\n",
              "            _schema_format=\"streaming_events\",\n",
              "        )\n",
              "        run_log = RunLog(state=None)  # type: ignore[arg-type]\n",
              "        encountered_start_event = False\n",
              "        _root_event_filter = _RootEventFilter(\n",
              "            include_names=include_names,\n",
              "            include_types=include_types,\n",
              "            include_tags=include_tags,\n",
              "            exclude_names=exclude_names,\n",
              "            exclude_types=exclude_types,\n",
              "            exclude_tags=exclude_tags,\n",
              "        )\n",
              "        config = ensure_config(config)\n",
              "        root_tags = config.get(\"tags\", [])\n",
              "        root_metadata = config.get(\"metadata\", {})\n",
              "        root_name = config.get(\"run_name\", self.get_name())\n",
              "        # Ignoring mypy complaint about too many different union combinations\n",
              "        # This arises because many of the argument types are unions\n",
              "        async for log in _astream_log_implementation(  # type: ignore[misc]\n",
              "            self,\n",
              "            input,\n",
              "            config=config,\n",
              "            stream=stream,\n",
              "            diff=True,\n",
              "            with_streamed_output_list=True,\n",
              "            **kwargs,\n",
              "        ):\n",
              "            run_log = run_log + log\n",
              "            if not encountered_start_event:\n",
              "                # Yield the start event for the root runnable.\n",
              "                encountered_start_event = True\n",
              "                state = run_log.state.copy()\n",
              "                event = StreamEvent(\n",
              "                    event=f\"on_{state['type']}_start\",\n",
              "                    run_id=state[\"id\"],\n",
              "                    name=root_name,\n",
              "                    tags=root_tags,\n",
              "                    metadata=root_metadata,\n",
              "                    data={\n",
              "                        \"input\": input,\n",
              "                    },\n",
              "                )\n",
              "                if _root_event_filter.include_event(event, state[\"type\"]):\n",
              "                    yield event\n",
              "            paths = {\n",
              "                op[\"path\"].split(\"/\")[2]\n",
              "                for op in log.ops\n",
              "                if op[\"path\"].startswith(\"/logs/\")\n",
              "            }\n",
              "            # Elements in a set should be iterated in the same order\n",
              "            # as they were inserted in modern python versions.\n",
              "            for path in paths:\n",
              "                data: EventData = {}\n",
              "                log_entry: LogEntry = run_log.state[\"logs\"][path]\n",
              "                if log_entry[\"end_time\"] is None:\n",
              "                    if log_entry[\"streamed_output\"]:\n",
              "                        event_type = \"stream\"\n",
              "                    else:\n",
              "                        event_type = \"start\"\n",
              "                else:\n",
              "                    event_type = \"end\"\n",
              "                if event_type == \"start\":\n",
              "                    # Include the inputs with the start event if they are available.\n",
              "                    # Usually they will NOT be available for components that operate\n",
              "                    # on streams, since those components stream the input and\n",
              "                    # don't know its final value until the end of the stream.\n",
              "                    inputs = log_entry[\"inputs\"]\n",
              "                    if inputs is not None:\n",
              "                        data[\"input\"] = inputs\n",
              "                    pass\n",
              "                if event_type == \"end\":\n",
              "                    inputs = log_entry[\"inputs\"]\n",
              "                    if inputs is not None:\n",
              "                        data[\"input\"] = inputs\n",
              "                    # None is a VALID output for an end event\n",
              "                    data[\"output\"] = log_entry[\"final_output\"]\n",
              "                if event_type == \"stream\":\n",
              "                    num_chunks = len(log_entry[\"streamed_output\"])\n",
              "                    if num_chunks != 1:\n",
              "                        raise AssertionError(\n",
              "                            f\"Expected exactly one chunk of streamed output, \"\n",
              "                            f\"got {num_chunks} instead. This is impossible. \"\n",
              "                            f\"Encountered in: {log_entry['name']}\"\n",
              "                        )\n",
              "                    data = {\"chunk\": log_entry[\"streamed_output\"][0]}\n",
              "                    # Clean up the stream, we don't need it anymore.\n",
              "                    # And this avoids duplicates as well!\n",
              "                    log_entry[\"streamed_output\"] = []\n",
              "                yield StreamEvent(\n",
              "                    event=f\"on_{log_entry['type']}_{event_type}\",\n",
              "                    name=log_entry[\"name\"],\n",
              "                    run_id=log_entry[\"id\"],\n",
              "                    tags=log_entry[\"tags\"],\n",
              "                    metadata=log_entry[\"metadata\"],\n",
              "                    data=data,\n",
              "                )\n",
              "            # Finally, we take care of the streaming output from the root chain\n",
              "            # if there is any.\n",
              "            state = run_log.state\n",
              "            if state[\"streamed_output\"]:\n",
              "                num_chunks = len(state[\"streamed_output\"])\n",
              "                if num_chunks != 1:\n",
              "                    raise AssertionError(\n",
              "                        f\"Expected exactly one chunk of streamed output, \"\n",
              "                        f\"got {num_chunks} instead. This is impossible. \"\n",
              "                        f\"Encountered in: {state['name']}\"\n",
              "                    )\n",
              "                data = {\"chunk\": state[\"streamed_output\"][0]}\n",
              "                # Clean up the stream, we don't need it anymore.\n",
              "                state[\"streamed_output\"] = []\n",
              "                event = StreamEvent(\n",
              "                    event=f\"on_{state['type']}_stream\",\n",
              "                    run_id=state[\"id\"],\n",
              "                    tags=root_tags,\n",
              "                    metadata=root_metadata,\n",
              "                    name=root_name,\n",
              "                    data=data,\n",
              "                )\n",
              "                if _root_event_filter.include_event(event, state[\"type\"]):\n",
              "                    yield event\n",
              "        state = run_log.state\n",
              "        # Finally yield the end event for the root runnable.\n",
              "        event = StreamEvent(\n",
              "            event=f\"on_{state['type']}_end\",\n",
              "            name=root_name,\n",
              "            run_id=state[\"id\"],\n",
              "            tags=root_tags,\n",
              "            metadata=root_metadata,\n",
              "            data={\n",
              "                \"output\": state[\"final_output\"],\n",
              "            },\n",
              "        )\n",
              "        if _root_event_filter.include_event(event, state[\"type\"]):\n",
              "            yield event\n",
              "[docs]    def transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        \"\"\"\n",
              "        Default implementation of transform, which buffers input and then calls stream.\n",
              "        Subclasses should override this method if they can start producing output while\n",
              "        input is still being generated.\n",
              "        \"\"\"\n",
              "        final: Input\n",
              "        got_first_val = False\n",
              "        for chunk in input:\n",
              "            if not got_first_val:\n",
              "                final = adapt_first_streaming_chunk(chunk)  # type: ignore\n",
              "                got_first_val = True\n",
              "            else:\n",
              "                # Make a best effort to gather, for any type that supports `+`\n",
              "                # This method should throw an error if gathering fails.\n",
              "                try:\n",
              "                    final = final + chunk  # type: ignore[operator]\n",
              "                except TypeError:\n",
              "                    raise TypeError(\n",
              "                        f\"Failed while trying to add together \"\n",
              "                        f\"type {type(final)} and {type(chunk)}.\"\n",
              "                        f\"These types should be addable for transform to work.\"\n",
              "                    )\n",
              "        if got_first_val:\n",
              "            yield from self.stream(final, config, **kwargs)\n",
              "[docs]    async def atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        \"\"\"\n",
              "        Default implementation of atransform, which buffers input and calls astream.\n",
              "        Subclasses should override this method if they can start producing output while\n",
              "        input is still being generated.\n",
              "        \"\"\"\n",
              "        final: Input\n",
              "        got_first_val = False\n",
              "        async for chunk in input:\n",
              "            if not got_first_val:\n",
              "                final = adapt_first_streaming_chunk(chunk)  # type: ignore\n",
              "                got_first_val = True\n",
              "            else:\n",
              "                # Make a best effort to gather, for any type that supports `+`\n",
              "                # This method should throw an error if gathering fails.\n",
              "                try:\n",
              "                    final = final + chunk  # type: ignore[operator]\n",
              "                except TypeError:\n",
              "                    raise TypeError(\n",
              "                        f\"Failed while trying to add together \"\n",
              "                        f\"type {type(final)} and {type(chunk)}.\"\n",
              "                        f\"These types should be addable for atransform to work.\"\n",
              "                    )\n",
              "        if got_first_val:\n",
              "            async for output in self.astream(final, config, **kwargs):\n",
              "                yield output\n",
              "[docs]    def bind(self, **kwargs: Any) -> Runnable[Input, Output]:\n",
              "        \"\"\"\n",
              "        Bind arguments to a Runnable, returning a new Runnable.\n",
              "        Useful when a runnable in a chain requires an argument that is not\n",
              "        in the output of the previous runnable or included in the user input.\n",
              "        Example:\n",
              "        .. code-block:: python\n",
              "            from langchain_community.chat_models import ChatOllama\n",
              "            from langchain_core.output_parsers import StrOutputParser\n",
              "            llm = ChatOllama(model='llama2')\n",
              "            # Without bind.\n",
              "            chain = (\n",
              "                llm\n",
              "                | StrOutputParser()\n",
              "            )\n",
              "            chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
              "            # Output is 'One two three four five.'\n",
              "            # With bind.\n",
              "            chain = (\n",
              "                llm.bind(stop=[\"three\"])\n",
              "                | StrOutputParser()\n",
              "            )\n",
              "            chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
              "            # Output is 'One two'\n",
              "        \"\"\"\n",
              "        return RunnableBinding(bound=self, kwargs=kwargs, config={})\n",
              "[docs]    def with_config(\n",
              "        self,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        # Sadly Unpack is not well supported by mypy so this will have to be untyped\n",
              "        **kwargs: Any,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        \"\"\"\n",
              "        Bind config to a Runnable, returning a new Runnable.\n",
              "        \"\"\"\n",
              "        return RunnableBinding(\n",
              "            bound=self,\n",
              "            config=cast(\n",
              "                RunnableConfig,\n",
              "                {**(config or {}), **kwargs},\n",
              "            ),  # type: ignore[misc]\n",
              "            kwargs={},\n",
              "        )\n",
              "[docs]    def with_listeners(\n",
              "        self,\n",
              "        *,\n",
              "        on_start: Optional[Listener] = None,\n",
              "        on_end: Optional[Listener] = None,\n",
              "        on_error: Optional[Listener] = None,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        \"\"\"\n",
              "        Bind lifecycle listeners to a Runnable, returning a new Runnable.\n",
              "        on_start: Called before the runnable starts running, with the Run object.\n",
              "        on_end: Called after the runnable finishes running, with the Run object.\n",
              "        on_error: Called if the runnable throws an error, with the Run object.\n",
              "        The Run object contains information about the run, including its id,\n",
              "        type, input, output, error, start_time, end_time, and any tags or metadata\n",
              "        added to the run.\n",
              "        Example:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import RunnableLambda\n",
              "            import time\n",
              "            def test_runnable(time_to_sleep : int):\n",
              "                time.sleep(time_to_sleep)\n",
              "            def fn_start(run_obj : Runnable):\n",
              "                print(\"start_time:\", run_obj.start_time)\n",
              "            def fn_end(run_obj : Runnable):\n",
              "                print(\"end_time:\", run_obj.end_time)\n",
              "            RunnableLambda(test_runnable).with_listeners(\n",
              "                on_start=fn_start,\n",
              "                on_end=fn_end\n",
              "                ).invoke(2)\n",
              "        \"\"\"\n",
              "        from langchain_core.tracers.root_listeners import RootListenersTracer\n",
              "        return RunnableBinding(\n",
              "            bound=self,\n",
              "            config_factories=[\n",
              "                lambda config: {\n",
              "                    \"callbacks\": [\n",
              "                        RootListenersTracer(\n",
              "                            config=config,\n",
              "                            on_start=on_start,\n",
              "                            on_end=on_end,\n",
              "                            on_error=on_error,\n",
              "                        )\n",
              "                    ],\n",
              "                }\n",
              "            ],\n",
              "        )\n",
              "[docs]    def with_types(\n",
              "        self,\n",
              "        *,\n",
              "        input_type: Optional[Type[Input]] = None,\n",
              "        output_type: Optional[Type[Output]] = None,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        \"\"\"\n",
              "        Bind input and output types to a Runnable, returning a new Runnable.\n",
              "        \"\"\"\n",
              "        return RunnableBinding(\n",
              "            bound=self,\n",
              "            custom_input_type=input_type,\n",
              "            custom_output_type=output_type,\n",
              "            kwargs={},\n",
              "        )\n",
              "[docs]    def with_retry(\n",
              "        self,\n",
              "        *,\n",
              "        retry_if_exception_type: Tuple[Type[BaseException], ...] = (Exception,),\n",
              "        wait_exponential_jitter: bool = True,\n",
              "        stop_after_attempt: int = 3,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        \"\"\"Create a new Runnable that retries the original runnable on exceptions.\n",
              "        Example:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import RunnableLambda\n",
              "            count = 0\n",
              "            def _lambda(x: int) -> None:\n",
              "                global count\n",
              "                count = count + 1\n",
              "                if x == 1:\n",
              "                    raise ValueError(\"x is 1\")\n",
              "                else:\n",
              "                     pass\n",
              "            runnable = RunnableLambda(_lambda)\n",
              "            try:\n",
              "                runnable.with_retry(\n",
              "                    stop_after_attempt=2,\n",
              "                    retry_if_exception_type=(ValueError,),\n",
              "                ).invoke(1)\n",
              "            except ValueError:\n",
              "                pass\n",
              "            assert (count == 2)\n",
              "        Args:\n",
              "            retry_if_exception_type: A tuple of exception types to retry on\n",
              "            wait_exponential_jitter: Whether to add jitter to the wait time\n",
              "                                     between retries\n",
              "            stop_after_attempt: The maximum number of attempts to make before giving up\n",
              "        Returns:\n",
              "            A new Runnable that retries the original runnable on exceptions.\n",
              "        \"\"\"\n",
              "        from langchain_core.runnables.retry import RunnableRetry\n",
              "        return RunnableRetry(\n",
              "            bound=self,\n",
              "            kwargs={},\n",
              "            config={},\n",
              "            retry_exception_types=retry_if_exception_type,\n",
              "            wait_exponential_jitter=wait_exponential_jitter,\n",
              "            max_attempt_number=stop_after_attempt,\n",
              "        )\n",
              "[docs]    def map(self) -> Runnable[List[Input], List[Output]]:\n",
              "        \"\"\"\n",
              "        Return a new Runnable that maps a list of inputs to a list of outputs,\n",
              "        by calling invoke() with each input.\n",
              "        Example:\n",
              "            .. code-block:: python\n",
              "                    from langchain_core.runnables import RunnableLambda\n",
              "                    def _lambda(x: int) -> int:\n",
              "                        return x + 1\n",
              "                    runnable = RunnableLambda(_lambda)\n",
              "                    print(runnable.map().invoke([1, 2, 3])) # [2, 3, 4]\n",
              "        \"\"\"\n",
              "        return RunnableEach(bound=self)\n",
              "[docs]    def with_fallbacks(\n",
              "        self,\n",
              "        fallbacks: Sequence[Runnable[Input, Output]],\n",
              "        *,\n",
              "        exceptions_to_handle: Tuple[Type[BaseException], ...] = (Exception,),\n",
              "        exception_key: Optional[str] = None,\n",
              "    ) -> RunnableWithFallbacksT[Input, Output]:\n",
              "        \"\"\"Add fallbacks to a runnable, returning a new Runnable.\n",
              "        Example:\n",
              "            .. code-block:: python\n",
              "                from typing import Iterator\n",
              "                from langchain_core.runnables import RunnableGenerator\n",
              "                def _generate_immediate_error(input: Iterator) -> Iterator[str]:\n",
              "                    raise ValueError()\n",
              "                    yield \"\"\n",
              "                def _generate(input: Iterator) -> Iterator[str]:\n",
              "                    yield from \"foo bar\"\n",
              "                runnable = RunnableGenerator(_generate_immediate_error).with_fallbacks(\n",
              "                    [RunnableGenerator(_generate)]\n",
              "                    )\n",
              "                print(''.join(runnable.stream({}))) #foo bar\n",
              "        Args:\n",
              "            fallbacks: A sequence of runnables to try if the original runnable fails.\n",
              "            exceptions_to_handle: A tuple of exception types to handle.\n",
              "            exception_key: If string is specified then handled exceptions will be passed\n",
              "                to fallbacks as part of the input under the specified key. If None,\n",
              "                exceptions will not be passed to fallbacks. If used, the base runnable\n",
              "                and its fallbacks must accept a dictionary as input.\n",
              "        Returns:\n",
              "            A new Runnable that will try the original runnable, and then each\n",
              "            fallback in order, upon failures.\n",
              "        \"\"\"\n",
              "        from langchain_core.runnables.fallbacks import RunnableWithFallbacks\n",
              "        return RunnableWithFallbacks(\n",
              "            runnable=self,\n",
              "            fallbacks=fallbacks,\n",
              "            exceptions_to_handle=exceptions_to_handle,\n",
              "            exception_key=exception_key,\n",
              "        )\n",
              "    \"\"\" --- Helper methods for Subclasses --- \"\"\"\n",
              "    def _call_with_config(\n",
              "        self,\n",
              "        func: Union[\n",
              "            Callable[[Input], Output],\n",
              "            Callable[[Input, CallbackManagerForChainRun], Output],\n",
              "            Callable[[Input, CallbackManagerForChainRun, RunnableConfig], Output],\n",
              "        ],\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig],\n",
              "        run_type: Optional[str] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        \"\"\"Helper method to transform an Input value to an Output value,\n",
              "        with callbacks. Use this method to implement invoke() in subclasses.\"\"\"\n",
              "        config = ensure_config(config)\n",
              "        callback_manager = get_callback_manager_for_config(config)\n",
              "        run_manager = callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            input,\n",
              "            run_type=run_type,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        try:\n",
              "            child_config = patch_config(config, callbacks=run_manager.get_child())\n",
              "            context = copy_context()\n",
              "            context.run(var_child_runnable_config.set, child_config)\n",
              "            output = cast(\n",
              "                Output,\n",
              "                context.run(\n",
              "                    call_func_with_variable_args,  # type: ignore[arg-type]\n",
              "                    func,  # type: ignore[arg-type]\n",
              "                    input,  # type: ignore[arg-type]\n",
              "                    config,\n",
              "                    run_manager,\n",
              "                    **kwargs,\n",
              "                ),\n",
              "            )\n",
              "        except BaseException as e:\n",
              "            run_manager.on_chain_error(e)\n",
              "            raise\n",
              "        else:\n",
              "            run_manager.on_chain_end(output)\n",
              "            return output\n",
              "    async def _acall_with_config(\n",
              "        self,\n",
              "        func: Union[\n",
              "            Callable[[Input], Awaitable[Output]],\n",
              "            Callable[[Input, AsyncCallbackManagerForChainRun], Awaitable[Output]],\n",
              "            Callable[\n",
              "                [Input, AsyncCallbackManagerForChainRun, RunnableConfig],\n",
              "                Awaitable[Output],\n",
              "            ],\n",
              "        ],\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig],\n",
              "        run_type: Optional[str] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        \"\"\"Helper method to transform an Input value to an Output value,\n",
              "        with callbacks. Use this method to implement ainvoke() in subclasses.\"\"\"\n",
              "        config = ensure_config(config)\n",
              "        callback_manager = get_async_callback_manager_for_config(config)\n",
              "        run_manager = await callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            input,\n",
              "            run_type=run_type,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        try:\n",
              "            child_config = patch_config(config, callbacks=run_manager.get_child())\n",
              "            context = copy_context()\n",
              "            context.run(var_child_runnable_config.set, child_config)\n",
              "            coro = acall_func_with_variable_args(\n",
              "                func, input, config, run_manager, **kwargs\n",
              "            )\n",
              "            if accepts_context(asyncio.create_task):\n",
              "                output: Output = await asyncio.create_task(coro, context=context)  # type: ignore\n",
              "            else:\n",
              "                output = await coro\n",
              "        except BaseException as e:\n",
              "            await run_manager.on_chain_error(e)\n",
              "            raise\n",
              "        else:\n",
              "            await run_manager.on_chain_end(output)\n",
              "            return output\n",
              "    def _batch_with_config(\n",
              "        self,\n",
              "        func: Union[\n",
              "            Callable[[List[Input]], List[Union[Exception, Output]]],\n",
              "            Callable[\n",
              "                [List[Input], List[CallbackManagerForChainRun]],\n",
              "                List[Union[Exception, Output]],\n",
              "            ],\n",
              "            Callable[\n",
              "                [List[Input], List[CallbackManagerForChainRun], List[RunnableConfig]],\n",
              "                List[Union[Exception, Output]],\n",
              "            ],\n",
              "        ],\n",
              "        input: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        run_type: Optional[str] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        \"\"\"Helper method to transform an Input value to an Output value,\n",
              "        with callbacks. Use this method to implement invoke() in subclasses.\"\"\"\n",
              "        if not input:\n",
              "            return []\n",
              "        configs = get_config_list(config, len(input))\n",
              "        callback_managers = [get_callback_manager_for_config(c) for c in configs]\n",
              "        run_managers = [\n",
              "            callback_manager.on_chain_start(\n",
              "                dumpd(self),\n",
              "                input,\n",
              "                run_type=run_type,\n",
              "                name=config.get(\"run_name\") or self.get_name(),\n",
              "                run_id=config.pop(\"run_id\", None),\n",
              "            )\n",
              "            for callback_manager, input, config in zip(\n",
              "                callback_managers, input, configs\n",
              "            )\n",
              "        ]\n",
              "        try:\n",
              "            if accepts_config(func):\n",
              "                kwargs[\"config\"] = [\n",
              "                    patch_config(c, callbacks=rm.get_child())\n",
              "                    for c, rm in zip(configs, run_managers)\n",
              "                ]\n",
              "            if accepts_run_manager(func):\n",
              "                kwargs[\"run_manager\"] = run_managers\n",
              "            output = func(input, **kwargs)  # type: ignore[call-arg]\n",
              "        except BaseException as e:\n",
              "            for run_manager in run_managers:\n",
              "                run_manager.on_chain_error(e)\n",
              "            if return_exceptions:\n",
              "                return cast(List[Output], [e for _ in input])\n",
              "            else:\n",
              "                raise\n",
              "        else:\n",
              "            first_exception: Optional[Exception] = None\n",
              "            for run_manager, out in zip(run_managers, output):\n",
              "                if isinstance(out, Exception):\n",
              "                    first_exception = first_exception or out\n",
              "                    run_manager.on_chain_error(out)\n",
              "                else:\n",
              "                    run_manager.on_chain_end(out)\n",
              "            if return_exceptions or first_exception is None:\n",
              "                return cast(List[Output], output)\n",
              "            else:\n",
              "                raise first_exception\n",
              "    async def _abatch_with_config(\n",
              "        self,\n",
              "        func: Union[\n",
              "            Callable[[List[Input]], Awaitable[List[Union[Exception, Output]]]],\n",
              "            Callable[\n",
              "                [List[Input], List[AsyncCallbackManagerForChainRun]],\n",
              "                Awaitable[List[Union[Exception, Output]]],\n",
              "            ],\n",
              "            Callable[\n",
              "                [\n",
              "                    List[Input],\n",
              "                    List[AsyncCallbackManagerForChainRun],\n",
              "                    List[RunnableConfig],\n",
              "                ],\n",
              "                Awaitable[List[Union[Exception, Output]]],\n",
              "            ],\n",
              "        ],\n",
              "        input: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        run_type: Optional[str] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        \"\"\"Helper method to transform an Input value to an Output value,\n",
              "        with callbacks. Use this method to implement invoke() in subclasses.\"\"\"\n",
              "        if not input:\n",
              "            return []\n",
              "        configs = get_config_list(config, len(input))\n",
              "        callback_managers = [get_async_callback_manager_for_config(c) for c in configs]\n",
              "        run_managers: List[AsyncCallbackManagerForChainRun] = await asyncio.gather(\n",
              "            *(\n",
              "                callback_manager.on_chain_start(\n",
              "                    dumpd(self),\n",
              "                    input,\n",
              "                    run_type=run_type,\n",
              "                    name=config.get(\"run_name\") or self.get_name(),\n",
              "                    run_id=config.pop(\"run_id\", None),\n",
              "                )\n",
              "                for callback_manager, input, config in zip(\n",
              "                    callback_managers, input, configs\n",
              "                )\n",
              "            )\n",
              "        )\n",
              "        try:\n",
              "            if accepts_config(func):\n",
              "                kwargs[\"config\"] = [\n",
              "                    patch_config(c, callbacks=rm.get_child())\n",
              "                    for c, rm in zip(configs, run_managers)\n",
              "                ]\n",
              "            if accepts_run_manager(func):\n",
              "                kwargs[\"run_manager\"] = run_managers\n",
              "            output = await func(input, **kwargs)  # type: ignore[call-arg]\n",
              "        except BaseException as e:\n",
              "            await asyncio.gather(\n",
              "                *(run_manager.on_chain_error(e) for run_manager in run_managers)\n",
              "            )\n",
              "            if return_exceptions:\n",
              "                return cast(List[Output], [e for _ in input])\n",
              "            else:\n",
              "                raise\n",
              "        else:\n",
              "            first_exception: Optional[Exception] = None\n",
              "            coros: List[Awaitable[None]] = []\n",
              "            for run_manager, out in zip(run_managers, output):\n",
              "                if isinstance(out, Exception):\n",
              "                    first_exception = first_exception or out\n",
              "                    coros.append(run_manager.on_chain_error(out))\n",
              "                else:\n",
              "                    coros.append(run_manager.on_chain_end(out))\n",
              "            await asyncio.gather(*coros)\n",
              "            if return_exceptions or first_exception is None:\n",
              "                return cast(List[Output], output)\n",
              "            else:\n",
              "                raise first_exception\n",
              "    def _transform_stream_with_config(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        transformer: Union[\n",
              "            Callable[[Iterator[Input]], Iterator[Output]],\n",
              "            Callable[[Iterator[Input], CallbackManagerForChainRun], Iterator[Output]],\n",
              "            Callable[\n",
              "                [\n",
              "                    Iterator[Input],\n",
              "                    CallbackManagerForChainRun,\n",
              "                    RunnableConfig,\n",
              "                ],\n",
              "                Iterator[Output],\n",
              "            ],\n",
              "        ],\n",
              "        config: Optional[RunnableConfig],\n",
              "        run_type: Optional[str] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        \"\"\"Helper method to transform an Iterator of Input values into an Iterator of\n",
              "        Output values, with callbacks.\n",
              "        Use this to implement `stream()` or `transform()` in Runnable subclasses.\"\"\"\n",
              "        # tee the input so we can iterate over it twice\n",
              "        input_for_tracing, input_for_transform = tee(input, 2)\n",
              "        # Start the input iterator to ensure the input runnable starts before this one\n",
              "        final_input: Optional[Input] = next(input_for_tracing, None)\n",
              "        final_input_supported = True\n",
              "        final_output: Optional[Output] = None\n",
              "        final_output_supported = True\n",
              "        config = ensure_config(config)\n",
              "        callback_manager = get_callback_manager_for_config(config)\n",
              "        run_manager = callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            {\"input\": \"\"},\n",
              "            run_type=run_type,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        try:\n",
              "            child_config = patch_config(config, callbacks=run_manager.get_child())\n",
              "            if accepts_config(transformer):\n",
              "                kwargs[\"config\"] = child_config\n",
              "            if accepts_run_manager(transformer):\n",
              "                kwargs[\"run_manager\"] = run_manager\n",
              "            context = copy_context()\n",
              "            context.run(var_child_runnable_config.set, child_config)\n",
              "            iterator = context.run(transformer, input_for_transform, **kwargs)  # type: ignore[arg-type]\n",
              "            try:\n",
              "                while True:\n",
              "                    chunk: Output = context.run(next, iterator)  # type: ignore\n",
              "                    yield chunk\n",
              "                    if final_output_supported:\n",
              "                        if final_output is None:\n",
              "                            final_output = chunk\n",
              "                        else:\n",
              "                            try:\n",
              "                                final_output = final_output + chunk  # type: ignore\n",
              "                            except TypeError:\n",
              "                                final_output = chunk\n",
              "                                final_output_supported = False\n",
              "                    else:\n",
              "                        final_output = chunk\n",
              "            except StopIteration:\n",
              "                pass\n",
              "            for ichunk in input_for_tracing:\n",
              "                if final_input_supported:\n",
              "                    if final_input is None:\n",
              "                        final_input = ichunk\n",
              "                    else:\n",
              "                        try:\n",
              "                            final_input = final_input + ichunk  # type: ignore\n",
              "                        except TypeError:\n",
              "                            final_input = ichunk\n",
              "                            final_input_supported = False\n",
              "                else:\n",
              "                    final_input = ichunk\n",
              "        except BaseException as e:\n",
              "            run_manager.on_chain_error(e, inputs=final_input)\n",
              "            raise\n",
              "        else:\n",
              "            run_manager.on_chain_end(final_output, inputs=final_input)\n",
              "    async def _atransform_stream_with_config(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        transformer: Union[\n",
              "            Callable[[AsyncIterator[Input]], AsyncIterator[Output]],\n",
              "            Callable[\n",
              "                [AsyncIterator[Input], AsyncCallbackManagerForChainRun],\n",
              "                AsyncIterator[Output],\n",
              "            ],\n",
              "            Callable[\n",
              "                [\n",
              "                    AsyncIterator[Input],\n",
              "                    AsyncCallbackManagerForChainRun,\n",
              "                    RunnableConfig,\n",
              "                ],\n",
              "                AsyncIterator[Output],\n",
              "            ],\n",
              "        ],\n",
              "        config: Optional[RunnableConfig],\n",
              "        run_type: Optional[str] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        \"\"\"Helper method to transform an Async Iterator of Input values into an Async\n",
              "        Iterator of Output values, with callbacks.\n",
              "        Use this to implement `astream()` or `atransform()` in Runnable subclasses.\"\"\"\n",
              "        from langchain_core.tracers.log_stream import LogStreamCallbackHandler\n",
              "        # tee the input so we can iterate over it twice\n",
              "        input_for_tracing, input_for_transform = atee(input, 2)\n",
              "        # Start the input iterator to ensure the input runnable starts before this one\n",
              "        final_input: Optional[Input] = await py_anext(input_for_tracing, None)\n",
              "        final_input_supported = True\n",
              "        final_output: Optional[Output] = None\n",
              "        final_output_supported = True\n",
              "        config = ensure_config(config)\n",
              "        callback_manager = get_async_callback_manager_for_config(config)\n",
              "        run_manager = await callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            {\"input\": \"\"},\n",
              "            run_type=run_type,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        try:\n",
              "            child_config = patch_config(config, callbacks=run_manager.get_child())\n",
              "            if accepts_config(transformer):\n",
              "                kwargs[\"config\"] = child_config\n",
              "            if accepts_run_manager(transformer):\n",
              "                kwargs[\"run_manager\"] = run_manager\n",
              "            context = copy_context()\n",
              "            context.run(var_child_runnable_config.set, child_config)\n",
              "            iterator = context.run(transformer, input_for_transform, **kwargs)  # type: ignore[arg-type]\n",
              "            if stream_log := next(\n",
              "                (\n",
              "                    h\n",
              "                    for h in run_manager.handlers\n",
              "                    if isinstance(h, LogStreamCallbackHandler)\n",
              "                ),\n",
              "                None,\n",
              "            ):\n",
              "                # populates streamed_output in astream_log() output if needed\n",
              "                iterator = stream_log.tap_output_aiter(run_manager.run_id, iterator)\n",
              "            try:\n",
              "                while True:\n",
              "                    if accepts_context(asyncio.create_task):\n",
              "                        chunk: Output = await asyncio.create_task(  # type: ignore[call-arg]\n",
              "                            py_anext(iterator),  # type: ignore[arg-type]\n",
              "                            context=context,\n",
              "                        )\n",
              "                    else:\n",
              "                        chunk = cast(Output, await py_anext(iterator))\n",
              "                    yield chunk\n",
              "                    if final_output_supported:\n",
              "                        if final_output is None:\n",
              "                            final_output = chunk\n",
              "                        else:\n",
              "                            try:\n",
              "                                final_output = final_output + chunk  # type: ignore\n",
              "                            except TypeError:\n",
              "                                final_output = chunk\n",
              "                                final_output_supported = False\n",
              "                    else:\n",
              "                        final_output = chunk\n",
              "            except StopAsyncIteration:\n",
              "                pass\n",
              "            async for ichunk in input_for_tracing:\n",
              "                if final_input_supported:\n",
              "                    if final_input is None:\n",
              "                        final_input = ichunk\n",
              "                    else:\n",
              "                        try:\n",
              "                            final_input = final_input + ichunk  # type: ignore[operator]\n",
              "                        except TypeError:\n",
              "                            final_input = ichunk\n",
              "                            final_input_supported = False\n",
              "                else:\n",
              "                    final_input = ichunk\n",
              "        except BaseException as e:\n",
              "            await run_manager.on_chain_error(e, inputs=final_input)\n",
              "            raise\n",
              "        else:\n",
              "            await run_manager.on_chain_end(final_output, inputs=final_input)\n",
              "[docs]class RunnableSerializable(Serializable, Runnable[Input, Output]):\n",
              "    \"\"\"Runnable that can be serialized to JSON.\"\"\"\n",
              "    name: Optional[str] = None\n",
              "    \"\"\"The name of the runnable. Used for debugging and tracing.\"\"\"\n",
              "[docs]    def to_json(self) -> Union[SerializedConstructor, SerializedNotImplemented]:\n",
              "        \"\"\"Serialize the runnable to JSON.\"\"\"\n",
              "        dumped = super().to_json()\n",
              "        try:\n",
              "            dumped[\"name\"] = self.get_name()\n",
              "            dumped[\"graph\"] = self.get_graph().to_json()\n",
              "        except Exception:\n",
              "            pass\n",
              "        return dumped\n",
              "[docs]    def configurable_fields(\n",
              "        self, **kwargs: AnyConfigurableField\n",
              "    ) -> RunnableSerializable[Input, Output]:\n",
              "        \"\"\"Configure particular runnable fields at runtime.\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import ConfigurableField\n",
              "            from langchain_openai import ChatOpenAI\n",
              "            model = ChatOpenAI(max_tokens=20).configurable_fields(\n",
              "                max_tokens=ConfigurableField(\n",
              "                    id=\"output_token_number\",\n",
              "                    name=\"Max tokens in the output\",\n",
              "                    description=\"The maximum number of tokens in the output\",\n",
              "                )\n",
              "            )\n",
              "            # max_tokens = 20\n",
              "            print(\n",
              "                \"max_tokens_20: \",\n",
              "                model.invoke(\"tell me something about chess\").content\n",
              "            )\n",
              "            # max_tokens = 200\n",
              "            print(\"max_tokens_200: \", model.with_config(\n",
              "                configurable={\"output_token_number\": 200}\n",
              "                ).invoke(\"tell me something about chess\").content\n",
              "            )\n",
              "        \"\"\"\n",
              "        from langchain_core.runnables.configurable import RunnableConfigurableFields\n",
              "        for key in kwargs:\n",
              "            if key not in self.__fields__:\n",
              "                raise ValueError(\n",
              "                    f\"Configuration key {key} not found in {self}: \"\n",
              "                    f\"available keys are {self.__fields__.keys()}\"\n",
              "                )\n",
              "        return RunnableConfigurableFields(default=self, fields=kwargs)\n",
              "[docs]    def configurable_alternatives(\n",
              "        self,\n",
              "        which: ConfigurableField,\n",
              "        *,\n",
              "        default_key: str = \"default\",\n",
              "        prefix_keys: bool = False,\n",
              "        **kwargs: Union[Runnable[Input, Output], Callable[[], Runnable[Input, Output]]],\n",
              "    ) -> RunnableSerializable[Input, Output]:\n",
              "        \"\"\"Configure alternatives for runnables that can be set at runtime.\n",
              "        .. code-block:: python\n",
              "            from langchain_anthropic import ChatAnthropic\n",
              "            from langchain_core.runnables.utils import ConfigurableField\n",
              "            from langchain_openai import ChatOpenAI\n",
              "            model = ChatAnthropic(\n",
              "                model_name=\"claude-3-sonnet-20240229\"\n",
              "            ).configurable_alternatives(\n",
              "                ConfigurableField(id=\"llm\"),\n",
              "                default_key=\"anthropic\",\n",
              "                openai=ChatOpenAI()\n",
              "            )\n",
              "            # uses the default model ChatAnthropic\n",
              "            print(model.invoke(\"which organization created you?\").content)\n",
              "            # uses ChatOpenaAI\n",
              "            print(\n",
              "                model.with_config(\n",
              "                    configurable={\"llm\": \"openai\"}\n",
              "                ).invoke(\"which organization created you?\").content\n",
              "            )\n",
              "        \"\"\"\n",
              "        from langchain_core.runnables.configurable import (\n",
              "            RunnableConfigurableAlternatives,\n",
              "        )\n",
              "        return RunnableConfigurableAlternatives(\n",
              "            which=which,\n",
              "            default=self,\n",
              "            alternatives=kwargs,\n",
              "            default_key=default_key,\n",
              "            prefix_keys=prefix_keys,\n",
              "        )\n",
              "def _seq_input_schema(\n",
              "    steps: List[Runnable[Any, Any]], config: Optional[RunnableConfig]\n",
              ") -> Type[BaseModel]:\n",
              "    from langchain_core.runnables.passthrough import RunnableAssign, RunnablePick\n",
              "    first = steps[0]\n",
              "    if len(steps) == 1:\n",
              "        return first.get_input_schema(config)\n",
              "    elif isinstance(first, RunnableAssign):\n",
              "        next_input_schema = _seq_input_schema(steps[1:], config)\n",
              "        if not next_input_schema.__custom_root_type__:\n",
              "            # it's a dict as expected\n",
              "            return create_model(  # type: ignore[call-overload]\n",
              "                \"RunnableSequenceInput\",\n",
              "                **{\n",
              "                    k: (v.annotation, v.default)\n",
              "                    for k, v in next_input_schema.__fields__.items()\n",
              "                    if k not in first.mapper.steps\n",
              "                },\n",
              "            )\n",
              "    elif isinstance(first, RunnablePick):\n",
              "        return _seq_input_schema(steps[1:], config)\n",
              "    return first.get_input_schema(config)\n",
              "def _seq_output_schema(\n",
              "    steps: List[Runnable[Any, Any]], config: Optional[RunnableConfig]\n",
              ") -> Type[BaseModel]:\n",
              "    from langchain_core.runnables.passthrough import RunnableAssign, RunnablePick\n",
              "    last = steps[-1]\n",
              "    if len(steps) == 1:\n",
              "        return last.get_input_schema(config)\n",
              "    elif isinstance(last, RunnableAssign):\n",
              "        mapper_output_schema = last.mapper.get_output_schema(config)\n",
              "        prev_output_schema = _seq_output_schema(steps[:-1], config)\n",
              "        if not prev_output_schema.__custom_root_type__:\n",
              "            # it's a dict as expected\n",
              "            return create_model(  # type: ignore[call-overload]\n",
              "                \"RunnableSequenceOutput\",\n",
              "                **{\n",
              "                    **{\n",
              "                        k: (v.annotation, v.default)\n",
              "                        for k, v in prev_output_schema.__fields__.items()\n",
              "                    },\n",
              "                    **{\n",
              "                        k: (v.annotation, v.default)\n",
              "                        for k, v in mapper_output_schema.__fields__.items()\n",
              "                    },\n",
              "                },\n",
              "            )\n",
              "    elif isinstance(last, RunnablePick):\n",
              "        prev_output_schema = _seq_output_schema(steps[:-1], config)\n",
              "        if not prev_output_schema.__custom_root_type__:\n",
              "            # it's a dict as expected\n",
              "            if isinstance(last.keys, list):\n",
              "                return create_model(  # type: ignore[call-overload]\n",
              "                    \"RunnableSequenceOutput\",\n",
              "                    **{\n",
              "                        k: (v.annotation, v.default)\n",
              "                        for k, v in prev_output_schema.__fields__.items()\n",
              "                        if k in last.keys\n",
              "                    },\n",
              "                )\n",
              "            else:\n",
              "                field = prev_output_schema.__fields__[last.keys]\n",
              "                return create_model(  # type: ignore[call-overload]\n",
              "                    \"RunnableSequenceOutput\",\n",
              "                    __root__=(field.annotation, field.default),\n",
              "                )\n",
              "    return last.get_output_schema(config)\n",
              "[docs]class RunnableSequence(RunnableSerializable[Input, Output]):\n",
              "    \"\"\"Sequence of Runnables, where the output of each is the input of the next.\n",
              "    RunnableSequence is the most important composition operator in LangChain as it is\n",
              "    used in virtually every chain.\n",
              "    A RunnableSequence can be instantiated directly or more commonly by using the `|`\n",
              "    operator where either the left or right operands (or both) must be a Runnable.\n",
              "    Any RunnableSequence automatically supports sync, async, batch.\n",
              "    The default implementations of `batch` and `abatch` utilize threadpools and\n",
              "    asyncio gather and will be faster than naive invocation of invoke or ainvoke\n",
              "    for IO bound Runnables.\n",
              "    Batching is implemented by invoking the batch method on each component of the\n",
              "    RunnableSequence in order.\n",
              "    A RunnableSequence preserves the streaming properties of its components, so if all\n",
              "    components of the sequence implement a `transform` method -- which\n",
              "    is the method that implements the logic to map a streaming input to a streaming\n",
              "    output -- then the sequence will be able to stream input to output!\n",
              "    If any component of the sequence does not implement transform then the\n",
              "    streaming will only begin after this component is run. If there are\n",
              "    multiple blocking components, streaming begins after the last one.\n",
              "    Please note: RunnableLambdas do not support `transform` by default! So if\n",
              "        you need to use a RunnableLambdas be careful about where you place them in a\n",
              "        RunnableSequence (if you need to use the .stream()/.astream() methods).\n",
              "        If you need arbitrary logic and need streaming, you can subclass\n",
              "        Runnable, and implement `transform` for whatever logic you need.\n",
              "    Here is a simple example that uses simple functions to illustrate the use of\n",
              "    RunnableSequence:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import RunnableLambda\n",
              "            def add_one(x: int) -> int:\n",
              "                return x + 1\n",
              "            def mul_two(x: int) -> int:\n",
              "                return x * 2\n",
              "            runnable_1 = RunnableLambda(add_one)\n",
              "            runnable_2 = RunnableLambda(mul_two)\n",
              "            sequence = runnable_1 | runnable_2\n",
              "            # Or equivalently:\n",
              "            # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
              "            sequence.invoke(1)\n",
              "            await sequence.ainvoke(1)\n",
              "            sequence.batch([1, 2, 3])\n",
              "            await sequence.abatch([1, 2, 3])\n",
              "    Here's an example that uses streams JSON output generated by an LLM:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.output_parsers.json import SimpleJsonOutputParser\n",
              "            from langchain_openai import ChatOpenAI\n",
              "            prompt = PromptTemplate.from_template(\n",
              "                'In JSON format, give me a list of {topic} and their '\n",
              "                'corresponding names in French, Spanish and in a '\n",
              "                'Cat Language.'\n",
              "            )\n",
              "            model = ChatOpenAI()\n",
              "            chain = prompt | model | SimpleJsonOutputParser()\n",
              "            async for chunk in chain.astream({'topic': 'colors'}):\n",
              "                print('-')  # noqa: T201\n",
              "                print(chunk, sep='', flush=True)  # noqa: T201\n",
              "    \"\"\"\n",
              "    # The steps are broken into first, middle and last, solely for type checking\n",
              "    # purposes. It allows specifying the `Input` on the first type, the `Output` of\n",
              "    # the last type.\n",
              "    first: Runnable[Input, Any]\n",
              "    \"\"\"The first runnable in the sequence.\"\"\"\n",
              "    middle: List[Runnable[Any, Any]] = Field(default_factory=list)\n",
              "    \"\"\"The middle runnables in the sequence.\"\"\"\n",
              "    last: Runnable[Any, Output]\n",
              "    \"\"\"The last runnable in the sequence.\"\"\"\n",
              "    def __init__(\n",
              "        self,\n",
              "        *steps: RunnableLike,\n",
              "        name: Optional[str] = None,\n",
              "        first: Optional[Runnable[Any, Any]] = None,\n",
              "        middle: Optional[List[Runnable[Any, Any]]] = None,\n",
              "        last: Optional[Runnable[Any, Any]] = None,\n",
              "    ) -> None:\n",
              "        \"\"\"Create a new RunnableSequence.\n",
              "        Args:\n",
              "            steps: The steps to include in the sequence.\n",
              "        \"\"\"\n",
              "        steps_flat: List[Runnable] = []\n",
              "        if not steps:\n",
              "            if first is not None and last is not None:\n",
              "                steps_flat = [first] + (middle or []) + [last]\n",
              "        for step in steps:\n",
              "            if isinstance(step, RunnableSequence):\n",
              "                steps_flat.extend(step.steps)\n",
              "            else:\n",
              "                steps_flat.append(coerce_to_runnable(step))\n",
              "        if len(steps_flat) < 2:\n",
              "            raise ValueError(\n",
              "                f\"RunnableSequence must have at least 2 steps, got {len(steps_flat)}\"\n",
              "            )\n",
              "        super().__init__(  # type: ignore[call-arg]\n",
              "            first=steps_flat[0],\n",
              "            middle=list(steps_flat[1:-1]),\n",
              "            last=steps_flat[-1],\n",
              "            name=name,\n",
              "        )\n",
              "[docs]    @classmethod\n",
              "    def get_lc_namespace(cls) -> List[str]:\n",
              "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
              "        return [\"langchain\", \"schema\", \"runnable\"]\n",
              "    @property\n",
              "    def steps(self) -> List[Runnable[Any, Any]]:\n",
              "        \"\"\"All the runnables that make up the sequence in order.\"\"\"\n",
              "        return [self.first] + self.middle + [self.last]\n",
              "[docs]    @classmethod\n",
              "    def is_lc_serializable(cls) -> bool:\n",
              "        return True\n",
              "    class Config:\n",
              "        arbitrary_types_allowed = True\n",
              "    @property\n",
              "    def InputType(self) -> Type[Input]:\n",
              "        return self.first.InputType\n",
              "    @property\n",
              "    def OutputType(self) -> Type[Output]:\n",
              "        return self.last.OutputType\n",
              "[docs]    def get_input_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        return _seq_input_schema(self.steps, config)\n",
              "[docs]    def get_output_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        return _seq_output_schema(self.steps, config)\n",
              "    @property\n",
              "    def config_specs(self) -> List[ConfigurableFieldSpec]:\n",
              "        from langchain_core.beta.runnables.context import (\n",
              "            CONTEXT_CONFIG_PREFIX,\n",
              "            _key_from_id,\n",
              "        )\n",
              "        # get all specs\n",
              "        all_specs = [\n",
              "            (spec, idx)\n",
              "            for idx, step in enumerate(self.steps)\n",
              "            for spec in step.config_specs\n",
              "        ]\n",
              "        # calculate context dependencies\n",
              "        specs_by_pos = groupby(\n",
              "            [tup for tup in all_specs if tup[0].id.startswith(CONTEXT_CONFIG_PREFIX)],\n",
              "            lambda x: x[1],\n",
              "        )\n",
              "        next_deps: Set[str] = set()\n",
              "        deps_by_pos: Dict[int, Set[str]] = {}\n",
              "        for pos, specs in specs_by_pos:\n",
              "            deps_by_pos[pos] = next_deps\n",
              "            next_deps = next_deps | {spec[0].id for spec in specs}\n",
              "        # assign context dependencies\n",
              "        for pos, (spec, idx) in enumerate(all_specs):\n",
              "            if spec.id.startswith(CONTEXT_CONFIG_PREFIX):\n",
              "                all_specs[pos] = (\n",
              "                    ConfigurableFieldSpec(\n",
              "                        id=spec.id,\n",
              "                        annotation=spec.annotation,\n",
              "                        name=spec.name,\n",
              "                        default=spec.default,\n",
              "                        description=spec.description,\n",
              "                        is_shared=spec.is_shared,\n",
              "                        dependencies=[\n",
              "                            d\n",
              "                            for d in deps_by_pos[idx]\n",
              "                            if _key_from_id(d) != _key_from_id(spec.id)\n",
              "                        ]\n",
              "                        + (spec.dependencies or []),\n",
              "                    ),\n",
              "                    idx,\n",
              "                )\n",
              "        return get_unique_config_specs(spec for spec, _ in all_specs)\n",
              "[docs]    def get_graph(self, config: Optional[RunnableConfig] = None) -> Graph:\n",
              "        from langchain_core.runnables.graph import Graph\n",
              "        graph = Graph()\n",
              "        for step in self.steps:\n",
              "            current_last_node = graph.last_node()\n",
              "            step_graph = step.get_graph(config)\n",
              "            if step is not self.first:\n",
              "                step_graph.trim_first_node()\n",
              "            if step is not self.last:\n",
              "                step_graph.trim_last_node()\n",
              "            graph.extend(step_graph)\n",
              "            step_first_node = step_graph.first_node()\n",
              "            if not step_first_node:\n",
              "                raise ValueError(f\"Runnable {step} has no first node\")\n",
              "            if current_last_node:\n",
              "                graph.add_edge(current_last_node, step_first_node)\n",
              "        return graph\n",
              "    def __repr__(self) -> str:\n",
              "        return \"\\n| \".join(\n",
              "            repr(s) if i == 0 else indent_lines_after_first(repr(s), \"| \")\n",
              "            for i, s in enumerate(self.steps)\n",
              "        )\n",
              "    def __or__(\n",
              "        self,\n",
              "        other: Union[\n",
              "            Runnable[Any, Other],\n",
              "            Callable[[Any], Other],\n",
              "            Callable[[Iterator[Any]], Iterator[Other]],\n",
              "            Mapping[str, Union[Runnable[Any, Other], Callable[[Any], Other], Any]],\n",
              "        ],\n",
              "    ) -> RunnableSerializable[Input, Other]:\n",
              "        if isinstance(other, RunnableSequence):\n",
              "            return RunnableSequence(\n",
              "                self.first,\n",
              "                *self.middle,\n",
              "                self.last,\n",
              "                other.first,\n",
              "                *other.middle,\n",
              "                other.last,\n",
              "                name=self.name or other.name,\n",
              "            )\n",
              "        else:\n",
              "            return RunnableSequence(\n",
              "                self.first,\n",
              "                *self.middle,\n",
              "                self.last,\n",
              "                coerce_to_runnable(other),\n",
              "                name=self.name,\n",
              "            )\n",
              "    def __ror__(\n",
              "        self,\n",
              "        other: Union[\n",
              "            Runnable[Other, Any],\n",
              "            Callable[[Other], Any],\n",
              "            Callable[[Iterator[Other]], Iterator[Any]],\n",
              "            Mapping[str, Union[Runnable[Other, Any], Callable[[Other], Any], Any]],\n",
              "        ],\n",
              "    ) -> RunnableSerializable[Other, Output]:\n",
              "        if isinstance(other, RunnableSequence):\n",
              "            return RunnableSequence(\n",
              "                other.first,\n",
              "                *other.middle,\n",
              "                other.last,\n",
              "                self.first,\n",
              "                *self.middle,\n",
              "                self.last,\n",
              "                name=other.name or self.name,\n",
              "            )\n",
              "        else:\n",
              "            return RunnableSequence(\n",
              "                coerce_to_runnable(other),\n",
              "                self.first,\n",
              "                *self.middle,\n",
              "                self.last,\n",
              "                name=self.name,\n",
              "            )\n",
              "[docs]    def invoke(self, input: Input, config: Optional[RunnableConfig] = None) -> Output:\n",
              "        from langchain_core.beta.runnables.context import config_with_context\n",
              "        # setup callbacks and context\n",
              "        config = config_with_context(ensure_config(config), self.steps)\n",
              "        callback_manager = get_callback_manager_for_config(config)\n",
              "        # start the root run\n",
              "        run_manager = callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            input,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        # invoke all steps in sequence\n",
              "        try:\n",
              "            for i, step in enumerate(self.steps):\n",
              "                input = step.invoke(\n",
              "                    input,\n",
              "                    # mark each step as a child run\n",
              "                    patch_config(\n",
              "                        config, callbacks=run_manager.get_child(f\"seq:step:{i+1}\")\n",
              "                    ),\n",
              "                )\n",
              "        # finish the root run\n",
              "        except BaseException as e:\n",
              "            run_manager.on_chain_error(e)\n",
              "            raise\n",
              "        else:\n",
              "            run_manager.on_chain_end(input)\n",
              "            return cast(Output, input)\n",
              "[docs]    async def ainvoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        from langchain_core.beta.runnables.context import aconfig_with_context\n",
              "        # setup callbacks and context\n",
              "        config = aconfig_with_context(ensure_config(config), self.steps)\n",
              "        callback_manager = get_async_callback_manager_for_config(config)\n",
              "        # start the root run\n",
              "        run_manager = await callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            input,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        # invoke all steps in sequence\n",
              "        try:\n",
              "            for i, step in enumerate(self.steps):\n",
              "                input = await step.ainvoke(\n",
              "                    input,\n",
              "                    # mark each step as a child run\n",
              "                    patch_config(\n",
              "                        config, callbacks=run_manager.get_child(f\"seq:step:{i+1}\")\n",
              "                    ),\n",
              "                )\n",
              "        # finish the root run\n",
              "        except BaseException as e:\n",
              "            await run_manager.on_chain_error(e)\n",
              "            raise\n",
              "        else:\n",
              "            await run_manager.on_chain_end(input)\n",
              "            return cast(Output, input)\n",
              "[docs]    def batch(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        from langchain_core.beta.runnables.context import config_with_context\n",
              "        from langchain_core.callbacks.manager import CallbackManager\n",
              "        if not inputs:\n",
              "            return []\n",
              "        # setup callbacks and context\n",
              "        configs = [\n",
              "            config_with_context(c, self.steps)\n",
              "            for c in get_config_list(config, len(inputs))\n",
              "        ]\n",
              "        callback_managers = [\n",
              "            CallbackManager.configure(\n",
              "                inheritable_callbacks=config.get(\"callbacks\"),\n",
              "                local_callbacks=None,\n",
              "                verbose=False,\n",
              "                inheritable_tags=config.get(\"tags\"),\n",
              "                local_tags=None,\n",
              "                inheritable_metadata=config.get(\"metadata\"),\n",
              "                local_metadata=None,\n",
              "            )\n",
              "            for config in configs\n",
              "        ]\n",
              "        # start the root runs, one per input\n",
              "        run_managers = [\n",
              "            cm.on_chain_start(\n",
              "                dumpd(self),\n",
              "                input,\n",
              "                name=config.get(\"run_name\") or self.get_name(),\n",
              "                run_id=config.pop(\"run_id\", None),\n",
              "            )\n",
              "            for cm, input, config in zip(callback_managers, inputs, configs)\n",
              "        ]\n",
              "        # invoke\n",
              "        try:\n",
              "            if return_exceptions:\n",
              "                # Track which inputs (by index) failed so far\n",
              "                # If an input has failed it will be present in this map,\n",
              "                # and the value will be the exception that was raised.\n",
              "                failed_inputs_map: Dict[int, Exception] = {}\n",
              "                for stepidx, step in enumerate(self.steps):\n",
              "                    # Assemble the original indexes of the remaining inputs\n",
              "                    # (i.e. the ones that haven't failed yet)\n",
              "                    remaining_idxs = [\n",
              "                        i for i in range(len(configs)) if i not in failed_inputs_map\n",
              "                    ]\n",
              "                    # Invoke the step on the remaining inputs\n",
              "                    inputs = step.batch(\n",
              "                        [\n",
              "                            inp\n",
              "                            for i, inp in zip(remaining_idxs, inputs)\n",
              "                            if i not in failed_inputs_map\n",
              "                        ],\n",
              "                        [\n",
              "                            # each step a child run of the corresponding root run\n",
              "                            patch_config(\n",
              "                                config, callbacks=rm.get_child(f\"seq:step:{stepidx+1}\")\n",
              "                            )\n",
              "                            for i, (rm, config) in enumerate(zip(run_managers, configs))\n",
              "                            if i not in failed_inputs_map\n",
              "                        ],\n",
              "                        return_exceptions=return_exceptions,\n",
              "                        **kwargs,\n",
              "                    )\n",
              "                    # If an input failed, add it to the map\n",
              "                    for i, inp in zip(remaining_idxs, inputs):\n",
              "                        if isinstance(inp, Exception):\n",
              "                            failed_inputs_map[i] = inp\n",
              "                    inputs = [inp for inp in inputs if not isinstance(inp, Exception)]\n",
              "                    # If all inputs have failed, stop processing\n",
              "                    if len(failed_inputs_map) == len(configs):\n",
              "                        break\n",
              "                # Reassemble the outputs, inserting Exceptions for failed inputs\n",
              "                inputs_copy = inputs.copy()\n",
              "                inputs = []\n",
              "                for i in range(len(configs)):\n",
              "                    if i in failed_inputs_map:\n",
              "                        inputs.append(cast(Input, failed_inputs_map[i]))\n",
              "                    else:\n",
              "                        inputs.append(inputs_copy.pop(0))\n",
              "            else:\n",
              "                for i, step in enumerate(self.steps):\n",
              "                    inputs = step.batch(\n",
              "                        inputs,\n",
              "                        [\n",
              "                            # each step a child run of the corresponding root run\n",
              "                            patch_config(\n",
              "                                config, callbacks=rm.get_child(f\"seq:step:{i+1}\")\n",
              "                            )\n",
              "                            for rm, config in zip(run_managers, configs)\n",
              "                        ],\n",
              "                    )\n",
              "        # finish the root runs\n",
              "        except BaseException as e:\n",
              "            for rm in run_managers:\n",
              "                rm.on_chain_error(e)\n",
              "            if return_exceptions:\n",
              "                return cast(List[Output], [e for _ in inputs])\n",
              "            else:\n",
              "                raise\n",
              "        else:\n",
              "            first_exception: Optional[Exception] = None\n",
              "            for run_manager, out in zip(run_managers, inputs):\n",
              "                if isinstance(out, Exception):\n",
              "                    first_exception = first_exception or out\n",
              "                    run_manager.on_chain_error(out)\n",
              "                else:\n",
              "                    run_manager.on_chain_end(out)\n",
              "            if return_exceptions or first_exception is None:\n",
              "                return cast(List[Output], inputs)\n",
              "            else:\n",
              "                raise first_exception\n",
              "[docs]    async def abatch(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        from langchain_core.beta.runnables.context import aconfig_with_context\n",
              "        from langchain_core.callbacks.manager import AsyncCallbackManager\n",
              "        if not inputs:\n",
              "            return []\n",
              "        # setup callbacks and context\n",
              "        configs = [\n",
              "            aconfig_with_context(c, self.steps)\n",
              "            for c in get_config_list(config, len(inputs))\n",
              "        ]\n",
              "        callback_managers = [\n",
              "            AsyncCallbackManager.configure(\n",
              "                inheritable_callbacks=config.get(\"callbacks\"),\n",
              "                local_callbacks=None,\n",
              "                verbose=False,\n",
              "                inheritable_tags=config.get(\"tags\"),\n",
              "                local_tags=None,\n",
              "                inheritable_metadata=config.get(\"metadata\"),\n",
              "                local_metadata=None,\n",
              "            )\n",
              "            for config in configs\n",
              "        ]\n",
              "        # start the root runs, one per input\n",
              "        run_managers: List[AsyncCallbackManagerForChainRun] = await asyncio.gather(\n",
              "            *(\n",
              "                cm.on_chain_start(\n",
              "                    dumpd(self),\n",
              "                    input,\n",
              "                    name=config.get(\"run_name\") or self.get_name(),\n",
              "                    run_id=config.pop(\"run_id\", None),\n",
              "                )\n",
              "                for cm, input, config in zip(callback_managers, inputs, configs)\n",
              "            )\n",
              "        )\n",
              "        # invoke .batch() on each step\n",
              "        # this uses batching optimizations in Runnable subclasses, like LLM\n",
              "        try:\n",
              "            if return_exceptions:\n",
              "                # Track which inputs (by index) failed so far\n",
              "                # If an input has failed it will be present in this map,\n",
              "                # and the value will be the exception that was raised.\n",
              "                failed_inputs_map: Dict[int, Exception] = {}\n",
              "                for stepidx, step in enumerate(self.steps):\n",
              "                    # Assemble the original indexes of the remaining inputs\n",
              "                    # (i.e. the ones that haven't failed yet)\n",
              "                    remaining_idxs = [\n",
              "                        i for i in range(len(configs)) if i not in failed_inputs_map\n",
              "                    ]\n",
              "                    # Invoke the step on the remaining inputs\n",
              "                    inputs = await step.abatch(\n",
              "                        [\n",
              "                            inp\n",
              "                            for i, inp in zip(remaining_idxs, inputs)\n",
              "                            if i not in failed_inputs_map\n",
              "                        ],\n",
              "                        [\n",
              "                            # each step a child run of the corresponding root run\n",
              "                            patch_config(\n",
              "                                config, callbacks=rm.get_child(f\"seq:step:{stepidx+1}\")\n",
              "                            )\n",
              "                            for i, (rm, config) in enumerate(zip(run_managers, configs))\n",
              "                            if i not in failed_inputs_map\n",
              "                        ],\n",
              "                        return_exceptions=return_exceptions,\n",
              "                        **kwargs,\n",
              "                    )\n",
              "                    # If an input failed, add it to the map\n",
              "                    for i, inp in zip(remaining_idxs, inputs):\n",
              "                        if isinstance(inp, Exception):\n",
              "                            failed_inputs_map[i] = inp\n",
              "                    inputs = [inp for inp in inputs if not isinstance(inp, Exception)]\n",
              "                    # If all inputs have failed, stop processing\n",
              "                    if len(failed_inputs_map) == len(configs):\n",
              "                        break\n",
              "                # Reassemble the outputs, inserting Exceptions for failed inputs\n",
              "                inputs_copy = inputs.copy()\n",
              "                inputs = []\n",
              "                for i in range(len(configs)):\n",
              "                    if i in failed_inputs_map:\n",
              "                        inputs.append(cast(Input, failed_inputs_map[i]))\n",
              "                    else:\n",
              "                        inputs.append(inputs_copy.pop(0))\n",
              "            else:\n",
              "                for i, step in enumerate(self.steps):\n",
              "                    inputs = await step.abatch(\n",
              "                        inputs,\n",
              "                        [\n",
              "                            # each step a child run of the corresponding root run\n",
              "                            patch_config(\n",
              "                                config, callbacks=rm.get_child(f\"seq:step:{i+1}\")\n",
              "                            )\n",
              "                            for rm, config in zip(run_managers, configs)\n",
              "                        ],\n",
              "                    )\n",
              "        # finish the root runs\n",
              "        except BaseException as e:\n",
              "            await asyncio.gather(*(rm.on_chain_error(e) for rm in run_managers))\n",
              "            if return_exceptions:\n",
              "                return cast(List[Output], [e for _ in inputs])\n",
              "            else:\n",
              "                raise\n",
              "        else:\n",
              "            first_exception: Optional[Exception] = None\n",
              "            coros: List[Awaitable[None]] = []\n",
              "            for run_manager, out in zip(run_managers, inputs):\n",
              "                if isinstance(out, Exception):\n",
              "                    first_exception = first_exception or out\n",
              "                    coros.append(run_manager.on_chain_error(out))\n",
              "                else:\n",
              "                    coros.append(run_manager.on_chain_end(out))\n",
              "            await asyncio.gather(*coros)\n",
              "            if return_exceptions or first_exception is None:\n",
              "                return cast(List[Output], inputs)\n",
              "            else:\n",
              "                raise first_exception\n",
              "    def _transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        run_manager: CallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "    ) -> Iterator[Output]:\n",
              "        from langchain_core.beta.runnables.context import config_with_context\n",
              "        steps = [self.first] + self.middle + [self.last]\n",
              "        config = config_with_context(config, self.steps)\n",
              "        # transform the input stream of each step with the next\n",
              "        # steps that don't natively support transforming an input stream will\n",
              "        # buffer input in memory until all available, and then start emitting output\n",
              "        final_pipeline = cast(Iterator[Output], input)\n",
              "        for step in steps:\n",
              "            final_pipeline = step.transform(\n",
              "                final_pipeline,\n",
              "                patch_config(\n",
              "                    config,\n",
              "                    callbacks=run_manager.get_child(f\"seq:step:{steps.index(step)+1}\"),\n",
              "                ),\n",
              "            )\n",
              "        for output in final_pipeline:\n",
              "            yield output\n",
              "    async def _atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        run_manager: AsyncCallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        from langchain_core.beta.runnables.context import aconfig_with_context\n",
              "        steps = [self.first] + self.middle + [self.last]\n",
              "        config = aconfig_with_context(config, self.steps)\n",
              "        # stream the last steps\n",
              "        # transform the input stream of each step with the next\n",
              "        # steps that don't natively support transforming an input stream will\n",
              "        # buffer input in memory until all available, and then start emitting output\n",
              "        final_pipeline = cast(AsyncIterator[Output], input)\n",
              "        for step in steps:\n",
              "            final_pipeline = step.atransform(\n",
              "                final_pipeline,\n",
              "                patch_config(\n",
              "                    config,\n",
              "                    callbacks=run_manager.get_child(f\"seq:step:{steps.index(step)+1}\"),\n",
              "                ),\n",
              "            )\n",
              "        async for output in final_pipeline:\n",
              "            yield output\n",
              "[docs]    def transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        yield from self._transform_stream_with_config(\n",
              "            input,\n",
              "            self._transform,\n",
              "            patch_config(config, run_name=(config or {}).get(\"run_name\") or self.name),\n",
              "            **kwargs,\n",
              "        )\n",
              "[docs]    def stream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        yield from self.transform(iter([input]), config, **kwargs)\n",
              "[docs]    async def atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async for chunk in self._atransform_stream_with_config(\n",
              "            input,\n",
              "            self._atransform,\n",
              "            patch_config(config, run_name=(config or {}).get(\"run_name\") or self.name),\n",
              "            **kwargs,\n",
              "        ):\n",
              "            yield chunk\n",
              "[docs]    async def astream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async def input_aiter() -> AsyncIterator[Input]:\n",
              "            yield input\n",
              "        async for chunk in self.atransform(input_aiter(), config, **kwargs):\n",
              "            yield chunk\n",
              "[docs]class RunnableParallel(RunnableSerializable[Input, Dict[str, Any]]):\n",
              "    \"\"\"Runnable that runs a mapping of Runnables in parallel, and returns a mapping\n",
              "    of their outputs.\n",
              "    RunnableParallel is one of the two main composition primitives for the LCEL,\n",
              "    alongside RunnableSequence. It invokes Runnables concurrently, providing the same\n",
              "    input to each.\n",
              "    A RunnableParallel can be instantiated directly or by using a dict literal within a\n",
              "    sequence.\n",
              "    Here is a simple example that uses functions to illustrate the use of\n",
              "    RunnableParallel:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import RunnableLambda\n",
              "            def add_one(x: int) -> int:\n",
              "                return x + 1\n",
              "            def mul_two(x: int) -> int:\n",
              "                return x * 2\n",
              "            def mul_three(x: int) -> int:\n",
              "                return x * 3\n",
              "            runnable_1 = RunnableLambda(add_one)\n",
              "            runnable_2 = RunnableLambda(mul_two)\n",
              "            runnable_3 = RunnableLambda(mul_three)\n",
              "            sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\n",
              "                \"mul_two\": runnable_2,\n",
              "                \"mul_three\": runnable_3,\n",
              "            }\n",
              "            # Or equivalently:\n",
              "            # sequence = runnable_1 | RunnableParallel(\n",
              "            #     {\"mul_two\": runnable_2, \"mul_three\": runnable_3}\n",
              "            # )\n",
              "            # Also equivalently:\n",
              "            # sequence = runnable_1 | RunnableParallel(\n",
              "            #     mul_two=runnable_2,\n",
              "            #     mul_three=runnable_3,\n",
              "            # )\n",
              "            sequence.invoke(1)\n",
              "            await sequence.ainvoke(1)\n",
              "            sequence.batch([1, 2, 3])\n",
              "            await sequence.abatch([1, 2, 3])\n",
              "    RunnableParallel makes it easy to run Runnables in parallel. In the below example,\n",
              "    we simultaneously stream output from two different Runnables:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.prompts import ChatPromptTemplate\n",
              "            from langchain_core.runnables import RunnableParallel\n",
              "            from langchain_openai import ChatOpenAI\n",
              "            model = ChatOpenAI()\n",
              "            joke_chain = (\n",
              "                ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
              "                | model\n",
              "            )\n",
              "            poem_chain = (\n",
              "                ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\")\n",
              "                | model\n",
              "            )\n",
              "            runnable = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
              "            # Display stream\n",
              "            output = {key: \"\" for key, _ in runnable.output_schema()}\n",
              "            for chunk in runnable.stream({\"topic\": \"bear\"}):\n",
              "                for key in chunk:\n",
              "                    output[key] = output[key] + chunk[key].content\n",
              "                print(output)  # noqa: T201\n",
              "    \"\"\"\n",
              "    steps: Mapping[str, Runnable[Input, Any]]\n",
              "    def __init__(\n",
              "        self,\n",
              "        __steps: Optional[\n",
              "            Mapping[\n",
              "                str,\n",
              "                Union[\n",
              "                    Runnable[Input, Any],\n",
              "                    Callable[[Input], Any],\n",
              "                    Mapping[str, Union[Runnable[Input, Any], Callable[[Input], Any]]],\n",
              "                ],\n",
              "            ]\n",
              "        ] = None,\n",
              "        **kwargs: Union[\n",
              "            Runnable[Input, Any],\n",
              "            Callable[[Input], Any],\n",
              "            Mapping[str, Union[Runnable[Input, Any], Callable[[Input], Any]]],\n",
              "        ],\n",
              "    ) -> None:\n",
              "        merged = {**__steps} if __steps is not None else {}\n",
              "        merged.update(kwargs)\n",
              "        super().__init__(  # type: ignore[call-arg]\n",
              "            steps={key: coerce_to_runnable(r) for key, r in merged.items()}\n",
              "        )\n",
              "[docs]    @classmethod\n",
              "    def is_lc_serializable(cls) -> bool:\n",
              "        return True\n",
              "[docs]    @classmethod\n",
              "    def get_lc_namespace(cls) -> List[str]:\n",
              "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
              "        return [\"langchain\", \"schema\", \"runnable\"]\n",
              "    class Config:\n",
              "        arbitrary_types_allowed = True\n",
              "[docs]    def get_name(\n",
              "        self, suffix: Optional[str] = None, *, name: Optional[str] = None\n",
              "    ) -> str:\n",
              "        name = name or self.name or f\"RunnableParallel<{','.join(self.steps.keys())}>\"\n",
              "        return super().get_name(suffix, name=name)\n",
              "    @property\n",
              "    def InputType(self) -> Any:\n",
              "        for step in self.steps.values():\n",
              "            if step.InputType:\n",
              "                return step.InputType\n",
              "        return Any\n",
              "[docs]    def get_input_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        if all(\n",
              "            s.get_input_schema(config).schema().get(\"type\", \"object\") == \"object\"\n",
              "            for s in self.steps.values()\n",
              "        ):\n",
              "            # This is correct, but pydantic typings/mypy don't think so.\n",
              "            return create_model(  # type: ignore[call-overload]\n",
              "                self.get_name(\"Input\"),\n",
              "                **{\n",
              "                    k: (v.annotation, v.default)\n",
              "                    for step in self.steps.values()\n",
              "                    for k, v in step.get_input_schema(config).__fields__.items()\n",
              "                    if k != \"__root__\"\n",
              "                },\n",
              "            )\n",
              "        return super().get_input_schema(config)\n",
              "[docs]    def get_output_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        # This is correct, but pydantic typings/mypy don't think so.\n",
              "        return create_model(  # type: ignore[call-overload]\n",
              "            self.get_name(\"Output\"),\n",
              "            **{k: (v.OutputType, None) for k, v in self.steps.items()},\n",
              "        )\n",
              "    @property\n",
              "    def config_specs(self) -> List[ConfigurableFieldSpec]:\n",
              "        return get_unique_config_specs(\n",
              "            spec for step in self.steps.values() for spec in step.config_specs\n",
              "        )\n",
              "[docs]    def get_graph(self, config: Optional[RunnableConfig] = None) -> Graph:\n",
              "        from langchain_core.runnables.graph import Graph\n",
              "        graph = Graph()\n",
              "        input_node = graph.add_node(self.get_input_schema(config))\n",
              "        output_node = graph.add_node(self.get_output_schema(config))\n",
              "        for step in self.steps.values():\n",
              "            step_graph = step.get_graph()\n",
              "            step_graph.trim_first_node()\n",
              "            step_graph.trim_last_node()\n",
              "            if not step_graph:\n",
              "                graph.add_edge(input_node, output_node)\n",
              "            else:\n",
              "                graph.extend(step_graph)\n",
              "                step_first_node = step_graph.first_node()\n",
              "                if not step_first_node:\n",
              "                    raise ValueError(f\"Runnable {step} has no first node\")\n",
              "                step_last_node = step_graph.last_node()\n",
              "                if not step_last_node:\n",
              "                    raise ValueError(f\"Runnable {step} has no last node\")\n",
              "                graph.add_edge(input_node, step_first_node)\n",
              "                graph.add_edge(step_last_node, output_node)\n",
              "        return graph\n",
              "    def __repr__(self) -> str:\n",
              "        map_for_repr = \",\\n  \".join(\n",
              "            f\"{k}: {indent_lines_after_first(repr(v), '  ' + k + ': ')}\"\n",
              "            for k, v in self.steps.items()\n",
              "        )\n",
              "        return \"{\\n  \" + map_for_repr + \"\\n}\"\n",
              "[docs]    def invoke(\n",
              "        self, input: Input, config: Optional[RunnableConfig] = None\n",
              "    ) -> Dict[str, Any]:\n",
              "        from langchain_core.callbacks.manager import CallbackManager\n",
              "        # setup callbacks\n",
              "        config = ensure_config(config)\n",
              "        callback_manager = CallbackManager.configure(\n",
              "            inheritable_callbacks=config.get(\"callbacks\"),\n",
              "            local_callbacks=None,\n",
              "            verbose=False,\n",
              "            inheritable_tags=config.get(\"tags\"),\n",
              "            local_tags=None,\n",
              "            inheritable_metadata=config.get(\"metadata\"),\n",
              "            local_metadata=None,\n",
              "        )\n",
              "        # start the root run\n",
              "        run_manager = callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            input,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        # gather results from all steps\n",
              "        try:\n",
              "            # copy to avoid issues from the caller mutating the steps during invoke()\n",
              "            steps = dict(self.steps)\n",
              "            with get_executor_for_config(config) as executor:\n",
              "                futures = [\n",
              "                    executor.submit(\n",
              "                        step.invoke,\n",
              "                        input,\n",
              "                        # mark each step as a child run\n",
              "                        patch_config(\n",
              "                            config,\n",
              "                            callbacks=run_manager.get_child(f\"map:key:{key}\"),\n",
              "                        ),\n",
              "                    )\n",
              "                    for key, step in steps.items()\n",
              "                ]\n",
              "                output = {key: future.result() for key, future in zip(steps, futures)}\n",
              "        # finish the root run\n",
              "        except BaseException as e:\n",
              "            run_manager.on_chain_error(e)\n",
              "            raise\n",
              "        else:\n",
              "            run_manager.on_chain_end(output)\n",
              "            return output\n",
              "[docs]    async def ainvoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Dict[str, Any]:\n",
              "        # setup callbacks\n",
              "        config = ensure_config(config)\n",
              "        callback_manager = get_async_callback_manager_for_config(config)\n",
              "        # start the root run\n",
              "        run_manager = await callback_manager.on_chain_start(\n",
              "            dumpd(self),\n",
              "            input,\n",
              "            name=config.get(\"run_name\") or self.get_name(),\n",
              "            run_id=config.pop(\"run_id\", None),\n",
              "        )\n",
              "        # gather results from all steps\n",
              "        try:\n",
              "            # copy to avoid issues from the caller mutating the steps during invoke()\n",
              "            steps = dict(self.steps)\n",
              "            results = await asyncio.gather(\n",
              "                *(\n",
              "                    step.ainvoke(\n",
              "                        input,\n",
              "                        # mark each step as a child run\n",
              "                        patch_config(\n",
              "                            config, callbacks=run_manager.get_child(f\"map:key:{key}\")\n",
              "                        ),\n",
              "                    )\n",
              "                    for key, step in steps.items()\n",
              "                )\n",
              "            )\n",
              "            output = {key: value for key, value in zip(steps, results)}\n",
              "        # finish the root run\n",
              "        except BaseException as e:\n",
              "            await run_manager.on_chain_error(e)\n",
              "            raise\n",
              "        else:\n",
              "            await run_manager.on_chain_end(output)\n",
              "            return output\n",
              "    def _transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        run_manager: CallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "    ) -> Iterator[AddableDict]:\n",
              "        # Shallow copy steps to ignore mutations while in progress\n",
              "        steps = dict(self.steps)\n",
              "        # Each step gets a copy of the input iterator,\n",
              "        # which is consumed in parallel in a separate thread.\n",
              "        input_copies = list(safetee(input, len(steps), lock=threading.Lock()))\n",
              "        with get_executor_for_config(config) as executor:\n",
              "            # Create the transform() generator for each step\n",
              "            named_generators = [\n",
              "                (\n",
              "                    name,\n",
              "                    step.transform(\n",
              "                        input_copies.pop(),\n",
              "                        patch_config(\n",
              "                            config, callbacks=run_manager.get_child(f\"map:key:{name}\")\n",
              "                        ),\n",
              "                    ),\n",
              "                )\n",
              "                for name, step in steps.items()\n",
              "            ]\n",
              "            # Start the first iteration of each generator\n",
              "            futures = {\n",
              "                executor.submit(next, generator): (step_name, generator)\n",
              "                for step_name, generator in named_generators\n",
              "            }\n",
              "            # Yield chunks from each as they become available,\n",
              "            # and start the next iteration of that generator that yielded it.\n",
              "            # When all generators are exhausted, stop.\n",
              "            while futures:\n",
              "                completed_futures, _ = wait(futures, return_when=FIRST_COMPLETED)\n",
              "                for future in completed_futures:\n",
              "                    (step_name, generator) = futures.pop(future)\n",
              "                    try:\n",
              "                        chunk = AddableDict({step_name: future.result()})\n",
              "                        yield chunk\n",
              "                        futures[executor.submit(next, generator)] = (\n",
              "                            step_name,\n",
              "                            generator,\n",
              "                        )\n",
              "                    except StopIteration:\n",
              "                        pass\n",
              "[docs]    def transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Dict[str, Any]]:\n",
              "        yield from self._transform_stream_with_config(\n",
              "            input, self._transform, config, **kwargs\n",
              "        )\n",
              "[docs]    def stream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Dict[str, Any]]:\n",
              "        yield from self.transform(iter([input]), config)\n",
              "    async def _atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        run_manager: AsyncCallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "    ) -> AsyncIterator[AddableDict]:\n",
              "        # Shallow copy steps to ignore mutations while in progress\n",
              "        steps = dict(self.steps)\n",
              "        # Each step gets a copy of the input iterator,\n",
              "        # which is consumed in parallel in a separate thread.\n",
              "        input_copies = list(atee(input, len(steps), lock=asyncio.Lock()))\n",
              "        # Create the transform() generator for each step\n",
              "        named_generators = [\n",
              "            (\n",
              "                name,\n",
              "                step.atransform(\n",
              "                    input_copies.pop(),\n",
              "                    patch_config(\n",
              "                        config, callbacks=run_manager.get_child(f\"map:key:{name}\")\n",
              "                    ),\n",
              "                ),\n",
              "            )\n",
              "            for name, step in steps.items()\n",
              "        ]\n",
              "        # Wrap in a coroutine to satisfy linter\n",
              "        async def get_next_chunk(generator: AsyncIterator) -> Optional[Output]:\n",
              "            return await py_anext(generator)\n",
              "        # Start the first iteration of each generator\n",
              "        tasks = {\n",
              "            asyncio.create_task(get_next_chunk(generator)): (step_name, generator)\n",
              "            for step_name, generator in named_generators\n",
              "        }\n",
              "        # Yield chunks from each as they become available,\n",
              "        # and start the next iteration of the generator that yielded it.\n",
              "        # When all generators are exhausted, stop.\n",
              "        while tasks:\n",
              "            completed_tasks, _ = await asyncio.wait(\n",
              "                tasks, return_when=asyncio.FIRST_COMPLETED\n",
              "            )\n",
              "            for task in completed_tasks:\n",
              "                (step_name, generator) = tasks.pop(task)\n",
              "                try:\n",
              "                    chunk = AddableDict({step_name: task.result()})\n",
              "                    yield chunk\n",
              "                    new_task = asyncio.create_task(get_next_chunk(generator))\n",
              "                    tasks[new_task] = (step_name, generator)\n",
              "                except StopAsyncIteration:\n",
              "                    pass\n",
              "[docs]    async def atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[Dict[str, Any]]:\n",
              "        async for chunk in self._atransform_stream_with_config(\n",
              "            input, self._atransform, config, **kwargs\n",
              "        ):\n",
              "            yield chunk\n",
              "[docs]    async def astream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Dict[str, Any]]:\n",
              "        async def input_aiter() -> AsyncIterator[Input]:\n",
              "            yield input\n",
              "        async for chunk in self.atransform(input_aiter(), config):\n",
              "            yield chunk\n",
              "# We support both names\n",
              "RunnableMap = RunnableParallel\n",
              "[docs]class RunnableGenerator(Runnable[Input, Output]):\n",
              "    \"\"\"Runnable that runs a generator function.\n",
              "    RunnableGenerators can be instantiated directly or by using a generator within\n",
              "    a sequence.\n",
              "    RunnableGenerators can be used to implement custom behavior, such as custom output\n",
              "    parsers, while preserving streaming capabilities. Given a generator function with\n",
              "    a signature Iterator[A] -> Iterator[B], wrapping it in a RunnableGenerator allows\n",
              "    it to emit output chunks as soon as they are streamed in from the previous step.\n",
              "    Note that if a generator function has a signature A -> Iterator[B], such that it\n",
              "    requires its input from the previous step to be completed before emitting chunks\n",
              "    (e.g., most LLMs need the entire prompt available to start generating), it can\n",
              "    instead be wrapped in a RunnableLambda.\n",
              "    Here is an example to show the basic mechanics of a RunnableGenerator:\n",
              "        .. code-block:: python\n",
              "            from typing import Any, AsyncIterator, Iterator\n",
              "            from langchain_core.runnables import RunnableGenerator\n",
              "            def gen(input: Iterator[Any]) -> Iterator[str]:\n",
              "                for token in [\"Have\", \" a\", \" nice\", \" day\"]:\n",
              "                    yield token\n",
              "            runnable = RunnableGenerator(gen)\n",
              "            runnable.invoke(None)  # \"Have a nice day\"\n",
              "            list(runnable.stream(None))  # [\"Have\", \" a\", \" nice\", \" day\"]\n",
              "            runnable.batch([None, None])  # [\"Have a nice day\", \"Have a nice day\"]\n",
              "            # Async version:\n",
              "            async def agen(input: AsyncIterator[Any]) -> AsyncIterator[str]:\n",
              "                for token in [\"Have\", \" a\", \" nice\", \" day\"]:\n",
              "                    yield token\n",
              "            runnable = RunnableGenerator(agen)\n",
              "            await runnable.ainvoke(None)  # \"Have a nice day\"\n",
              "            [p async for p in runnable.astream(None)] # [\"Have\", \" a\", \" nice\", \" day\"]\n",
              "    RunnableGenerator makes it easy to implement custom behavior within a streaming\n",
              "    context. Below we show an example:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.prompts import ChatPromptTemplate\n",
              "            from langchain_core.runnables import RunnableGenerator, RunnableLambda\n",
              "            from langchain_openai import ChatOpenAI\n",
              "            from langchain_core.output_parsers import StrOutputParser\n",
              "            model = ChatOpenAI()\n",
              "            chant_chain = (\n",
              "                ChatPromptTemplate.from_template(\"Give me a 3 word chant about {topic}\")\n",
              "                | model\n",
              "                | StrOutputParser()\n",
              "            )\n",
              "            def character_generator(input: Iterator[str]) -> Iterator[str]:\n",
              "                for token in input:\n",
              "                    if \",\" in token or \".\" in token:\n",
              "                        yield \"👏\" + token\n",
              "                    else:\n",
              "                        yield token\n",
              "            runnable = chant_chain | character_generator\n",
              "            assert type(runnable.last) is RunnableGenerator\n",
              "            \"\".join(runnable.stream({\"topic\": \"waste\"})) # Reduce👏, Reuse👏, Recycle👏.\n",
              "            # Note that RunnableLambda can be used to delay streaming of one step in a\n",
              "            # sequence until the previous step is finished:\n",
              "            def reverse_generator(input: str) -> Iterator[str]:\n",
              "                # Yield characters of input in reverse order.\n",
              "                for character in input[::-1]:\n",
              "                    yield character\n",
              "            runnable = chant_chain | RunnableLambda(reverse_generator)\n",
              "            \"\".join(runnable.stream({\"topic\": \"waste\"}))  # \".elcycer ,esuer ,ecudeR\"\n",
              "    \"\"\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        transform: Union[\n",
              "            Callable[[Iterator[Input]], Iterator[Output]],\n",
              "            Callable[[AsyncIterator[Input]], AsyncIterator[Output]],\n",
              "        ],\n",
              "        atransform: Optional[\n",
              "            Callable[[AsyncIterator[Input]], AsyncIterator[Output]]\n",
              "        ] = None,\n",
              "    ) -> None:\n",
              "        if atransform is not None:\n",
              "            self._atransform = atransform\n",
              "            func_for_name: Callable = atransform\n",
              "        if inspect.isasyncgenfunction(transform):\n",
              "            self._atransform = transform  # type: ignore[assignment]\n",
              "            func_for_name = transform\n",
              "        elif inspect.isgeneratorfunction(transform):\n",
              "            self._transform = transform\n",
              "            func_for_name = transform\n",
              "        else:\n",
              "            raise TypeError(\n",
              "                \"Expected a generator function type for `transform`.\"\n",
              "                f\"Instead got an unsupported type: {type(transform)}\"\n",
              "            )\n",
              "        try:\n",
              "            self.name = func_for_name.__name__\n",
              "        except AttributeError:\n",
              "            pass\n",
              "    @property\n",
              "    def InputType(self) -> Any:\n",
              "        func = getattr(self, \"_transform\", None) or getattr(self, \"_atransform\")\n",
              "        try:\n",
              "            params = inspect.signature(func).parameters\n",
              "            first_param = next(iter(params.values()), None)\n",
              "            if first_param and first_param.annotation != inspect.Parameter.empty:\n",
              "                return getattr(first_param.annotation, \"__args__\", (Any,))[0]\n",
              "            else:\n",
              "                return Any\n",
              "        except ValueError:\n",
              "            return Any\n",
              "    @property\n",
              "    def OutputType(self) -> Any:\n",
              "        func = getattr(self, \"_transform\", None) or getattr(self, \"_atransform\")\n",
              "        try:\n",
              "            sig = inspect.signature(func)\n",
              "            return (\n",
              "                getattr(sig.return_annotation, \"__args__\", (Any,))[0]\n",
              "                if sig.return_annotation != inspect.Signature.empty\n",
              "                else Any\n",
              "            )\n",
              "        except ValueError:\n",
              "            return Any\n",
              "    def __eq__(self, other: Any) -> bool:\n",
              "        if isinstance(other, RunnableGenerator):\n",
              "            if hasattr(self, \"_transform\") and hasattr(other, \"_transform\"):\n",
              "                return self._transform == other._transform\n",
              "            elif hasattr(self, \"_atransform\") and hasattr(other, \"_atransform\"):\n",
              "                return self._atransform == other._atransform\n",
              "            else:\n",
              "                return False\n",
              "        else:\n",
              "            return False\n",
              "    def __repr__(self) -> str:\n",
              "        return f\"RunnableGenerator({self.name})\"\n",
              "[docs]    def transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Output]:\n",
              "        if not hasattr(self, \"_transform\"):\n",
              "            raise NotImplementedError(f\"{repr(self)} only supports async methods.\")\n",
              "        return self._transform_stream_with_config(\n",
              "            input,\n",
              "            self._transform,  # type: ignore[arg-type]\n",
              "            config,\n",
              "            **kwargs,  # type: ignore[arg-type]\n",
              "        )\n",
              "[docs]    def stream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Output]:\n",
              "        return self.transform(iter([input]), config, **kwargs)\n",
              "[docs]    def invoke(\n",
              "        self, input: Input, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
              "    ) -> Output:\n",
              "        final = None\n",
              "        for output in self.stream(input, config, **kwargs):\n",
              "            if final is None:\n",
              "                final = output\n",
              "            else:\n",
              "                final = final + output\n",
              "        return cast(Output, final)\n",
              "[docs]    def atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        if not hasattr(self, \"_atransform\"):\n",
              "            raise NotImplementedError(f\"{repr(self)} only supports sync methods.\")\n",
              "        return self._atransform_stream_with_config(\n",
              "            input, self._atransform, config, **kwargs\n",
              "        )\n",
              "[docs]    def astream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async def input_aiter() -> AsyncIterator[Input]:\n",
              "            yield input\n",
              "        return self.atransform(input_aiter(), config, **kwargs)\n",
              "[docs]    async def ainvoke(\n",
              "        self, input: Input, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
              "    ) -> Output:\n",
              "        final = None\n",
              "        async for output in self.astream(input, config, **kwargs):\n",
              "            if final is None:\n",
              "                final = output\n",
              "            else:\n",
              "                final = final + output\n",
              "        return cast(Output, final)\n",
              "[docs]class RunnableLambda(Runnable[Input, Output]):\n",
              "    \"\"\"RunnableLambda converts a python callable into a Runnable.\n",
              "    Wrapping a callable in a RunnableLambda makes the callable usable\n",
              "    within either a sync or async context.\n",
              "    RunnableLambda can be composed as any other Runnable and provides\n",
              "    seamless integration with LangChain tracing.\n",
              "    Examples:\n",
              "        .. code-block:: python\n",
              "            # This is a RunnableLambda\n",
              "            from langchain_core.runnables import RunnableLambda\n",
              "            def add_one(x: int) -> int:\n",
              "                return x + 1\n",
              "            runnable = RunnableLambda(add_one)\n",
              "            runnable.invoke(1) # returns 2\n",
              "            runnable.batch([1, 2, 3]) # returns [2, 3, 4]\n",
              "            # Async is supported by default by delegating to the sync implementation\n",
              "            await runnable.ainvoke(1) # returns 2\n",
              "            await runnable.abatch([1, 2, 3]) # returns [2, 3, 4]\n",
              "            # Alternatively, can provide both synd and sync implementations\n",
              "            async def add_one_async(x: int) -> int:\n",
              "                return x + 1\n",
              "            runnable = RunnableLambda(add_one, afunc=add_one_async)\n",
              "            runnable.invoke(1) # Uses add_one\n",
              "            await runnable.ainvoke(1) # Uses add_one_async\n",
              "    \"\"\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        func: Union[\n",
              "            Union[\n",
              "                Callable[[Input], Output],\n",
              "                Callable[[Input], Iterator[Output]],\n",
              "                Callable[[Input, RunnableConfig], Output],\n",
              "                Callable[[Input, CallbackManagerForChainRun], Output],\n",
              "                Callable[[Input, CallbackManagerForChainRun, RunnableConfig], Output],\n",
              "            ],\n",
              "            Union[\n",
              "                Callable[[Input], Awaitable[Output]],\n",
              "                Callable[[Input], AsyncIterator[Output]],\n",
              "                Callable[[Input, RunnableConfig], Awaitable[Output]],\n",
              "                Callable[[Input, AsyncCallbackManagerForChainRun], Awaitable[Output]],\n",
              "                Callable[\n",
              "                    [Input, AsyncCallbackManagerForChainRun, RunnableConfig],\n",
              "                    Awaitable[Output],\n",
              "                ],\n",
              "            ],\n",
              "        ],\n",
              "        afunc: Optional[\n",
              "            Union[\n",
              "                Callable[[Input], Awaitable[Output]],\n",
              "                Callable[[Input], AsyncIterator[Output]],\n",
              "                Callable[[Input, RunnableConfig], Awaitable[Output]],\n",
              "                Callable[[Input, AsyncCallbackManagerForChainRun], Awaitable[Output]],\n",
              "                Callable[\n",
              "                    [Input, AsyncCallbackManagerForChainRun, RunnableConfig],\n",
              "                    Awaitable[Output],\n",
              "                ],\n",
              "            ]\n",
              "        ] = None,\n",
              "        name: Optional[str] = None,\n",
              "    ) -> None:\n",
              "        \"\"\"Create a RunnableLambda from a callable, and async callable or both.\n",
              "        Accepts both sync and async variants to allow providing efficient\n",
              "        implementations for sync and async execution.\n",
              "        Args:\n",
              "            func: Either sync or async callable\n",
              "            afunc: An async callable that takes an input and returns an output.\n",
              "        \"\"\"\n",
              "        if afunc is not None:\n",
              "            self.afunc = afunc\n",
              "            func_for_name: Callable = afunc\n",
              "        if inspect.iscoroutinefunction(func) or inspect.isasyncgenfunction(func):\n",
              "            if afunc is not None:\n",
              "                raise TypeError(\n",
              "                    \"Func was provided as a coroutine function, but afunc was \"\n",
              "                    \"also provided. If providing both, func should be a regular \"\n",
              "                    \"function to avoid ambiguity.\"\n",
              "                )\n",
              "            self.afunc = func\n",
              "            func_for_name = func\n",
              "        elif callable(func):\n",
              "            self.func = cast(Callable[[Input], Output], func)\n",
              "            func_for_name = func\n",
              "        else:\n",
              "            raise TypeError(\n",
              "                \"Expected a callable type for `func`.\"\n",
              "                f\"Instead got an unsupported type: {type(func)}\"\n",
              "            )\n",
              "        try:\n",
              "            if name is not None:\n",
              "                self.name = name\n",
              "            elif func_for_name.__name__ != \"<lambda>\":\n",
              "                self.name = func_for_name.__name__\n",
              "        except AttributeError:\n",
              "            pass\n",
              "    @property\n",
              "    def InputType(self) -> Any:\n",
              "        \"\"\"The type of the input to this runnable.\"\"\"\n",
              "        func = getattr(self, \"func\", None) or getattr(self, \"afunc\")\n",
              "        try:\n",
              "            params = inspect.signature(func).parameters\n",
              "            first_param = next(iter(params.values()), None)\n",
              "            if first_param and first_param.annotation != inspect.Parameter.empty:\n",
              "                return first_param.annotation\n",
              "            else:\n",
              "                return Any\n",
              "        except ValueError:\n",
              "            return Any\n",
              "[docs]    def get_input_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        \"\"\"The pydantic schema for the input to this runnable.\"\"\"\n",
              "        func = getattr(self, \"func\", None) or getattr(self, \"afunc\")\n",
              "        if isinstance(func, itemgetter):\n",
              "            # This is terrible, but afaict it's not possible to access _items\n",
              "            # on itemgetter objects, so we have to parse the repr\n",
              "            items = str(func).replace(\"operator.itemgetter(\", \"\")[:-1].split(\", \")\n",
              "            if all(\n",
              "                item[0] == \"'\" and item[-1] == \"'\" and len(item) > 2 for item in items\n",
              "            ):\n",
              "                # It's a dict, lol\n",
              "                return create_model(\n",
              "                    self.get_name(\"Input\"),\n",
              "                    **{item[1:-1]: (Any, None) for item in items},  # type: ignore\n",
              "                )\n",
              "            else:\n",
              "                return create_model(\n",
              "                    self.get_name(\"Input\"),\n",
              "                    __root__=(List[Any], None),\n",
              "                )\n",
              "        if self.InputType != Any:\n",
              "            return super().get_input_schema(config)\n",
              "        if dict_keys := get_function_first_arg_dict_keys(func):\n",
              "            return create_model(\n",
              "                self.get_name(\"Input\"),\n",
              "                **{key: (Any, None) for key in dict_keys},  # type: ignore\n",
              "            )\n",
              "        return super().get_input_schema(config)\n",
              "    @property\n",
              "    def OutputType(self) -> Any:\n",
              "        \"\"\"The type of the output of this runnable as a type annotation.\"\"\"\n",
              "        func = getattr(self, \"func\", None) or getattr(self, \"afunc\")\n",
              "        try:\n",
              "            sig = inspect.signature(func)\n",
              "            if sig.return_annotation != inspect.Signature.empty:\n",
              "                # unwrap iterator types\n",
              "                if getattr(sig.return_annotation, \"__origin__\", None) in (\n",
              "                    collections.abc.Iterator,\n",
              "                    collections.abc.AsyncIterator,\n",
              "                ):\n",
              "                    return getattr(sig.return_annotation, \"__args__\", (Any,))[0]\n",
              "                return sig.return_annotation\n",
              "            else:\n",
              "                return Any\n",
              "        except ValueError:\n",
              "            return Any\n",
              "    @property\n",
              "    def deps(self) -> List[Runnable]:\n",
              "        \"\"\"The dependencies of this runnable.\"\"\"\n",
              "        if hasattr(self, \"func\"):\n",
              "            objects = get_function_nonlocals(self.func)\n",
              "        elif hasattr(self, \"afunc\"):\n",
              "            objects = get_function_nonlocals(self.afunc)\n",
              "        else:\n",
              "            objects = []\n",
              "        return [obj for obj in objects if isinstance(obj, Runnable)]\n",
              "    @property\n",
              "    def config_specs(self) -> List[ConfigurableFieldSpec]:\n",
              "        return get_unique_config_specs(\n",
              "            spec for dep in self.deps for spec in dep.config_specs\n",
              "        )\n",
              "[docs]    def get_graph(self, config: RunnableConfig | None = None) -> Graph:\n",
              "        if deps := self.deps:\n",
              "            graph = Graph()\n",
              "            input_node = graph.add_node(self.get_input_schema(config))\n",
              "            output_node = graph.add_node(self.get_output_schema(config))\n",
              "            for dep in deps:\n",
              "                dep_graph = dep.get_graph()\n",
              "                dep_graph.trim_first_node()\n",
              "                dep_graph.trim_last_node()\n",
              "                if not dep_graph:\n",
              "                    graph.add_edge(input_node, output_node)\n",
              "                else:\n",
              "                    graph.extend(dep_graph)\n",
              "                    dep_first_node = dep_graph.first_node()\n",
              "                    if not dep_first_node:\n",
              "                        raise ValueError(f\"Runnable {dep} has no first node\")\n",
              "                    dep_last_node = dep_graph.last_node()\n",
              "                    if not dep_last_node:\n",
              "                        raise ValueError(f\"Runnable {dep} has no last node\")\n",
              "                    graph.add_edge(input_node, dep_first_node)\n",
              "                    graph.add_edge(dep_last_node, output_node)\n",
              "        else:\n",
              "            graph = super().get_graph(config)\n",
              "        return graph\n",
              "    def __eq__(self, other: Any) -> bool:\n",
              "        if isinstance(other, RunnableLambda):\n",
              "            if hasattr(self, \"func\") and hasattr(other, \"func\"):\n",
              "                return self.func == other.func\n",
              "            elif hasattr(self, \"afunc\") and hasattr(other, \"afunc\"):\n",
              "                return self.afunc == other.afunc\n",
              "            else:\n",
              "                return False\n",
              "        else:\n",
              "            return False\n",
              "    def __repr__(self) -> str:\n",
              "        \"\"\"A string representation of this runnable.\"\"\"\n",
              "        if hasattr(self, \"func\") and isinstance(self.func, itemgetter):\n",
              "            return f\"RunnableLambda({str(self.func)[len('operator.'):]})\"\n",
              "        elif hasattr(self, \"func\"):\n",
              "            return f\"RunnableLambda({get_lambda_source(self.func) or '...'})\"\n",
              "        elif hasattr(self, \"afunc\"):\n",
              "            return f\"RunnableLambda(afunc={get_lambda_source(self.afunc) or '...'})\"\n",
              "        else:\n",
              "            return \"RunnableLambda(...)\"\n",
              "    def _invoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        run_manager: CallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "        **kwargs: Any,\n",
              "    ) -> Output:\n",
              "        if inspect.isgeneratorfunction(self.func):\n",
              "            output: Optional[Output] = None\n",
              "            for chunk in call_func_with_variable_args(\n",
              "                cast(Callable[[Input], Iterator[Output]], self.func),\n",
              "                input,\n",
              "                config,\n",
              "                run_manager,\n",
              "                **kwargs,\n",
              "            ):\n",
              "                if output is None:\n",
              "                    output = chunk\n",
              "                else:\n",
              "                    try:\n",
              "                        output = output + chunk  # type: ignore[operator]\n",
              "                    except TypeError:\n",
              "                        output = chunk\n",
              "        else:\n",
              "            output = call_func_with_variable_args(\n",
              "                self.func, input, config, run_manager, **kwargs\n",
              "            )\n",
              "        # If the output is a runnable, invoke it\n",
              "        if isinstance(output, Runnable):\n",
              "            recursion_limit = config[\"recursion_limit\"]\n",
              "            if recursion_limit <= 0:\n",
              "                raise RecursionError(\n",
              "                    f\"Recursion limit reached when invoking {self} with input {input}.\"\n",
              "                )\n",
              "            output = output.invoke(\n",
              "                input,\n",
              "                patch_config(\n",
              "                    config,\n",
              "                    callbacks=run_manager.get_child(),\n",
              "                    recursion_limit=recursion_limit - 1,\n",
              "                ),\n",
              "            )\n",
              "        return cast(Output, output)\n",
              "    async def _ainvoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        run_manager: AsyncCallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "        **kwargs: Any,\n",
              "    ) -> Output:\n",
              "        if hasattr(self, \"afunc\"):\n",
              "            afunc = self.afunc\n",
              "        else:\n",
              "            if inspect.isgeneratorfunction(self.func):\n",
              "                def func(\n",
              "                    input: Input,\n",
              "                    run_manager: AsyncCallbackManagerForChainRun,\n",
              "                    config: RunnableConfig,\n",
              "                    **kwargs: Any,\n",
              "                ) -> Output:\n",
              "                    output: Optional[Output] = None\n",
              "                    for chunk in call_func_with_variable_args(\n",
              "                        cast(Callable[[Input], Iterator[Output]], self.func),\n",
              "                        input,\n",
              "                        config,\n",
              "                        run_manager.get_sync(),\n",
              "                        **kwargs,\n",
              "                    ):\n",
              "                        if output is None:\n",
              "                            output = chunk\n",
              "                        else:\n",
              "                            try:\n",
              "                                output = output + chunk  # type: ignore[operator]\n",
              "                            except TypeError:\n",
              "                                output = chunk\n",
              "                    return cast(Output, output)\n",
              "            else:\n",
              "                def func(\n",
              "                    input: Input,\n",
              "                    run_manager: AsyncCallbackManagerForChainRun,\n",
              "                    config: RunnableConfig,\n",
              "                    **kwargs: Any,\n",
              "                ) -> Output:\n",
              "                    return call_func_with_variable_args(\n",
              "                        self.func, input, config, run_manager.get_sync(), **kwargs\n",
              "                    )\n",
              "            @wraps(func)\n",
              "            async def f(*args, **kwargs):  # type: ignore[no-untyped-def]\n",
              "                return await run_in_executor(config, func, *args, **kwargs)\n",
              "            afunc = f\n",
              "        if inspect.isasyncgenfunction(afunc):\n",
              "            output: Optional[Output] = None\n",
              "            async for chunk in cast(\n",
              "                AsyncIterator[Output],\n",
              "                acall_func_with_variable_args(\n",
              "                    cast(Callable, afunc),\n",
              "                    input,\n",
              "                    config,\n",
              "                    run_manager,\n",
              "                    **kwargs,\n",
              "                ),\n",
              "            ):\n",
              "                if output is None:\n",
              "                    output = chunk\n",
              "                else:\n",
              "                    try:\n",
              "                        output = output + chunk  # type: ignore[operator]\n",
              "                    except TypeError:\n",
              "                        output = chunk\n",
              "        else:\n",
              "            output = await acall_func_with_variable_args(\n",
              "                cast(Callable, afunc), input, config, run_manager, **kwargs\n",
              "            )\n",
              "        # If the output is a runnable, invoke it\n",
              "        if isinstance(output, Runnable):\n",
              "            recursion_limit = config[\"recursion_limit\"]\n",
              "            if recursion_limit <= 0:\n",
              "                raise RecursionError(\n",
              "                    f\"Recursion limit reached when invoking {self} with input {input}.\"\n",
              "                )\n",
              "            output = await output.ainvoke(\n",
              "                input,\n",
              "                patch_config(\n",
              "                    config,\n",
              "                    callbacks=run_manager.get_child(),\n",
              "                    recursion_limit=recursion_limit - 1,\n",
              "                ),\n",
              "            )\n",
              "        return cast(Output, output)\n",
              "    def _config(\n",
              "        self, config: Optional[RunnableConfig], callable: Callable[..., Any]\n",
              "    ) -> RunnableConfig:\n",
              "        return ensure_config(config)\n",
              "[docs]    def invoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        \"\"\"Invoke this runnable synchronously.\"\"\"\n",
              "        if hasattr(self, \"func\"):\n",
              "            return self._call_with_config(\n",
              "                self._invoke,\n",
              "                input,\n",
              "                self._config(config, self.func),\n",
              "                **kwargs,\n",
              "            )\n",
              "        else:\n",
              "            raise TypeError(\n",
              "                \"Cannot invoke a coroutine function synchronously.\"\n",
              "                \"Use `ainvoke` instead.\"\n",
              "            )\n",
              "[docs]    async def ainvoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        \"\"\"Invoke this runnable asynchronously.\"\"\"\n",
              "        the_func = self.afunc if hasattr(self, \"afunc\") else self.func\n",
              "        return await self._acall_with_config(\n",
              "            self._ainvoke,\n",
              "            input,\n",
              "            self._config(config, the_func),\n",
              "            **kwargs,\n",
              "        )\n",
              "    def _transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        run_manager: CallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Output]:\n",
              "        final: Optional[Input] = None\n",
              "        for ichunk in input:\n",
              "            if final is None:\n",
              "                final = adapt_first_streaming_chunk(ichunk)  # type: ignore\n",
              "            else:\n",
              "                try:\n",
              "                    final = final + ichunk  # type: ignore[operator]\n",
              "                except TypeError:\n",
              "                    final = ichunk\n",
              "        if inspect.isgeneratorfunction(self.func):\n",
              "            output: Optional[Output] = None\n",
              "            for chunk in call_func_with_variable_args(\n",
              "                self.func, cast(Input, final), config, run_manager, **kwargs\n",
              "            ):\n",
              "                yield chunk\n",
              "                if output is None:\n",
              "                    output = chunk\n",
              "                else:\n",
              "                    try:\n",
              "                        output = output + chunk\n",
              "                    except TypeError:\n",
              "                        output = chunk\n",
              "        else:\n",
              "            output = call_func_with_variable_args(\n",
              "                self.func, cast(Input, final), config, run_manager, **kwargs\n",
              "            )\n",
              "        # If the output is a runnable, use its stream output\n",
              "        if isinstance(output, Runnable):\n",
              "            recursion_limit = config[\"recursion_limit\"]\n",
              "            if recursion_limit <= 0:\n",
              "                raise RecursionError(\n",
              "                    f\"Recursion limit reached when invoking \"\n",
              "                    f\"{self} with input {final}.\"\n",
              "                )\n",
              "            for chunk in output.stream(\n",
              "                final,\n",
              "                patch_config(\n",
              "                    config,\n",
              "                    callbacks=run_manager.get_child(),\n",
              "                    recursion_limit=recursion_limit - 1,\n",
              "                ),\n",
              "            ):\n",
              "                yield chunk\n",
              "        elif not inspect.isgeneratorfunction(self.func):\n",
              "            # Otherwise, just yield it\n",
              "            yield cast(Output, output)\n",
              "[docs]    def transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        if hasattr(self, \"func\"):\n",
              "            for output in self._transform_stream_with_config(\n",
              "                input,\n",
              "                self._transform,\n",
              "                self._config(config, self.func),\n",
              "                **kwargs,\n",
              "            ):\n",
              "                yield output\n",
              "        else:\n",
              "            raise TypeError(\n",
              "                \"Cannot stream a coroutine function synchronously.\"\n",
              "                \"Use `astream` instead.\"\n",
              "            )\n",
              "[docs]    def stream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        return self.transform(iter([input]), config, **kwargs)\n",
              "    async def _atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        run_manager: AsyncCallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        final: Optional[Input] = None\n",
              "        async for ichunk in input:\n",
              "            if final is None:\n",
              "                final = adapt_first_streaming_chunk(ichunk)\n",
              "            else:\n",
              "                try:\n",
              "                    final = final + ichunk  # type: ignore[operator]\n",
              "                except TypeError:\n",
              "                    final = ichunk\n",
              "        if hasattr(self, \"afunc\"):\n",
              "            afunc = self.afunc\n",
              "        else:\n",
              "            if inspect.isgeneratorfunction(self.func):\n",
              "                raise TypeError(\n",
              "                    \"Cannot stream from a generator function asynchronously.\"\n",
              "                    \"Use .stream() instead.\"\n",
              "                )\n",
              "            def func(\n",
              "                input: Input,\n",
              "                run_manager: AsyncCallbackManagerForChainRun,\n",
              "                config: RunnableConfig,\n",
              "                **kwargs: Any,\n",
              "            ) -> Output:\n",
              "                return call_func_with_variable_args(\n",
              "                    self.func, input, config, run_manager.get_sync(), **kwargs\n",
              "                )\n",
              "            @wraps(func)\n",
              "            async def f(*args, **kwargs):  # type: ignore[no-untyped-def]\n",
              "                return await run_in_executor(config, func, *args, **kwargs)\n",
              "            afunc = f\n",
              "        if inspect.isasyncgenfunction(afunc):\n",
              "            output: Optional[Output] = None\n",
              "            async for chunk in cast(\n",
              "                AsyncIterator[Output],\n",
              "                acall_func_with_variable_args(\n",
              "                    cast(Callable, afunc),\n",
              "                    cast(Input, final),\n",
              "                    config,\n",
              "                    run_manager,\n",
              "                    **kwargs,\n",
              "                ),\n",
              "            ):\n",
              "                yield chunk\n",
              "                if output is None:\n",
              "                    output = chunk\n",
              "                else:\n",
              "                    try:\n",
              "                        output = output + chunk  # type: ignore[operator]\n",
              "                    except TypeError:\n",
              "                        output = chunk\n",
              "        else:\n",
              "            output = await acall_func_with_variable_args(\n",
              "                cast(Callable, afunc), cast(Input, final), config, run_manager, **kwargs\n",
              "            )\n",
              "        # If the output is a runnable, use its astream output\n",
              "        if isinstance(output, Runnable):\n",
              "            recursion_limit = config[\"recursion_limit\"]\n",
              "            if recursion_limit <= 0:\n",
              "                raise RecursionError(\n",
              "                    f\"Recursion limit reached when invoking \"\n",
              "                    f\"{self} with input {final}.\"\n",
              "                )\n",
              "            async for chunk in output.astream(\n",
              "                final,\n",
              "                patch_config(\n",
              "                    config,\n",
              "                    callbacks=run_manager.get_child(),\n",
              "                    recursion_limit=recursion_limit - 1,\n",
              "                ),\n",
              "            ):\n",
              "                yield chunk\n",
              "        elif not inspect.isasyncgenfunction(afunc):\n",
              "            # Otherwise, just yield it\n",
              "            yield cast(Output, output)\n",
              "[docs]    async def atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async for output in self._atransform_stream_with_config(\n",
              "            input,\n",
              "            self._atransform,\n",
              "            self._config(config, self.afunc if hasattr(self, \"afunc\") else self.func),\n",
              "            **kwargs,\n",
              "        ):\n",
              "            yield output\n",
              "[docs]    async def astream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async def input_aiter() -> AsyncIterator[Input]:\n",
              "            yield input\n",
              "        async for chunk in self.atransform(input_aiter(), config, **kwargs):\n",
              "            yield chunk\n",
              "[docs]class RunnableEachBase(RunnableSerializable[List[Input], List[Output]]):\n",
              "    \"\"\"Runnable that delegates calls to another Runnable\n",
              "    with each element of the input sequence.\n",
              "    Use only if creating a new RunnableEach subclass with different __init__ args.\n",
              "    See documentation for RunnableEach for more details.\n",
              "    \"\"\"\n",
              "    bound: Runnable[Input, Output]\n",
              "    class Config:\n",
              "        arbitrary_types_allowed = True\n",
              "    @property\n",
              "    def InputType(self) -> Any:\n",
              "        return List[self.bound.InputType]  # type: ignore[name-defined]\n",
              "[docs]    def get_input_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        return create_model(\n",
              "            self.get_name(\"Input\"),\n",
              "            __root__=(\n",
              "                List[self.bound.get_input_schema(config)],  # type: ignore\n",
              "                None,\n",
              "            ),\n",
              "        )\n",
              "    @property\n",
              "    def OutputType(self) -> Type[List[Output]]:\n",
              "        return List[self.bound.OutputType]  # type: ignore[name-defined]\n",
              "[docs]    def get_output_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        schema = self.bound.get_output_schema(config)\n",
              "        return create_model(\n",
              "            self.get_name(\"Output\"),\n",
              "            __root__=(\n",
              "                List[schema],  # type: ignore\n",
              "                None,\n",
              "            ),\n",
              "        )\n",
              "    @property\n",
              "    def config_specs(self) -> List[ConfigurableFieldSpec]:\n",
              "        return self.bound.config_specs\n",
              "[docs]    def get_graph(self, config: Optional[RunnableConfig] = None) -> Graph:\n",
              "        return self.bound.get_graph(config)\n",
              "[docs]    @classmethod\n",
              "    def is_lc_serializable(cls) -> bool:\n",
              "        return True\n",
              "[docs]    @classmethod\n",
              "    def get_lc_namespace(cls) -> List[str]:\n",
              "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
              "        return [\"langchain\", \"schema\", \"runnable\"]\n",
              "    def _invoke(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        run_manager: CallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Output]:\n",
              "        return self.bound.batch(\n",
              "            inputs, patch_config(config, callbacks=run_manager.get_child()), **kwargs\n",
              "        )\n",
              "[docs]    def invoke(\n",
              "        self, input: List[Input], config: Optional[RunnableConfig] = None, **kwargs: Any\n",
              "    ) -> List[Output]:\n",
              "        return self._call_with_config(self._invoke, input, config, **kwargs)\n",
              "    async def _ainvoke(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        run_manager: AsyncCallbackManagerForChainRun,\n",
              "        config: RunnableConfig,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Output]:\n",
              "        return await self.bound.abatch(\n",
              "            inputs, patch_config(config, callbacks=run_manager.get_child()), **kwargs\n",
              "        )\n",
              "[docs]    async def ainvoke(\n",
              "        self, input: List[Input], config: Optional[RunnableConfig] = None, **kwargs: Any\n",
              "    ) -> List[Output]:\n",
              "        return await self._acall_with_config(self._ainvoke, input, config, **kwargs)\n",
              "[docs]    async def astream_events(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[StreamEvent]:\n",
              "        for _ in range(1):\n",
              "            raise NotImplementedError(\n",
              "                \"RunnableEach does not support astream_events yet.\"\n",
              "            )\n",
              "            yield\n",
              "[docs]class RunnableEach(RunnableEachBase[Input, Output]):\n",
              "    \"\"\"Runnable that delegates calls to another Runnable\n",
              "    with each element of the input sequence.\n",
              "    It allows you to call multiple inputs with the bounded Runnable.\n",
              "    RunnableEach makes it easy to run multiple inputs for the runnable.\n",
              "    In the below example, we associate and run three inputs\n",
              "    with a Runnable:\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables.base import RunnableEach\n",
              "            from langchain_openai import ChatOpenAI\n",
              "            from langchain_core.prompts import ChatPromptTemplate\n",
              "            from langchain_core.output_parsers import StrOutputParser\n",
              "            prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about\n",
              "            {topic}\")\n",
              "            model = ChatOpenAI()\n",
              "            output_parser = StrOutputParser()\n",
              "            runnable = prompt | model | output_parser\n",
              "            runnable_each = RunnableEach(bound=runnable)\n",
              "            output = runnable_each.invoke([{'topic':'Computer Science'},\n",
              "                                        {'topic':'Art'},\n",
              "                                        {'topic':'Biology'}])\n",
              "            print(output)  # noqa: T201\n",
              "    \"\"\"\n",
              "[docs]    @classmethod\n",
              "    def get_lc_namespace(cls) -> List[str]:\n",
              "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
              "        return [\"langchain\", \"schema\", \"runnable\"]\n",
              "[docs]    def get_name(\n",
              "        self, suffix: Optional[str] = None, *, name: Optional[str] = None\n",
              "    ) -> str:\n",
              "        name = name or self.name or f\"RunnableEach<{self.bound.get_name()}>\"\n",
              "        return super().get_name(suffix, name=name)\n",
              "[docs]    def bind(self, **kwargs: Any) -> RunnableEach[Input, Output]:\n",
              "        return RunnableEach(bound=self.bound.bind(**kwargs))\n",
              "[docs]    def with_config(\n",
              "        self, config: Optional[RunnableConfig] = None, **kwargs: Any\n",
              "    ) -> RunnableEach[Input, Output]:\n",
              "        return RunnableEach(bound=self.bound.with_config(config, **kwargs))\n",
              "[docs]    def with_listeners(\n",
              "        self,\n",
              "        *,\n",
              "        on_start: Optional[Listener] = None,\n",
              "        on_end: Optional[Listener] = None,\n",
              "        on_error: Optional[Listener] = None,\n",
              "    ) -> RunnableEach[Input, Output]:\n",
              "        \"\"\"\n",
              "        Bind lifecycle listeners to a Runnable, returning a new Runnable.\n",
              "        on_start: Called before the runnable starts running, with the Run object.\n",
              "        on_end: Called after the runnable finishes running, with the Run object.\n",
              "        on_error: Called if the runnable throws an error, with the Run object.\n",
              "        The Run object contains information about the run, including its id,\n",
              "        type, input, output, error, start_time, end_time, and any tags or metadata\n",
              "        added to the run.\n",
              "        \"\"\"\n",
              "        return RunnableEach(\n",
              "            bound=self.bound.with_listeners(\n",
              "                on_start=on_start, on_end=on_end, on_error=on_error\n",
              "            )\n",
              "        )\n",
              "[docs]class RunnableBindingBase(RunnableSerializable[Input, Output]):\n",
              "    \"\"\"Runnable that delegates calls to another Runnable with a set of kwargs.\n",
              "    Use only if creating a new RunnableBinding subclass with different __init__ args.\n",
              "    See documentation for RunnableBinding for more details.\n",
              "    \"\"\"\n",
              "    bound: Runnable[Input, Output]\n",
              "    \"\"\"The underlying runnable that this runnable delegates to.\"\"\"\n",
              "    kwargs: Mapping[str, Any] = Field(default_factory=dict)\n",
              "    \"\"\"kwargs to pass to the underlying runnable when running.\n",
              "    For example, when the runnable binding is invoked the underlying\n",
              "    runnable will be invoked with the same input but with these additional\n",
              "    kwargs.\n",
              "    \"\"\"\n",
              "    config: RunnableConfig = Field(default_factory=dict)\n",
              "    \"\"\"The config to bind to the underlying runnable.\"\"\"\n",
              "    config_factories: List[Callable[[RunnableConfig], RunnableConfig]] = Field(\n",
              "        default_factory=list\n",
              "    )\n",
              "    \"\"\"The config factories to bind to the underlying runnable.\"\"\"\n",
              "    # Union[Type[Input], BaseModel] + things like List[str]\n",
              "    custom_input_type: Optional[Any] = None\n",
              "    \"\"\"Override the input type of the underlying runnable with a custom type.\n",
              "    The type can be a pydantic model, or a type annotation (e.g., `List[str]`).\n",
              "    \"\"\"\n",
              "    # Union[Type[Output], BaseModel] + things like List[str]\n",
              "    custom_output_type: Optional[Any] = None\n",
              "    \"\"\"Override the output type of the underlying runnable with a custom type.\n",
              "    The type can be a pydantic model, or a type annotation (e.g., `List[str]`).\n",
              "    \"\"\"\n",
              "    class Config:\n",
              "        arbitrary_types_allowed = True\n",
              "    def __init__(\n",
              "        self,\n",
              "        *,\n",
              "        bound: Runnable[Input, Output],\n",
              "        kwargs: Optional[Mapping[str, Any]] = None,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        config_factories: Optional[\n",
              "            List[Callable[[RunnableConfig], RunnableConfig]]\n",
              "        ] = None,\n",
              "        custom_input_type: Optional[Union[Type[Input], BaseModel]] = None,\n",
              "        custom_output_type: Optional[Union[Type[Output], BaseModel]] = None,\n",
              "        **other_kwargs: Any,\n",
              "    ) -> None:\n",
              "        \"\"\"Create a RunnableBinding from a runnable and kwargs.\n",
              "        Args:\n",
              "            bound: The underlying runnable that this runnable delegates calls to.\n",
              "            kwargs: optional kwargs to pass to the underlying runnable, when running\n",
              "                    the underlying runnable (e.g., via `invoke`, `batch`,\n",
              "                    `transform`, or `stream` or async variants)\n",
              "            config: config_factories:\n",
              "            config_factories: optional list of config factories to apply to the\n",
              "            custom_input_type: Specify to override the input type of the underlying\n",
              "                               runnable with a custom type.\n",
              "            custom_output_type: Specify to override the output type of the underlying\n",
              "                runnable with a custom type.\n",
              "            **other_kwargs: Unpacked into the base class.\n",
              "        \"\"\"\n",
              "        super().__init__(  # type: ignore[call-arg]\n",
              "            bound=bound,\n",
              "            kwargs=kwargs or {},\n",
              "            config=config or {},\n",
              "            config_factories=config_factories or [],\n",
              "            custom_input_type=custom_input_type,\n",
              "            custom_output_type=custom_output_type,\n",
              "            **other_kwargs,\n",
              "        )\n",
              "        # if we don't explicitly set config to the TypedDict here,\n",
              "        # the pydantic init above will strip out any of the \"extra\"\n",
              "        # fields even though total=False on the typed dict.\n",
              "        self.config = config or {}\n",
              "[docs]    def get_name(\n",
              "        self, suffix: Optional[str] = None, *, name: Optional[str] = None\n",
              "    ) -> str:\n",
              "        return self.bound.get_name(suffix, name=name)\n",
              "    @property\n",
              "    def InputType(self) -> Type[Input]:\n",
              "        return (\n",
              "            cast(Type[Input], self.custom_input_type)\n",
              "            if self.custom_input_type is not None\n",
              "            else self.bound.InputType\n",
              "        )\n",
              "    @property\n",
              "    def OutputType(self) -> Type[Output]:\n",
              "        return (\n",
              "            cast(Type[Output], self.custom_output_type)\n",
              "            if self.custom_output_type is not None\n",
              "            else self.bound.OutputType\n",
              "        )\n",
              "[docs]    def get_input_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        if self.custom_input_type is not None:\n",
              "            return super().get_input_schema(config)\n",
              "        return self.bound.get_input_schema(merge_configs(self.config, config))\n",
              "[docs]    def get_output_schema(\n",
              "        self, config: Optional[RunnableConfig] = None\n",
              "    ) -> Type[BaseModel]:\n",
              "        if self.custom_output_type is not None:\n",
              "            return super().get_output_schema(config)\n",
              "        return self.bound.get_output_schema(merge_configs(self.config, config))\n",
              "    @property\n",
              "    def config_specs(self) -> List[ConfigurableFieldSpec]:\n",
              "        return self.bound.config_specs\n",
              "[docs]    def get_graph(self, config: Optional[RunnableConfig] = None) -> Graph:\n",
              "        return self.bound.get_graph(config)\n",
              "[docs]    @classmethod\n",
              "    def is_lc_serializable(cls) -> bool:\n",
              "        return True\n",
              "[docs]    @classmethod\n",
              "    def get_lc_namespace(cls) -> List[str]:\n",
              "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
              "        return [\"langchain\", \"schema\", \"runnable\"]\n",
              "    def _merge_configs(self, *configs: Optional[RunnableConfig]) -> RunnableConfig:\n",
              "        config = merge_configs(self.config, *configs)\n",
              "        return merge_configs(config, *(f(config) for f in self.config_factories))\n",
              "[docs]    def invoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        return self.bound.invoke(\n",
              "            input,\n",
              "            self._merge_configs(config),\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        )\n",
              "[docs]    async def ainvoke(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Output:\n",
              "        return await self.bound.ainvoke(\n",
              "            input,\n",
              "            self._merge_configs(config),\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        )\n",
              "[docs]    def batch(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        if isinstance(config, list):\n",
              "            configs = cast(\n",
              "                List[RunnableConfig],\n",
              "                [self._merge_configs(conf) for conf in config],\n",
              "            )\n",
              "        else:\n",
              "            configs = [self._merge_configs(config) for _ in range(len(inputs))]\n",
              "        return self.bound.batch(\n",
              "            inputs,\n",
              "            configs,\n",
              "            return_exceptions=return_exceptions,\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        )\n",
              "[docs]    async def abatch(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> List[Output]:\n",
              "        if isinstance(config, list):\n",
              "            configs = cast(\n",
              "                List[RunnableConfig],\n",
              "                [self._merge_configs(conf) for conf in config],\n",
              "            )\n",
              "        else:\n",
              "            configs = [self._merge_configs(config) for _ in range(len(inputs))]\n",
              "        return await self.bound.abatch(\n",
              "            inputs,\n",
              "            configs,\n",
              "            return_exceptions=return_exceptions,\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        )\n",
              "    @overload\n",
              "    def batch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[False] = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Tuple[int, Output]]:\n",
              "        ...\n",
              "    @overload\n",
              "    def batch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[True],\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        ...\n",
              "[docs]    def batch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        if isinstance(config, list):\n",
              "            configs = cast(\n",
              "                List[RunnableConfig],\n",
              "                [self._merge_configs(conf) for conf in config],\n",
              "            )\n",
              "        else:\n",
              "            configs = [self._merge_configs(config) for _ in range(len(inputs))]\n",
              "        # lol mypy\n",
              "        if return_exceptions:\n",
              "            yield from self.bound.batch_as_completed(\n",
              "                inputs,\n",
              "                configs,\n",
              "                return_exceptions=return_exceptions,\n",
              "                **{**self.kwargs, **kwargs},\n",
              "            )\n",
              "        else:\n",
              "            yield from self.bound.batch_as_completed(\n",
              "                inputs,\n",
              "                configs,\n",
              "                return_exceptions=return_exceptions,\n",
              "                **{**self.kwargs, **kwargs},\n",
              "            )\n",
              "    @overload\n",
              "    def abatch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[False] = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Tuple[int, Output]]:\n",
              "        ...\n",
              "    @overload\n",
              "    def abatch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: Literal[True],\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        ...\n",
              "[docs]    async def abatch_as_completed(\n",
              "        self,\n",
              "        inputs: List[Input],\n",
              "        config: Optional[Union[RunnableConfig, List[RunnableConfig]]] = None,\n",
              "        *,\n",
              "        return_exceptions: bool = False,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Tuple[int, Union[Output, Exception]]]:\n",
              "        if isinstance(config, list):\n",
              "            configs = cast(\n",
              "                List[RunnableConfig],\n",
              "                [self._merge_configs(conf) for conf in config],\n",
              "            )\n",
              "        else:\n",
              "            configs = [self._merge_configs(config) for _ in range(len(inputs))]\n",
              "        if return_exceptions:\n",
              "            async for item in self.bound.abatch_as_completed(\n",
              "                inputs,\n",
              "                configs,\n",
              "                return_exceptions=return_exceptions,\n",
              "                **{**self.kwargs, **kwargs},\n",
              "            ):\n",
              "                yield item\n",
              "        else:\n",
              "            async for item in self.bound.abatch_as_completed(\n",
              "                inputs,\n",
              "                configs,\n",
              "                return_exceptions=return_exceptions,\n",
              "                **{**self.kwargs, **kwargs},\n",
              "            ):\n",
              "                yield item\n",
              "[docs]    def stream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> Iterator[Output]:\n",
              "        yield from self.bound.stream(\n",
              "            input,\n",
              "            self._merge_configs(config),\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        )\n",
              "[docs]    async def astream(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async for item in self.bound.astream(\n",
              "            input,\n",
              "            self._merge_configs(config),\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        ):\n",
              "            yield item\n",
              "[docs]    async def astream_events(\n",
              "        self,\n",
              "        input: Input,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Optional[Any],\n",
              "    ) -> AsyncIterator[StreamEvent]:\n",
              "        async for item in self.bound.astream_events(\n",
              "            input, self._merge_configs(config), **{**self.kwargs, **kwargs}\n",
              "        ):\n",
              "            yield item\n",
              "[docs]    def transform(\n",
              "        self,\n",
              "        input: Iterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> Iterator[Output]:\n",
              "        yield from self.bound.transform(\n",
              "            input,\n",
              "            self._merge_configs(config),\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        )\n",
              "[docs]    async def atransform(\n",
              "        self,\n",
              "        input: AsyncIterator[Input],\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> AsyncIterator[Output]:\n",
              "        async for item in self.bound.atransform(\n",
              "            input,\n",
              "            self._merge_configs(config),\n",
              "            **{**self.kwargs, **kwargs},\n",
              "        ):\n",
              "            yield item\n",
              "RunnableBindingBase.update_forward_refs(RunnableConfig=RunnableConfig)\n",
              "[docs]class RunnableBinding(RunnableBindingBase[Input, Output]):\n",
              "    \"\"\"Wrap a Runnable with additional functionality.\n",
              "    A RunnableBinding can be thought of as a \"runnable decorator\" that\n",
              "    preserves the essential features of Runnable; i.e., batching, streaming,\n",
              "    and async support, while adding additional functionality.\n",
              "    Any class that inherits from Runnable can be bound to a `RunnableBinding`.\n",
              "    Runnables expose a standard set of methods for creating `RunnableBindings`\n",
              "    or sub-classes of `RunnableBindings` (e.g., `RunnableRetry`,\n",
              "    `RunnableWithFallbacks`) that add additional functionality.\n",
              "    These methods include:\n",
              "    - `bind`: Bind kwargs to pass to the underlying runnable when running it.\n",
              "    - `with_config`: Bind config to pass to the underlying runnable when running it.\n",
              "    - `with_listeners`:  Bind lifecycle listeners to the underlying runnable.\n",
              "    - `with_types`: Override the input and output types of the underlying runnable.\n",
              "    - `with_retry`: Bind a retry policy to the underlying runnable.\n",
              "    - `with_fallbacks`: Bind a fallback policy to the underlying runnable.\n",
              "    Example:\n",
              "    `bind`: Bind kwargs to pass to the underlying runnable when running it.\n",
              "        .. code-block:: python\n",
              "            # Create a runnable binding that invokes the ChatModel with the\n",
              "            # additional kwarg `stop=['-']` when running it.\n",
              "            from langchain_community.chat_models import ChatOpenAI\n",
              "            model = ChatOpenAI()\n",
              "            model.invoke('Say \"Parrot-MAGIC\"', stop=['-']) # Should return `Parrot`\n",
              "            # Using it the easy way via `bind` method which returns a new\n",
              "            # RunnableBinding\n",
              "            runnable_binding = model.bind(stop=['-'])\n",
              "            runnable_binding.invoke('Say \"Parrot-MAGIC\"') # Should return `Parrot`\n",
              "        Can also be done by instantiating a RunnableBinding directly (not recommended):\n",
              "        .. code-block:: python\n",
              "            from langchain_core.runnables import RunnableBinding\n",
              "            runnable_binding = RunnableBinding(\n",
              "                bound=model,\n",
              "                kwargs={'stop': ['-']} # <-- Note the additional kwargs\n",
              "            )\n",
              "            runnable_binding.invoke('Say \"Parrot-MAGIC\"') # Should return `Parrot`\n",
              "    \"\"\"\n",
              "[docs]    @classmethod\n",
              "    def get_lc_namespace(cls) -> List[str]:\n",
              "        \"\"\"Get the namespace of the langchain object.\"\"\"\n",
              "        return [\"langchain\", \"schema\", \"runnable\"]\n",
              "[docs]    def bind(self, **kwargs: Any) -> Runnable[Input, Output]:\n",
              "        \"\"\"Bind additional kwargs to a Runnable, returning a new Runnable.\n",
              "        Args:\n",
              "            **kwargs: The kwargs to bind to the Runnable.\n",
              "        Returns:\n",
              "            A new Runnable with the same type and config as the original,\n",
              "            but with the additional kwargs bound.\n",
              "        \"\"\"\n",
              "        return self.__class__(\n",
              "            bound=self.bound,\n",
              "            config=self.config,\n",
              "            kwargs={**self.kwargs, **kwargs},\n",
              "            custom_input_type=self.custom_input_type,\n",
              "            custom_output_type=self.custom_output_type,\n",
              "        )\n",
              "[docs]    def with_config(\n",
              "        self,\n",
              "        config: Optional[RunnableConfig] = None,\n",
              "        # Sadly Unpack is not well supported by mypy so this will have to be untyped\n",
              "        **kwargs: Any,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        return self.__class__(\n",
              "            bound=self.bound,\n",
              "            kwargs=self.kwargs,\n",
              "            config=cast(RunnableConfig, {**self.config, **(config or {}), **kwargs}),\n",
              "            custom_input_type=self.custom_input_type,\n",
              "            custom_output_type=self.custom_output_type,\n",
              "        )\n",
              "[docs]    def with_listeners(\n",
              "        self,\n",
              "        *,\n",
              "        on_start: Optional[Listener] = None,\n",
              "        on_end: Optional[Listener] = None,\n",
              "        on_error: Optional[Listener] = None,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        \"\"\"Bind lifecycle listeners to a Runnable, returning a new Runnable.\n",
              "        Args:\n",
              "            on_start: Called before the runnable starts running, with the Run object.\n",
              "            on_end: Called after the runnable finishes running, with the Run object.\n",
              "            on_error: Called if the runnable throws an error, with the Run object.\n",
              "        Returns:\n",
              "            The Run object contains information about the run, including its id,\n",
              "            type, input, output, error, start_time, end_time, and any tags or metadata\n",
              "            added to the run.\n",
              "        \"\"\"\n",
              "        from langchain_core.tracers.root_listeners import RootListenersTracer\n",
              "        return self.__class__(\n",
              "            bound=self.bound,\n",
              "            kwargs=self.kwargs,\n",
              "            config=self.config,\n",
              "            config_factories=[\n",
              "                lambda config: {\n",
              "                    \"callbacks\": [\n",
              "                        RootListenersTracer(\n",
              "                            config=config,\n",
              "                            on_start=on_start,\n",
              "                            on_end=on_end,\n",
              "                            on_error=on_error,\n",
              "                        )\n",
              "                    ],\n",
              "                }\n",
              "            ],\n",
              "            custom_input_type=self.custom_input_type,\n",
              "            custom_output_type=self.custom_output_type,\n",
              "        )\n",
              "[docs]    def with_types(\n",
              "        self,\n",
              "        input_type: Optional[Union[Type[Input], BaseModel]] = None,\n",
              "        output_type: Optional[Union[Type[Output], BaseModel]] = None,\n",
              "    ) -> Runnable[Input, Output]:\n",
              "        return self.__class__(\n",
              "            bound=self.bound,\n",
              "            kwargs=self.kwargs,\n",
              "            config=self.config,\n",
              "            custom_input_type=(\n",
              "                input_type if input_type is not None else self.custom_input_type\n",
              "            ),\n",
              "            custom_output_type=(\n",
              "                output_type if output_type is not None else self.custom_output_type\n",
              "            ),\n",
              "        )\n",
              "[docs]    def with_retry(self, **kwargs: Any) -> Runnable[Input, Output]:\n",
              "        return self.__class__(\n",
              "            bound=self.bound.with_retry(**kwargs),\n",
              "            kwargs=self.kwargs,\n",
              "            config=self.config,\n",
              "        )\n",
              "RunnableLike = Union[\n",
              "    Runnable[Input, Output],\n",
              "    Callable[[Input], Output],\n",
              "    Callable[[Input], Awaitable[Output]],\n",
              "    Callable[[Iterator[Input]], Iterator[Output]],\n",
              "    Callable[[AsyncIterator[Input]], AsyncIterator[Output]],\n",
              "    Mapping[str, Any],\n",
              "]\n",
              "[docs]def coerce_to_runnable(thing: RunnableLike) -> Runnable[Input, Output]:\n",
              "    \"\"\"Coerce a runnable-like object into a Runnable.\n",
              "    Args:\n",
              "        thing: A runnable-like object.\n",
              "    Returns:\n",
              "        A Runnable.\n",
              "    \"\"\"\n",
              "    if isinstance(thing, Runnable):\n",
              "        return thing\n",
              "    elif inspect.isasyncgenfunction(thing) or inspect.isgeneratorfunction(thing):\n",
              "        return RunnableGenerator(thing)\n",
              "    elif callable(thing):\n",
              "        return RunnableLambda(cast(Callable[[Input], Output], thing))\n",
              "    elif isinstance(thing, dict):\n",
              "        return cast(Runnable[Input, Output], RunnableParallel(thing))\n",
              "    else:\n",
              "        raise TypeError(\n",
              "            f\"Expected a Runnable, callable or dict.\"\n",
              "            f\"Instead got an unsupported type: {type(thing)}\"\n",
              "        )\n",
              "@overload\n",
              "def chain(\n",
              "    func: Callable[[Input], Coroutine[Any, Any, Output]],\n",
              ") -> Runnable[Input, Output]:\n",
              "    ...\n",
              "@overload\n",
              "def chain(\n",
              "    func: Callable[[Input], Iterator[Output]],\n",
              ") -> Runnable[Input, Output]:\n",
              "    ...\n",
              "@overload\n",
              "def chain(\n",
              "    func: Callable[[Input], AsyncIterator[Output]],\n",
              ") -> Runnable[Input, Output]:\n",
              "    ...\n",
              "@overload\n",
              "def chain(\n",
              "    func: Callable[[Input], Output],\n",
              ") -> Runnable[Input, Output]:\n",
              "    ...\n",
              "[docs]def chain(\n",
              "    func: Union[\n",
              "        Callable[[Input], Output],\n",
              "        Callable[[Input], Iterator[Output]],\n",
              "        Callable[[Input], Coroutine[Any, Any, Output]],\n",
              "        Callable[[Input], AsyncIterator[Output]],\n",
              "    ],\n",
              ") -> Runnable[Input, Output]:\n",
              "    \"\"\"Decorate a function to make it a Runnable.\n",
              "    Sets the name of the runnable to the name of the function.\n",
              "    Any runnables called by the function will be traced as dependencies.\n",
              "    Args:\n",
              "        func: A callable.\n",
              "    Returns:\n",
              "        A Runnable.\n",
              "    Example:\n",
              "    .. code-block:: python\n",
              "        from langchain_core.runnables import chain\n",
              "        from langchain_core.prompts import PromptTemplate\n",
              "        from langchain_openai import OpenAI\n",
              "        @chain\n",
              "        def my_func(fields):\n",
              "            prompt = PromptTemplate(\"Hello, {name}!\")\n",
              "            llm = OpenAI()\n",
              "            formatted = prompt.invoke(**fields)\n",
              "            for chunk in llm.stream(formatted):\n",
              "                yield chunk\n",
              "    \"\"\"\n",
              "    return RunnableLambda(func)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[3083]=================</br><pre><code class=\"python\">Source code for langchain_community.cache\n",
              "\"\"\"\n",
              ".. warning::\n",
              "  Beta Feature!\n",
              "**Cache** provides an optional caching layer for LLMs.\n",
              "Cache is useful for two reasons:\n",
              "- It can save you money by reducing the number of API calls you make to the LLM\n",
              "  provider if you're often requesting the same completion multiple times.\n",
              "- It can speed up your application by reducing the number of API calls you make\n",
              "  to the LLM provider.\n",
              "Cache directly competes with Memory. See documentation for Pros and Cons.\n",
              "**Class hierarchy:**\n",
              ".. code-block::\n",
              "    BaseCache --> <name>Cache  # Examples: InMemoryCache, RedisCache, GPTCache\n",
              "\"\"\"\n",
              "from __future__ import annotations\n",
              "import hashlib\n",
              "import inspect\n",
              "import json\n",
              "import logging\n",
              "import uuid\n",
              "import warnings\n",
              "from abc import ABC\n",
              "from datetime import timedelta\n",
              "from enum import Enum\n",
              "from functools import lru_cache, wraps\n",
              "from typing import (\n",
              "    TYPE_CHECKING,\n",
              "    Any,\n",
              "    Awaitable,\n",
              "    Callable,\n",
              "    Dict,\n",
              "    Generator,\n",
              "    List,\n",
              "    Optional,\n",
              "    Sequence,\n",
              "    Tuple,\n",
              "    Type,\n",
              "    Union,\n",
              "    cast,\n",
              ")\n",
              "from sqlalchemy import Column, Integer, String, create_engine, delete, select\n",
              "from sqlalchemy.engine import Row\n",
              "from sqlalchemy.engine.base import Engine\n",
              "from sqlalchemy.orm import Session\n",
              "from langchain_community.vectorstores.azure_cosmos_db import (\n",
              "    CosmosDBSimilarityType,\n",
              "    CosmosDBVectorSearchType,\n",
              ")\n",
              "try:\n",
              "    from sqlalchemy.orm import declarative_base\n",
              "except ImportError:\n",
              "    from sqlalchemy.ext.declarative import declarative_base\n",
              "from langchain_core._api.deprecation import deprecated\n",
              "from langchain_core.caches import RETURN_VAL_TYPE, BaseCache\n",
              "from langchain_core.embeddings import Embeddings\n",
              "from langchain_core.language_models.llms import LLM, aget_prompts, get_prompts\n",
              "from langchain_core.load.dump import dumps\n",
              "from langchain_core.load.load import loads\n",
              "from langchain_core.outputs import ChatGeneration, Generation\n",
              "from langchain_core.utils import get_from_env\n",
              "from langchain_community.utilities.astradb import (\n",
              "    SetupMode,\n",
              "    _AstraDBCollectionEnvironment,\n",
              ")\n",
              "from langchain_community.vectorstores import AzureCosmosDBVectorSearch\n",
              "from langchain_community.vectorstores.redis import Redis as RedisVectorstore\n",
              "logger = logging.getLogger(__file__)\n",
              "if TYPE_CHECKING:\n",
              "    import momento\n",
              "    from astrapy.db import AstraDB, AsyncAstraDB\n",
              "    from cassandra.cluster import Session as CassandraSession\n",
              "def _hash(_input: str) -> str:\n",
              "    \"\"\"Use a deterministic hashing approach.\"\"\"\n",
              "    return hashlib.md5(_input.encode()).hexdigest()\n",
              "def _dump_generations_to_json(generations: RETURN_VAL_TYPE) -> str:\n",
              "    \"\"\"Dump generations to json.\n",
              "    Args:\n",
              "        generations (RETURN_VAL_TYPE): A list of language model generations.\n",
              "    Returns:\n",
              "        str: Json representing a list of generations.\n",
              "    Warning: would not work well with arbitrary subclasses of `Generation`\n",
              "    \"\"\"\n",
              "    return json.dumps([generation.dict() for generation in generations])\n",
              "def _load_generations_from_json(generations_json: str) -> RETURN_VAL_TYPE:\n",
              "    \"\"\"Load generations from json.\n",
              "    Args:\n",
              "        generations_json (str): A string of json representing a list of generations.\n",
              "    Raises:\n",
              "        ValueError: Could not decode json string to list of generations.\n",
              "    Returns:\n",
              "        RETURN_VAL_TYPE: A list of generations.\n",
              "    Warning: would not work well with arbitrary subclasses of `Generation`\n",
              "    \"\"\"\n",
              "    try:\n",
              "        results = json.loads(generations_json)\n",
              "        return [Generation(**generation_dict) for generation_dict in results]\n",
              "    except json.JSONDecodeError:\n",
              "        raise ValueError(\n",
              "            f\"Could not decode json to list of generations: {generations_json}\"\n",
              "        )\n",
              "def _dumps_generations(generations: RETURN_VAL_TYPE) -> str:\n",
              "    \"\"\"\n",
              "    Serialization for generic RETURN_VAL_TYPE, i.e. sequence of `Generation`\n",
              "    Args:\n",
              "        generations (RETURN_VAL_TYPE): A list of language model generations.\n",
              "    Returns:\n",
              "        str: a single string representing a list of generations.\n",
              "    This function (+ its counterpart `_loads_generations`) rely on\n",
              "    the dumps/loads pair with Reviver, so are able to deal\n",
              "    with all subclasses of Generation.\n",
              "    Each item in the list can be `dumps`ed to a string,\n",
              "    then we make the whole list of strings into a json-dumped.\n",
              "    \"\"\"\n",
              "    return json.dumps([dumps(_item) for _item in generations])\n",
              "def _loads_generations(generations_str: str) -> Union[RETURN_VAL_TYPE, None]:\n",
              "    \"\"\"\n",
              "    Deserialization of a string into a generic RETURN_VAL_TYPE\n",
              "    (i.e. a sequence of `Generation`).\n",
              "    See `_dumps_generations`, the inverse of this function.\n",
              "    Args:\n",
              "        generations_str (str): A string representing a list of generations.\n",
              "    Compatible with the legacy cache-blob format\n",
              "    Does not raise exceptions for malformed entries, just logs a warning\n",
              "    and returns none: the caller should be prepared for such a cache miss.\n",
              "    Returns:\n",
              "        RETURN_VAL_TYPE: A list of generations.\n",
              "    \"\"\"\n",
              "    try:\n",
              "        generations = [loads(_item_str) for _item_str in json.loads(generations_str)]\n",
              "        return generations\n",
              "    except (json.JSONDecodeError, TypeError):\n",
              "        # deferring the (soft) handling to after the legacy-format attempt\n",
              "        pass\n",
              "    try:\n",
              "        gen_dicts = json.loads(generations_str)\n",
              "        # not relying on `_load_generations_from_json` (which could disappear):\n",
              "        generations = [Generation(**generation_dict) for generation_dict in gen_dicts]\n",
              "        logger.warning(\n",
              "            f\"Legacy 'Generation' cached blob encountered: '{generations_str}'\"\n",
              "        )\n",
              "        return generations\n",
              "    except (json.JSONDecodeError, TypeError):\n",
              "        logger.warning(\n",
              "            f\"Malformed/unparsable cached blob encountered: '{generations_str}'\"\n",
              "        )\n",
              "        return None\n",
              "[docs]class InMemoryCache(BaseCache):\n",
              "    \"\"\"Cache that stores things in memory.\"\"\"\n",
              "[docs]    def __init__(self) -> None:\n",
              "        \"\"\"Initialize with empty cache.\"\"\"\n",
              "        self._cache: Dict[Tuple[str, str], RETURN_VAL_TYPE] = {}\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        return self._cache.get((prompt, llm_string), None)\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        self._cache[(prompt, llm_string)] = return_val\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache.\"\"\"\n",
              "        self._cache = {}\n",
              "[docs]    async def alookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        return self.lookup(prompt, llm_string)\n",
              "[docs]    async def aupdate(\n",
              "        self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE\n",
              "    ) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        self.update(prompt, llm_string, return_val)\n",
              "[docs]    async def aclear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache.\"\"\"\n",
              "        self.clear()\n",
              "Base = declarative_base()\n",
              "[docs]class FullLLMCache(Base):  # type: ignore\n",
              "    \"\"\"SQLite table for full LLM Cache (all generations).\"\"\"\n",
              "    __tablename__ = \"full_llm_cache\"\n",
              "    prompt = Column(String, primary_key=True)\n",
              "    llm = Column(String, primary_key=True)\n",
              "    idx = Column(Integer, primary_key=True)\n",
              "    response = Column(String)\n",
              "[docs]class SQLAlchemyCache(BaseCache):\n",
              "    \"\"\"Cache that uses SQAlchemy as a backend.\"\"\"\n",
              "[docs]    def __init__(self, engine: Engine, cache_schema: Type[FullLLMCache] = FullLLMCache):\n",
              "        \"\"\"Initialize by creating all tables.\"\"\"\n",
              "        self.engine = engine\n",
              "        self.cache_schema = cache_schema\n",
              "        self.cache_schema.metadata.create_all(self.engine)\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        stmt = (\n",
              "            select(self.cache_schema.response)\n",
              "            .where(self.cache_schema.prompt == prompt)  # type: ignore\n",
              "            .where(self.cache_schema.llm == llm_string)\n",
              "            .order_by(self.cache_schema.idx)\n",
              "        )\n",
              "        with Session(self.engine) as session:\n",
              "            rows = session.execute(stmt).fetchall()\n",
              "            if rows:\n",
              "                try:\n",
              "                    return [loads(row[0]) for row in rows]\n",
              "                except Exception:\n",
              "                    logger.warning(\n",
              "                        \"Retrieving a cache value that could not be deserialized \"\n",
              "                        \"properly. This is likely due to the cache being in an \"\n",
              "                        \"older format. Please recreate your cache to avoid this \"\n",
              "                        \"error.\"\n",
              "                    )\n",
              "                    # In a previous life we stored the raw text directly\n",
              "                    # in the table, so assume it's in that format.\n",
              "                    return [Generation(text=row[0]) for row in rows]\n",
              "        return None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update based on prompt and llm_string.\"\"\"\n",
              "        items = [\n",
              "            self.cache_schema(prompt=prompt, llm=llm_string, response=dumps(gen), idx=i)\n",
              "            for i, gen in enumerate(return_val)\n",
              "        ]\n",
              "        with Session(self.engine) as session, session.begin():\n",
              "            for item in items:\n",
              "                session.merge(item)\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache.\"\"\"\n",
              "        with Session(self.engine) as session:\n",
              "            session.query(self.cache_schema).delete()\n",
              "            session.commit()\n",
              "[docs]class SQLiteCache(SQLAlchemyCache):\n",
              "    \"\"\"Cache that uses SQLite as a backend.\"\"\"\n",
              "[docs]    def __init__(self, database_path: str = \".langchain.db\"):\n",
              "        \"\"\"Initialize by creating the engine and all tables.\"\"\"\n",
              "        engine = create_engine(f\"sqlite:///{database_path}\")\n",
              "        super().__init__(engine)\n",
              "[docs]class UpstashRedisCache(BaseCache):\n",
              "    \"\"\"Cache that uses Upstash Redis as a backend.\"\"\"\n",
              "[docs]    def __init__(self, redis_: Any, *, ttl: Optional[int] = None):\n",
              "        \"\"\"\n",
              "        Initialize an instance of UpstashRedisCache.\n",
              "        This method initializes an object with Upstash Redis caching capabilities.\n",
              "        It takes a `redis_` parameter, which should be an instance of an Upstash Redis\n",
              "        client class, allowing the object to interact with Upstash Redis\n",
              "        server for caching purposes.\n",
              "        Parameters:\n",
              "            redis_: An instance of Upstash Redis client class\n",
              "                (e.g., Redis) used for caching.\n",
              "                This allows the object to communicate with\n",
              "                Redis server for caching operations on.\n",
              "            ttl (int, optional): Time-to-live (TTL) for cached items in seconds.\n",
              "                If provided, it sets the time duration for how long cached\n",
              "                items will remain valid. If not provided, cached items will not\n",
              "                have an automatic expiration.\n",
              "        \"\"\"\n",
              "        try:\n",
              "            from upstash_redis import Redis\n",
              "        except ImportError:\n",
              "            raise ValueError(\n",
              "                \"Could not import upstash_redis python package. \"\n",
              "                \"Please install it with `pip install upstash_redis`.\"\n",
              "            )\n",
              "        if not isinstance(redis_, Redis):\n",
              "            raise ValueError(\"Please pass in Upstash Redis object.\")\n",
              "        self.redis = redis_\n",
              "        self.ttl = ttl\n",
              "    def _key(self, prompt: str, llm_string: str) -> str:\n",
              "        \"\"\"Compute key from prompt and llm_string\"\"\"\n",
              "        return _hash(prompt + llm_string)\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        generations = []\n",
              "        # Read from a HASH\n",
              "        results = self.redis.hgetall(self._key(prompt, llm_string))\n",
              "        if results:\n",
              "            for _, text in results.items():\n",
              "                generations.append(Generation(text=text))\n",
              "        return generations if generations else None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        for gen in return_val:\n",
              "            if not isinstance(gen, Generation):\n",
              "                raise ValueError(\n",
              "                    \"UpstashRedisCache supports caching of normal LLM generations, \"\n",
              "                    f\"got {type(gen)}\"\n",
              "                )\n",
              "            if isinstance(gen, ChatGeneration):\n",
              "                warnings.warn(\n",
              "                    \"NOTE: Generation has not been cached. UpstashRedisCache does not\"\n",
              "                    \" support caching ChatModel outputs.\"\n",
              "                )\n",
              "                return\n",
              "        # Write to a HASH\n",
              "        key = self._key(prompt, llm_string)\n",
              "        mapping = {\n",
              "            str(idx): generation.text for idx, generation in enumerate(return_val)\n",
              "        }\n",
              "        self.redis.hset(key=key, values=mapping)\n",
              "        if self.ttl is not None:\n",
              "            self.redis.expire(key, self.ttl)\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"\n",
              "        Clear cache. If `asynchronous` is True, flush asynchronously.\n",
              "        This flushes the *whole* db.\n",
              "        \"\"\"\n",
              "        asynchronous = kwargs.get(\"asynchronous\", False)\n",
              "        if asynchronous:\n",
              "            asynchronous = \"ASYNC\"\n",
              "        else:\n",
              "            asynchronous = \"SYNC\"\n",
              "        self.redis.flushdb(flush_type=asynchronous)\n",
              "class _RedisCacheBase(BaseCache, ABC):\n",
              "    @staticmethod\n",
              "    def _key(prompt: str, llm_string: str) -> str:\n",
              "        \"\"\"Compute key from prompt and llm_string\"\"\"\n",
              "        return _hash(prompt + llm_string)\n",
              "    @staticmethod\n",
              "    def _ensure_generation_type(return_val: RETURN_VAL_TYPE) -> None:\n",
              "        for gen in return_val:\n",
              "            if not isinstance(gen, Generation):\n",
              "                raise ValueError(\n",
              "                    \"RedisCache only supports caching of normal LLM generations, \"\n",
              "                    f\"got {type(gen)}\"\n",
              "                )\n",
              "    @staticmethod\n",
              "    def _get_generations(\n",
              "        results: dict[str | bytes, str | bytes],\n",
              "    ) -> Optional[List[Generation]]:\n",
              "        generations = []\n",
              "        if results:\n",
              "            for _, text in results.items():\n",
              "                try:\n",
              "                    generations.append(loads(cast(str, text)))\n",
              "                except Exception:\n",
              "                    logger.warning(\n",
              "                        \"Retrieving a cache value that could not be deserialized \"\n",
              "                        \"properly. This is likely due to the cache being in an \"\n",
              "                        \"older format. Please recreate your cache to avoid this \"\n",
              "                        \"error.\"\n",
              "                    )\n",
              "                    # In a previous life we stored the raw text directly\n",
              "                    # in the table, so assume it's in that format.\n",
              "                    generations.append(Generation(text=text))\n",
              "        return generations if generations else None\n",
              "    @staticmethod\n",
              "    def _configure_pipeline_for_update(\n",
              "        key: str, pipe: Any, return_val: RETURN_VAL_TYPE, ttl: Optional[int] = None\n",
              "    ) -> None:\n",
              "        pipe.hset(\n",
              "            key,\n",
              "            mapping={\n",
              "                str(idx): dumps(generation) for idx, generation in enumerate(return_val)\n",
              "            },\n",
              "        )\n",
              "        if ttl is not None:\n",
              "            pipe.expire(key, ttl)\n",
              "[docs]class RedisCache(_RedisCacheBase):\n",
              "    \"\"\"\n",
              "    Cache that uses Redis as a backend. Allows to use a sync `redis.Redis` client.\n",
              "    \"\"\"\n",
              "[docs]    def __init__(self, redis_: Any, *, ttl: Optional[int] = None):\n",
              "        \"\"\"\n",
              "        Initialize an instance of RedisCache.\n",
              "        This method initializes an object with Redis caching capabilities.\n",
              "        It takes a `redis_` parameter, which should be an instance of a Redis\n",
              "        client class (`redis.Redis`), allowing the object\n",
              "        to interact with a Redis server for caching purposes.\n",
              "        Parameters:\n",
              "            redis_ (Any): An instance of a Redis client class\n",
              "                (`redis.Redis`) to be used for caching.\n",
              "                This allows the object to communicate with a\n",
              "                Redis server for caching operations.\n",
              "            ttl (int, optional): Time-to-live (TTL) for cached items in seconds.\n",
              "                If provided, it sets the time duration for how long cached\n",
              "                items will remain valid. If not provided, cached items will not\n",
              "                have an automatic expiration.\n",
              "        \"\"\"\n",
              "        try:\n",
              "            from redis import Redis\n",
              "        except ImportError:\n",
              "            raise ValueError(\n",
              "                \"Could not import `redis` python package. \"\n",
              "                \"Please install it with `pip install redis`.\"\n",
              "            )\n",
              "        if not isinstance(redis_, Redis):\n",
              "            raise ValueError(\"Please pass a valid `redis.Redis` client.\")\n",
              "        self.redis = redis_\n",
              "        self.ttl = ttl\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        # Read from a Redis HASH\n",
              "        try:\n",
              "            results = self.redis.hgetall(self._key(prompt, llm_string))\n",
              "            return self._get_generations(results)  # type: ignore[arg-type]\n",
              "        except Exception as e:\n",
              "            logger.error(f\"Redis lookup failed: {e}\")\n",
              "            return None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        self._ensure_generation_type(return_val)\n",
              "        key = self._key(prompt, llm_string)\n",
              "        try:\n",
              "            with self.redis.pipeline() as pipe:\n",
              "                self._configure_pipeline_for_update(key, pipe, return_val, self.ttl)\n",
              "                pipe.execute()\n",
              "        except Exception as e:\n",
              "            logger.error(f\"Redis update failed: {e}\")\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache. If `asynchronous` is True, flush asynchronously.\"\"\"\n",
              "        try:\n",
              "            asynchronous = kwargs.get(\"asynchronous\", False)\n",
              "            self.redis.flushdb(asynchronous=asynchronous, **kwargs)\n",
              "        except Exception as e:\n",
              "            logger.error(f\"Redis clear failed: {e}\")\n",
              "[docs]class AsyncRedisCache(_RedisCacheBase):\n",
              "    \"\"\"\n",
              "    Cache that uses Redis as a backend. Allows to use an\n",
              "    async `redis.asyncio.Redis` client.\n",
              "    \"\"\"\n",
              "[docs]    def __init__(self, redis_: Any, *, ttl: Optional[int] = None):\n",
              "        \"\"\"\n",
              "        Initialize an instance of AsyncRedisCache.\n",
              "        This method initializes an object with Redis caching capabilities.\n",
              "        It takes a `redis_` parameter, which should be an instance of a Redis\n",
              "        client class (`redis.asyncio.Redis`), allowing the object\n",
              "        to interact with a Redis server for caching purposes.\n",
              "        Parameters:\n",
              "            redis_ (Any): An instance of a Redis client class\n",
              "                (`redis.asyncio.Redis`) to be used for caching.\n",
              "                This allows the object to communicate with a\n",
              "                Redis server for caching operations.\n",
              "            ttl (int, optional): Time-to-live (TTL) for cached items in seconds.\n",
              "                If provided, it sets the time duration for how long cached\n",
              "                items will remain valid. If not provided, cached items will not\n",
              "                have an automatic expiration.\n",
              "        \"\"\"\n",
              "        try:\n",
              "            from redis.asyncio import Redis\n",
              "        except ImportError:\n",
              "            raise ValueError(\n",
              "                \"Could not import `redis.asyncio` python package. \"\n",
              "                \"Please install it with `pip install redis`.\"\n",
              "            )\n",
              "        if not isinstance(redis_, Redis):\n",
              "            raise ValueError(\"Please pass a valid `redis.asyncio.Redis` client.\")\n",
              "        self.redis = redis_\n",
              "        self.ttl = ttl\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        raise NotImplementedError(\n",
              "            \"This async Redis cache does not implement `lookup()` method. \"\n",
              "            \"Consider using the async `alookup()` version.\"\n",
              "        )\n",
              "[docs]    async def alookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string. Async version.\"\"\"\n",
              "        try:\n",
              "            results = await self.redis.hgetall(self._key(prompt, llm_string))\n",
              "            return self._get_generations(results)  # type: ignore[arg-type]\n",
              "        except Exception as e:\n",
              "            logger.error(f\"Redis async lookup failed: {e}\")\n",
              "            return None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        raise NotImplementedError(\n",
              "            \"This async Redis cache does not implement `update()` method. \"\n",
              "            \"Consider using the async `aupdate()` version.\"\n",
              "        )\n",
              "[docs]    async def aupdate(\n",
              "        self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE\n",
              "    ) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string. Async version.\"\"\"\n",
              "        self._ensure_generation_type(return_val)\n",
              "        key = self._key(prompt, llm_string)\n",
              "        try:\n",
              "            async with self.redis.pipeline() as pipe:\n",
              "                self._configure_pipeline_for_update(key, pipe, return_val, self.ttl)\n",
              "                await pipe.execute()  # type: ignore[attr-defined]\n",
              "        except Exception as e:\n",
              "            logger.error(f\"Redis async update failed: {e}\")\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache. If `asynchronous` is True, flush asynchronously.\"\"\"\n",
              "        raise NotImplementedError(\n",
              "            \"This async Redis cache does not implement `clear()` method. \"\n",
              "            \"Consider using the async `aclear()` version.\"\n",
              "        )\n",
              "[docs]    async def aclear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"\n",
              "        Clear cache. If `asynchronous` is True, flush asynchronously.\n",
              "        Async version.\n",
              "        \"\"\"\n",
              "        try:\n",
              "            asynchronous = kwargs.get(\"asynchronous\", False)\n",
              "            await self.redis.flushdb(asynchronous=asynchronous, **kwargs)\n",
              "        except Exception as e:\n",
              "            logger.error(f\"Redis async clear failed: {e}\")\n",
              "[docs]class RedisSemanticCache(BaseCache):\n",
              "    \"\"\"Cache that uses Redis as a vector-store backend.\"\"\"\n",
              "    # TODO - implement a TTL policy in Redis\n",
              "    DEFAULT_SCHEMA = {\n",
              "        \"content_key\": \"prompt\",\n",
              "        \"text\": [\n",
              "            {\"name\": \"prompt\"},\n",
              "        ],\n",
              "        \"extra\": [{\"name\": \"return_val\"}, {\"name\": \"llm_string\"}],\n",
              "    }\n",
              "[docs]    def __init__(\n",
              "        self, redis_url: str, embedding: Embeddings, score_threshold: float = 0.2\n",
              "    ):\n",
              "        \"\"\"Initialize by passing in the `init` GPTCache func\n",
              "        Args:\n",
              "            redis_url (str): URL to connect to Redis.\n",
              "            embedding (Embedding): Embedding provider for semantic encoding and search.\n",
              "            score_threshold (float, 0.2):\n",
              "        Example:\n",
              "        .. code-block:: python\n",
              "            from langchain_community.globals import set_llm_cache\n",
              "            from langchain_community.cache import RedisSemanticCache\n",
              "            from langchain_community.embeddings import OpenAIEmbeddings\n",
              "            set_llm_cache(RedisSemanticCache(\n",
              "                redis_url=\"redis://localhost:6379\",\n",
              "                embedding=OpenAIEmbeddings()\n",
              "            ))\n",
              "        \"\"\"\n",
              "        self._cache_dict: Dict[str, RedisVectorstore] = {}\n",
              "        self.redis_url = redis_url\n",
              "        self.embedding = embedding\n",
              "        self.score_threshold = score_threshold\n",
              "    def _index_name(self, llm_string: str) -> str:\n",
              "        hashed_index = _hash(llm_string)\n",
              "        return f\"cache:{hashed_index}\"\n",
              "    def _get_llm_cache(self, llm_string: str) -> RedisVectorstore:\n",
              "        index_name = self._index_name(llm_string)\n",
              "        # return vectorstore client for the specific llm string\n",
              "        if index_name in self._cache_dict:\n",
              "            return self._cache_dict[index_name]\n",
              "        # create new vectorstore client for the specific llm string\n",
              "        try:\n",
              "            self._cache_dict[index_name] = RedisVectorstore.from_existing_index(\n",
              "                embedding=self.embedding,\n",
              "                index_name=index_name,\n",
              "                redis_url=self.redis_url,\n",
              "                schema=cast(Dict, self.DEFAULT_SCHEMA),\n",
              "            )\n",
              "        except ValueError:\n",
              "            redis = RedisVectorstore(\n",
              "                embedding=self.embedding,\n",
              "                index_name=index_name,\n",
              "                redis_url=self.redis_url,\n",
              "                index_schema=cast(Dict, self.DEFAULT_SCHEMA),\n",
              "            )\n",
              "            _embedding = self.embedding.embed_query(text=\"test\")\n",
              "            redis._create_index_if_not_exist(dim=len(_embedding))\n",
              "            self._cache_dict[index_name] = redis\n",
              "        return self._cache_dict[index_name]\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear semantic cache for a given llm_string.\"\"\"\n",
              "        index_name = self._index_name(kwargs[\"llm_string\"])\n",
              "        if index_name in self._cache_dict:\n",
              "            self._cache_dict[index_name].drop_index(\n",
              "                index_name=index_name, delete_documents=True, redis_url=self.redis_url\n",
              "            )\n",
              "            del self._cache_dict[index_name]\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        llm_cache = self._get_llm_cache(llm_string)\n",
              "        generations: List = []\n",
              "        # Read from a Hash\n",
              "        results = llm_cache.similarity_search(\n",
              "            query=prompt,\n",
              "            k=1,\n",
              "            distance_threshold=self.score_threshold,\n",
              "        )\n",
              "        if results:\n",
              "            for document in results:\n",
              "                try:\n",
              "                    generations.extend(loads(document.metadata[\"return_val\"]))\n",
              "                except Exception:\n",
              "                    logger.warning(\n",
              "                        \"Retrieving a cache value that could not be deserialized \"\n",
              "                        \"properly. This is likely due to the cache being in an \"\n",
              "                        \"older format. Please recreate your cache to avoid this \"\n",
              "                        \"error.\"\n",
              "                    )\n",
              "                    # In a previous life we stored the raw text directly\n",
              "                    # in the table, so assume it's in that format.\n",
              "                    generations.extend(\n",
              "                        _load_generations_from_json(document.metadata[\"return_val\"])\n",
              "                    )\n",
              "        return generations if generations else None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        for gen in return_val:\n",
              "            if not isinstance(gen, Generation):\n",
              "                raise ValueError(\n",
              "                    \"RedisSemanticCache only supports caching of \"\n",
              "                    f\"normal LLM generations, got {type(gen)}\"\n",
              "                )\n",
              "        llm_cache = self._get_llm_cache(llm_string)\n",
              "        metadata = {\n",
              "            \"llm_string\": llm_string,\n",
              "            \"prompt\": prompt,\n",
              "            \"return_val\": dumps([g for g in return_val]),\n",
              "        }\n",
              "        llm_cache.add_texts(texts=[prompt], metadatas=[metadata])\n",
              "[docs]class GPTCache(BaseCache):\n",
              "    \"\"\"Cache that uses GPTCache as a backend.\"\"\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        init_func: Union[\n",
              "            Callable[[Any, str], None], Callable[[Any], None], None\n",
              "        ] = None,\n",
              "    ):\n",
              "        \"\"\"Initialize by passing in init function (default: `None`).\n",
              "        Args:\n",
              "            init_func (Optional[Callable[[Any], None]]): init `GPTCache` function\n",
              "            (default: `None`)\n",
              "        Example:\n",
              "        .. code-block:: python\n",
              "            # Initialize GPTCache with a custom init function\n",
              "            import gptcache\n",
              "            from gptcache.processor.pre import get_prompt\n",
              "            from gptcache.manager.factory import get_data_manager\n",
              "            from langchain_community.globals import set_llm_cache\n",
              "            # Avoid multiple caches using the same file,\n",
              "            causing different llm model caches to affect each other\n",
              "            def init_gptcache(cache_obj: gptcache.Cache, llm str):\n",
              "                cache_obj.init(\n",
              "                    pre_embedding_func=get_prompt,\n",
              "                    data_manager=manager_factory(\n",
              "                        manager=\"map\",\n",
              "                        data_dir=f\"map_cache_{llm}\"\n",
              "                    ),\n",
              "                )\n",
              "            set_llm_cache(GPTCache(init_gptcache))\n",
              "        \"\"\"\n",
              "        try:\n",
              "            import gptcache  # noqa: F401\n",
              "        except ImportError:\n",
              "            raise ImportError(\n",
              "                \"Could not import gptcache python package. \"\n",
              "                \"Please install it with `pip install gptcache`.\"\n",
              "            )\n",
              "        self.init_gptcache_func: Union[\n",
              "            Callable[[Any, str], None], Callable[[Any], None], None\n",
              "        ] = init_func\n",
              "        self.gptcache_dict: Dict[str, Any] = {}\n",
              "    def _new_gptcache(self, llm_string: str) -> Any:\n",
              "        \"\"\"New gptcache object\"\"\"\n",
              "        from gptcache import Cache\n",
              "        from gptcache.manager.factory import get_data_manager\n",
              "        from gptcache.processor.pre import get_prompt\n",
              "        _gptcache = Cache()\n",
              "        if self.init_gptcache_func is not None:\n",
              "            sig = inspect.signature(self.init_gptcache_func)\n",
              "            if len(sig.parameters) == 2:\n",
              "                self.init_gptcache_func(_gptcache, llm_string)  # type: ignore[call-arg]\n",
              "            else:\n",
              "                self.init_gptcache_func(_gptcache)  # type: ignore[call-arg]\n",
              "        else:\n",
              "            _gptcache.init(\n",
              "                pre_embedding_func=get_prompt,\n",
              "                data_manager=get_data_manager(data_path=llm_string),\n",
              "            )\n",
              "        self.gptcache_dict[llm_string] = _gptcache\n",
              "        return _gptcache\n",
              "    def _get_gptcache(self, llm_string: str) -> Any:\n",
              "        \"\"\"Get a cache object.\n",
              "        When the corresponding llm model cache does not exist, it will be created.\"\"\"\n",
              "        _gptcache = self.gptcache_dict.get(llm_string, None)\n",
              "        if not _gptcache:\n",
              "            _gptcache = self._new_gptcache(llm_string)\n",
              "        return _gptcache\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up the cache data.\n",
              "        First, retrieve the corresponding cache object using the `llm_string` parameter,\n",
              "        and then retrieve the data from the cache based on the `prompt`.\n",
              "        \"\"\"\n",
              "        from gptcache.adapter.api import get\n",
              "        _gptcache = self._get_gptcache(llm_string)\n",
              "        res = get(prompt, cache_obj=_gptcache)\n",
              "        return _loads_generations(res) if res is not None else None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache.\n",
              "        First, retrieve the corresponding cache object using the `llm_string` parameter,\n",
              "        and then store the `prompt` and `return_val` in the cache object.\n",
              "        \"\"\"\n",
              "        for gen in return_val:\n",
              "            if not isinstance(gen, Generation):\n",
              "                raise ValueError(\n",
              "                    \"GPTCache only supports caching of normal LLM generations, \"\n",
              "                    f\"got {type(gen)}\"\n",
              "                )\n",
              "        from gptcache.adapter.api import put\n",
              "        _gptcache = self._get_gptcache(llm_string)\n",
              "        handled_data = _dumps_generations(return_val)\n",
              "        put(prompt, handled_data, cache_obj=_gptcache)\n",
              "        return None\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache.\"\"\"\n",
              "        from gptcache import Cache\n",
              "        for gptcache_instance in self.gptcache_dict.values():\n",
              "            gptcache_instance = cast(Cache, gptcache_instance)\n",
              "            gptcache_instance.flush()\n",
              "        self.gptcache_dict.clear()\n",
              "def _ensure_cache_exists(cache_client: momento.CacheClient, cache_name: str) -> None:\n",
              "    \"\"\"Create cache if it doesn't exist.\n",
              "    Raises:\n",
              "        SdkException: Momento service or network error\n",
              "        Exception: Unexpected response\n",
              "    \"\"\"\n",
              "    from momento.responses import CreateCache\n",
              "    create_cache_response = cache_client.create_cache(cache_name)\n",
              "    if isinstance(create_cache_response, CreateCache.Success) or isinstance(\n",
              "        create_cache_response, CreateCache.CacheAlreadyExists\n",
              "    ):\n",
              "        return None\n",
              "    elif isinstance(create_cache_response, CreateCache.Error):\n",
              "        raise create_cache_response.inner_exception\n",
              "    else:\n",
              "        raise Exception(f\"Unexpected response cache creation: {create_cache_response}\")\n",
              "def _validate_ttl(ttl: Optional[timedelta]) -> None:\n",
              "    if ttl is not None and ttl <= timedelta(seconds=0):\n",
              "        raise ValueError(f\"ttl must be positive but was {ttl}.\")\n",
              "[docs]class MomentoCache(BaseCache):\n",
              "    \"\"\"Cache that uses Momento as a backend. See https://gomomento.com/\"\"\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        cache_client: momento.CacheClient,\n",
              "        cache_name: str,\n",
              "        *,\n",
              "        ttl: Optional[timedelta] = None,\n",
              "        ensure_cache_exists: bool = True,\n",
              "    ):\n",
              "        \"\"\"Instantiate a prompt cache using Momento as a backend.\n",
              "        Note: to instantiate the cache client passed to MomentoCache,\n",
              "        you must have a Momento account. See https://gomomento.com/.\n",
              "        Args:\n",
              "            cache_client (CacheClient): The Momento cache client.\n",
              "            cache_name (str): The name of the cache to use to store the data.\n",
              "            ttl (Optional[timedelta], optional): The time to live for the cache items.\n",
              "                Defaults to None, ie use the client default TTL.\n",
              "            ensure_cache_exists (bool, optional): Create the cache if it doesn't\n",
              "                exist. Defaults to True.\n",
              "        Raises:\n",
              "            ImportError: Momento python package is not installed.\n",
              "            TypeError: cache_client is not of type momento.CacheClientObject\n",
              "            ValueError: ttl is non-null and non-negative\n",
              "        \"\"\"\n",
              "        try:\n",
              "            from momento import CacheClient\n",
              "        except ImportError:\n",
              "            raise ImportError(\n",
              "                \"Could not import momento python package. \"\n",
              "                \"Please install it with `pip install momento`.\"\n",
              "            )\n",
              "        if not isinstance(cache_client, CacheClient):\n",
              "            raise TypeError(\"cache_client must be a momento.CacheClient object.\")\n",
              "        _validate_ttl(ttl)\n",
              "        if ensure_cache_exists:\n",
              "            _ensure_cache_exists(cache_client, cache_name)\n",
              "        self.cache_client = cache_client\n",
              "        self.cache_name = cache_name\n",
              "        self.ttl = ttl\n",
              "[docs]    @classmethod\n",
              "    def from_client_params(\n",
              "        cls,\n",
              "        cache_name: str,\n",
              "        ttl: timedelta,\n",
              "        *,\n",
              "        configuration: Optional[momento.config.Configuration] = None,\n",
              "        api_key: Optional[str] = None,\n",
              "        auth_token: Optional[str] = None,  # for backwards compatibility\n",
              "        **kwargs: Any,\n",
              "    ) -> MomentoCache:\n",
              "        \"\"\"Construct cache from CacheClient parameters.\"\"\"\n",
              "        try:\n",
              "            from momento import CacheClient, Configurations, CredentialProvider\n",
              "        except ImportError:\n",
              "            raise ImportError(\n",
              "                \"Could not import momento python package. \"\n",
              "                \"Please install it with `pip install momento`.\"\n",
              "            )\n",
              "        if configuration is None:\n",
              "            configuration = Configurations.Laptop.v1()\n",
              "        # Try checking `MOMENTO_AUTH_TOKEN` first for backwards compatibility\n",
              "        try:\n",
              "            api_key = auth_token or get_from_env(\"auth_token\", \"MOMENTO_AUTH_TOKEN\")\n",
              "        except ValueError:\n",
              "            api_key = api_key or get_from_env(\"api_key\", \"MOMENTO_API_KEY\")\n",
              "        credentials = CredentialProvider.from_string(api_key)\n",
              "        cache_client = CacheClient(configuration, credentials, default_ttl=ttl)\n",
              "        return cls(cache_client, cache_name, ttl=ttl, **kwargs)\n",
              "    def __key(self, prompt: str, llm_string: str) -> str:\n",
              "        \"\"\"Compute cache key from prompt and associated model and settings.\n",
              "        Args:\n",
              "            prompt (str): The prompt run through the language model.\n",
              "            llm_string (str): The language model version and settings.\n",
              "        Returns:\n",
              "            str: The cache key.\n",
              "        \"\"\"\n",
              "        return _hash(prompt + llm_string)\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Lookup llm generations in cache by prompt and associated model and settings.\n",
              "        Args:\n",
              "            prompt (str): The prompt run through the language model.\n",
              "            llm_string (str): The language model version and settings.\n",
              "        Raises:\n",
              "            SdkException: Momento service or network error\n",
              "        Returns:\n",
              "            Optional[RETURN_VAL_TYPE]: A list of language model generations.\n",
              "        \"\"\"\n",
              "        from momento.responses import CacheGet\n",
              "        generations: RETURN_VAL_TYPE = []\n",
              "        get_response = self.cache_client.get(\n",
              "            self.cache_name, self.__key(prompt, llm_string)\n",
              "        )\n",
              "        if isinstance(get_response, CacheGet.Hit):\n",
              "            value = get_response.value_string\n",
              "            generations = _load_generations_from_json(value)\n",
              "        elif isinstance(get_response, CacheGet.Miss):\n",
              "            pass\n",
              "        elif isinstance(get_response, CacheGet.Error):\n",
              "            raise get_response.inner_exception\n",
              "        return generations if generations else None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Store llm generations in cache.\n",
              "        Args:\n",
              "            prompt (str): The prompt run through the language model.\n",
              "            llm_string (str): The language model string.\n",
              "            return_val (RETURN_VAL_TYPE): A list of language model generations.\n",
              "        Raises:\n",
              "            SdkException: Momento service or network error\n",
              "            Exception: Unexpected response\n",
              "        \"\"\"\n",
              "        for gen in return_val:\n",
              "            if not isinstance(gen, Generation):\n",
              "                raise ValueError(\n",
              "                    \"Momento only supports caching of normal LLM generations, \"\n",
              "                    f\"got {type(gen)}\"\n",
              "                )\n",
              "        key = self.__key(prompt, llm_string)\n",
              "        value = _dump_generations_to_json(return_val)\n",
              "        set_response = self.cache_client.set(self.cache_name, key, value, self.ttl)\n",
              "        from momento.responses import CacheSet\n",
              "        if isinstance(set_response, CacheSet.Success):\n",
              "            pass\n",
              "        elif isinstance(set_response, CacheSet.Error):\n",
              "            raise set_response.inner_exception\n",
              "        else:\n",
              "            raise Exception(f\"Unexpected response: {set_response}\")\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear the cache.\n",
              "        Raises:\n",
              "            SdkException: Momento service or network error\n",
              "        \"\"\"\n",
              "        from momento.responses import CacheFlush\n",
              "        flush_response = self.cache_client.flush_cache(self.cache_name)\n",
              "        if isinstance(flush_response, CacheFlush.Success):\n",
              "            pass\n",
              "        elif isinstance(flush_response, CacheFlush.Error):\n",
              "            raise flush_response.inner_exception\n",
              "CASSANDRA_CACHE_DEFAULT_TABLE_NAME = \"langchain_llm_cache\"\n",
              "CASSANDRA_CACHE_DEFAULT_TTL_SECONDS = None\n",
              "[docs]class CassandraCache(BaseCache):\n",
              "    \"\"\"\n",
              "    Cache that uses Cassandra / Astra DB as a backend.\n",
              "    It uses a single Cassandra table.\n",
              "    The lookup keys (which get to form the primary key) are:\n",
              "        - prompt, a string\n",
              "        - llm_string, a deterministic str representation of the model parameters.\n",
              "          (needed to prevent collisions same-prompt-different-model collisions)\n",
              "    \"\"\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        session: Optional[CassandraSession] = None,\n",
              "        keyspace: Optional[str] = None,\n",
              "        table_name: str = CASSANDRA_CACHE_DEFAULT_TABLE_NAME,\n",
              "        ttl_seconds: Optional[int] = CASSANDRA_CACHE_DEFAULT_TTL_SECONDS,\n",
              "        skip_provisioning: bool = False,\n",
              "    ):\n",
              "        \"\"\"\n",
              "        Initialize with a ready session and a keyspace name.\n",
              "        Args:\n",
              "            session (cassandra.cluster.Session): an open Cassandra session\n",
              "            keyspace (str): the keyspace to use for storing the cache\n",
              "            table_name (str): name of the Cassandra table to use as cache\n",
              "            ttl_seconds (optional int): time-to-live for cache entries\n",
              "                (default: None, i.e. forever)\n",
              "        \"\"\"\n",
              "        try:\n",
              "            from cassio.table import ElasticCassandraTable\n",
              "        except (ImportError, ModuleNotFoundError):\n",
              "            raise ValueError(\n",
              "                \"Could not import cassio python package. \"\n",
              "                \"Please install it with `pip install cassio`.\"\n",
              "            )\n",
              "        self.session = session\n",
              "        self.keyspace = keyspace\n",
              "        self.table_name = table_name\n",
              "        self.ttl_seconds = ttl_seconds\n",
              "        self.kv_cache = ElasticCassandraTable(\n",
              "            session=self.session,\n",
              "            keyspace=self.keyspace,\n",
              "            table=self.table_name,\n",
              "            keys=[\"llm_string\", \"prompt\"],\n",
              "            primary_key_type=[\"TEXT\", \"TEXT\"],\n",
              "            ttl_seconds=self.ttl_seconds,\n",
              "            skip_provisioning=skip_provisioning,\n",
              "        )\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        item = self.kv_cache.get(\n",
              "            llm_string=_hash(llm_string),\n",
              "            prompt=_hash(prompt),\n",
              "        )\n",
              "        if item is not None:\n",
              "            generations = _loads_generations(item[\"body_blob\"])\n",
              "            # this protects against malformed cached items:\n",
              "            if generations is not None:\n",
              "                return generations\n",
              "            else:\n",
              "                return None\n",
              "        else:\n",
              "            return None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        blob = _dumps_generations(return_val)\n",
              "        self.kv_cache.put(\n",
              "            llm_string=_hash(llm_string),\n",
              "            prompt=_hash(prompt),\n",
              "            body_blob=blob,\n",
              "        )\n",
              "[docs]    def delete_through_llm(\n",
              "        self, prompt: str, llm: LLM, stop: Optional[List[str]] = None\n",
              "    ) -> None:\n",
              "        \"\"\"\n",
              "        A wrapper around `delete` with the LLM being passed.\n",
              "        In case the llm(prompt) calls have a `stop` param, you should pass it here\n",
              "        \"\"\"\n",
              "        llm_string = get_prompts(\n",
              "            {**llm.dict(), **{\"stop\": stop}},\n",
              "            [],\n",
              "        )[1]\n",
              "        return self.delete(prompt, llm_string=llm_string)\n",
              "[docs]    def delete(self, prompt: str, llm_string: str) -> None:\n",
              "        \"\"\"Evict from cache if there's an entry.\"\"\"\n",
              "        return self.kv_cache.delete(\n",
              "            llm_string=_hash(llm_string),\n",
              "            prompt=_hash(prompt),\n",
              "        )\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache. This is for all LLMs at once.\"\"\"\n",
              "        self.kv_cache.clear()\n",
              "CASSANDRA_SEMANTIC_CACHE_DEFAULT_DISTANCE_METRIC = \"dot\"\n",
              "CASSANDRA_SEMANTIC_CACHE_DEFAULT_SCORE_THRESHOLD = 0.85\n",
              "CASSANDRA_SEMANTIC_CACHE_DEFAULT_TABLE_NAME = \"langchain_llm_semantic_cache\"\n",
              "CASSANDRA_SEMANTIC_CACHE_DEFAULT_TTL_SECONDS = None\n",
              "CASSANDRA_SEMANTIC_CACHE_EMBEDDING_CACHE_SIZE = 16\n",
              "[docs]class CassandraSemanticCache(BaseCache):\n",
              "    \"\"\"\n",
              "    Cache that uses Cassandra as a vector-store backend for semantic\n",
              "    (i.e. similarity-based) lookup.\n",
              "    It uses a single (vector) Cassandra table and stores, in principle,\n",
              "    cached values from several LLMs, so the LLM's llm_string is part\n",
              "    of the rows' primary keys.\n",
              "    The similarity is based on one of several distance metrics (default: \"dot\").\n",
              "    If choosing another metric, the default threshold is to be re-tuned accordingly.\n",
              "    \"\"\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        session: Optional[CassandraSession],\n",
              "        keyspace: Optional[str],\n",
              "        embedding: Embeddings,\n",
              "        table_name: str = CASSANDRA_SEMANTIC_CACHE_DEFAULT_TABLE_NAME,\n",
              "        distance_metric: str = CASSANDRA_SEMANTIC_CACHE_DEFAULT_DISTANCE_METRIC,\n",
              "        score_threshold: float = CASSANDRA_SEMANTIC_CACHE_DEFAULT_SCORE_THRESHOLD,\n",
              "        ttl_seconds: Optional[int] = CASSANDRA_SEMANTIC_CACHE_DEFAULT_TTL_SECONDS,\n",
              "        skip_provisioning: bool = False,\n",
              "    ):\n",
              "        \"\"\"\n",
              "        Initialize the cache with all relevant parameters.\n",
              "        Args:\n",
              "            session (cassandra.cluster.Session): an open Cassandra session\n",
              "            keyspace (str): the keyspace to use for storing the cache\n",
              "            embedding (Embedding): Embedding provider for semantic\n",
              "                encoding and search.\n",
              "            table_name (str): name of the Cassandra (vector) table\n",
              "                to use as cache\n",
              "            distance_metric (str, 'dot'): which measure to adopt for\n",
              "                similarity searches\n",
              "            score_threshold (optional float): numeric value to use as\n",
              "                cutoff for the similarity searches\n",
              "            ttl_seconds (optional int): time-to-live for cache entries\n",
              "                (default: None, i.e. forever)\n",
              "        The default score threshold is tuned to the default metric.\n",
              "        Tune it carefully yourself if switching to another distance metric.\n",
              "        \"\"\"\n",
              "        try:\n",
              "            from cassio.table import MetadataVectorCassandraTable\n",
              "        except (ImportError, ModuleNotFoundError):\n",
              "            raise ValueError(\n",
              "                \"Could not import cassio python package. \"\n",
              "                \"Please install it with `pip install cassio`.\"\n",
              "            )\n",
              "        self.session = session\n",
              "        self.keyspace = keyspace\n",
              "        self.embedding = embedding\n",
              "        self.table_name = table_name\n",
              "        self.distance_metric = distance_metric\n",
              "        self.score_threshold = score_threshold\n",
              "        self.ttl_seconds = ttl_seconds\n",
              "        # The contract for this class has separate lookup and update:\n",
              "        # in order to spare some embedding calculations we cache them between\n",
              "        # the two calls.\n",
              "        # Note: each instance of this class has its own `_get_embedding` with\n",
              "        # its own lru.\n",
              "        @lru_cache(maxsize=CASSANDRA_SEMANTIC_CACHE_EMBEDDING_CACHE_SIZE)\n",
              "        def _cache_embedding(text: str) -> List[float]:\n",
              "            return self.embedding.embed_query(text=text)\n",
              "        self._get_embedding = _cache_embedding\n",
              "        self.embedding_dimension = self._get_embedding_dimension()\n",
              "        self.table = MetadataVectorCassandraTable(\n",
              "            session=self.session,\n",
              "            keyspace=self.keyspace,\n",
              "            table=self.table_name,\n",
              "            primary_key_type=[\"TEXT\"],\n",
              "            vector_dimension=self.embedding_dimension,\n",
              "            ttl_seconds=self.ttl_seconds,\n",
              "            metadata_indexing=(\"allow\", {\"_llm_string_hash\"}),\n",
              "            skip_provisioning=skip_provisioning,\n",
              "        )\n",
              "    def _get_embedding_dimension(self) -> int:\n",
              "        return len(self._get_embedding(text=\"This is a sample sentence.\"))\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        embedding_vector = self._get_embedding(text=prompt)\n",
              "        llm_string_hash = _hash(llm_string)\n",
              "        body = _dumps_generations(return_val)\n",
              "        metadata = {\n",
              "            \"_prompt\": prompt,\n",
              "            \"_llm_string_hash\": llm_string_hash,\n",
              "        }\n",
              "        row_id = f\"{_hash(prompt)}-{llm_string_hash}\"\n",
              "        #\n",
              "        self.table.put(\n",
              "            body_blob=body,\n",
              "            vector=embedding_vector,\n",
              "            row_id=row_id,\n",
              "            metadata=metadata,\n",
              "        )\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        hit_with_id = self.lookup_with_id(prompt, llm_string)\n",
              "        if hit_with_id is not None:\n",
              "            return hit_with_id[1]\n",
              "        else:\n",
              "            return None\n",
              "[docs]    def lookup_with_id(\n",
              "        self, prompt: str, llm_string: str\n",
              "    ) -> Optional[Tuple[str, RETURN_VAL_TYPE]]:\n",
              "        \"\"\"\n",
              "        Look up based on prompt and llm_string.\n",
              "        If there are hits, return (document_id, cached_entry)\n",
              "        \"\"\"\n",
              "        prompt_embedding: List[float] = self._get_embedding(text=prompt)\n",
              "        hits = list(\n",
              "            self.table.metric_ann_search(\n",
              "                vector=prompt_embedding,\n",
              "                metadata={\"_llm_string_hash\": _hash(llm_string)},\n",
              "                n=1,\n",
              "                metric=self.distance_metric,\n",
              "                metric_threshold=self.score_threshold,\n",
              "            )\n",
              "        )\n",
              "        if hits:\n",
              "            hit = hits[0]\n",
              "            generations = _loads_generations(hit[\"body_blob\"])\n",
              "            if generations is not None:\n",
              "                # this protects against malformed cached items:\n",
              "                return (\n",
              "                    hit[\"row_id\"],\n",
              "                    generations,\n",
              "                )\n",
              "            else:\n",
              "                return None\n",
              "        else:\n",
              "            return None\n",
              "[docs]    def lookup_with_id_through_llm(\n",
              "        self, prompt: str, llm: LLM, stop: Optional[List[str]] = None\n",
              "    ) -> Optional[Tuple[str, RETURN_VAL_TYPE]]:\n",
              "        llm_string = get_prompts(\n",
              "            {**llm.dict(), **{\"stop\": stop}},\n",
              "            [],\n",
              "        )[1]\n",
              "        return self.lookup_with_id(prompt, llm_string=llm_string)\n",
              "[docs]    def delete_by_document_id(self, document_id: str) -> None:\n",
              "        \"\"\"\n",
              "        Given this is a \"similarity search\" cache, an invalidation pattern\n",
              "        that makes sense is first a lookup to get an ID, and then deleting\n",
              "        with that ID. This is for the second step.\n",
              "        \"\"\"\n",
              "        self.table.delete(row_id=document_id)\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear the *whole* semantic cache.\"\"\"\n",
              "        self.table.clear()\n",
              "[docs]class FullMd5LLMCache(Base):  # type: ignore\n",
              "    \"\"\"SQLite table for full LLM Cache (all generations).\"\"\"\n",
              "    __tablename__ = \"full_md5_llm_cache\"\n",
              "    id = Column(String, primary_key=True)\n",
              "    prompt_md5 = Column(String, index=True)\n",
              "    llm = Column(String, index=True)\n",
              "    idx = Column(Integer, index=True)\n",
              "    prompt = Column(String)\n",
              "    response = Column(String)\n",
              "[docs]class SQLAlchemyMd5Cache(BaseCache):\n",
              "    \"\"\"Cache that uses SQAlchemy as a backend.\"\"\"\n",
              "[docs]    def __init__(\n",
              "        self, engine: Engine, cache_schema: Type[FullMd5LLMCache] = FullMd5LLMCache\n",
              "    ):\n",
              "        \"\"\"Initialize by creating all tables.\"\"\"\n",
              "        self.engine = engine\n",
              "        self.cache_schema = cache_schema\n",
              "        self.cache_schema.metadata.create_all(self.engine)\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        rows = self._search_rows(prompt, llm_string)\n",
              "        if rows:\n",
              "            return [loads(row[0]) for row in rows]\n",
              "        return None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update based on prompt and llm_string.\"\"\"\n",
              "        with Session(self.engine) as session, session.begin():\n",
              "            self._delete_previous(session, prompt, llm_string)\n",
              "            prompt_md5 = self.get_md5(prompt)\n",
              "            items = [\n",
              "                self.cache_schema(\n",
              "                    id=str(uuid.uuid1()),\n",
              "                    prompt=prompt,\n",
              "                    prompt_md5=prompt_md5,\n",
              "                    llm=llm_string,\n",
              "                    response=dumps(gen),\n",
              "                    idx=i,\n",
              "                )\n",
              "                for i, gen in enumerate(return_val)\n",
              "            ]\n",
              "            for item in items:\n",
              "                session.merge(item)\n",
              "    def _delete_previous(self, session: Session, prompt: str, llm_string: str) -> None:\n",
              "        stmt = (\n",
              "            delete(self.cache_schema)\n",
              "            .where(self.cache_schema.prompt_md5 == self.get_md5(prompt))  # type: ignore\n",
              "            .where(self.cache_schema.llm == llm_string)\n",
              "            .where(self.cache_schema.prompt == prompt)\n",
              "        )\n",
              "        session.execute(stmt)\n",
              "    def _search_rows(self, prompt: str, llm_string: str) -> Sequence[Row]:\n",
              "        prompt_pd5 = self.get_md5(prompt)\n",
              "        stmt = (\n",
              "            select(self.cache_schema.response)\n",
              "            .where(self.cache_schema.prompt_md5 == prompt_pd5)  # type: ignore\n",
              "            .where(self.cache_schema.llm == llm_string)\n",
              "            .where(self.cache_schema.prompt == prompt)\n",
              "            .order_by(self.cache_schema.idx)\n",
              "        )\n",
              "        with Session(self.engine) as session:\n",
              "            return session.execute(stmt).fetchall()\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear cache.\"\"\"\n",
              "        with Session(self.engine) as session:\n",
              "            session.execute(self.cache_schema.delete())\n",
              "[docs]    @staticmethod\n",
              "    def get_md5(input_string: str) -> str:\n",
              "        return hashlib.md5(input_string.encode()).hexdigest()\n",
              "ASTRA_DB_CACHE_DEFAULT_COLLECTION_NAME = \"langchain_astradb_cache\"\n",
              "[docs]@deprecated(\n",
              "    since=\"0.0.28\",\n",
              "    removal=\"0.2.0\",\n",
              "    alternative_import=\"langchain_astradb.AstraDBCache\",\n",
              ")\n",
              "class AstraDBCache(BaseCache):\n",
              "    @staticmethod\n",
              "    def _make_id(prompt: str, llm_string: str) -> str:\n",
              "        return f\"{_hash(prompt)}#{_hash(llm_string)}\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        *,\n",
              "        collection_name: str = ASTRA_DB_CACHE_DEFAULT_COLLECTION_NAME,\n",
              "        token: Optional[str] = None,\n",
              "        api_endpoint: Optional[str] = None,\n",
              "        astra_db_client: Optional[AstraDB] = None,\n",
              "        async_astra_db_client: Optional[AsyncAstraDB] = None,\n",
              "        namespace: Optional[str] = None,\n",
              "        pre_delete_collection: bool = False,\n",
              "        setup_mode: SetupMode = SetupMode.SYNC,\n",
              "    ):\n",
              "        \"\"\"\n",
              "        Cache that uses Astra DB as a backend.\n",
              "        It uses a single collection as a kv store\n",
              "        The lookup keys, combined in the _id of the documents, are:\n",
              "            - prompt, a string\n",
              "            - llm_string, a deterministic str representation of the model parameters.\n",
              "              (needed to prevent same-prompt-different-model collisions)\n",
              "        Args:\n",
              "            collection_name: name of the Astra DB collection to create/use.\n",
              "            token: API token for Astra DB usage.\n",
              "            api_endpoint: full URL to the API endpoint,\n",
              "                such as `https://<DB-ID>-us-east1.apps.astra.datastax.com`.\n",
              "            astra_db_client: *alternative to token+api_endpoint*,\n",
              "                you can pass an already-created 'astrapy.db.AstraDB' instance.\n",
              "            async_astra_db_client: *alternative to token+api_endpoint*,\n",
              "                you can pass an already-created 'astrapy.db.AsyncAstraDB' instance.\n",
              "            namespace: namespace (aka keyspace) where the\n",
              "                collection is created. Defaults to the database's \"default namespace\".\n",
              "            setup_mode: mode used to create the Astra DB collection (SYNC, ASYNC or\n",
              "                OFF).\n",
              "            pre_delete_collection: whether to delete the collection\n",
              "                before creating it. If False and the collection already exists,\n",
              "                the collection will be used as is.\n",
              "        \"\"\"\n",
              "        self.astra_env = _AstraDBCollectionEnvironment(\n",
              "            collection_name=collection_name,\n",
              "            token=token,\n",
              "            api_endpoint=api_endpoint,\n",
              "            astra_db_client=astra_db_client,\n",
              "            async_astra_db_client=async_astra_db_client,\n",
              "            namespace=namespace,\n",
              "            setup_mode=setup_mode,\n",
              "            pre_delete_collection=pre_delete_collection,\n",
              "        )\n",
              "        self.collection = self.astra_env.collection\n",
              "        self.async_collection = self.astra_env.async_collection\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        item = self.collection.find_one(\n",
              "            filter={\n",
              "                \"_id\": doc_id,\n",
              "            },\n",
              "            projection={\n",
              "                \"body_blob\": 1,\n",
              "            },\n",
              "        )[\"data\"][\"document\"]\n",
              "        return _loads_generations(item[\"body_blob\"]) if item is not None else None\n",
              "[docs]    async def alookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        item = (\n",
              "            await self.async_collection.find_one(\n",
              "                filter={\n",
              "                    \"_id\": doc_id,\n",
              "                },\n",
              "                projection={\n",
              "                    \"body_blob\": 1,\n",
              "                },\n",
              "            )\n",
              "        )[\"data\"][\"document\"]\n",
              "        return _loads_generations(item[\"body_blob\"]) if item is not None else None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        blob = _dumps_generations(return_val)\n",
              "        self.collection.upsert(\n",
              "            {\n",
              "                \"_id\": doc_id,\n",
              "                \"body_blob\": blob,\n",
              "            },\n",
              "        )\n",
              "[docs]    async def aupdate(\n",
              "        self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE\n",
              "    ) -> None:\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        blob = _dumps_generations(return_val)\n",
              "        await self.async_collection.upsert(\n",
              "            {\n",
              "                \"_id\": doc_id,\n",
              "                \"body_blob\": blob,\n",
              "            },\n",
              "        )\n",
              "[docs]    def delete_through_llm(\n",
              "        self, prompt: str, llm: LLM, stop: Optional[List[str]] = None\n",
              "    ) -> None:\n",
              "        \"\"\"\n",
              "        A wrapper around `delete` with the LLM being passed.\n",
              "        In case the llm(prompt) calls have a `stop` param, you should pass it here\n",
              "        \"\"\"\n",
              "        llm_string = get_prompts(\n",
              "            {**llm.dict(), **{\"stop\": stop}},\n",
              "            [],\n",
              "        )[1]\n",
              "        return self.delete(prompt, llm_string=llm_string)\n",
              "[docs]    async def adelete_through_llm(\n",
              "        self, prompt: str, llm: LLM, stop: Optional[List[str]] = None\n",
              "    ) -> None:\n",
              "        \"\"\"\n",
              "        A wrapper around `adelete` with the LLM being passed.\n",
              "        In case the llm(prompt) calls have a `stop` param, you should pass it here\n",
              "        \"\"\"\n",
              "        llm_string = (\n",
              "            await aget_prompts(\n",
              "                {**llm.dict(), **{\"stop\": stop}},\n",
              "                [],\n",
              "            )\n",
              "        )[1]\n",
              "        return await self.adelete(prompt, llm_string=llm_string)\n",
              "[docs]    def delete(self, prompt: str, llm_string: str) -> None:\n",
              "        \"\"\"Evict from cache if there's an entry.\"\"\"\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        self.collection.delete_one(doc_id)\n",
              "[docs]    async def adelete(self, prompt: str, llm_string: str) -> None:\n",
              "        \"\"\"Evict from cache if there's an entry.\"\"\"\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        await self.async_collection.delete_one(doc_id)\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        self.collection.clear()\n",
              "[docs]    async def aclear(self, **kwargs: Any) -> None:\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        await self.async_collection.clear()\n",
              "ASTRA_DB_SEMANTIC_CACHE_DEFAULT_THRESHOLD = 0.85\n",
              "ASTRA_DB_CACHE_DEFAULT_COLLECTION_NAME = \"langchain_astradb_semantic_cache\"\n",
              "ASTRA_DB_SEMANTIC_CACHE_EMBEDDING_CACHE_SIZE = 16\n",
              "_unset = [\"unset\"]\n",
              "class _CachedAwaitable:\n",
              "    \"\"\"Caches the result of an awaitable so it can be awaited multiple times\"\"\"\n",
              "    def __init__(self, awaitable: Awaitable[Any]):\n",
              "        self.awaitable = awaitable\n",
              "        self.result = _unset\n",
              "    def __await__(self) -> Generator:\n",
              "        if self.result is _unset:\n",
              "            self.result = yield from self.awaitable.__await__()\n",
              "        return self.result\n",
              "def _reawaitable(func: Callable) -> Callable:\n",
              "    \"\"\"Makes an async function result awaitable multiple times\"\"\"\n",
              "    @wraps(func)\n",
              "    def wrapper(*args: Any, **kwargs: Any) -> _CachedAwaitable:\n",
              "        return _CachedAwaitable(func(*args, **kwargs))\n",
              "    return wrapper\n",
              "def _async_lru_cache(maxsize: int = 128, typed: bool = False) -> Callable:\n",
              "    \"\"\"Least-recently-used async cache decorator.\n",
              "    Equivalent to functools.lru_cache for async functions\"\"\"\n",
              "    def decorating_function(user_function: Callable) -> Callable:\n",
              "        return lru_cache(maxsize, typed)(_reawaitable(user_function))\n",
              "    return decorating_function\n",
              "[docs]@deprecated(\n",
              "    since=\"0.0.28\",\n",
              "    removal=\"0.2.0\",\n",
              "    alternative_import=\"langchain_astradb.AstraDBSemanticCache\",\n",
              ")\n",
              "class AstraDBSemanticCache(BaseCache):\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        *,\n",
              "        collection_name: str = ASTRA_DB_CACHE_DEFAULT_COLLECTION_NAME,\n",
              "        token: Optional[str] = None,\n",
              "        api_endpoint: Optional[str] = None,\n",
              "        astra_db_client: Optional[AstraDB] = None,\n",
              "        async_astra_db_client: Optional[AsyncAstraDB] = None,\n",
              "        namespace: Optional[str] = None,\n",
              "        setup_mode: SetupMode = SetupMode.SYNC,\n",
              "        pre_delete_collection: bool = False,\n",
              "        embedding: Embeddings,\n",
              "        metric: Optional[str] = None,\n",
              "        similarity_threshold: float = ASTRA_DB_SEMANTIC_CACHE_DEFAULT_THRESHOLD,\n",
              "    ):\n",
              "        \"\"\"\n",
              "        Cache that uses Astra DB as a vector-store backend for semantic\n",
              "        (i.e. similarity-based) lookup.\n",
              "        It uses a single (vector) collection and can store\n",
              "        cached values from several LLMs, so the LLM's 'llm_string' is stored\n",
              "        in the document metadata.\n",
              "        You can choose the preferred similarity (or use the API default).\n",
              "        The default score threshold is tuned to the default metric.\n",
              "        Tune it carefully yourself if switching to another distance metric.\n",
              "        Args:\n",
              "            collection_name: name of the Astra DB collection to create/use.\n",
              "            token: API token for Astra DB usage.\n",
              "            api_endpoint: full URL to the API endpoint,\n",
              "                such as `https://<DB-ID>-us-east1.apps.astra.datastax.com`.\n",
              "            astra_db_client: *alternative to token+api_endpoint*,\n",
              "                you can pass an already-created 'astrapy.db.AstraDB' instance.\n",
              "            async_astra_db_client: *alternative to token+api_endpoint*,\n",
              "                you can pass an already-created 'astrapy.db.AsyncAstraDB' instance.\n",
              "            namespace: namespace (aka keyspace) where the\n",
              "                collection is created. Defaults to the database's \"default namespace\".\n",
              "            setup_mode: mode used to create the Astra DB collection (SYNC, ASYNC or\n",
              "                OFF).\n",
              "            pre_delete_collection: whether to delete the collection\n",
              "                before creating it. If False and the collection already exists,\n",
              "                the collection will be used as is.\n",
              "            embedding: Embedding provider for semantic encoding and search.\n",
              "            metric: the function to use for evaluating similarity of text embeddings.\n",
              "                Defaults to 'cosine' (alternatives: 'euclidean', 'dot_product')\n",
              "            similarity_threshold: the minimum similarity for accepting a\n",
              "                (semantic-search) match.\n",
              "        \"\"\"\n",
              "        self.embedding = embedding\n",
              "        self.metric = metric\n",
              "        self.similarity_threshold = similarity_threshold\n",
              "        self.collection_name = collection_name\n",
              "        # The contract for this class has separate lookup and update:\n",
              "        # in order to spare some embedding calculations we cache them between\n",
              "        # the two calls.\n",
              "        # Note: each instance of this class has its own `_get_embedding` with\n",
              "        # its own lru.\n",
              "        @lru_cache(maxsize=ASTRA_DB_SEMANTIC_CACHE_EMBEDDING_CACHE_SIZE)\n",
              "        def _cache_embedding(text: str) -> List[float]:\n",
              "            return self.embedding.embed_query(text=text)\n",
              "        self._get_embedding = _cache_embedding\n",
              "        @_async_lru_cache(maxsize=ASTRA_DB_SEMANTIC_CACHE_EMBEDDING_CACHE_SIZE)\n",
              "        async def _acache_embedding(text: str) -> List[float]:\n",
              "            return await self.embedding.aembed_query(text=text)\n",
              "        self._aget_embedding = _acache_embedding\n",
              "        embedding_dimension: Union[int, Awaitable[int], None] = None\n",
              "        if setup_mode == SetupMode.ASYNC:\n",
              "            embedding_dimension = self._aget_embedding_dimension()\n",
              "        elif setup_mode == SetupMode.SYNC:\n",
              "            embedding_dimension = self._get_embedding_dimension()\n",
              "        self.astra_env = _AstraDBCollectionEnvironment(\n",
              "            collection_name=collection_name,\n",
              "            token=token,\n",
              "            api_endpoint=api_endpoint,\n",
              "            astra_db_client=astra_db_client,\n",
              "            async_astra_db_client=async_astra_db_client,\n",
              "            namespace=namespace,\n",
              "            setup_mode=setup_mode,\n",
              "            pre_delete_collection=pre_delete_collection,\n",
              "            embedding_dimension=embedding_dimension,\n",
              "            metric=metric,\n",
              "        )\n",
              "        self.collection = self.astra_env.collection\n",
              "        self.async_collection = self.astra_env.async_collection\n",
              "    def _get_embedding_dimension(self) -> int:\n",
              "        return len(self._get_embedding(text=\"This is a sample sentence.\"))\n",
              "    async def _aget_embedding_dimension(self) -> int:\n",
              "        return len(await self._aget_embedding(text=\"This is a sample sentence.\"))\n",
              "    @staticmethod\n",
              "    def _make_id(prompt: str, llm_string: str) -> str:\n",
              "        return f\"{_hash(prompt)}#{_hash(llm_string)}\"\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        llm_string_hash = _hash(llm_string)\n",
              "        embedding_vector = self._get_embedding(text=prompt)\n",
              "        body = _dumps_generations(return_val)\n",
              "        #\n",
              "        self.collection.upsert(\n",
              "            {\n",
              "                \"_id\": doc_id,\n",
              "                \"body_blob\": body,\n",
              "                \"llm_string_hash\": llm_string_hash,\n",
              "                \"$vector\": embedding_vector,\n",
              "            }\n",
              "        )\n",
              "[docs]    async def aupdate(\n",
              "        self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE\n",
              "    ) -> None:\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        doc_id = self._make_id(prompt, llm_string)\n",
              "        llm_string_hash = _hash(llm_string)\n",
              "        embedding_vector = await self._aget_embedding(text=prompt)\n",
              "        body = _dumps_generations(return_val)\n",
              "        #\n",
              "        await self.async_collection.upsert(\n",
              "            {\n",
              "                \"_id\": doc_id,\n",
              "                \"body_blob\": body,\n",
              "                \"llm_string_hash\": llm_string_hash,\n",
              "                \"$vector\": embedding_vector,\n",
              "            }\n",
              "        )\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        hit_with_id = self.lookup_with_id(prompt, llm_string)\n",
              "        if hit_with_id is not None:\n",
              "            return hit_with_id[1]\n",
              "        else:\n",
              "            return None\n",
              "[docs]    async def alookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        hit_with_id = await self.alookup_with_id(prompt, llm_string)\n",
              "        if hit_with_id is not None:\n",
              "            return hit_with_id[1]\n",
              "        else:\n",
              "            return None\n",
              "[docs]    def lookup_with_id(\n",
              "        self, prompt: str, llm_string: str\n",
              "    ) -> Optional[Tuple[str, RETURN_VAL_TYPE]]:\n",
              "        \"\"\"\n",
              "        Look up based on prompt and llm_string.\n",
              "        If there are hits, return (document_id, cached_entry) for the top hit\n",
              "        \"\"\"\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        prompt_embedding: List[float] = self._get_embedding(text=prompt)\n",
              "        llm_string_hash = _hash(llm_string)\n",
              "        hit = self.collection.vector_find_one(\n",
              "            vector=prompt_embedding,\n",
              "            filter={\n",
              "                \"llm_string_hash\": llm_string_hash,\n",
              "            },\n",
              "            fields=[\"body_blob\", \"_id\"],\n",
              "            include_similarity=True,\n",
              "        )\n",
              "        if hit is None or hit[\"$similarity\"] < self.similarity_threshold:\n",
              "            return None\n",
              "        else:\n",
              "            generations = _loads_generations(hit[\"body_blob\"])\n",
              "            if generations is not None:\n",
              "                # this protects against malformed cached items:\n",
              "                return hit[\"_id\"], generations\n",
              "            else:\n",
              "                return None\n",
              "[docs]    async def alookup_with_id(\n",
              "        self, prompt: str, llm_string: str\n",
              "    ) -> Optional[Tuple[str, RETURN_VAL_TYPE]]:\n",
              "        \"\"\"\n",
              "        Look up based on prompt and llm_string.\n",
              "        If there are hits, return (document_id, cached_entry) for the top hit\n",
              "        \"\"\"\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        prompt_embedding: List[float] = await self._aget_embedding(text=prompt)\n",
              "        llm_string_hash = _hash(llm_string)\n",
              "        hit = await self.async_collection.vector_find_one(\n",
              "            vector=prompt_embedding,\n",
              "            filter={\n",
              "                \"llm_string_hash\": llm_string_hash,\n",
              "            },\n",
              "            fields=[\"body_blob\", \"_id\"],\n",
              "            include_similarity=True,\n",
              "        )\n",
              "        if hit is None or hit[\"$similarity\"] < self.similarity_threshold:\n",
              "            return None\n",
              "        else:\n",
              "            generations = _loads_generations(hit[\"body_blob\"])\n",
              "            if generations is not None:\n",
              "                # this protects against malformed cached items:\n",
              "                return hit[\"_id\"], generations\n",
              "            else:\n",
              "                return None\n",
              "[docs]    def lookup_with_id_through_llm(\n",
              "        self, prompt: str, llm: LLM, stop: Optional[List[str]] = None\n",
              "    ) -> Optional[Tuple[str, RETURN_VAL_TYPE]]:\n",
              "        llm_string = get_prompts(\n",
              "            {**llm.dict(), **{\"stop\": stop}},\n",
              "            [],\n",
              "        )[1]\n",
              "        return self.lookup_with_id(prompt, llm_string=llm_string)\n",
              "[docs]    async def alookup_with_id_through_llm(\n",
              "        self, prompt: str, llm: LLM, stop: Optional[List[str]] = None\n",
              "    ) -> Optional[Tuple[str, RETURN_VAL_TYPE]]:\n",
              "        llm_string = (\n",
              "            await aget_prompts(\n",
              "                {**llm.dict(), **{\"stop\": stop}},\n",
              "                [],\n",
              "            )\n",
              "        )[1]\n",
              "        return await self.alookup_with_id(prompt, llm_string=llm_string)\n",
              "[docs]    def delete_by_document_id(self, document_id: str) -> None:\n",
              "        \"\"\"\n",
              "        Given this is a \"similarity search\" cache, an invalidation pattern\n",
              "        that makes sense is first a lookup to get an ID, and then deleting\n",
              "        with that ID. This is for the second step.\n",
              "        \"\"\"\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        self.collection.delete_one(document_id)\n",
              "[docs]    async def adelete_by_document_id(self, document_id: str) -> None:\n",
              "        \"\"\"\n",
              "        Given this is a \"similarity search\" cache, an invalidation pattern\n",
              "        that makes sense is first a lookup to get an ID, and then deleting\n",
              "        with that ID. This is for the second step.\n",
              "        \"\"\"\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        await self.async_collection.delete_one(document_id)\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        self.astra_env.ensure_db_setup()\n",
              "        self.collection.clear()\n",
              "[docs]    async def aclear(self, **kwargs: Any) -> None:\n",
              "        await self.astra_env.aensure_db_setup()\n",
              "        await self.async_collection.clear()\n",
              "[docs]class AzureCosmosDBSemanticCache(BaseCache):\n",
              "    \"\"\"Cache that uses Cosmos DB Mongo vCore vector-store backend\"\"\"\n",
              "    DEFAULT_DATABASE_NAME = \"CosmosMongoVCoreCacheDB\"\n",
              "    DEFAULT_COLLECTION_NAME = \"CosmosMongoVCoreCacheColl\"\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        cosmosdb_connection_string: str,\n",
              "        database_name: str,\n",
              "        collection_name: str,\n",
              "        embedding: Embeddings,\n",
              "        *,\n",
              "        cosmosdb_client: Optional[Any] = None,\n",
              "        num_lists: int = 100,\n",
              "        similarity: CosmosDBSimilarityType = CosmosDBSimilarityType.COS,\n",
              "        kind: CosmosDBVectorSearchType = CosmosDBVectorSearchType.VECTOR_IVF,\n",
              "        dimensions: int = 1536,\n",
              "        m: int = 16,\n",
              "        ef_construction: int = 64,\n",
              "        ef_search: int = 40,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        application_name: str = \"LANGCHAIN_CACHING_PYTHON\",\n",
              "    ):\n",
              "        \"\"\"\n",
              "        Args:\n",
              "            cosmosdb_connection_string: Cosmos DB Mongo vCore connection string\n",
              "            cosmosdb_client: Cosmos DB Mongo vCore client\n",
              "            embedding (Embedding): Embedding provider for semantic encoding and search.\n",
              "            database_name: Database name for the CosmosDBMongoVCoreSemanticCache\n",
              "            collection_name: Collection name for the CosmosDBMongoVCoreSemanticCache\n",
              "            num_lists: This integer is the number of clusters that the\n",
              "                inverted file (IVF) index uses to group the vector data.\n",
              "                We recommend that numLists is set to documentCount/1000\n",
              "                for up to 1 million documents and to sqrt(documentCount)\n",
              "                for more than 1 million documents.\n",
              "                Using a numLists value of 1 is akin to performing\n",
              "                brute-force search, which has limited performance\n",
              "            dimensions: Number of dimensions for vector similarity.\n",
              "                The maximum number of supported dimensions is 2000\n",
              "            similarity: Similarity metric to use with the IVF index.\n",
              "                Possible options are:\n",
              "                    - CosmosDBSimilarityType.COS (cosine distance),\n",
              "                    - CosmosDBSimilarityType.L2 (Euclidean distance), and\n",
              "                    - CosmosDBSimilarityType.IP (inner product).\n",
              "            kind: Type of vector index to create.\n",
              "                Possible options are:\n",
              "                    - vector-ivf\n",
              "                    - vector-hnsw: available as a preview feature only,\n",
              "                                   to enable visit https://learn.microsoft.com/en-us/azure/azure-resource-manager/management/preview-features\n",
              "            m: The max number of connections per layer (16 by default, minimum\n",
              "               value is 2, maximum value is 100). Higher m is suitable for datasets\n",
              "               with high dimensionality and/or high accuracy requirements.\n",
              "            ef_construction: the size of the dynamic candidate list for constructing\n",
              "                            the graph (64 by default, minimum value is 4, maximum\n",
              "                            value is 1000). Higher ef_construction will result in\n",
              "                            better index quality and higher accuracy, but it will\n",
              "                            also increase the time required to build the index.\n",
              "                            ef_construction has to be at least 2 * m\n",
              "            ef_search: The size of the dynamic candidate list for search\n",
              "                       (40 by default). A higher value provides better\n",
              "                       recall at the cost of speed.\n",
              "            score_threshold: Maximum score used to filter the vector search documents.\n",
              "            application_name: Application name for the client for tracking and logging\n",
              "        \"\"\"\n",
              "        self._validate_enum_value(similarity, CosmosDBSimilarityType)\n",
              "        self._validate_enum_value(kind, CosmosDBVectorSearchType)\n",
              "        if not cosmosdb_connection_string:\n",
              "            raise ValueError(\" CosmosDB connection string can be empty.\")\n",
              "        self.cosmosdb_connection_string = cosmosdb_connection_string\n",
              "        self.cosmosdb_client = cosmosdb_client\n",
              "        self.embedding = embedding\n",
              "        self.database_name = database_name or self.DEFAULT_DATABASE_NAME\n",
              "        self.collection_name = collection_name or self.DEFAULT_COLLECTION_NAME\n",
              "        self.num_lists = num_lists\n",
              "        self.dimensions = dimensions\n",
              "        self.similarity = similarity\n",
              "        self.kind = kind\n",
              "        self.m = m\n",
              "        self.ef_construction = ef_construction\n",
              "        self.ef_search = ef_search\n",
              "        self.score_threshold = score_threshold\n",
              "        self._cache_dict: Dict[str, AzureCosmosDBVectorSearch] = {}\n",
              "        self.application_name = application_name\n",
              "    def _index_name(self, llm_string: str) -> str:\n",
              "        hashed_index = _hash(llm_string)\n",
              "        return f\"cache:{hashed_index}\"\n",
              "    def _get_llm_cache(self, llm_string: str) -> AzureCosmosDBVectorSearch:\n",
              "        index_name = self._index_name(llm_string)\n",
              "        namespace = self.database_name + \".\" + self.collection_name\n",
              "        # return vectorstore client for the specific llm string\n",
              "        if index_name in self._cache_dict:\n",
              "            return self._cache_dict[index_name]\n",
              "        # create new vectorstore client for the specific llm string\n",
              "        if self.cosmosdb_client:\n",
              "            collection = self.cosmosdb_client[self.database_name][self.collection_name]\n",
              "            self._cache_dict[index_name] = AzureCosmosDBVectorSearch(\n",
              "                collection=collection,\n",
              "                embedding=self.embedding,\n",
              "                index_name=index_name,\n",
              "            )\n",
              "        else:\n",
              "            self._cache_dict[\n",
              "                index_name\n",
              "            ] = AzureCosmosDBVectorSearch.from_connection_string(\n",
              "                connection_string=self.cosmosdb_connection_string,\n",
              "                namespace=namespace,\n",
              "                embedding=self.embedding,\n",
              "                index_name=index_name,\n",
              "                application_name=self.application_name,\n",
              "            )\n",
              "        # create index for the vectorstore\n",
              "        vectorstore = self._cache_dict[index_name]\n",
              "        if not vectorstore.index_exists():\n",
              "            vectorstore.create_index(\n",
              "                self.num_lists,\n",
              "                self.dimensions,\n",
              "                self.similarity,\n",
              "                self.kind,\n",
              "                self.m,\n",
              "                self.ef_construction,\n",
              "            )\n",
              "        return vectorstore\n",
              "[docs]    def lookup(self, prompt: str, llm_string: str) -> Optional[RETURN_VAL_TYPE]:\n",
              "        \"\"\"Look up based on prompt and llm_string.\"\"\"\n",
              "        llm_cache = self._get_llm_cache(llm_string)\n",
              "        generations: List = []\n",
              "        # Read from a Hash\n",
              "        results = llm_cache.similarity_search(\n",
              "            query=prompt,\n",
              "            k=1,\n",
              "            kind=self.kind,\n",
              "            ef_search=self.ef_search,\n",
              "            score_threshold=self.score_threshold,  # type: ignore[arg-type]\n",
              "        )\n",
              "        if results:\n",
              "            for document in results:\n",
              "                try:\n",
              "                    generations.extend(loads(document.metadata[\"return_val\"]))\n",
              "                except Exception:\n",
              "                    logger.warning(\n",
              "                        \"Retrieving a cache value that could not be deserialized \"\n",
              "                        \"properly. This is likely due to the cache being in an \"\n",
              "                        \"older format. Please recreate your cache to avoid this \"\n",
              "                        \"error.\"\n",
              "                    )\n",
              "                    # In a previous life we stored the raw text directly\n",
              "                    # in the table, so assume it's in that format.\n",
              "                    generations.extend(\n",
              "                        _load_generations_from_json(document.metadata[\"return_val\"])\n",
              "                    )\n",
              "        return generations if generations else None\n",
              "[docs]    def update(self, prompt: str, llm_string: str, return_val: RETURN_VAL_TYPE) -> None:\n",
              "        \"\"\"Update cache based on prompt and llm_string.\"\"\"\n",
              "        for gen in return_val:\n",
              "            if not isinstance(gen, Generation):\n",
              "                raise ValueError(\n",
              "                    \"CosmosDBMongoVCoreSemanticCache only supports caching of \"\n",
              "                    f\"normal LLM generations, got {type(gen)}\"\n",
              "                )\n",
              "        llm_cache = self._get_llm_cache(llm_string)\n",
              "        metadata = {\n",
              "            \"llm_string\": llm_string,\n",
              "            \"prompt\": prompt,\n",
              "            \"return_val\": dumps([g for g in return_val]),\n",
              "        }\n",
              "        llm_cache.add_texts(texts=[prompt], metadatas=[metadata])\n",
              "[docs]    def clear(self, **kwargs: Any) -> None:\n",
              "        \"\"\"Clear semantic cache for a given llm_string.\"\"\"\n",
              "        index_name = self._index_name(kwargs[\"llm_string\"])\n",
              "        if index_name in self._cache_dict:\n",
              "            self._cache_dict[index_name].get_collection().delete_many({})\n",
              "            # self._cache_dict[index_name].clear_collection()\n",
              "    @staticmethod\n",
              "    def _validate_enum_value(value: Any, enum_type: Type[Enum]) -> None:\n",
              "        if not isinstance(value, enum_type):\n",
              "            raise ValueError(f\"Invalid enum value: {value}. Expected {enum_type}.\")</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[3892]=================</br><pre><code class=\"python\">Source code for langchain_community.vectorstores.qdrant\n",
              "from __future__ import annotations\n",
              "import functools\n",
              "import uuid\n",
              "import warnings\n",
              "from itertools import islice\n",
              "from operator import itemgetter\n",
              "from typing import (\n",
              "    TYPE_CHECKING,\n",
              "    Any,\n",
              "    AsyncGenerator,\n",
              "    Callable,\n",
              "    Dict,\n",
              "    Generator,\n",
              "    Iterable,\n",
              "    List,\n",
              "    Optional,\n",
              "    Sequence,\n",
              "    Tuple,\n",
              "    Type,\n",
              "    Union,\n",
              ")\n",
              "import numpy as np\n",
              "from langchain_core.embeddings import Embeddings\n",
              "from langchain_core.runnables.config import run_in_executor\n",
              "from langchain_core.vectorstores import VectorStore\n",
              "from langchain_community.docstore.document import Document\n",
              "from langchain_community.vectorstores.utils import maximal_marginal_relevance\n",
              "if TYPE_CHECKING:\n",
              "    from qdrant_client import grpc  # noqa\n",
              "    from qdrant_client.conversions import common_types\n",
              "    from qdrant_client.http import models as rest\n",
              "    DictFilter = Dict[str, Union[str, int, bool, dict, list]]\n",
              "    MetadataFilter = Union[DictFilter, common_types.Filter]\n",
              "[docs]class QdrantException(Exception):\n",
              "    \"\"\"`Qdrant` related exceptions.\"\"\"\n",
              "[docs]def sync_call_fallback(method: Callable) -> Callable:\n",
              "    \"\"\"\n",
              "    Decorator to call the synchronous method of the class if the async method is not\n",
              "    implemented. This decorator might be only used for the methods that are defined\n",
              "    as async in the class.\n",
              "    \"\"\"\n",
              "    @functools.wraps(method)\n",
              "    async def wrapper(self: Any, *args: Any, **kwargs: Any) -> Any:\n",
              "        try:\n",
              "            return await method(self, *args, **kwargs)\n",
              "        except NotImplementedError:\n",
              "            # If the async method is not implemented, call the synchronous method\n",
              "            # by removing the first letter from the method name. For example,\n",
              "            # if the async method is called ``aaad_texts``, the synchronous method\n",
              "            # will be called ``aad_texts``.\n",
              "            return await run_in_executor(\n",
              "                None, getattr(self, method.__name__[1:]), *args, **kwargs\n",
              "            )\n",
              "    return wrapper\n",
              "[docs]class Qdrant(VectorStore):\n",
              "    \"\"\"`Qdrant` vector store.\n",
              "    To use you should have the ``qdrant-client`` package installed.\n",
              "    Example:\n",
              "        .. code-block:: python\n",
              "            from qdrant_client import QdrantClient\n",
              "            from langchain_community.vectorstores import Qdrant\n",
              "            client = QdrantClient()\n",
              "            collection_name = \"MyCollection\"\n",
              "            qdrant = Qdrant(client, collection_name, embedding_function)\n",
              "    \"\"\"\n",
              "    CONTENT_KEY = \"page_content\"\n",
              "    METADATA_KEY = \"metadata\"\n",
              "    VECTOR_NAME = None\n",
              "[docs]    def __init__(\n",
              "        self,\n",
              "        client: Any,\n",
              "        collection_name: str,\n",
              "        embeddings: Optional[Embeddings] = None,\n",
              "        content_payload_key: str = CONTENT_KEY,\n",
              "        metadata_payload_key: str = METADATA_KEY,\n",
              "        distance_strategy: str = \"COSINE\",\n",
              "        vector_name: Optional[str] = VECTOR_NAME,\n",
              "        async_client: Optional[Any] = None,\n",
              "        embedding_function: Optional[Callable] = None,  # deprecated\n",
              "    ):\n",
              "        \"\"\"Initialize with necessary components.\"\"\"\n",
              "        try:\n",
              "            import qdrant_client\n",
              "        except ImportError:\n",
              "            raise ImportError(\n",
              "                \"Could not import qdrant-client python package. \"\n",
              "                \"Please install it with `pip install qdrant-client`.\"\n",
              "            )\n",
              "        if not isinstance(client, qdrant_client.QdrantClient):\n",
              "            raise ValueError(\n",
              "                f\"client should be an instance of qdrant_client.QdrantClient, \"\n",
              "                f\"got {type(client)}\"\n",
              "            )\n",
              "        if async_client is not None and not isinstance(\n",
              "            async_client, qdrant_client.AsyncQdrantClient\n",
              "        ):\n",
              "            raise ValueError(\n",
              "                f\"async_client should be an instance of qdrant_client.AsyncQdrantClient\"\n",
              "                f\"got {type(async_client)}\"\n",
              "            )\n",
              "        if embeddings is None and embedding_function is None:\n",
              "            raise ValueError(\n",
              "                \"`embeddings` value can't be None. Pass `Embeddings` instance.\"\n",
              "            )\n",
              "        if embeddings is not None and embedding_function is not None:\n",
              "            raise ValueError(\n",
              "                \"Both `embeddings` and `embedding_function` are passed. \"\n",
              "                \"Use `embeddings` only.\"\n",
              "            )\n",
              "        self._embeddings = embeddings\n",
              "        self._embeddings_function = embedding_function\n",
              "        self.client: qdrant_client.QdrantClient = client\n",
              "        self.async_client: Optional[qdrant_client.AsyncQdrantClient] = async_client\n",
              "        self.collection_name = collection_name\n",
              "        self.content_payload_key = content_payload_key or self.CONTENT_KEY\n",
              "        self.metadata_payload_key = metadata_payload_key or self.METADATA_KEY\n",
              "        self.vector_name = vector_name or self.VECTOR_NAME\n",
              "        if embedding_function is not None:\n",
              "            warnings.warn(\n",
              "                \"Using `embedding_function` is deprecated. \"\n",
              "                \"Pass `Embeddings` instance to `embeddings` instead.\"\n",
              "            )\n",
              "        if not isinstance(embeddings, Embeddings):\n",
              "            warnings.warn(\n",
              "                \"`embeddings` should be an instance of `Embeddings`.\"\n",
              "                \"Using `embeddings` as `embedding_function` which is deprecated\"\n",
              "            )\n",
              "            self._embeddings_function = embeddings\n",
              "            self._embeddings = None\n",
              "        self.distance_strategy = distance_strategy.upper()\n",
              "    @property\n",
              "    def embeddings(self) -> Optional[Embeddings]:\n",
              "        return self._embeddings\n",
              "[docs]    def add_texts(\n",
              "        self,\n",
              "        texts: Iterable[str],\n",
              "        metadatas: Optional[List[dict]] = None,\n",
              "        ids: Optional[Sequence[str]] = None,\n",
              "        batch_size: int = 64,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[str]:\n",
              "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
              "        Args:\n",
              "            texts: Iterable of strings to add to the vectorstore.\n",
              "            metadatas: Optional list of metadatas associated with the texts.\n",
              "            ids:\n",
              "                Optional list of ids to associate with the texts. Ids have to be\n",
              "                uuid-like strings.\n",
              "            batch_size:\n",
              "                How many vectors upload per-request.\n",
              "                Default: 64\n",
              "        Returns:\n",
              "            List of ids from adding the texts into the vectorstore.\n",
              "        \"\"\"\n",
              "        added_ids = []\n",
              "        for batch_ids, points in self._generate_rest_batches(\n",
              "            texts, metadatas, ids, batch_size\n",
              "        ):\n",
              "            self.client.upsert(\n",
              "                collection_name=self.collection_name, points=points, **kwargs\n",
              "            )\n",
              "            added_ids.extend(batch_ids)\n",
              "        return added_ids\n",
              "[docs]    @sync_call_fallback\n",
              "    async def aadd_texts(\n",
              "        self,\n",
              "        texts: Iterable[str],\n",
              "        metadatas: Optional[List[dict]] = None,\n",
              "        ids: Optional[Sequence[str]] = None,\n",
              "        batch_size: int = 64,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[str]:\n",
              "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
              "        Args:\n",
              "            texts: Iterable of strings to add to the vectorstore.\n",
              "            metadatas: Optional list of metadatas associated with the texts.\n",
              "            ids:\n",
              "                Optional list of ids to associate with the texts. Ids have to be\n",
              "                uuid-like strings.\n",
              "            batch_size:\n",
              "                How many vectors upload per-request.\n",
              "                Default: 64\n",
              "        Returns:\n",
              "            List of ids from adding the texts into the vectorstore.\n",
              "        \"\"\"\n",
              "        from qdrant_client.local.async_qdrant_local import AsyncQdrantLocal\n",
              "        if self.async_client is None or isinstance(\n",
              "            self.async_client._client, AsyncQdrantLocal\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"QdrantLocal cannot interoperate with sync and async clients\"\n",
              "            )\n",
              "        added_ids = []\n",
              "        async for batch_ids, points in self._agenerate_rest_batches(\n",
              "            texts, metadatas, ids, batch_size\n",
              "        ):\n",
              "            await self.async_client.upsert(\n",
              "                collection_name=self.collection_name, points=points, **kwargs\n",
              "            )\n",
              "            added_ids.extend(batch_ids)\n",
              "        return added_ids\n",
              "[docs]    def similarity_search(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs most similar to query.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of Documents most similar to the query.\n",
              "        \"\"\"\n",
              "        results = self.similarity_search_with_score(\n",
              "            query,\n",
              "            k,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            offset=offset,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return list(map(itemgetter(0), results))\n",
              "[docs]    @sync_call_fallback\n",
              "    async def asimilarity_search(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs most similar to query.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "        Returns:\n",
              "            List of Documents most similar to the query.\n",
              "        \"\"\"\n",
              "        results = await self.asimilarity_search_with_score(query, k, filter, **kwargs)\n",
              "        return list(map(itemgetter(0), results))\n",
              "[docs]    def similarity_search_with_score(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs most similar to query.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of documents most similar to the query text and distance for each.\n",
              "        \"\"\"\n",
              "        return self.similarity_search_with_score_by_vector(\n",
              "            self._embed_query(query),\n",
              "            k,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            offset=offset,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "[docs]    @sync_call_fallback\n",
              "    async def asimilarity_search_with_score(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs most similar to query.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to\n",
              "                AsyncQdrantClient.Search().\n",
              "        Returns:\n",
              "            List of documents most similar to the query text and distance for each.\n",
              "        \"\"\"\n",
              "        query_embedding = await self._aembed_query(query)\n",
              "        return await self.asimilarity_search_with_score_by_vector(\n",
              "            query_embedding,\n",
              "            k,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            offset=offset,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "[docs]    def similarity_search_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs most similar to embedding vector.\n",
              "        Args:\n",
              "            embedding: Embedding vector to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of Documents most similar to the query.\n",
              "        \"\"\"\n",
              "        results = self.similarity_search_with_score_by_vector(\n",
              "            embedding,\n",
              "            k,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            offset=offset,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return list(map(itemgetter(0), results))\n",
              "[docs]    @sync_call_fallback\n",
              "    async def asimilarity_search_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs most similar to embedding vector.\n",
              "        Args:\n",
              "            embedding: Embedding vector to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to\n",
              "                AsyncQdrantClient.Search().\n",
              "        Returns:\n",
              "            List of Documents most similar to the query.\n",
              "        \"\"\"\n",
              "        results = await self.asimilarity_search_with_score_by_vector(\n",
              "            embedding,\n",
              "            k,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            offset=offset,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return list(map(itemgetter(0), results))\n",
              "[docs]    def similarity_search_with_score_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs most similar to embedding vector.\n",
              "        Args:\n",
              "            embedding: Embedding vector to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of documents most similar to the query text and distance for each.\n",
              "        \"\"\"\n",
              "        if filter is not None and isinstance(filter, dict):\n",
              "            warnings.warn(\n",
              "                \"Using dict as a `filter` is deprecated. Please use qdrant-client \"\n",
              "                \"filters directly: \"\n",
              "                \"https://qdrant.tech/documentation/concepts/filtering/\",\n",
              "                DeprecationWarning,\n",
              "            )\n",
              "            qdrant_filter = self._qdrant_filter_from_dict(filter)\n",
              "        else:\n",
              "            qdrant_filter = filter\n",
              "        query_vector = embedding\n",
              "        if self.vector_name is not None:\n",
              "            query_vector = (self.vector_name, embedding)  # type: ignore[assignment]\n",
              "        results = self.client.search(\n",
              "            collection_name=self.collection_name,\n",
              "            query_vector=query_vector,\n",
              "            query_filter=qdrant_filter,\n",
              "            search_params=search_params,\n",
              "            limit=k,\n",
              "            offset=offset,\n",
              "            with_payload=True,\n",
              "            with_vectors=False,  # Langchain does not expect vectors to be returned\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return [\n",
              "            (\n",
              "                self._document_from_scored_point(\n",
              "                    result,\n",
              "                    self.collection_name,\n",
              "                    self.content_payload_key,\n",
              "                    self.metadata_payload_key,\n",
              "                ),\n",
              "                result.score,\n",
              "            )\n",
              "            for result in results\n",
              "        ]\n",
              "[docs]    @sync_call_fallback\n",
              "    async def asimilarity_search_with_score_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        offset: int = 0,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs most similar to embedding vector.\n",
              "        Args:\n",
              "            embedding: Embedding vector to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            offset:\n",
              "                Offset of the first result to return.\n",
              "                May be used to paginate results.\n",
              "                Note: large offset values may cause performance issues.\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to\n",
              "                AsyncQdrantClient.Search().\n",
              "        Returns:\n",
              "            List of documents most similar to the query text and distance for each.\n",
              "        \"\"\"\n",
              "        from qdrant_client.local.async_qdrant_local import AsyncQdrantLocal\n",
              "        if self.async_client is None or isinstance(\n",
              "            self.async_client._client, AsyncQdrantLocal\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"QdrantLocal cannot interoperate with sync and async clients\"\n",
              "            )\n",
              "        if filter is not None and isinstance(filter, dict):\n",
              "            warnings.warn(\n",
              "                \"Using dict as a `filter` is deprecated. Please use qdrant-client \"\n",
              "                \"filters directly: \"\n",
              "                \"https://qdrant.tech/documentation/concepts/filtering/\",\n",
              "                DeprecationWarning,\n",
              "            )\n",
              "            qdrant_filter = self._qdrant_filter_from_dict(filter)\n",
              "        else:\n",
              "            qdrant_filter = filter\n",
              "        query_vector = embedding\n",
              "        if self.vector_name is not None:\n",
              "            query_vector = (self.vector_name, embedding)  # type: ignore[assignment]\n",
              "        results = await self.async_client.search(\n",
              "            collection_name=self.collection_name,\n",
              "            query_vector=query_vector,\n",
              "            query_filter=qdrant_filter,\n",
              "            search_params=search_params,\n",
              "            limit=k,\n",
              "            offset=offset,\n",
              "            with_payload=True,\n",
              "            with_vectors=False,  # Langchain does not expect vectors to be returned\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return [\n",
              "            (\n",
              "                self._document_from_scored_point(\n",
              "                    result,\n",
              "                    self.collection_name,\n",
              "                    self.content_payload_key,\n",
              "                    self.metadata_payload_key,\n",
              "                ),\n",
              "                result.score,\n",
              "            )\n",
              "            for result in results\n",
              "        ]\n",
              "[docs]    def max_marginal_relevance_search(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        fetch_k: int = 20,\n",
              "        lambda_mult: float = 0.5,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
              "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
              "        among selected documents.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
              "                     Defaults to 20.\n",
              "            lambda_mult: Number between 0 and 1 that determines the degree\n",
              "                        of diversity among the results with 0 corresponding\n",
              "                        to maximum diversity and 1 to minimum diversity.\n",
              "                        Defaults to 0.5.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of Documents selected by maximal marginal relevance.\n",
              "        \"\"\"\n",
              "        query_embedding = self._embed_query(query)\n",
              "        return self.max_marginal_relevance_search_by_vector(\n",
              "            query_embedding,\n",
              "            k=k,\n",
              "            fetch_k=fetch_k,\n",
              "            lambda_mult=lambda_mult,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "[docs]    @sync_call_fallback\n",
              "    async def amax_marginal_relevance_search(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        fetch_k: int = 20,\n",
              "        lambda_mult: float = 0.5,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
              "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
              "        among selected documents.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
              "                     Defaults to 20.\n",
              "            lambda_mult: Number between 0 and 1 that determines the degree\n",
              "                        of diversity among the results with 0 corresponding\n",
              "                        to maximum diversity and 1 to minimum diversity.\n",
              "                        Defaults to 0.5.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to\n",
              "                AsyncQdrantClient.Search().\n",
              "        Returns:\n",
              "            List of Documents selected by maximal marginal relevance.\n",
              "        \"\"\"\n",
              "        query_embedding = await self._aembed_query(query)\n",
              "        return await self.amax_marginal_relevance_search_by_vector(\n",
              "            query_embedding,\n",
              "            k=k,\n",
              "            fetch_k=fetch_k,\n",
              "            lambda_mult=lambda_mult,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "[docs]    def max_marginal_relevance_search_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        fetch_k: int = 20,\n",
              "        lambda_mult: float = 0.5,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
              "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
              "        among selected documents.\n",
              "        Args:\n",
              "            embedding: Embedding to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
              "            lambda_mult: Number between 0 and 1 that determines the degree\n",
              "                        of diversity among the results with 0 corresponding\n",
              "                        to maximum diversity and 1 to minimum diversity.\n",
              "                        Defaults to 0.5.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of Documents selected by maximal marginal relevance.\n",
              "        \"\"\"\n",
              "        results = self.max_marginal_relevance_search_with_score_by_vector(\n",
              "            embedding,\n",
              "            k=k,\n",
              "            fetch_k=fetch_k,\n",
              "            lambda_mult=lambda_mult,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return list(map(itemgetter(0), results))\n",
              "[docs]    @sync_call_fallback\n",
              "    async def amax_marginal_relevance_search_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        fetch_k: int = 20,\n",
              "        lambda_mult: float = 0.5,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Document]:\n",
              "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
              "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
              "        among selected documents.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
              "                     Defaults to 20.\n",
              "            lambda_mult: Number between 0 and 1 that determines the degree\n",
              "                        of diversity among the results with 0 corresponding\n",
              "                        to maximum diversity and 1 to minimum diversity.\n",
              "                        Defaults to 0.5.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to\n",
              "                AsyncQdrantClient.Search().\n",
              "        Returns:\n",
              "            List of Documents selected by maximal marginal relevance and distance for\n",
              "            each.\n",
              "        \"\"\"\n",
              "        results = await self.amax_marginal_relevance_search_with_score_by_vector(\n",
              "            embedding,\n",
              "            k=k,\n",
              "            fetch_k=fetch_k,\n",
              "            lambda_mult=lambda_mult,\n",
              "            filter=filter,\n",
              "            search_params=search_params,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        return list(map(itemgetter(0), results))\n",
              "[docs]    def max_marginal_relevance_search_with_score_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        fetch_k: int = 20,\n",
              "        lambda_mult: float = 0.5,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
              "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
              "        among selected documents.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
              "                     Defaults to 20.\n",
              "            lambda_mult: Number between 0 and 1 that determines the degree\n",
              "                        of diversity among the results with 0 corresponding\n",
              "                        to maximum diversity and 1 to minimum diversity.\n",
              "                        Defaults to 0.5.\n",
              "            filter: Filter by metadata. Defaults to None.\n",
              "            search_params: Additional search params\n",
              "            score_threshold:\n",
              "                Define a minimal score threshold for the result.\n",
              "                If defined, less similar results will not be returned.\n",
              "                Score of the returned result might be higher or smaller than the\n",
              "                threshold depending on the Distance function used.\n",
              "                E.g. for cosine similarity only higher scores will be returned.\n",
              "            consistency:\n",
              "                Read consistency of the search. Defines how many replicas should be\n",
              "                queried before returning the result.\n",
              "                Values:\n",
              "                - int - number of replicas to query, values should present in all\n",
              "                        queried replicas\n",
              "                - 'majority' - query all replicas, but return values present in the\n",
              "                               majority of replicas\n",
              "                - 'quorum' - query the majority of replicas, return values present in\n",
              "                             all of them\n",
              "                - 'all' - query all replicas, and return values present in all replicas\n",
              "            **kwargs:\n",
              "                Any other named arguments to pass through to QdrantClient.search()\n",
              "        Returns:\n",
              "            List of Documents selected by maximal marginal relevance and distance for\n",
              "            each.\n",
              "        \"\"\"\n",
              "        query_vector = embedding\n",
              "        if self.vector_name is not None:\n",
              "            query_vector = (self.vector_name, query_vector)  # type: ignore[assignment]\n",
              "        results = self.client.search(\n",
              "            collection_name=self.collection_name,\n",
              "            query_vector=query_vector,\n",
              "            query_filter=filter,\n",
              "            search_params=search_params,\n",
              "            limit=fetch_k,\n",
              "            with_payload=True,\n",
              "            with_vectors=True,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        embeddings = [\n",
              "            result.vector.get(self.vector_name)  # type: ignore[index, union-attr]\n",
              "            if self.vector_name is not None\n",
              "            else result.vector\n",
              "            for result in results\n",
              "        ]\n",
              "        mmr_selected = maximal_marginal_relevance(\n",
              "            np.array(embedding), embeddings, k=k, lambda_mult=lambda_mult\n",
              "        )\n",
              "        return [\n",
              "            (\n",
              "                self._document_from_scored_point(\n",
              "                    results[i],\n",
              "                    self.collection_name,\n",
              "                    self.content_payload_key,\n",
              "                    self.metadata_payload_key,\n",
              "                ),\n",
              "                results[i].score,\n",
              "            )\n",
              "            for i in mmr_selected\n",
              "        ]\n",
              "[docs]    @sync_call_fallback\n",
              "    async def amax_marginal_relevance_search_with_score_by_vector(\n",
              "        self,\n",
              "        embedding: List[float],\n",
              "        k: int = 4,\n",
              "        fetch_k: int = 20,\n",
              "        lambda_mult: float = 0.5,\n",
              "        filter: Optional[MetadataFilter] = None,\n",
              "        search_params: Optional[common_types.SearchParams] = None,\n",
              "        score_threshold: Optional[float] = None,\n",
              "        consistency: Optional[common_types.ReadConsistency] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs selected using the maximal marginal relevance.\n",
              "        Maximal marginal relevance optimizes for similarity to query AND diversity\n",
              "        among selected documents.\n",
              "        Args:\n",
              "            query: Text to look up documents similar to.\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
              "                     Defaults to 20.\n",
              "            lambda_mult: Number between 0 and 1 that determines the degree\n",
              "                        of diversity among the results with 0 corresponding\n",
              "                        to maximum diversity and 1 to minimum diversity.\n",
              "                        Defaults to 0.5.\n",
              "        Returns:\n",
              "            List of Documents selected by maximal marginal relevance and distance for\n",
              "            each.\n",
              "        \"\"\"\n",
              "        from qdrant_client.local.async_qdrant_local import AsyncQdrantLocal\n",
              "        if self.async_client is None or isinstance(\n",
              "            self.async_client._client, AsyncQdrantLocal\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"QdrantLocal cannot interoperate with sync and async clients\"\n",
              "            )\n",
              "        query_vector = embedding\n",
              "        if self.vector_name is not None:\n",
              "            query_vector = (self.vector_name, query_vector)  # type: ignore[assignment]\n",
              "        results = await self.async_client.search(\n",
              "            collection_name=self.collection_name,\n",
              "            query_vector=query_vector,\n",
              "            query_filter=filter,\n",
              "            search_params=search_params,\n",
              "            limit=fetch_k,\n",
              "            with_payload=True,\n",
              "            with_vectors=True,\n",
              "            score_threshold=score_threshold,\n",
              "            consistency=consistency,\n",
              "            **kwargs,\n",
              "        )\n",
              "        embeddings = [\n",
              "            result.vector.get(self.vector_name)  # type: ignore[index, union-attr]\n",
              "            if self.vector_name is not None\n",
              "            else result.vector\n",
              "            for result in results\n",
              "        ]\n",
              "        mmr_selected = maximal_marginal_relevance(\n",
              "            np.array(embedding), embeddings, k=k, lambda_mult=lambda_mult\n",
              "        )\n",
              "        return [\n",
              "            (\n",
              "                self._document_from_scored_point(\n",
              "                    results[i],\n",
              "                    self.collection_name,\n",
              "                    self.content_payload_key,\n",
              "                    self.metadata_payload_key,\n",
              "                ),\n",
              "                results[i].score,\n",
              "            )\n",
              "            for i in mmr_selected\n",
              "        ]\n",
              "[docs]    def delete(self, ids: Optional[List[str]] = None, **kwargs: Any) -> Optional[bool]:\n",
              "        \"\"\"Delete by vector ID or other criteria.\n",
              "        Args:\n",
              "            ids: List of ids to delete.\n",
              "            **kwargs: Other keyword arguments that subclasses might use.\n",
              "        Returns:\n",
              "            True if deletion is successful, False otherwise.\n",
              "        \"\"\"\n",
              "        from qdrant_client.http import models as rest\n",
              "        result = self.client.delete(\n",
              "            collection_name=self.collection_name,\n",
              "            points_selector=ids,\n",
              "        )\n",
              "        return result.status == rest.UpdateStatus.COMPLETED\n",
              "[docs]    @sync_call_fallback\n",
              "    async def adelete(\n",
              "        self, ids: Optional[List[str]] = None, **kwargs: Any\n",
              "    ) -> Optional[bool]:\n",
              "        \"\"\"Delete by vector ID or other criteria.\n",
              "        Args:\n",
              "            ids: List of ids to delete.\n",
              "            **kwargs: Other keyword arguments that subclasses might use.\n",
              "        Returns:\n",
              "            True if deletion is successful, False otherwise.\n",
              "        \"\"\"\n",
              "        from qdrant_client.local.async_qdrant_local import AsyncQdrantLocal\n",
              "        if self.async_client is None or isinstance(\n",
              "            self.async_client._client, AsyncQdrantLocal\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"QdrantLocal cannot interoperate with sync and async clients\"\n",
              "            )\n",
              "        from qdrant_client.http import models as rest\n",
              "        result = await self.async_client.delete(\n",
              "            collection_name=self.collection_name,\n",
              "            points_selector=ids,\n",
              "        )\n",
              "        return result.status == rest.UpdateStatus.COMPLETED\n",
              "[docs]    @classmethod\n",
              "    def from_texts(\n",
              "        cls: Type[Qdrant],\n",
              "        texts: List[str],\n",
              "        embedding: Embeddings,\n",
              "        metadatas: Optional[List[dict]] = None,\n",
              "        ids: Optional[Sequence[str]] = None,\n",
              "        location: Optional[str] = None,\n",
              "        url: Optional[str] = None,\n",
              "        port: Optional[int] = 6333,\n",
              "        grpc_port: int = 6334,\n",
              "        prefer_grpc: bool = False,\n",
              "        https: Optional[bool] = None,\n",
              "        api_key: Optional[str] = None,\n",
              "        prefix: Optional[str] = None,\n",
              "        timeout: Optional[float] = None,\n",
              "        host: Optional[str] = None,\n",
              "        path: Optional[str] = None,\n",
              "        collection_name: Optional[str] = None,\n",
              "        distance_func: str = \"Cosine\",\n",
              "        content_payload_key: str = CONTENT_KEY,\n",
              "        metadata_payload_key: str = METADATA_KEY,\n",
              "        vector_name: Optional[str] = VECTOR_NAME,\n",
              "        batch_size: int = 64,\n",
              "        shard_number: Optional[int] = None,\n",
              "        replication_factor: Optional[int] = None,\n",
              "        write_consistency_factor: Optional[int] = None,\n",
              "        on_disk_payload: Optional[bool] = None,\n",
              "        hnsw_config: Optional[common_types.HnswConfigDiff] = None,\n",
              "        optimizers_config: Optional[common_types.OptimizersConfigDiff] = None,\n",
              "        wal_config: Optional[common_types.WalConfigDiff] = None,\n",
              "        quantization_config: Optional[common_types.QuantizationConfig] = None,\n",
              "        init_from: Optional[common_types.InitFrom] = None,\n",
              "        on_disk: Optional[bool] = None,\n",
              "        force_recreate: bool = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> Qdrant:\n",
              "        \"\"\"Construct Qdrant wrapper from a list of texts.\n",
              "        Args:\n",
              "            texts: A list of texts to be indexed in Qdrant.\n",
              "            embedding: A subclass of `Embeddings`, responsible for text vectorization.\n",
              "            metadatas:\n",
              "                An optional list of metadata. If provided it has to be of the same\n",
              "                length as a list of texts.\n",
              "            ids:\n",
              "                Optional list of ids to associate with the texts. Ids have to be\n",
              "                uuid-like strings.\n",
              "            location:\n",
              "                If `:memory:` - use in-memory Qdrant instance.\n",
              "                If `str` - use it as a `url` parameter.\n",
              "                If `None` - fallback to relying on `host` and `port` parameters.\n",
              "            url: either host or str of \"Optional[scheme], host, Optional[port],\n",
              "                Optional[prefix]\". Default: `None`\n",
              "            port: Port of the REST API interface. Default: 6333\n",
              "            grpc_port: Port of the gRPC interface. Default: 6334\n",
              "            prefer_grpc:\n",
              "                If true - use gPRC interface whenever possible in custom methods.\n",
              "                Default: False\n",
              "            https: If true - use HTTPS(SSL) protocol. Default: None\n",
              "            api_key: API key for authentication in Qdrant Cloud. Default: None\n",
              "            prefix:\n",
              "                If not None - add prefix to the REST URL path.\n",
              "                Example: service/v1 will result in\n",
              "                    http://localhost:6333/service/v1/{qdrant-endpoint} for REST API.\n",
              "                Default: None\n",
              "            timeout:\n",
              "                Timeout for REST and gRPC API requests.\n",
              "                Default: 5.0 seconds for REST and unlimited for gRPC\n",
              "            host:\n",
              "                Host name of Qdrant service. If url and host are None, set to\n",
              "                'localhost'. Default: None\n",
              "            path:\n",
              "                Path in which the vectors will be stored while using local mode.\n",
              "                Default: None\n",
              "            collection_name:\n",
              "                Name of the Qdrant collection to be used. If not provided,\n",
              "                it will be created randomly. Default: None\n",
              "            distance_func:\n",
              "                Distance function. One of: \"Cosine\" / \"Euclid\" / \"Dot\".\n",
              "                Default: \"Cosine\"\n",
              "            content_payload_key:\n",
              "                A payload key used to store the content of the document.\n",
              "                Default: \"page_content\"\n",
              "            metadata_payload_key:\n",
              "                A payload key used to store the metadata of the document.\n",
              "                Default: \"metadata\"\n",
              "            vector_name:\n",
              "                Name of the vector to be used internally in Qdrant.\n",
              "                Default: None\n",
              "            batch_size:\n",
              "                How many vectors upload per-request.\n",
              "                Default: 64\n",
              "            shard_number: Number of shards in collection. Default is 1, minimum is 1.\n",
              "            replication_factor:\n",
              "                Replication factor for collection. Default is 1, minimum is 1.\n",
              "                Defines how many copies of each shard will be created.\n",
              "                Have effect only in distributed mode.\n",
              "            write_consistency_factor:\n",
              "                Write consistency factor for collection. Default is 1, minimum is 1.\n",
              "                Defines how many replicas should apply the operation for us to consider\n",
              "                it successful. Increasing this number will make the collection more\n",
              "                resilient to inconsistencies, but will also make it fail if not enough\n",
              "                replicas are available.\n",
              "                Does not have any performance impact.\n",
              "                Have effect only in distributed mode.\n",
              "            on_disk_payload:\n",
              "                If true - point`s payload will not be stored in memory.\n",
              "                It will be read from the disk every time it is requested.\n",
              "                This setting saves RAM by (slightly) increasing the response time.\n",
              "                Note: those payload values that are involved in filtering and are\n",
              "                indexed - remain in RAM.\n",
              "            hnsw_config: Params for HNSW index\n",
              "            optimizers_config: Params for optimizer\n",
              "            wal_config: Params for Write-Ahead-Log\n",
              "            quantization_config:\n",
              "                Params for quantization, if None - quantization will be disabled\n",
              "            init_from:\n",
              "                Use data stored in another collection to initialize this collection\n",
              "            force_recreate:\n",
              "                Force recreating the collection\n",
              "            **kwargs:\n",
              "                Additional arguments passed directly into REST client initialization\n",
              "        This is a user-friendly interface that:\n",
              "        1. Creates embeddings, one for each text\n",
              "        2. Initializes the Qdrant database as an in-memory docstore by default\n",
              "           (and overridable to a remote docstore)\n",
              "        3. Adds the text embeddings to the Qdrant database\n",
              "        This is intended to be a quick way to get started.\n",
              "        Example:\n",
              "            .. code-block:: python\n",
              "                from langchain_community.vectorstores import Qdrant\n",
              "                from langchain_community.embeddings import OpenAIEmbeddings\n",
              "                embeddings = OpenAIEmbeddings()\n",
              "                qdrant = Qdrant.from_texts(texts, embeddings, \"localhost\")\n",
              "        \"\"\"\n",
              "        qdrant = cls.construct_instance(\n",
              "            texts,\n",
              "            embedding,\n",
              "            location,\n",
              "            url,\n",
              "            port,\n",
              "            grpc_port,\n",
              "            prefer_grpc,\n",
              "            https,\n",
              "            api_key,\n",
              "            prefix,\n",
              "            timeout,\n",
              "            host,\n",
              "            path,\n",
              "            collection_name,\n",
              "            distance_func,\n",
              "            content_payload_key,\n",
              "            metadata_payload_key,\n",
              "            vector_name,\n",
              "            shard_number,\n",
              "            replication_factor,\n",
              "            write_consistency_factor,\n",
              "            on_disk_payload,\n",
              "            hnsw_config,\n",
              "            optimizers_config,\n",
              "            wal_config,\n",
              "            quantization_config,\n",
              "            init_from,\n",
              "            on_disk,\n",
              "            force_recreate,\n",
              "            **kwargs,\n",
              "        )\n",
              "        qdrant.add_texts(texts, metadatas, ids, batch_size)\n",
              "        return qdrant\n",
              "[docs]    @classmethod\n",
              "    @sync_call_fallback\n",
              "    async def afrom_texts(\n",
              "        cls: Type[Qdrant],\n",
              "        texts: List[str],\n",
              "        embedding: Embeddings,\n",
              "        metadatas: Optional[List[dict]] = None,\n",
              "        ids: Optional[Sequence[str]] = None,\n",
              "        location: Optional[str] = None,\n",
              "        url: Optional[str] = None,\n",
              "        port: Optional[int] = 6333,\n",
              "        grpc_port: int = 6334,\n",
              "        prefer_grpc: bool = False,\n",
              "        https: Optional[bool] = None,\n",
              "        api_key: Optional[str] = None,\n",
              "        prefix: Optional[str] = None,\n",
              "        timeout: Optional[float] = None,\n",
              "        host: Optional[str] = None,\n",
              "        path: Optional[str] = None,\n",
              "        collection_name: Optional[str] = None,\n",
              "        distance_func: str = \"Cosine\",\n",
              "        content_payload_key: str = CONTENT_KEY,\n",
              "        metadata_payload_key: str = METADATA_KEY,\n",
              "        vector_name: Optional[str] = VECTOR_NAME,\n",
              "        batch_size: int = 64,\n",
              "        shard_number: Optional[int] = None,\n",
              "        replication_factor: Optional[int] = None,\n",
              "        write_consistency_factor: Optional[int] = None,\n",
              "        on_disk_payload: Optional[bool] = None,\n",
              "        hnsw_config: Optional[common_types.HnswConfigDiff] = None,\n",
              "        optimizers_config: Optional[common_types.OptimizersConfigDiff] = None,\n",
              "        wal_config: Optional[common_types.WalConfigDiff] = None,\n",
              "        quantization_config: Optional[common_types.QuantizationConfig] = None,\n",
              "        init_from: Optional[common_types.InitFrom] = None,\n",
              "        on_disk: Optional[bool] = None,\n",
              "        force_recreate: bool = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> Qdrant:\n",
              "        \"\"\"Construct Qdrant wrapper from a list of texts.\n",
              "        Args:\n",
              "            texts: A list of texts to be indexed in Qdrant.\n",
              "            embedding: A subclass of `Embeddings`, responsible for text vectorization.\n",
              "            metadatas:\n",
              "                An optional list of metadata. If provided it has to be of the same\n",
              "                length as a list of texts.\n",
              "            ids:\n",
              "                Optional list of ids to associate with the texts. Ids have to be\n",
              "                uuid-like strings.\n",
              "            location:\n",
              "                If `:memory:` - use in-memory Qdrant instance.\n",
              "                If `str` - use it as a `url` parameter.\n",
              "                If `None` - fallback to relying on `host` and `port` parameters.\n",
              "            url: either host or str of \"Optional[scheme], host, Optional[port],\n",
              "                Optional[prefix]\". Default: `None`\n",
              "            port: Port of the REST API interface. Default: 6333\n",
              "            grpc_port: Port of the gRPC interface. Default: 6334\n",
              "            prefer_grpc:\n",
              "                If true - use gPRC interface whenever possible in custom methods.\n",
              "                Default: False\n",
              "            https: If true - use HTTPS(SSL) protocol. Default: None\n",
              "            api_key: API key for authentication in Qdrant Cloud. Default: None\n",
              "            prefix:\n",
              "                If not None - add prefix to the REST URL path.\n",
              "                Example: service/v1 will result in\n",
              "                    http://localhost:6333/service/v1/{qdrant-endpoint} for REST API.\n",
              "                Default: None\n",
              "            timeout:\n",
              "                Timeout for REST and gRPC API requests.\n",
              "                Default: 5.0 seconds for REST and unlimited for gRPC\n",
              "            host:\n",
              "                Host name of Qdrant service. If url and host are None, set to\n",
              "                'localhost'. Default: None\n",
              "            path:\n",
              "                Path in which the vectors will be stored while using local mode.\n",
              "                Default: None\n",
              "            collection_name:\n",
              "                Name of the Qdrant collection to be used. If not provided,\n",
              "                it will be created randomly. Default: None\n",
              "            distance_func:\n",
              "                Distance function. One of: \"Cosine\" / \"Euclid\" / \"Dot\".\n",
              "                Default: \"Cosine\"\n",
              "            content_payload_key:\n",
              "                A payload key used to store the content of the document.\n",
              "                Default: \"page_content\"\n",
              "            metadata_payload_key:\n",
              "                A payload key used to store the metadata of the document.\n",
              "                Default: \"metadata\"\n",
              "            vector_name:\n",
              "                Name of the vector to be used internally in Qdrant.\n",
              "                Default: None\n",
              "            batch_size:\n",
              "                How many vectors upload per-request.\n",
              "                Default: 64\n",
              "            shard_number: Number of shards in collection. Default is 1, minimum is 1.\n",
              "            replication_factor:\n",
              "                Replication factor for collection. Default is 1, minimum is 1.\n",
              "                Defines how many copies of each shard will be created.\n",
              "                Have effect only in distributed mode.\n",
              "            write_consistency_factor:\n",
              "                Write consistency factor for collection. Default is 1, minimum is 1.\n",
              "                Defines how many replicas should apply the operation for us to consider\n",
              "                it successful. Increasing this number will make the collection more\n",
              "                resilient to inconsistencies, but will also make it fail if not enough\n",
              "                replicas are available.\n",
              "                Does not have any performance impact.\n",
              "                Have effect only in distributed mode.\n",
              "            on_disk_payload:\n",
              "                If true - point`s payload will not be stored in memory.\n",
              "                It will be read from the disk every time it is requested.\n",
              "                This setting saves RAM by (slightly) increasing the response time.\n",
              "                Note: those payload values that are involved in filtering and are\n",
              "                indexed - remain in RAM.\n",
              "            hnsw_config: Params for HNSW index\n",
              "            optimizers_config: Params for optimizer\n",
              "            wal_config: Params for Write-Ahead-Log\n",
              "            quantization_config:\n",
              "                Params for quantization, if None - quantization will be disabled\n",
              "            init_from:\n",
              "                Use data stored in another collection to initialize this collection\n",
              "            force_recreate:\n",
              "                Force recreating the collection\n",
              "            **kwargs:\n",
              "                Additional arguments passed directly into REST client initialization\n",
              "        This is a user-friendly interface that:\n",
              "        1. Creates embeddings, one for each text\n",
              "        2. Initializes the Qdrant database as an in-memory docstore by default\n",
              "           (and overridable to a remote docstore)\n",
              "        3. Adds the text embeddings to the Qdrant database\n",
              "        This is intended to be a quick way to get started.\n",
              "        Example:\n",
              "            .. code-block:: python\n",
              "                from langchain_community.vectorstores import Qdrant\n",
              "                from langchain_community.embeddings import OpenAIEmbeddings\n",
              "                embeddings = OpenAIEmbeddings()\n",
              "                qdrant = await Qdrant.afrom_texts(texts, embeddings, \"localhost\")\n",
              "        \"\"\"\n",
              "        qdrant = await cls.aconstruct_instance(\n",
              "            texts,\n",
              "            embedding,\n",
              "            location,\n",
              "            url,\n",
              "            port,\n",
              "            grpc_port,\n",
              "            prefer_grpc,\n",
              "            https,\n",
              "            api_key,\n",
              "            prefix,\n",
              "            timeout,\n",
              "            host,\n",
              "            path,\n",
              "            collection_name,\n",
              "            distance_func,\n",
              "            content_payload_key,\n",
              "            metadata_payload_key,\n",
              "            vector_name,\n",
              "            shard_number,\n",
              "            replication_factor,\n",
              "            write_consistency_factor,\n",
              "            on_disk_payload,\n",
              "            hnsw_config,\n",
              "            optimizers_config,\n",
              "            wal_config,\n",
              "            quantization_config,\n",
              "            init_from,\n",
              "            on_disk,\n",
              "            force_recreate,\n",
              "            **kwargs,\n",
              "        )\n",
              "        await qdrant.aadd_texts(texts, metadatas, ids, batch_size)\n",
              "        return qdrant\n",
              "[docs]    @classmethod\n",
              "    def construct_instance(\n",
              "        cls: Type[Qdrant],\n",
              "        texts: List[str],\n",
              "        embedding: Embeddings,\n",
              "        location: Optional[str] = None,\n",
              "        url: Optional[str] = None,\n",
              "        port: Optional[int] = 6333,\n",
              "        grpc_port: int = 6334,\n",
              "        prefer_grpc: bool = False,\n",
              "        https: Optional[bool] = None,\n",
              "        api_key: Optional[str] = None,\n",
              "        prefix: Optional[str] = None,\n",
              "        timeout: Optional[float] = None,\n",
              "        host: Optional[str] = None,\n",
              "        path: Optional[str] = None,\n",
              "        collection_name: Optional[str] = None,\n",
              "        distance_func: str = \"Cosine\",\n",
              "        content_payload_key: str = CONTENT_KEY,\n",
              "        metadata_payload_key: str = METADATA_KEY,\n",
              "        vector_name: Optional[str] = VECTOR_NAME,\n",
              "        shard_number: Optional[int] = None,\n",
              "        replication_factor: Optional[int] = None,\n",
              "        write_consistency_factor: Optional[int] = None,\n",
              "        on_disk_payload: Optional[bool] = None,\n",
              "        hnsw_config: Optional[common_types.HnswConfigDiff] = None,\n",
              "        optimizers_config: Optional[common_types.OptimizersConfigDiff] = None,\n",
              "        wal_config: Optional[common_types.WalConfigDiff] = None,\n",
              "        quantization_config: Optional[common_types.QuantizationConfig] = None,\n",
              "        init_from: Optional[common_types.InitFrom] = None,\n",
              "        on_disk: Optional[bool] = None,\n",
              "        force_recreate: bool = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> Qdrant:\n",
              "        try:\n",
              "            import qdrant_client  # noqa\n",
              "        except ImportError:\n",
              "            raise ValueError(\n",
              "                \"Could not import qdrant-client python package. \"\n",
              "                \"Please install it with `pip install qdrant-client`.\"\n",
              "            )\n",
              "        from grpc import RpcError\n",
              "        from qdrant_client.http import models as rest\n",
              "        from qdrant_client.http.exceptions import UnexpectedResponse\n",
              "        # Just do a single quick embedding to get vector size\n",
              "        partial_embeddings = embedding.embed_documents(texts[:1])\n",
              "        vector_size = len(partial_embeddings[0])\n",
              "        collection_name = collection_name or uuid.uuid4().hex\n",
              "        distance_func = distance_func.upper()\n",
              "        client, async_client = cls._generate_clients(\n",
              "            location=location,\n",
              "            url=url,\n",
              "            port=port,\n",
              "            grpc_port=grpc_port,\n",
              "            prefer_grpc=prefer_grpc,\n",
              "            https=https,\n",
              "            api_key=api_key,\n",
              "            prefix=prefix,\n",
              "            timeout=timeout,\n",
              "            host=host,\n",
              "            path=path,\n",
              "            **kwargs,\n",
              "        )\n",
              "        try:\n",
              "            # Skip any validation in case of forced collection recreate.\n",
              "            if force_recreate:\n",
              "                raise ValueError\n",
              "            # Get the vector configuration of the existing collection and vector, if it\n",
              "            # was specified. If the old configuration does not match the current one,\n",
              "            # an exception is being thrown.\n",
              "            collection_info = client.get_collection(collection_name=collection_name)\n",
              "            current_vector_config = collection_info.config.params.vectors\n",
              "            if isinstance(current_vector_config, dict) and vector_name is not None:\n",
              "                if vector_name not in current_vector_config:\n",
              "                    raise QdrantException(\n",
              "                        f\"Existing Qdrant collection {collection_name} does not \"\n",
              "                        f\"contain vector named {vector_name}. Did you mean one of the \"\n",
              "                        f\"existing vectors: {', '.join(current_vector_config.keys())}? \"\n",
              "                        f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                        f\"parameter to `True`.\"\n",
              "                    )\n",
              "                current_vector_config = current_vector_config.get(vector_name)  # type: ignore[assignment]\n",
              "            elif isinstance(current_vector_config, dict) and vector_name is None:\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection {collection_name} uses named vectors. \"\n",
              "                    f\"If you want to reuse it, please set `vector_name` to any of the \"\n",
              "                    f\"existing named vectors: \"\n",
              "                    f\"{', '.join(current_vector_config.keys())}.\"  # noqa\n",
              "                    f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                    f\"parameter to `True`.\"\n",
              "                )\n",
              "            elif (\n",
              "                not isinstance(current_vector_config, dict) and vector_name is not None\n",
              "            ):\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection {collection_name} doesn't use named \"\n",
              "                    f\"vectors. If you want to reuse it, please set `vector_name` to \"\n",
              "                    f\"`None`. If you want to recreate the collection, set \"\n",
              "                    f\"`force_recreate` parameter to `True`.\"\n",
              "                )\n",
              "            # Check if the vector configuration has the same dimensionality.\n",
              "            if current_vector_config.size != vector_size:  # type: ignore[union-attr]\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection is configured for vectors with \"\n",
              "                    f\"{current_vector_config.size} \"  # type: ignore[union-attr]\n",
              "                    f\"dimensions. Selected embeddings are {vector_size}-dimensional. \"\n",
              "                    f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                    f\"parameter to `True`.\"\n",
              "                )\n",
              "            current_distance_func = (\n",
              "                current_vector_config.distance.name.upper()  # type: ignore[union-attr]\n",
              "            )\n",
              "            if current_distance_func != distance_func:\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection is configured for \"\n",
              "                    f\"{current_distance_func} similarity, but requested \"\n",
              "                    f\"{distance_func}. Please set `distance_func` parameter to \"\n",
              "                    f\"`{current_distance_func}` if you want to reuse it. \"\n",
              "                    f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                    f\"parameter to `True`.\"\n",
              "                )\n",
              "        except (UnexpectedResponse, RpcError, ValueError):\n",
              "            vectors_config = rest.VectorParams(\n",
              "                size=vector_size,\n",
              "                distance=rest.Distance[distance_func],\n",
              "                on_disk=on_disk,\n",
              "            )\n",
              "            # If vector name was provided, we're going to use the named vectors feature\n",
              "            # with just a single vector.\n",
              "            if vector_name is not None:\n",
              "                vectors_config = {  # type: ignore[assignment]\n",
              "                    vector_name: vectors_config,\n",
              "                }\n",
              "            client.recreate_collection(\n",
              "                collection_name=collection_name,\n",
              "                vectors_config=vectors_config,\n",
              "                shard_number=shard_number,\n",
              "                replication_factor=replication_factor,\n",
              "                write_consistency_factor=write_consistency_factor,\n",
              "                on_disk_payload=on_disk_payload,\n",
              "                hnsw_config=hnsw_config,\n",
              "                optimizers_config=optimizers_config,\n",
              "                wal_config=wal_config,\n",
              "                quantization_config=quantization_config,\n",
              "                init_from=init_from,\n",
              "                timeout=timeout,  # type: ignore[arg-type]\n",
              "            )\n",
              "        qdrant = cls(\n",
              "            client=client,\n",
              "            collection_name=collection_name,\n",
              "            embeddings=embedding,\n",
              "            content_payload_key=content_payload_key,\n",
              "            metadata_payload_key=metadata_payload_key,\n",
              "            distance_strategy=distance_func,\n",
              "            vector_name=vector_name,\n",
              "            async_client=async_client,\n",
              "        )\n",
              "        return qdrant\n",
              "[docs]    @classmethod\n",
              "    async def aconstruct_instance(\n",
              "        cls: Type[Qdrant],\n",
              "        texts: List[str],\n",
              "        embedding: Embeddings,\n",
              "        location: Optional[str] = None,\n",
              "        url: Optional[str] = None,\n",
              "        port: Optional[int] = 6333,\n",
              "        grpc_port: int = 6334,\n",
              "        prefer_grpc: bool = False,\n",
              "        https: Optional[bool] = None,\n",
              "        api_key: Optional[str] = None,\n",
              "        prefix: Optional[str] = None,\n",
              "        timeout: Optional[float] = None,\n",
              "        host: Optional[str] = None,\n",
              "        path: Optional[str] = None,\n",
              "        collection_name: Optional[str] = None,\n",
              "        distance_func: str = \"Cosine\",\n",
              "        content_payload_key: str = CONTENT_KEY,\n",
              "        metadata_payload_key: str = METADATA_KEY,\n",
              "        vector_name: Optional[str] = VECTOR_NAME,\n",
              "        shard_number: Optional[int] = None,\n",
              "        replication_factor: Optional[int] = None,\n",
              "        write_consistency_factor: Optional[int] = None,\n",
              "        on_disk_payload: Optional[bool] = None,\n",
              "        hnsw_config: Optional[common_types.HnswConfigDiff] = None,\n",
              "        optimizers_config: Optional[common_types.OptimizersConfigDiff] = None,\n",
              "        wal_config: Optional[common_types.WalConfigDiff] = None,\n",
              "        quantization_config: Optional[common_types.QuantizationConfig] = None,\n",
              "        init_from: Optional[common_types.InitFrom] = None,\n",
              "        on_disk: Optional[bool] = None,\n",
              "        force_recreate: bool = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> Qdrant:\n",
              "        try:\n",
              "            import qdrant_client  # noqa\n",
              "        except ImportError:\n",
              "            raise ValueError(\n",
              "                \"Could not import qdrant-client python package. \"\n",
              "                \"Please install it with `pip install qdrant-client`.\"\n",
              "            )\n",
              "        from grpc import RpcError\n",
              "        from qdrant_client.http import models as rest\n",
              "        from qdrant_client.http.exceptions import UnexpectedResponse\n",
              "        # Just do a single quick embedding to get vector size\n",
              "        partial_embeddings = await embedding.aembed_documents(texts[:1])\n",
              "        vector_size = len(partial_embeddings[0])\n",
              "        collection_name = collection_name or uuid.uuid4().hex\n",
              "        distance_func = distance_func.upper()\n",
              "        client, async_client = cls._generate_clients(\n",
              "            location=location,\n",
              "            url=url,\n",
              "            port=port,\n",
              "            grpc_port=grpc_port,\n",
              "            prefer_grpc=prefer_grpc,\n",
              "            https=https,\n",
              "            api_key=api_key,\n",
              "            prefix=prefix,\n",
              "            timeout=timeout,\n",
              "            host=host,\n",
              "            path=path,\n",
              "            **kwargs,\n",
              "        )\n",
              "        try:\n",
              "            # Skip any validation in case of forced collection recreate.\n",
              "            if force_recreate:\n",
              "                raise ValueError\n",
              "            # Get the vector configuration of the existing collection and vector, if it\n",
              "            # was specified. If the old configuration does not match the current one,\n",
              "            # an exception is being thrown.\n",
              "            collection_info = client.get_collection(collection_name=collection_name)\n",
              "            current_vector_config = collection_info.config.params.vectors\n",
              "            if isinstance(current_vector_config, dict) and vector_name is not None:\n",
              "                if vector_name not in current_vector_config:\n",
              "                    raise QdrantException(\n",
              "                        f\"Existing Qdrant collection {collection_name} does not \"\n",
              "                        f\"contain vector named {vector_name}. Did you mean one of the \"\n",
              "                        f\"existing vectors: {', '.join(current_vector_config.keys())}? \"\n",
              "                        f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                        f\"parameter to `True`.\"\n",
              "                    )\n",
              "                current_vector_config = current_vector_config.get(vector_name)  # type: ignore[assignment]\n",
              "            elif isinstance(current_vector_config, dict) and vector_name is None:\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection {collection_name} uses named vectors. \"\n",
              "                    f\"If you want to reuse it, please set `vector_name` to any of the \"\n",
              "                    f\"existing named vectors: \"\n",
              "                    f\"{', '.join(current_vector_config.keys())}.\"  # noqa\n",
              "                    f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                    f\"parameter to `True`.\"\n",
              "                )\n",
              "            elif (\n",
              "                not isinstance(current_vector_config, dict) and vector_name is not None\n",
              "            ):\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection {collection_name} doesn't use named \"\n",
              "                    f\"vectors. If you want to reuse it, please set `vector_name` to \"\n",
              "                    f\"`None`. If you want to recreate the collection, set \"\n",
              "                    f\"`force_recreate` parameter to `True`.\"\n",
              "                )\n",
              "            # Check if the vector configuration has the same dimensionality.\n",
              "            if current_vector_config.size != vector_size:  # type: ignore[union-attr]\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection is configured for vectors with \"\n",
              "                    f\"{current_vector_config.size} \"  # type: ignore[union-attr]\n",
              "                    f\"dimensions. Selected embeddings are {vector_size}-dimensional. \"\n",
              "                    f\"If you want to recreate the collection, set `force_recreate` \"\n",
              "                    f\"parameter to `True`.\"\n",
              "                )\n",
              "            current_distance_func = (\n",
              "                current_vector_config.distance.name.upper()  # type: ignore[union-attr]\n",
              "            )\n",
              "            if current_distance_func != distance_func:\n",
              "                raise QdrantException(\n",
              "                    f\"Existing Qdrant collection is configured for \"\n",
              "                    f\"{current_vector_config.distance} \"  # type: ignore[union-attr]\n",
              "                    f\"similarity. Please set `distance_func` parameter to \"\n",
              "                    f\"`{distance_func}` if you want to reuse it. If you want to \"\n",
              "                    f\"recreate the collection, set `force_recreate` parameter to \"\n",
              "                    f\"`True`.\"\n",
              "                )\n",
              "        except (UnexpectedResponse, RpcError, ValueError):\n",
              "            vectors_config = rest.VectorParams(\n",
              "                size=vector_size,\n",
              "                distance=rest.Distance[distance_func],\n",
              "                on_disk=on_disk,\n",
              "            )\n",
              "            # If vector name was provided, we're going to use the named vectors feature\n",
              "            # with just a single vector.\n",
              "            if vector_name is not None:\n",
              "                vectors_config = {  # type: ignore[assignment]\n",
              "                    vector_name: vectors_config,\n",
              "                }\n",
              "            client.recreate_collection(\n",
              "                collection_name=collection_name,\n",
              "                vectors_config=vectors_config,\n",
              "                shard_number=shard_number,\n",
              "                replication_factor=replication_factor,\n",
              "                write_consistency_factor=write_consistency_factor,\n",
              "                on_disk_payload=on_disk_payload,\n",
              "                hnsw_config=hnsw_config,\n",
              "                optimizers_config=optimizers_config,\n",
              "                wal_config=wal_config,\n",
              "                quantization_config=quantization_config,\n",
              "                init_from=init_from,\n",
              "                timeout=timeout,  # type: ignore[arg-type]\n",
              "            )\n",
              "        qdrant = cls(\n",
              "            client=client,\n",
              "            collection_name=collection_name,\n",
              "            embeddings=embedding,\n",
              "            content_payload_key=content_payload_key,\n",
              "            metadata_payload_key=metadata_payload_key,\n",
              "            distance_strategy=distance_func,\n",
              "            vector_name=vector_name,\n",
              "            async_client=async_client,\n",
              "        )\n",
              "        return qdrant\n",
              "    @staticmethod\n",
              "    def _cosine_relevance_score_fn(distance: float) -> float:\n",
              "        \"\"\"Normalize the distance to a score on a scale [0, 1].\"\"\"\n",
              "        return (distance + 1.0) / 2.0\n",
              "    def _select_relevance_score_fn(self) -> Callable[[float], float]:\n",
              "        \"\"\"\n",
              "        The 'correct' relevance function\n",
              "        may differ depending on a few things, including:\n",
              "        - the distance / similarity metric used by the VectorStore\n",
              "        - the scale of your embeddings (OpenAI's are unit normed. Many others are not!)\n",
              "        - embedding dimensionality\n",
              "        - etc.\n",
              "        \"\"\"\n",
              "        if self.distance_strategy == \"COSINE\":\n",
              "            return self._cosine_relevance_score_fn\n",
              "        elif self.distance_strategy == \"DOT\":\n",
              "            return self._max_inner_product_relevance_score_fn\n",
              "        elif self.distance_strategy == \"EUCLID\":\n",
              "            return self._euclidean_relevance_score_fn\n",
              "        else:\n",
              "            raise ValueError(\n",
              "                \"Unknown distance strategy, must be cosine, \"\n",
              "                \"max_inner_product, or euclidean\"\n",
              "            )\n",
              "    def _similarity_search_with_relevance_scores(\n",
              "        self,\n",
              "        query: str,\n",
              "        k: int = 4,\n",
              "        **kwargs: Any,\n",
              "    ) -> List[Tuple[Document, float]]:\n",
              "        \"\"\"Return docs and relevance scores in the range [0, 1].\n",
              "        0 is dissimilar, 1 is most similar.\n",
              "        Args:\n",
              "            query: input text\n",
              "            k: Number of Documents to return. Defaults to 4.\n",
              "            **kwargs: kwargs to be passed to similarity search. Should include:\n",
              "                score_threshold: Optional, a floating point value between 0 to 1 to\n",
              "                    filter the resulting set of retrieved docs\n",
              "        Returns:\n",
              "            List of Tuples of (doc, similarity_score)\n",
              "        \"\"\"\n",
              "        return self.similarity_search_with_score(query, k, **kwargs)\n",
              "    @classmethod\n",
              "    def _build_payloads(\n",
              "        cls,\n",
              "        texts: Iterable[str],\n",
              "        metadatas: Optional[List[dict]],\n",
              "        content_payload_key: str,\n",
              "        metadata_payload_key: str,\n",
              "    ) -> List[dict]:\n",
              "        payloads = []\n",
              "        for i, text in enumerate(texts):\n",
              "            if text is None:\n",
              "                raise ValueError(\n",
              "                    \"At least one of the texts is None. Please remove it before \"\n",
              "                    \"calling .from_texts or .add_texts on Qdrant instance.\"\n",
              "                )\n",
              "            metadata = metadatas[i] if metadatas is not None else None\n",
              "            payloads.append(\n",
              "                {\n",
              "                    content_payload_key: text,\n",
              "                    metadata_payload_key: metadata,\n",
              "                }\n",
              "            )\n",
              "        return payloads\n",
              "    @classmethod\n",
              "    def _document_from_scored_point(\n",
              "        cls,\n",
              "        scored_point: Any,\n",
              "        collection_name: str,\n",
              "        content_payload_key: str,\n",
              "        metadata_payload_key: str,\n",
              "    ) -> Document:\n",
              "        metadata = scored_point.payload.get(metadata_payload_key) or {}\n",
              "        metadata[\"_id\"] = scored_point.id\n",
              "        metadata[\"_collection_name\"] = collection_name\n",
              "        return Document(\n",
              "            page_content=scored_point.payload.get(content_payload_key),\n",
              "            metadata=metadata,\n",
              "        )\n",
              "    def _build_condition(self, key: str, value: Any) -> List[rest.FieldCondition]:\n",
              "        from qdrant_client.http import models as rest\n",
              "        out = []\n",
              "        if isinstance(value, dict):\n",
              "            for _key, value in value.items():\n",
              "                out.extend(self._build_condition(f\"{key}.{_key}\", value))\n",
              "        elif isinstance(value, list):\n",
              "            for _value in value:\n",
              "                if isinstance(_value, dict):\n",
              "                    out.extend(self._build_condition(f\"{key}[]\", _value))\n",
              "                else:\n",
              "                    out.extend(self._build_condition(f\"{key}\", _value))\n",
              "        else:\n",
              "            out.append(\n",
              "                rest.FieldCondition(\n",
              "                    key=f\"{self.metadata_payload_key}.{key}\",\n",
              "                    match=rest.MatchValue(value=value),\n",
              "                )\n",
              "            )\n",
              "        return out\n",
              "    def _qdrant_filter_from_dict(\n",
              "        self, filter: Optional[DictFilter]\n",
              "    ) -> Optional[rest.Filter]:\n",
              "        from qdrant_client.http import models as rest\n",
              "        if not filter:\n",
              "            return None\n",
              "        return rest.Filter(\n",
              "            must=[\n",
              "                condition\n",
              "                for key, value in filter.items()\n",
              "                for condition in self._build_condition(key, value)\n",
              "            ]\n",
              "        )\n",
              "    def _embed_query(self, query: str) -> List[float]:\n",
              "        \"\"\"Embed query text.\n",
              "        Used to provide backward compatibility with `embedding_function` argument.\n",
              "        Args:\n",
              "            query: Query text.\n",
              "        Returns:\n",
              "            List of floats representing the query embedding.\n",
              "        \"\"\"\n",
              "        if self.embeddings is not None:\n",
              "            embedding = self.embeddings.embed_query(query)\n",
              "        else:\n",
              "            if self._embeddings_function is not None:\n",
              "                embedding = self._embeddings_function(query)\n",
              "            else:\n",
              "                raise ValueError(\"Neither of embeddings or embedding_function is set\")\n",
              "        return embedding.tolist() if hasattr(embedding, \"tolist\") else embedding\n",
              "    async def _aembed_query(self, query: str) -> List[float]:\n",
              "        \"\"\"Embed query text asynchronously.\n",
              "        Used to provide backward compatibility with `embedding_function` argument.\n",
              "        Args:\n",
              "            query: Query text.\n",
              "        Returns:\n",
              "            List of floats representing the query embedding.\n",
              "        \"\"\"\n",
              "        if self.embeddings is not None:\n",
              "            embedding = await self.embeddings.aembed_query(query)\n",
              "        else:\n",
              "            if self._embeddings_function is not None:\n",
              "                embedding = self._embeddings_function(query)\n",
              "            else:\n",
              "                raise ValueError(\"Neither of embeddings or embedding_function is set\")\n",
              "        return embedding.tolist() if hasattr(embedding, \"tolist\") else embedding\n",
              "    def _embed_texts(self, texts: Iterable[str]) -> List[List[float]]:\n",
              "        \"\"\"Embed search texts.\n",
              "        Used to provide backward compatibility with `embedding_function` argument.\n",
              "        Args:\n",
              "            texts: Iterable of texts to embed.\n",
              "        Returns:\n",
              "            List of floats representing the texts embedding.\n",
              "        \"\"\"\n",
              "        if self.embeddings is not None:\n",
              "            embeddings = self.embeddings.embed_documents(list(texts))\n",
              "            if hasattr(embeddings, \"tolist\"):\n",
              "                embeddings = embeddings.tolist()\n",
              "        elif self._embeddings_function is not None:\n",
              "            embeddings = []\n",
              "            for text in texts:\n",
              "                embedding = self._embeddings_function(text)\n",
              "                if hasattr(embeddings, \"tolist\"):\n",
              "                    embedding = embedding.tolist()\n",
              "                embeddings.append(embedding)\n",
              "        else:\n",
              "            raise ValueError(\"Neither of embeddings or embedding_function is set\")\n",
              "        return embeddings\n",
              "    async def _aembed_texts(self, texts: Iterable[str]) -> List[List[float]]:\n",
              "        \"\"\"Embed search texts.\n",
              "        Used to provide backward compatibility with `embedding_function` argument.\n",
              "        Args:\n",
              "            texts: Iterable of texts to embed.\n",
              "        Returns:\n",
              "            List of floats representing the texts embedding.\n",
              "        \"\"\"\n",
              "        if self.embeddings is not None:\n",
              "            embeddings = await self.embeddings.aembed_documents(list(texts))\n",
              "            if hasattr(embeddings, \"tolist\"):\n",
              "                embeddings = embeddings.tolist()\n",
              "        elif self._embeddings_function is not None:\n",
              "            embeddings = []\n",
              "            for text in texts:\n",
              "                embedding = self._embeddings_function(text)\n",
              "                if hasattr(embeddings, \"tolist\"):\n",
              "                    embedding = embedding.tolist()\n",
              "                embeddings.append(embedding)\n",
              "        else:\n",
              "            raise ValueError(\"Neither of embeddings or embedding_function is set\")\n",
              "        return embeddings\n",
              "    def _generate_rest_batches(\n",
              "        self,\n",
              "        texts: Iterable[str],\n",
              "        metadatas: Optional[List[dict]] = None,\n",
              "        ids: Optional[Sequence[str]] = None,\n",
              "        batch_size: int = 64,\n",
              "    ) -> Generator[Tuple[List[str], List[rest.PointStruct]], None, None]:\n",
              "        from qdrant_client.http import models as rest\n",
              "        texts_iterator = iter(texts)\n",
              "        metadatas_iterator = iter(metadatas or [])\n",
              "        ids_iterator = iter(ids or [uuid.uuid4().hex for _ in iter(texts)])\n",
              "        while batch_texts := list(islice(texts_iterator, batch_size)):\n",
              "            # Take the corresponding metadata and id for each text in a batch\n",
              "            batch_metadatas = list(islice(metadatas_iterator, batch_size)) or None\n",
              "            batch_ids = list(islice(ids_iterator, batch_size))\n",
              "            # Generate the embeddings for all the texts in a batch\n",
              "            batch_embeddings = self._embed_texts(batch_texts)\n",
              "            points = [\n",
              "                rest.PointStruct(\n",
              "                    id=point_id,\n",
              "                    vector=vector\n",
              "                    if self.vector_name is None\n",
              "                    else {self.vector_name: vector},\n",
              "                    payload=payload,\n",
              "                )\n",
              "                for point_id, vector, payload in zip(\n",
              "                    batch_ids,\n",
              "                    batch_embeddings,\n",
              "                    self._build_payloads(\n",
              "                        batch_texts,\n",
              "                        batch_metadatas,\n",
              "                        self.content_payload_key,\n",
              "                        self.metadata_payload_key,\n",
              "                    ),\n",
              "                )\n",
              "            ]\n",
              "            yield batch_ids, points\n",
              "    async def _agenerate_rest_batches(\n",
              "        self,\n",
              "        texts: Iterable[str],\n",
              "        metadatas: Optional[List[dict]] = None,\n",
              "        ids: Optional[Sequence[str]] = None,\n",
              "        batch_size: int = 64,\n",
              "    ) -> AsyncGenerator[Tuple[List[str], List[rest.PointStruct]], None]:\n",
              "        from qdrant_client.http import models as rest\n",
              "        texts_iterator = iter(texts)\n",
              "        metadatas_iterator = iter(metadatas or [])\n",
              "        ids_iterator = iter(ids or [uuid.uuid4().hex for _ in iter(texts)])\n",
              "        while batch_texts := list(islice(texts_iterator, batch_size)):\n",
              "            # Take the corresponding metadata and id for each text in a batch\n",
              "            batch_metadatas = list(islice(metadatas_iterator, batch_size)) or None\n",
              "            batch_ids = list(islice(ids_iterator, batch_size))\n",
              "            # Generate the embeddings for all the texts in a batch\n",
              "            batch_embeddings = await self._aembed_texts(batch_texts)\n",
              "            points = [\n",
              "                rest.PointStruct(\n",
              "                    id=point_id,\n",
              "                    vector=vector\n",
              "                    if self.vector_name is None\n",
              "                    else {self.vector_name: vector},\n",
              "                    payload=payload,\n",
              "                )\n",
              "                for point_id, vector, payload in zip(\n",
              "                    batch_ids,\n",
              "                    batch_embeddings,\n",
              "                    self._build_payloads(\n",
              "                        batch_texts,\n",
              "                        batch_metadatas,\n",
              "                        self.content_payload_key,\n",
              "                        self.metadata_payload_key,\n",
              "                    ),\n",
              "                )\n",
              "            ]\n",
              "            yield batch_ids, points\n",
              "    @staticmethod\n",
              "    def _generate_clients(\n",
              "        location: Optional[str] = None,\n",
              "        url: Optional[str] = None,\n",
              "        port: Optional[int] = 6333,\n",
              "        grpc_port: int = 6334,\n",
              "        prefer_grpc: bool = False,\n",
              "        https: Optional[bool] = None,\n",
              "        api_key: Optional[str] = None,\n",
              "        prefix: Optional[str] = None,\n",
              "        timeout: Optional[float] = None,\n",
              "        host: Optional[str] = None,\n",
              "        path: Optional[str] = None,\n",
              "        **kwargs: Any,\n",
              "    ) -> Tuple[Any, Any]:\n",
              "        from qdrant_client import AsyncQdrantClient, QdrantClient\n",
              "        sync_client = QdrantClient(\n",
              "            location=location,\n",
              "            url=url,\n",
              "            port=port,\n",
              "            grpc_port=grpc_port,\n",
              "            prefer_grpc=prefer_grpc,\n",
              "            https=https,\n",
              "            api_key=api_key,\n",
              "            prefix=prefix,\n",
              "            timeout=timeout,\n",
              "            host=host,\n",
              "            path=path,\n",
              "            **kwargs,\n",
              "        )\n",
              "        if location == \":memory:\" or path is not None:\n",
              "            # Local Qdrant cannot co-exist with Sync and Async clients\n",
              "            # We fallback to sync operations in this case\n",
              "            async_client = None\n",
              "        else:\n",
              "            async_client = AsyncQdrantClient(\n",
              "                location=location,\n",
              "                url=url,\n",
              "                port=port,\n",
              "                grpc_port=grpc_port,\n",
              "                prefer_grpc=prefer_grpc,\n",
              "                https=https,\n",
              "                api_key=api_key,\n",
              "                prefix=prefix,\n",
              "                timeout=timeout,\n",
              "                host=host,\n",
              "                path=path,\n",
              "                **kwargs,\n",
              "            )\n",
              "        return sync_client, async_client</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[4156]=================</br><pre><code class=\"python\">Source code for sqlalchemy.orm.decl_base\n",
              "# orm/decl_base.py\n",
              "# Copyright (C) 2005-2024 the SQLAlchemy authors and contributors\n",
              "# <see AUTHORS file>\n",
              "#\n",
              "# This module is part of SQLAlchemy and is released under\n",
              "# the MIT License: https://www.opensource.org/licenses/mit-license.php\n",
              "\"\"\"Internal implementation for declarative.\"\"\"\n",
              "from __future__ import annotations\n",
              "import collections\n",
              "import dataclasses\n",
              "import re\n",
              "from typing import Any\n",
              "from typing import Callable\n",
              "from typing import cast\n",
              "from typing import Dict\n",
              "from typing import Iterable\n",
              "from typing import List\n",
              "from typing import Mapping\n",
              "from typing import NamedTuple\n",
              "from typing import NoReturn\n",
              "from typing import Optional\n",
              "from typing import Sequence\n",
              "from typing import Tuple\n",
              "from typing import Type\n",
              "from typing import TYPE_CHECKING\n",
              "from typing import TypeVar\n",
              "from typing import Union\n",
              "import weakref\n",
              "from . import attributes\n",
              "from . import clsregistry\n",
              "from . import exc as orm_exc\n",
              "from . import instrumentation\n",
              "from . import mapperlib\n",
              "from ._typing import _O\n",
              "from ._typing import attr_is_internal_proxy\n",
              "from .attributes import InstrumentedAttribute\n",
              "from .attributes import QueryableAttribute\n",
              "from .base import _is_mapped_class\n",
              "from .base import InspectionAttr\n",
              "from .descriptor_props import CompositeProperty\n",
              "from .descriptor_props import SynonymProperty\n",
              "from .interfaces import _AttributeOptions\n",
              "from .interfaces import _DCAttributeOptions\n",
              "from .interfaces import _IntrospectsAnnotations\n",
              "from .interfaces import _MappedAttribute\n",
              "from .interfaces import _MapsColumns\n",
              "from .interfaces import MapperProperty\n",
              "from .mapper import Mapper\n",
              "from .properties import ColumnProperty\n",
              "from .properties import MappedColumn\n",
              "from .util import _extract_mapped_subtype\n",
              "from .util import _is_mapped_annotation\n",
              "from .util import class_mapper\n",
              "from .util import de_stringify_annotation\n",
              "from .. import event\n",
              "from .. import exc\n",
              "from .. import util\n",
              "from ..sql import expression\n",
              "from ..sql.base import _NoArg\n",
              "from ..sql.schema import Column\n",
              "from ..sql.schema import Table\n",
              "from ..util import topological\n",
              "from ..util.typing import _AnnotationScanType\n",
              "from ..util.typing import is_fwd_ref\n",
              "from ..util.typing import is_literal\n",
              "from ..util.typing import Protocol\n",
              "from ..util.typing import TypedDict\n",
              "from ..util.typing import typing_get_args\n",
              "if TYPE_CHECKING:\n",
              "    from ._typing import _ClassDict\n",
              "    from ._typing import _RegistryType\n",
              "    from .base import Mapped\n",
              "    from .decl_api import declared_attr\n",
              "    from .instrumentation import ClassManager\n",
              "    from ..sql.elements import NamedColumn\n",
              "    from ..sql.schema import MetaData\n",
              "    from ..sql.selectable import FromClause\n",
              "_T = TypeVar(\"_T\", bound=Any)\n",
              "_MapperKwArgs = Mapping[str, Any]\n",
              "_TableArgsType = Union[Tuple[Any, ...], Dict[str, Any]]\n",
              "class MappedClassProtocol(Protocol[_O]):\n",
              "    \"\"\"A protocol representing a SQLAlchemy mapped class.\n",
              "    The protocol is generic on the type of class, use\n",
              "    ``MappedClassProtocol[Any]`` to allow any mapped class.\n",
              "    \"\"\"\n",
              "    __name__: str\n",
              "    __mapper__: Mapper[_O]\n",
              "    __table__: FromClause\n",
              "    def __call__(self, **kw: Any) -> _O: ...\n",
              "class _DeclMappedClassProtocol(MappedClassProtocol[_O], Protocol):\n",
              "    \"Internal more detailed version of ``MappedClassProtocol``.\"\n",
              "    metadata: MetaData\n",
              "    __tablename__: str\n",
              "    __mapper_args__: _MapperKwArgs\n",
              "    __table_args__: Optional[_TableArgsType]\n",
              "    _sa_apply_dc_transforms: Optional[_DataclassArguments]\n",
              "    def __declare_first__(self) -> None: ...\n",
              "    def __declare_last__(self) -> None: ...\n",
              "class _DataclassArguments(TypedDict):\n",
              "    init: Union[_NoArg, bool]\n",
              "    repr: Union[_NoArg, bool]\n",
              "    eq: Union[_NoArg, bool]\n",
              "    order: Union[_NoArg, bool]\n",
              "    unsafe_hash: Union[_NoArg, bool]\n",
              "    match_args: Union[_NoArg, bool]\n",
              "    kw_only: Union[_NoArg, bool]\n",
              "    dataclass_callable: Union[_NoArg, Callable[..., Type[Any]]]\n",
              "def _declared_mapping_info(\n",
              "    cls: Type[Any],\n",
              ") -> Optional[Union[_DeferredMapperConfig, Mapper[Any]]]:\n",
              "    # deferred mapping\n",
              "    if _DeferredMapperConfig.has_cls(cls):\n",
              "        return _DeferredMapperConfig.config_for_cls(cls)\n",
              "    # regular mapping\n",
              "    elif _is_mapped_class(cls):\n",
              "        return class_mapper(cls, configure=False)\n",
              "    else:\n",
              "        return None\n",
              "def _is_supercls_for_inherits(cls: Type[Any]) -> bool:\n",
              "    \"\"\"return True if this class will be used as a superclass to set in\n",
              "    'inherits'.\n",
              "    This includes deferred mapper configs that aren't mapped yet, however does\n",
              "    not include classes with _sa_decl_prepare_nocascade (e.g.\n",
              "    ``AbstractConcreteBase``); these concrete-only classes are not set up as\n",
              "    \"inherits\" until after mappers are configured using\n",
              "    mapper._set_concrete_base()\n",
              "    \"\"\"\n",
              "    if _DeferredMapperConfig.has_cls(cls):\n",
              "        return not _get_immediate_cls_attr(\n",
              "            cls, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        )\n",
              "    # regular mapping\n",
              "    elif _is_mapped_class(cls):\n",
              "        return True\n",
              "    else:\n",
              "        return False\n",
              "def _resolve_for_abstract_or_classical(cls: Type[Any]) -> Optional[Type[Any]]:\n",
              "    if cls is object:\n",
              "        return None\n",
              "    sup: Optional[Type[Any]]\n",
              "    if cls.__dict__.get(\"__abstract__\", False):\n",
              "        for base_ in cls.__bases__:\n",
              "            sup = _resolve_for_abstract_or_classical(base_)\n",
              "            if sup is not None:\n",
              "                return sup\n",
              "        else:\n",
              "            return None\n",
              "    else:\n",
              "        clsmanager = _dive_for_cls_manager(cls)\n",
              "        if clsmanager:\n",
              "            return clsmanager.class_\n",
              "        else:\n",
              "            return cls\n",
              "def _get_immediate_cls_attr(\n",
              "    cls: Type[Any], attrname: str, strict: bool = False\n",
              ") -> Optional[Any]:\n",
              "    \"\"\"return an attribute of the class that is either present directly\n",
              "    on the class, e.g. not on a superclass, or is from a superclass but\n",
              "    this superclass is a non-mapped mixin, that is, not a descendant of\n",
              "    the declarative base and is also not classically mapped.\n",
              "    This is used to detect attributes that indicate something about\n",
              "    a mapped class independently from any mapped classes that it may\n",
              "    inherit from.\n",
              "    \"\"\"\n",
              "    # the rules are different for this name than others,\n",
              "    # make sure we've moved it out.  transitional\n",
              "    assert attrname != \"__abstract__\"\n",
              "    if not issubclass(cls, object):\n",
              "        return None\n",
              "    if attrname in cls.__dict__:\n",
              "        return getattr(cls, attrname)\n",
              "    for base in cls.__mro__[1:]:\n",
              "        _is_classical_inherits = _dive_for_cls_manager(base) is not None\n",
              "        if attrname in base.__dict__ and (\n",
              "            base is cls\n",
              "            or (\n",
              "                (base in cls.__bases__ if strict else True)\n",
              "                and not _is_classical_inherits\n",
              "            )\n",
              "        ):\n",
              "            return getattr(base, attrname)\n",
              "    else:\n",
              "        return None\n",
              "def _dive_for_cls_manager(cls: Type[_O]) -> Optional[ClassManager[_O]]:\n",
              "    # because the class manager registration is pluggable,\n",
              "    # we need to do the search for every class in the hierarchy,\n",
              "    # rather than just a simple \"cls._sa_class_manager\"\n",
              "    for base in cls.__mro__:\n",
              "        manager: Optional[ClassManager[_O]] = attributes.opt_manager_of_class(\n",
              "            base\n",
              "        )\n",
              "        if manager:\n",
              "            return manager\n",
              "    return None\n",
              "def _as_declarative(\n",
              "    registry: _RegistryType, cls: Type[Any], dict_: _ClassDict\n",
              ") -> Optional[_MapperConfig]:\n",
              "    # declarative scans the class for attributes.  no table or mapper\n",
              "    # args passed separately.\n",
              "    return _MapperConfig.setup_mapping(registry, cls, dict_, None, {})\n",
              "def _mapper(\n",
              "    registry: _RegistryType,\n",
              "    cls: Type[_O],\n",
              "    table: Optional[FromClause],\n",
              "    mapper_kw: _MapperKwArgs,\n",
              ") -> Mapper[_O]:\n",
              "    _ImperativeMapperConfig(registry, cls, table, mapper_kw)\n",
              "    return cast(\"MappedClassProtocol[_O]\", cls).__mapper__\n",
              "@util.preload_module(\"sqlalchemy.orm.decl_api\")\n",
              "def _is_declarative_props(obj: Any) -> bool:\n",
              "    _declared_attr_common = util.preloaded.orm_decl_api._declared_attr_common\n",
              "    return isinstance(obj, (_declared_attr_common, util.classproperty))\n",
              "def _check_declared_props_nocascade(\n",
              "    obj: Any, name: str, cls: Type[_O]\n",
              ") -> bool:\n",
              "    if _is_declarative_props(obj):\n",
              "        if getattr(obj, \"_cascading\", False):\n",
              "            util.warn(\n",
              "                \"@declared_attr.cascading is not supported on the %s \"\n",
              "                \"attribute on class %s.  This attribute invokes for \"\n",
              "                \"subclasses in any case.\" % (name, cls)\n",
              "            )\n",
              "        return True\n",
              "    else:\n",
              "        return False\n",
              "class _MapperConfig:\n",
              "    __slots__ = (\n",
              "        \"cls\",\n",
              "        \"classname\",\n",
              "        \"properties\",\n",
              "        \"declared_attr_reg\",\n",
              "        \"__weakref__\",\n",
              "    )\n",
              "    cls: Type[Any]\n",
              "    classname: str\n",
              "    properties: util.OrderedDict[\n",
              "        str,\n",
              "        Union[\n",
              "            Sequence[NamedColumn[Any]], NamedColumn[Any], MapperProperty[Any]\n",
              "        ],\n",
              "    ]\n",
              "    declared_attr_reg: Dict[declared_attr[Any], Any]\n",
              "    @classmethod\n",
              "    def setup_mapping(\n",
              "        cls,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        dict_: _ClassDict,\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ) -> Optional[_MapperConfig]:\n",
              "        manager = attributes.opt_manager_of_class(cls)\n",
              "        if manager and manager.class_ is cls_:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Class {cls!r} already has been instrumented declaratively\"\n",
              "            )\n",
              "        if cls_.__dict__.get(\"__abstract__\", False):\n",
              "            return None\n",
              "        defer_map = _get_immediate_cls_attr(\n",
              "            cls_, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        ) or hasattr(cls_, \"_sa_decl_prepare\")\n",
              "        if defer_map:\n",
              "            return _DeferredMapperConfig(\n",
              "                registry, cls_, dict_, table, mapper_kw\n",
              "            )\n",
              "        else:\n",
              "            return _ClassScanMapperConfig(\n",
              "                registry, cls_, dict_, table, mapper_kw\n",
              "            )\n",
              "    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[Any],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        self.cls = util.assert_arg_type(cls_, type, \"cls_\")\n",
              "        self.classname = cls_.__name__\n",
              "        self.properties = util.OrderedDict()\n",
              "        self.declared_attr_reg = {}\n",
              "        if not mapper_kw.get(\"non_primary\", False):\n",
              "            instrumentation.register_class(\n",
              "                self.cls,\n",
              "                finalize=False,\n",
              "                registry=registry,\n",
              "                declarative_scan=self,\n",
              "                init_method=registry.constructor,\n",
              "            )\n",
              "        else:\n",
              "            manager = attributes.opt_manager_of_class(self.cls)\n",
              "            if not manager or not manager.is_mapped:\n",
              "                raise exc.InvalidRequestError(\n",
              "                    \"Class %s has no primary mapper configured.  Configure \"\n",
              "                    \"a primary mapper first before setting up a non primary \"\n",
              "                    \"Mapper.\" % self.cls\n",
              "                )\n",
              "    def set_cls_attribute(self, attrname: str, value: _T) -> _T:\n",
              "        manager = instrumentation.manager_of_class(self.cls)\n",
              "        manager.install_member(attrname, value)\n",
              "        return value\n",
              "    def map(self, mapper_kw: _MapperKwArgs = ...) -> Mapper[Any]:\n",
              "        raise NotImplementedError()\n",
              "    def _early_mapping(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        self.map(mapper_kw)\n",
              "class _ImperativeMapperConfig(_MapperConfig):\n",
              "    __slots__ = (\"local_table\", \"inherits\")\n",
              "    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        super().__init__(registry, cls_, mapper_kw)\n",
              "        self.local_table = self.set_cls_attribute(\"__table__\", table)\n",
              "        with mapperlib._CONFIGURE_MUTEX:\n",
              "            if not mapper_kw.get(\"non_primary\", False):\n",
              "                clsregistry.add_class(\n",
              "                    self.classname, self.cls, registry._class_registry\n",
              "                )\n",
              "            self._setup_inheritance(mapper_kw)\n",
              "            self._early_mapping(mapper_kw)\n",
              "    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        mapper_cls = Mapper\n",
              "        return self.set_cls_attribute(\n",
              "            \"__mapper__\",\n",
              "            mapper_cls(self.cls, self.local_table, **mapper_kw),\n",
              "        )\n",
              "    def _setup_inheritance(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        cls = self.cls\n",
              "        inherits = mapper_kw.get(\"inherits\", None)\n",
              "        if inherits is None:\n",
              "            # since we search for classical mappings now, search for\n",
              "            # multiple mapped bases as well and raise an error.\n",
              "            inherits_search = []\n",
              "            for base_ in cls.__bases__:\n",
              "                c = _resolve_for_abstract_or_classical(base_)\n",
              "                if c is None:\n",
              "                    continue\n",
              "                if _is_supercls_for_inherits(c) and c not in inherits_search:\n",
              "                    inherits_search.append(c)\n",
              "            if inherits_search:\n",
              "                if len(inherits_search) > 1:\n",
              "                    raise exc.InvalidRequestError(\n",
              "                        \"Class %s has multiple mapped bases: %r\"\n",
              "                        % (cls, inherits_search)\n",
              "                    )\n",
              "                inherits = inherits_search[0]\n",
              "        elif isinstance(inherits, Mapper):\n",
              "            inherits = inherits.class_\n",
              "        self.inherits = inherits\n",
              "class _CollectedAnnotation(NamedTuple):\n",
              "    raw_annotation: _AnnotationScanType\n",
              "    mapped_container: Optional[Type[Mapped[Any]]]\n",
              "    extracted_mapped_annotation: Union[Type[Any], str]\n",
              "    is_dataclass: bool\n",
              "    attr_value: Any\n",
              "    originating_module: str\n",
              "    originating_class: Type[Any]\n",
              "class _ClassScanMapperConfig(_MapperConfig):\n",
              "    __slots__ = (\n",
              "        \"registry\",\n",
              "        \"clsdict_view\",\n",
              "        \"collected_attributes\",\n",
              "        \"collected_annotations\",\n",
              "        \"local_table\",\n",
              "        \"persist_selectable\",\n",
              "        \"declared_columns\",\n",
              "        \"column_ordering\",\n",
              "        \"column_copies\",\n",
              "        \"table_args\",\n",
              "        \"tablename\",\n",
              "        \"mapper_args\",\n",
              "        \"mapper_args_fn\",\n",
              "        \"inherits\",\n",
              "        \"single\",\n",
              "        \"allow_dataclass_fields\",\n",
              "        \"dataclass_setup_arguments\",\n",
              "        \"is_dataclass_prior_to_mapping\",\n",
              "        \"allow_unmapped_annotations\",\n",
              "    )\n",
              "    is_deferred = False\n",
              "    registry: _RegistryType\n",
              "    clsdict_view: _ClassDict\n",
              "    collected_annotations: Dict[str, _CollectedAnnotation]\n",
              "    collected_attributes: Dict[str, Any]\n",
              "    local_table: Optional[FromClause]\n",
              "    persist_selectable: Optional[FromClause]\n",
              "    declared_columns: util.OrderedSet[Column[Any]]\n",
              "    column_ordering: Dict[Column[Any], int]\n",
              "    column_copies: Dict[\n",
              "        Union[MappedColumn[Any], Column[Any]],\n",
              "        Union[MappedColumn[Any], Column[Any]],\n",
              "    ]\n",
              "    tablename: Optional[str]\n",
              "    mapper_args: Mapping[str, Any]\n",
              "    table_args: Optional[_TableArgsType]\n",
              "    mapper_args_fn: Optional[Callable[[], Dict[str, Any]]]\n",
              "    inherits: Optional[Type[Any]]\n",
              "    single: bool\n",
              "    is_dataclass_prior_to_mapping: bool\n",
              "    allow_unmapped_annotations: bool\n",
              "    dataclass_setup_arguments: Optional[_DataclassArguments]\n",
              "    \"\"\"if the class has SQLAlchemy native dataclass parameters, where\n",
              "    we will turn the class into a dataclass within the declarative mapping\n",
              "    process.\n",
              "    \"\"\"\n",
              "    allow_dataclass_fields: bool\n",
              "    \"\"\"if true, look for dataclass-processed Field objects on the target\n",
              "    class as well as superclasses and extract ORM mapping directives from\n",
              "    the \"metadata\" attribute of each Field.\n",
              "    if False, dataclass fields can still be used, however they won't be\n",
              "    mapped.\n",
              "    \"\"\"\n",
              "    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        dict_: _ClassDict,\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        # grab class dict before the instrumentation manager has been added.\n",
              "        # reduces cycles\n",
              "        self.clsdict_view = (\n",
              "            util.immutabledict(dict_) if dict_ else util.EMPTY_DICT\n",
              "        )\n",
              "        super().__init__(registry, cls_, mapper_kw)\n",
              "        self.registry = registry\n",
              "        self.persist_selectable = None\n",
              "        self.collected_attributes = {}\n",
              "        self.collected_annotations = {}\n",
              "        self.declared_columns = util.OrderedSet()\n",
              "        self.column_ordering = {}\n",
              "        self.column_copies = {}\n",
              "        self.single = False\n",
              "        self.dataclass_setup_arguments = dca = getattr(\n",
              "            self.cls, \"_sa_apply_dc_transforms\", None\n",
              "        )\n",
              "        self.allow_unmapped_annotations = getattr(\n",
              "            self.cls, \"__allow_unmapped__\", False\n",
              "        ) or bool(self.dataclass_setup_arguments)\n",
              "        self.is_dataclass_prior_to_mapping = cld = dataclasses.is_dataclass(\n",
              "            cls_\n",
              "        )\n",
              "        sdk = _get_immediate_cls_attr(cls_, \"__sa_dataclass_metadata_key__\")\n",
              "        # we don't want to consume Field objects from a not-already-dataclass.\n",
              "        # the Field objects won't have their \"name\" or \"type\" populated,\n",
              "        # and while it seems like we could just set these on Field as we\n",
              "        # read them, Field is documented as \"user read only\" and we need to\n",
              "        # stay far away from any off-label use of dataclasses APIs.\n",
              "        if (not cld or dca) and sdk:\n",
              "            raise exc.InvalidRequestError(\n",
              "                \"SQLAlchemy mapped dataclasses can't consume mapping \"\n",
              "                \"information from dataclass.Field() objects if the immediate \"\n",
              "                \"class is not already a dataclass.\"\n",
              "            )\n",
              "        # if already a dataclass, and __sa_dataclass_metadata_key__ present,\n",
              "        # then also look inside of dataclass.Field() objects yielded by\n",
              "        # dataclasses.get_fields(cls) when scanning for attributes\n",
              "        self.allow_dataclass_fields = bool(sdk and cld)\n",
              "        self._setup_declared_events()\n",
              "        self._scan_attributes()\n",
              "        self._setup_dataclasses_transforms()\n",
              "        with mapperlib._CONFIGURE_MUTEX:\n",
              "            clsregistry.add_class(\n",
              "                self.classname, self.cls, registry._class_registry\n",
              "            )\n",
              "            self._setup_inheriting_mapper(mapper_kw)\n",
              "            self._extract_mappable_attributes()\n",
              "            self._extract_declared_columns()\n",
              "            self._setup_table(table)\n",
              "            self._setup_inheriting_columns(mapper_kw)\n",
              "            self._early_mapping(mapper_kw)\n",
              "    def _setup_declared_events(self) -> None:\n",
              "        if _get_immediate_cls_attr(self.cls, \"__declare_last__\"):\n",
              "            @event.listens_for(Mapper, \"after_configured\")\n",
              "            def after_configured() -> None:\n",
              "                cast(\n",
              "                    \"_DeclMappedClassProtocol[Any]\", self.cls\n",
              "                ).__declare_last__()\n",
              "        if _get_immediate_cls_attr(self.cls, \"__declare_first__\"):\n",
              "            @event.listens_for(Mapper, \"before_configured\")\n",
              "            def before_configured() -> None:\n",
              "                cast(\n",
              "                    \"_DeclMappedClassProtocol[Any]\", self.cls\n",
              "                ).__declare_first__()\n",
              "    def _cls_attr_override_checker(\n",
              "        self, cls: Type[_O]\n",
              "    ) -> Callable[[str, Any], bool]:\n",
              "        \"\"\"Produce a function that checks if a class has overridden an\n",
              "        attribute, taking SQLAlchemy-enabled dataclass fields into account.\n",
              "        \"\"\"\n",
              "        if self.allow_dataclass_fields:\n",
              "            sa_dataclass_metadata_key = _get_immediate_cls_attr(\n",
              "                cls, \"__sa_dataclass_metadata_key__\"\n",
              "            )\n",
              "        else:\n",
              "            sa_dataclass_metadata_key = None\n",
              "        if not sa_dataclass_metadata_key:\n",
              "            def attribute_is_overridden(key: str, obj: Any) -> bool:\n",
              "                return getattr(cls, key, obj) is not obj\n",
              "        else:\n",
              "            all_datacls_fields = {\n",
              "                f.name: f.metadata[sa_dataclass_metadata_key]\n",
              "                for f in util.dataclass_fields(cls)\n",
              "                if sa_dataclass_metadata_key in f.metadata\n",
              "            }\n",
              "            local_datacls_fields = {\n",
              "                f.name: f.metadata[sa_dataclass_metadata_key]\n",
              "                for f in util.local_dataclass_fields(cls)\n",
              "                if sa_dataclass_metadata_key in f.metadata\n",
              "            }\n",
              "            absent = object()\n",
              "            def attribute_is_overridden(key: str, obj: Any) -> bool:\n",
              "                if _is_declarative_props(obj):\n",
              "                    obj = obj.fget\n",
              "                # this function likely has some failure modes still if\n",
              "                # someone is doing a deep mixing of the same attribute\n",
              "                # name as plain Python attribute vs. dataclass field.\n",
              "                ret = local_datacls_fields.get(key, absent)\n",
              "                if _is_declarative_props(ret):\n",
              "                    ret = ret.fget\n",
              "                if ret is obj:\n",
              "                    return False\n",
              "                elif ret is not absent:\n",
              "                    return True\n",
              "                all_field = all_datacls_fields.get(key, absent)\n",
              "                ret = getattr(cls, key, obj)\n",
              "                if ret is obj:\n",
              "                    return False\n",
              "                # for dataclasses, this could be the\n",
              "                # 'default' of the field.  so filter more specifically\n",
              "                # for an already-mapped InstrumentedAttribute\n",
              "                if ret is not absent and isinstance(\n",
              "                    ret, InstrumentedAttribute\n",
              "                ):\n",
              "                    return True\n",
              "                if all_field is obj:\n",
              "                    return False\n",
              "                elif all_field is not absent:\n",
              "                    return True\n",
              "                # can't find another attribute\n",
              "                return False\n",
              "        return attribute_is_overridden\n",
              "    _include_dunders = {\n",
              "        \"__table__\",\n",
              "        \"__mapper_args__\",\n",
              "        \"__tablename__\",\n",
              "        \"__table_args__\",\n",
              "    }\n",
              "    _match_exclude_dunders = re.compile(r\"^(?:_sa_|__)\")\n",
              "    def _cls_attr_resolver(\n",
              "        self, cls: Type[Any]\n",
              "    ) -> Callable[[], Iterable[Tuple[str, Any, Any, bool]]]:\n",
              "        \"\"\"produce a function to iterate the \"attributes\" of a class\n",
              "        which we want to consider for mapping, adjusting for SQLAlchemy fields\n",
              "        embedded in dataclass fields.\n",
              "        \"\"\"\n",
              "        cls_annotations = util.get_annotations(cls)\n",
              "        cls_vars = vars(cls)\n",
              "        _include_dunders = self._include_dunders\n",
              "        _match_exclude_dunders = self._match_exclude_dunders\n",
              "        names = [\n",
              "            n\n",
              "            for n in util.merge_lists_w_ordering(\n",
              "                list(cls_vars), list(cls_annotations)\n",
              "            )\n",
              "            if not _match_exclude_dunders.match(n) or n in _include_dunders\n",
              "        ]\n",
              "        if self.allow_dataclass_fields:\n",
              "            sa_dataclass_metadata_key: Optional[str] = _get_immediate_cls_attr(\n",
              "                cls, \"__sa_dataclass_metadata_key__\"\n",
              "            )\n",
              "        else:\n",
              "            sa_dataclass_metadata_key = None\n",
              "        if not sa_dataclass_metadata_key:\n",
              "            def local_attributes_for_class() -> (\n",
              "                Iterable[Tuple[str, Any, Any, bool]]\n",
              "            ):\n",
              "                return (\n",
              "                    (\n",
              "                        name,\n",
              "                        cls_vars.get(name),\n",
              "                        cls_annotations.get(name),\n",
              "                        False,\n",
              "                    )\n",
              "                    for name in names\n",
              "                )\n",
              "        else:\n",
              "            dataclass_fields = {\n",
              "                field.name: field for field in util.local_dataclass_fields(cls)\n",
              "            }\n",
              "            fixed_sa_dataclass_metadata_key = sa_dataclass_metadata_key\n",
              "            def local_attributes_for_class() -> (\n",
              "                Iterable[Tuple[str, Any, Any, bool]]\n",
              "            ):\n",
              "                for name in names:\n",
              "                    field = dataclass_fields.get(name, None)\n",
              "                    if field and sa_dataclass_metadata_key in field.metadata:\n",
              "                        yield field.name, _as_dc_declaredattr(\n",
              "                            field.metadata, fixed_sa_dataclass_metadata_key\n",
              "                        ), cls_annotations.get(field.name), True\n",
              "                    else:\n",
              "                        yield name, cls_vars.get(name), cls_annotations.get(\n",
              "                            name\n",
              "                        ), False\n",
              "        return local_attributes_for_class\n",
              "    def _scan_attributes(self) -> None:\n",
              "        cls = self.cls\n",
              "        cls_as_Decl = cast(\"_DeclMappedClassProtocol[Any]\", cls)\n",
              "        clsdict_view = self.clsdict_view\n",
              "        collected_attributes = self.collected_attributes\n",
              "        column_copies = self.column_copies\n",
              "        _include_dunders = self._include_dunders\n",
              "        mapper_args_fn = None\n",
              "        table_args = inherited_table_args = None\n",
              "        tablename = None\n",
              "        fixed_table = \"__table__\" in clsdict_view\n",
              "        attribute_is_overridden = self._cls_attr_override_checker(self.cls)\n",
              "        bases = []\n",
              "        for base in cls.__mro__:\n",
              "            # collect bases and make sure standalone columns are copied\n",
              "            # to be the column they will ultimately be on the class,\n",
              "            # so that declared_attr functions use the right columns.\n",
              "            # need to do this all the way up the hierarchy first\n",
              "            # (see #8190)\n",
              "            class_mapped = base is not cls and _is_supercls_for_inherits(base)\n",
              "            local_attributes_for_class = self._cls_attr_resolver(base)\n",
              "            if not class_mapped and base is not cls:\n",
              "                locally_collected_columns = self._produce_column_copies(\n",
              "                    local_attributes_for_class,\n",
              "                    attribute_is_overridden,\n",
              "                    fixed_table,\n",
              "                    base,\n",
              "                )\n",
              "            else:\n",
              "                locally_collected_columns = {}\n",
              "            bases.append(\n",
              "                (\n",
              "                    base,\n",
              "                    class_mapped,\n",
              "                    local_attributes_for_class,\n",
              "                    locally_collected_columns,\n",
              "                )\n",
              "            )\n",
              "        for (\n",
              "            base,\n",
              "            class_mapped,\n",
              "            local_attributes_for_class,\n",
              "            locally_collected_columns,\n",
              "        ) in bases:\n",
              "            # this transfer can also take place as we scan each name\n",
              "            # for finer-grained control of how collected_attributes is\n",
              "            # populated, as this is what impacts column ordering.\n",
              "            # however it's simpler to get it out of the way here.\n",
              "            collected_attributes.update(locally_collected_columns)\n",
              "            for (\n",
              "                name,\n",
              "                obj,\n",
              "                annotation,\n",
              "                is_dataclass_field,\n",
              "            ) in local_attributes_for_class():\n",
              "                if name in _include_dunders:\n",
              "                    if name == \"__mapper_args__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not mapper_args_fn and (\n",
              "                            not class_mapped or check_decl\n",
              "                        ):\n",
              "                            # don't even invoke __mapper_args__ until\n",
              "                            # after we've determined everything about the\n",
              "                            # mapped table.\n",
              "                            # make a copy of it so a class-level dictionary\n",
              "                            # is not overwritten when we update column-based\n",
              "                            # arguments.\n",
              "                            def _mapper_args_fn() -> Dict[str, Any]:\n",
              "                                return dict(cls_as_Decl.__mapper_args__)\n",
              "                            mapper_args_fn = _mapper_args_fn\n",
              "                    elif name == \"__tablename__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not tablename and (not class_mapped or check_decl):\n",
              "                            tablename = cls_as_Decl.__tablename__\n",
              "                    elif name == \"__table_args__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not table_args and (not class_mapped or check_decl):\n",
              "                            table_args = cls_as_Decl.__table_args__\n",
              "                            if not isinstance(\n",
              "                                table_args, (tuple, dict, type(None))\n",
              "                            ):\n",
              "                                raise exc.ArgumentError(\n",
              "                                    \"__table_args__ value must be a tuple, \"\n",
              "                                    \"dict, or None\"\n",
              "                                )\n",
              "                            if base is not cls:\n",
              "                                inherited_table_args = True\n",
              "                    else:\n",
              "                        # skip all other dunder names, which at the moment\n",
              "                        # should only be __table__\n",
              "                        continue\n",
              "                elif class_mapped:\n",
              "                    if _is_declarative_props(obj) and not obj._quiet:\n",
              "                        util.warn(\n",
              "                            \"Regular (i.e. not __special__) \"\n",
              "                            \"attribute '%s.%s' uses @declared_attr, \"\n",
              "                            \"but owning class %s is mapped - \"\n",
              "                            \"not applying to subclass %s.\"\n",
              "                            % (base.__name__, name, base, cls)\n",
              "                        )\n",
              "                    continue\n",
              "                elif base is not cls:\n",
              "                    # we're a mixin, abstract base, or something that is\n",
              "                    # acting like that for now.\n",
              "                    if isinstance(obj, (Column, MappedColumn)):\n",
              "                        # already copied columns to the mapped class.\n",
              "                        continue\n",
              "                    elif isinstance(obj, MapperProperty):\n",
              "                        raise exc.InvalidRequestError(\n",
              "                            \"Mapper properties (i.e. deferred,\"\n",
              "                            \"column_property(), relationship(), etc.) must \"\n",
              "                            \"be declared as @declared_attr callables \"\n",
              "                            \"on declarative mixin classes.  For dataclass \"\n",
              "                            \"field() objects, use a lambda:\"\n",
              "                        )\n",
              "                    elif _is_declarative_props(obj):\n",
              "                        # tried to get overloads to tell this to\n",
              "                        # pylance, no luck\n",
              "                        assert obj is not None\n",
              "                        if obj._cascading:\n",
              "                            if name in clsdict_view:\n",
              "                                # unfortunately, while we can use the user-\n",
              "                                # defined attribute here to allow a clean\n",
              "                                # override, if there's another\n",
              "                                # subclass below then it still tries to use\n",
              "                                # this.  not sure if there is enough\n",
              "                                # information here to add this as a feature\n",
              "                                # later on.\n",
              "                                util.warn(\n",
              "                                    \"Attribute '%s' on class %s cannot be \"\n",
              "                                    \"processed due to \"\n",
              "                                    \"@declared_attr.cascading; \"\n",
              "                                    \"skipping\" % (name, cls)\n",
              "                                )\n",
              "                            collected_attributes[name] = column_copies[obj] = (\n",
              "                                ret\n",
              "                            ) = obj.__get__(obj, cls)\n",
              "                            setattr(cls, name, ret)\n",
              "                        else:\n",
              "                            if is_dataclass_field:\n",
              "                                # access attribute using normal class access\n",
              "                                # first, to see if it's been mapped on a\n",
              "                                # superclass.   note if the dataclasses.field()\n",
              "                                # has \"default\", this value can be anything.\n",
              "                                ret = getattr(cls, name, None)\n",
              "                                # so, if it's anything that's not ORM\n",
              "                                # mapped, assume we should invoke the\n",
              "                                # declared_attr\n",
              "                                if not isinstance(ret, InspectionAttr):\n",
              "                                    ret = obj.fget()\n",
              "                            else:\n",
              "                                # access attribute using normal class access.\n",
              "                                # if the declared attr already took place\n",
              "                                # on a superclass that is mapped, then\n",
              "                                # this is no longer a declared_attr, it will\n",
              "                                # be the InstrumentedAttribute\n",
              "                                ret = getattr(cls, name)\n",
              "                            # correct for proxies created from hybrid_property\n",
              "                            # or similar.  note there is no known case that\n",
              "                            # produces nested proxies, so we are only\n",
              "                            # looking one level deep right now.\n",
              "                            if (\n",
              "                                isinstance(ret, InspectionAttr)\n",
              "                                and attr_is_internal_proxy(ret)\n",
              "                                and not isinstance(\n",
              "                                    ret.original_property, MapperProperty\n",
              "                                )\n",
              "                            ):\n",
              "                                ret = ret.descriptor\n",
              "                            collected_attributes[name] = column_copies[obj] = (\n",
              "                                ret\n",
              "                            )\n",
              "                        if (\n",
              "                            isinstance(ret, (Column, MapperProperty))\n",
              "                            and ret.doc is None\n",
              "                        ):\n",
              "                            ret.doc = obj.__doc__\n",
              "                        self._collect_annotation(\n",
              "                            name,\n",
              "                            obj._collect_return_annotation(),\n",
              "                            base,\n",
              "                            True,\n",
              "                            obj,\n",
              "                        )\n",
              "                    elif _is_mapped_annotation(annotation, cls, base):\n",
              "                        # Mapped annotation without any object.\n",
              "                        # product_column_copies should have handled this.\n",
              "                        # if future support for other MapperProperty,\n",
              "                        # then test if this name is already handled and\n",
              "                        # otherwise proceed to generate.\n",
              "                        if not fixed_table:\n",
              "                            assert (\n",
              "                                name in collected_attributes\n",
              "                                or attribute_is_overridden(name, None)\n",
              "                            )\n",
              "                        continue\n",
              "                    else:\n",
              "                        # here, the attribute is some other kind of\n",
              "                        # property that we assume is not part of the\n",
              "                        # declarative mapping.  however, check for some\n",
              "                        # more common mistakes\n",
              "                        self._warn_for_decl_attributes(base, name, obj)\n",
              "                elif is_dataclass_field and (\n",
              "                    name not in clsdict_view or clsdict_view[name] is not obj\n",
              "                ):\n",
              "                    # here, we are definitely looking at the target class\n",
              "                    # and not a superclass.   this is currently a\n",
              "                    # dataclass-only path.  if the name is only\n",
              "                    # a dataclass field and isn't in local cls.__dict__,\n",
              "                    # put the object there.\n",
              "                    # assert that the dataclass-enabled resolver agrees\n",
              "                    # with what we are seeing\n",
              "                    assert not attribute_is_overridden(name, obj)\n",
              "                    if _is_declarative_props(obj):\n",
              "                        obj = obj.fget()\n",
              "                    collected_attributes[name] = obj\n",
              "                    self._collect_annotation(\n",
              "                        name, annotation, base, False, obj\n",
              "                    )\n",
              "                else:\n",
              "                    collected_annotation = self._collect_annotation(\n",
              "                        name, annotation, base, None, obj\n",
              "                    )\n",
              "                    is_mapped = (\n",
              "                        collected_annotation is not None\n",
              "                        and collected_annotation.mapped_container is not None\n",
              "                    )\n",
              "                    generated_obj = (\n",
              "                        collected_annotation.attr_value\n",
              "                        if collected_annotation is not None\n",
              "                        else obj\n",
              "                    )\n",
              "                    if obj is None and not fixed_table and is_mapped:\n",
              "                        collected_attributes[name] = (\n",
              "                            generated_obj\n",
              "                            if generated_obj is not None\n",
              "                            else MappedColumn()\n",
              "                        )\n",
              "                    elif name in clsdict_view:\n",
              "                        collected_attributes[name] = obj\n",
              "                    # else if the name is not in the cls.__dict__,\n",
              "                    # don't collect it as an attribute.\n",
              "                    # we will see the annotation only, which is meaningful\n",
              "                    # both for mapping and dataclasses setup\n",
              "        if inherited_table_args and not tablename:\n",
              "            table_args = None\n",
              "        self.table_args = table_args\n",
              "        self.tablename = tablename\n",
              "        self.mapper_args_fn = mapper_args_fn\n",
              "    def _setup_dataclasses_transforms(self) -> None:\n",
              "        dataclass_setup_arguments = self.dataclass_setup_arguments\n",
              "        if not dataclass_setup_arguments:\n",
              "            return\n",
              "        # can't use is_dataclass since it uses hasattr\n",
              "        if \"__dataclass_fields__\" in self.cls.__dict__:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Class {self.cls} is already a dataclass; ensure that \"\n",
              "                \"base classes / decorator styles of establishing dataclasses \"\n",
              "                \"are not being mixed. \"\n",
              "                \"This can happen if a class that inherits from \"\n",
              "                \"'MappedAsDataclass', even indirectly, is been mapped with \"\n",
              "                \"'@registry.mapped_as_dataclass'\"\n",
              "            )\n",
              "        warn_for_non_dc_attrs = collections.defaultdict(list)\n",
              "        def _allow_dataclass_field(\n",
              "            key: str, originating_class: Type[Any]\n",
              "        ) -> bool:\n",
              "            if (\n",
              "                originating_class is not self.cls\n",
              "                and \"__dataclass_fields__\" not in originating_class.__dict__\n",
              "            ):\n",
              "                warn_for_non_dc_attrs[originating_class].append(key)\n",
              "            return True\n",
              "        manager = instrumentation.manager_of_class(self.cls)\n",
              "        assert manager is not None\n",
              "        field_list = [\n",
              "            _AttributeOptions._get_arguments_for_make_dataclass(\n",
              "                key,\n",
              "                anno,\n",
              "                mapped_container,\n",
              "                self.collected_attributes.get(key, _NoArg.NO_ARG),\n",
              "            )\n",
              "            for key, anno, mapped_container in (\n",
              "                (\n",
              "                    key,\n",
              "                    mapped_anno if mapped_anno else raw_anno,\n",
              "                    mapped_container,\n",
              "                )\n",
              "                for key, (\n",
              "                    raw_anno,\n",
              "                    mapped_container,\n",
              "                    mapped_anno,\n",
              "                    is_dc,\n",
              "                    attr_value,\n",
              "                    originating_module,\n",
              "                    originating_class,\n",
              "                ) in self.collected_annotations.items()\n",
              "                if _allow_dataclass_field(key, originating_class)\n",
              "                and (\n",
              "                    key not in self.collected_attributes\n",
              "                    # issue #9226; check for attributes that we've collected\n",
              "                    # which are already instrumented, which we would assume\n",
              "                    # mean we are in an ORM inheritance mapping and this\n",
              "                    # attribute is already mapped on the superclass.   Under\n",
              "                    # no circumstance should any QueryableAttribute be sent to\n",
              "                    # the dataclass() function; anything that's mapped should\n",
              "                    # be Field and that's it\n",
              "                    or not isinstance(\n",
              "                        self.collected_attributes[key], QueryableAttribute\n",
              "                    )\n",
              "                )\n",
              "            )\n",
              "        ]\n",
              "        if warn_for_non_dc_attrs:\n",
              "            for (\n",
              "                originating_class,\n",
              "                non_dc_attrs,\n",
              "            ) in warn_for_non_dc_attrs.items():\n",
              "                util.warn_deprecated(\n",
              "                    f\"When transforming {self.cls} to a dataclass, \"\n",
              "                    f\"attribute(s) \"\n",
              "                    f\"{', '.join(repr(key) for key in non_dc_attrs)} \"\n",
              "                    f\"originates from superclass \"\n",
              "                    f\"{originating_class}, which is not a dataclass.  This \"\n",
              "                    f\"usage is deprecated and will raise an error in \"\n",
              "                    f\"SQLAlchemy 2.1.  When declaring SQLAlchemy Declarative \"\n",
              "                    f\"Dataclasses, ensure that all mixin classes and other \"\n",
              "                    f\"superclasses which include attributes are also a \"\n",
              "                    f\"subclass of MappedAsDataclass.\",\n",
              "                    \"2.0\",\n",
              "                    code=\"dcmx\",\n",
              "                )\n",
              "        annotations = {}\n",
              "        defaults = {}\n",
              "        for item in field_list:\n",
              "            if len(item) == 2:\n",
              "                name, tp = item\n",
              "            elif len(item) == 3:\n",
              "                name, tp, spec = item\n",
              "                defaults[name] = spec\n",
              "            else:\n",
              "                assert False\n",
              "            annotations[name] = tp\n",
              "        for k, v in defaults.items():\n",
              "            setattr(self.cls, k, v)\n",
              "        self._apply_dataclasses_to_any_class(\n",
              "            dataclass_setup_arguments, self.cls, annotations\n",
              "        )\n",
              "    @classmethod\n",
              "    def _update_annotations_for_non_mapped_class(\n",
              "        cls, klass: Type[_O]\n",
              "    ) -> Mapping[str, _AnnotationScanType]:\n",
              "        cls_annotations = util.get_annotations(klass)\n",
              "        new_anno = {}\n",
              "        for name, annotation in cls_annotations.items():\n",
              "            if _is_mapped_annotation(annotation, klass, klass):\n",
              "                extracted = _extract_mapped_subtype(\n",
              "                    annotation,\n",
              "                    klass,\n",
              "                    klass.__module__,\n",
              "                    name,\n",
              "                    type(None),\n",
              "                    required=False,\n",
              "                    is_dataclass_field=False,\n",
              "                    expect_mapped=False,\n",
              "                )\n",
              "                if extracted:\n",
              "                    inner, _ = extracted\n",
              "                    new_anno[name] = inner\n",
              "            else:\n",
              "                new_anno[name] = annotation\n",
              "        return new_anno\n",
              "    @classmethod\n",
              "    def _apply_dataclasses_to_any_class(\n",
              "        cls,\n",
              "        dataclass_setup_arguments: _DataclassArguments,\n",
              "        klass: Type[_O],\n",
              "        use_annotations: Mapping[str, _AnnotationScanType],\n",
              "    ) -> None:\n",
              "        cls._assert_dc_arguments(dataclass_setup_arguments)\n",
              "        dataclass_callable = dataclass_setup_arguments[\"dataclass_callable\"]\n",
              "        if dataclass_callable is _NoArg.NO_ARG:\n",
              "            dataclass_callable = dataclasses.dataclass\n",
              "        restored: Optional[Any]\n",
              "        if use_annotations:\n",
              "            # apply constructed annotations that should look \"normal\" to a\n",
              "            # dataclasses callable, based on the fields present.  This\n",
              "            # means remove the Mapped[] container and ensure all Field\n",
              "            # entries have an annotation\n",
              "            restored = getattr(klass, \"__annotations__\", None)\n",
              "            klass.__annotations__ = cast(\"Dict[str, Any]\", use_annotations)\n",
              "        else:\n",
              "            restored = None\n",
              "        try:\n",
              "            dataclass_callable(\n",
              "                klass,\n",
              "                **{\n",
              "                    k: v\n",
              "                    for k, v in dataclass_setup_arguments.items()\n",
              "                    if v is not _NoArg.NO_ARG and k != \"dataclass_callable\"\n",
              "                },\n",
              "            )\n",
              "        except (TypeError, ValueError) as ex:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Python dataclasses error encountered when creating \"\n",
              "                f\"dataclass for {klass.__name__!r}: \"\n",
              "                f\"{ex!r}. Please refer to Python dataclasses \"\n",
              "                \"documentation for additional information.\",\n",
              "                code=\"dcte\",\n",
              "            ) from ex\n",
              "        finally:\n",
              "            # restore original annotations outside of the dataclasses\n",
              "            # process; for mixins and __abstract__ superclasses, SQLAlchemy\n",
              "            # Declarative will need to see the Mapped[] container inside the\n",
              "            # annotations in order to map subclasses\n",
              "            if use_annotations:\n",
              "                if restored is None:\n",
              "                    del klass.__annotations__\n",
              "                else:\n",
              "                    klass.__annotations__ = restored\n",
              "    @classmethod\n",
              "    def _assert_dc_arguments(cls, arguments: _DataclassArguments) -> None:\n",
              "        allowed = {\n",
              "            \"init\",\n",
              "            \"repr\",\n",
              "            \"order\",\n",
              "            \"eq\",\n",
              "            \"unsafe_hash\",\n",
              "            \"kw_only\",\n",
              "            \"match_args\",\n",
              "            \"dataclass_callable\",\n",
              "        }\n",
              "        disallowed_args = set(arguments).difference(allowed)\n",
              "        if disallowed_args:\n",
              "            msg = \", \".join(f\"{arg!r}\" for arg in sorted(disallowed_args))\n",
              "            raise exc.ArgumentError(\n",
              "                f\"Dataclass argument(s) {msg} are not accepted\"\n",
              "            )\n",
              "    def _collect_annotation(\n",
              "        self,\n",
              "        name: str,\n",
              "        raw_annotation: _AnnotationScanType,\n",
              "        originating_class: Type[Any],\n",
              "        expect_mapped: Optional[bool],\n",
              "        attr_value: Any,\n",
              "    ) -> Optional[_CollectedAnnotation]:\n",
              "        if name in self.collected_annotations:\n",
              "            return self.collected_annotations[name]\n",
              "        if raw_annotation is None:\n",
              "            return None\n",
              "        is_dataclass = self.is_dataclass_prior_to_mapping\n",
              "        allow_unmapped = self.allow_unmapped_annotations\n",
              "        if expect_mapped is None:\n",
              "            is_dataclass_field = isinstance(attr_value, dataclasses.Field)\n",
              "            expect_mapped = (\n",
              "                not is_dataclass_field\n",
              "                and not allow_unmapped\n",
              "                and (\n",
              "                    attr_value is None\n",
              "                    or isinstance(attr_value, _MappedAttribute)\n",
              "                )\n",
              "            )\n",
              "        else:\n",
              "            is_dataclass_field = False\n",
              "        is_dataclass_field = False\n",
              "        extracted = _extract_mapped_subtype(\n",
              "            raw_annotation,\n",
              "            self.cls,\n",
              "            originating_class.__module__,\n",
              "            name,\n",
              "            type(attr_value),\n",
              "            required=False,\n",
              "            is_dataclass_field=is_dataclass_field,\n",
              "            expect_mapped=expect_mapped\n",
              "            and not is_dataclass,  # self.allow_dataclass_fields,\n",
              "        )\n",
              "        if extracted is None:\n",
              "            # ClassVar can come out here\n",
              "            return None\n",
              "        extracted_mapped_annotation, mapped_container = extracted\n",
              "        if attr_value is None and not is_literal(extracted_mapped_annotation):\n",
              "            for elem in typing_get_args(extracted_mapped_annotation):\n",
              "                if isinstance(elem, str) or is_fwd_ref(\n",
              "                    elem, check_generic=True\n",
              "                ):\n",
              "                    elem = de_stringify_annotation(\n",
              "                        self.cls,\n",
              "                        elem,\n",
              "                        originating_class.__module__,\n",
              "                        include_generic=True,\n",
              "                    )\n",
              "                # look in Annotated[...] for an ORM construct,\n",
              "                # such as Annotated[int, mapped_column(primary_key=True)]\n",
              "                if isinstance(elem, _IntrospectsAnnotations):\n",
              "                    attr_value = elem.found_in_pep593_annotated()\n",
              "        self.collected_annotations[name] = ca = _CollectedAnnotation(\n",
              "            raw_annotation,\n",
              "            mapped_container,\n",
              "            extracted_mapped_annotation,\n",
              "            is_dataclass,\n",
              "            attr_value,\n",
              "            originating_class.__module__,\n",
              "            originating_class,\n",
              "        )\n",
              "        return ca\n",
              "    def _warn_for_decl_attributes(\n",
              "        self, cls: Type[Any], key: str, c: Any\n",
              "    ) -> None:\n",
              "        if isinstance(c, expression.ColumnElement):\n",
              "            util.warn(\n",
              "                f\"Attribute '{key}' on class {cls} appears to \"\n",
              "                \"be a non-schema SQLAlchemy expression \"\n",
              "                \"object; this won't be part of the declarative mapping. \"\n",
              "                \"To map arbitrary expressions, use ``column_property()`` \"\n",
              "                \"or a similar function such as ``deferred()``, \"\n",
              "                \"``query_expression()`` etc. \"\n",
              "            )\n",
              "    def _produce_column_copies(\n",
              "        self,\n",
              "        attributes_for_class: Callable[\n",
              "            [], Iterable[Tuple[str, Any, Any, bool]]\n",
              "        ],\n",
              "        attribute_is_overridden: Callable[[str, Any], bool],\n",
              "        fixed_table: bool,\n",
              "        originating_class: Type[Any],\n",
              "    ) -> Dict[str, Union[Column[Any], MappedColumn[Any]]]:\n",
              "        cls = self.cls\n",
              "        dict_ = self.clsdict_view\n",
              "        locally_collected_attributes = {}\n",
              "        column_copies = self.column_copies\n",
              "        # copy mixin columns to the mapped class\n",
              "        for name, obj, annotation, is_dataclass in attributes_for_class():\n",
              "            if (\n",
              "                not fixed_table\n",
              "                and obj is None\n",
              "                and _is_mapped_annotation(annotation, cls, originating_class)\n",
              "            ):\n",
              "                # obj is None means this is the annotation only path\n",
              "                if attribute_is_overridden(name, obj):\n",
              "                    # perform same \"overridden\" check as we do for\n",
              "                    # Column/MappedColumn, this is how a mixin col is not\n",
              "                    # applied to an inherited subclass that does not have\n",
              "                    # the mixin.   the anno-only path added here for\n",
              "                    # #9564\n",
              "                    continue\n",
              "                collected_annotation = self._collect_annotation(\n",
              "                    name, annotation, originating_class, True, obj\n",
              "                )\n",
              "                obj = (\n",
              "                    collected_annotation.attr_value\n",
              "                    if collected_annotation is not None\n",
              "                    else obj\n",
              "                )\n",
              "                if obj is None:\n",
              "                    obj = MappedColumn()\n",
              "                locally_collected_attributes[name] = obj\n",
              "                setattr(cls, name, obj)\n",
              "            elif isinstance(obj, (Column, MappedColumn)):\n",
              "                if attribute_is_overridden(name, obj):\n",
              "                    # if column has been overridden\n",
              "                    # (like by the InstrumentedAttribute of the\n",
              "                    # superclass), skip.  don't collect the annotation\n",
              "                    # either (issue #8718)\n",
              "                    continue\n",
              "                collected_annotation = self._collect_annotation(\n",
              "                    name, annotation, originating_class, True, obj\n",
              "                )\n",
              "                obj = (\n",
              "                    collected_annotation.attr_value\n",
              "                    if collected_annotation is not None\n",
              "                    else obj\n",
              "                )\n",
              "                if name not in dict_ and not (\n",
              "                    \"__table__\" in dict_\n",
              "                    and (getattr(obj, \"name\", None) or name)\n",
              "                    in dict_[\"__table__\"].c\n",
              "                ):\n",
              "                    if obj.foreign_keys:\n",
              "                        for fk in obj.foreign_keys:\n",
              "                            if (\n",
              "                                fk._table_column is not None\n",
              "                                and fk._table_column.table is None\n",
              "                            ):\n",
              "                                raise exc.InvalidRequestError(\n",
              "                                    \"Columns with foreign keys to \"\n",
              "                                    \"non-table-bound \"\n",
              "                                    \"columns must be declared as \"\n",
              "                                    \"@declared_attr callables \"\n",
              "                                    \"on declarative mixin classes.  \"\n",
              "                                    \"For dataclass \"\n",
              "                                    \"field() objects, use a lambda:.\"\n",
              "                                )\n",
              "                    column_copies[obj] = copy_ = obj._copy()\n",
              "                    locally_collected_attributes[name] = copy_\n",
              "                    setattr(cls, name, copy_)\n",
              "        return locally_collected_attributes\n",
              "    def _extract_mappable_attributes(self) -> None:\n",
              "        cls = self.cls\n",
              "        collected_attributes = self.collected_attributes\n",
              "        our_stuff = self.properties\n",
              "        _include_dunders = self._include_dunders\n",
              "        late_mapped = _get_immediate_cls_attr(\n",
              "            cls, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        )\n",
              "        allow_unmapped_annotations = self.allow_unmapped_annotations\n",
              "        expect_annotations_wo_mapped = (\n",
              "            allow_unmapped_annotations or self.is_dataclass_prior_to_mapping\n",
              "        )\n",
              "        look_for_dataclass_things = bool(self.dataclass_setup_arguments)\n",
              "        for k in list(collected_attributes):\n",
              "            if k in _include_dunders:\n",
              "                continue\n",
              "            value = collected_attributes[k]\n",
              "            if _is_declarative_props(value):\n",
              "                # @declared_attr in collected_attributes only occurs here for a\n",
              "                # @declared_attr that's directly on the mapped class;\n",
              "                # for a mixin, these have already been evaluated\n",
              "                if value._cascading:\n",
              "                    util.warn(\n",
              "                        \"Use of @declared_attr.cascading only applies to \"\n",
              "                        \"Declarative 'mixin' and 'abstract' classes.  \"\n",
              "                        \"Currently, this flag is ignored on mapped class \"\n",
              "                        \"%s\" % self.cls\n",
              "                    )\n",
              "                value = getattr(cls, k)\n",
              "            elif (\n",
              "                isinstance(value, QueryableAttribute)\n",
              "                and value.class_ is not cls\n",
              "                and value.key != k\n",
              "            ):\n",
              "                # detect a QueryableAttribute that's already mapped being\n",
              "                # assigned elsewhere in userland, turn into a synonym()\n",
              "                value = SynonymProperty(value.key)\n",
              "                setattr(cls, k, value)\n",
              "            if (\n",
              "                isinstance(value, tuple)\n",
              "                and len(value) == 1\n",
              "                and isinstance(value[0], (Column, _MappedAttribute))\n",
              "            ):\n",
              "                util.warn(\n",
              "                    \"Ignoring declarative-like tuple value of attribute \"\n",
              "                    \"'%s': possibly a copy-and-paste error with a comma \"\n",
              "                    \"accidentally placed at the end of the line?\" % k\n",
              "                )\n",
              "                continue\n",
              "            elif look_for_dataclass_things and isinstance(\n",
              "                value, dataclasses.Field\n",
              "            ):\n",
              "                # we collected a dataclass Field; dataclasses would have\n",
              "                # set up the correct state on the class\n",
              "                continue\n",
              "            elif not isinstance(value, (Column, _DCAttributeOptions)):\n",
              "                # using @declared_attr for some object that\n",
              "                # isn't Column/MapperProperty/_DCAttributeOptions; remove\n",
              "                # from the clsdict_view\n",
              "                # and place the evaluated value onto the class.\n",
              "                collected_attributes.pop(k)\n",
              "                self._warn_for_decl_attributes(cls, k, value)\n",
              "                if not late_mapped:\n",
              "                    setattr(cls, k, value)\n",
              "                continue\n",
              "            # we expect to see the name 'metadata' in some valid cases;\n",
              "            # however at this point we see it's assigned to something trying\n",
              "            # to be mapped, so raise for that.\n",
              "            # TODO: should \"registry\" here be also?   might be too late\n",
              "            # to change that now (2.0 betas)\n",
              "            elif k in (\"metadata\",):\n",
              "                raise exc.InvalidRequestError(\n",
              "                    f\"Attribute name '{k}' is reserved when using the \"\n",
              "                    \"Declarative API.\"\n",
              "                )\n",
              "            elif isinstance(value, Column):\n",
              "                _undefer_column_name(\n",
              "                    k, self.column_copies.get(value, value)  # type: ignore\n",
              "                )\n",
              "            else:\n",
              "                if isinstance(value, _IntrospectsAnnotations):\n",
              "                    (\n",
              "                        annotation,\n",
              "                        mapped_container,\n",
              "                        extracted_mapped_annotation,\n",
              "                        is_dataclass,\n",
              "                        attr_value,\n",
              "                        originating_module,\n",
              "                        originating_class,\n",
              "                    ) = self.collected_annotations.get(\n",
              "                        k, (None, None, None, False, None, None, None)\n",
              "                    )\n",
              "                    # issue #8692 - don't do any annotation interpretation if\n",
              "                    # an annotation were present and a container such as\n",
              "                    # Mapped[] etc. were not used.  If annotation is None,\n",
              "                    # do declarative_scan so that the property can raise\n",
              "                    # for required\n",
              "                    if (\n",
              "                        mapped_container is not None\n",
              "                        or annotation is None\n",
              "                        # issue #10516: need to do declarative_scan even with\n",
              "                        # a non-Mapped annotation if we are doing\n",
              "                        # __allow_unmapped__, for things like col.name\n",
              "                        # assignment\n",
              "                        or allow_unmapped_annotations\n",
              "                    ):\n",
              "                        try:\n",
              "                            value.declarative_scan(\n",
              "                                self,\n",
              "                                self.registry,\n",
              "                                cls,\n",
              "                                originating_module,\n",
              "                                k,\n",
              "                                mapped_container,\n",
              "                                annotation,\n",
              "                                extracted_mapped_annotation,\n",
              "                                is_dataclass,\n",
              "                            )\n",
              "                        except NameError as ne:\n",
              "                            raise exc.ArgumentError(\n",
              "                                f\"Could not resolve all types within mapped \"\n",
              "                                f'annotation: \"{annotation}\".  Ensure all '\n",
              "                                f\"types are written correctly and are \"\n",
              "                                f\"imported within the module in use.\"\n",
              "                            ) from ne\n",
              "                    else:\n",
              "                        # assert that we were expecting annotations\n",
              "                        # without Mapped[] were going to be passed.\n",
              "                        # otherwise an error should have been raised\n",
              "                        # by util._extract_mapped_subtype before we got here.\n",
              "                        assert expect_annotations_wo_mapped\n",
              "                if isinstance(value, _DCAttributeOptions):\n",
              "                    if (\n",
              "                        value._has_dataclass_arguments\n",
              "                        and not look_for_dataclass_things\n",
              "                    ):\n",
              "                        if isinstance(value, MapperProperty):\n",
              "                            argnames = [\n",
              "                                \"init\",\n",
              "                                \"default_factory\",\n",
              "                                \"repr\",\n",
              "                                \"default\",\n",
              "                            ]\n",
              "                        else:\n",
              "                            argnames = [\"init\", \"default_factory\", \"repr\"]\n",
              "                        args = {\n",
              "                            a\n",
              "                            for a in argnames\n",
              "                            if getattr(\n",
              "                                value._attribute_options, f\"dataclasses_{a}\"\n",
              "                            )\n",
              "                            is not _NoArg.NO_ARG\n",
              "                        }\n",
              "                        raise exc.ArgumentError(\n",
              "                            f\"Attribute '{k}' on class {cls} includes \"\n",
              "                            f\"dataclasses argument(s): \"\n",
              "                            f\"{', '.join(sorted(repr(a) for a in args))} but \"\n",
              "                            f\"class does not specify \"\n",
              "                            \"SQLAlchemy native dataclass configuration.\"\n",
              "                        )\n",
              "                    if not isinstance(value, (MapperProperty, _MapsColumns)):\n",
              "                        # filter for _DCAttributeOptions objects that aren't\n",
              "                        # MapperProperty / mapped_column().  Currently this\n",
              "                        # includes AssociationProxy.   pop it from the things\n",
              "                        # we're going to map and set it up as a descriptor\n",
              "                        # on the class.\n",
              "                        collected_attributes.pop(k)\n",
              "                        # Assoc Prox (or other descriptor object that may\n",
              "                        # use _DCAttributeOptions) is usually here, except if\n",
              "                        # 1. we're a\n",
              "                        # dataclass, dataclasses would have removed the\n",
              "                        # attr here or 2. assoc proxy is coming from a\n",
              "                        # superclass, we want it to be direct here so it\n",
              "                        # tracks state or 3. assoc prox comes from\n",
              "                        # declared_attr, uncommon case\n",
              "                        setattr(cls, k, value)\n",
              "                        continue\n",
              "            our_stuff[k] = value\n",
              "    def _extract_declared_columns(self) -> None:\n",
              "        our_stuff = self.properties\n",
              "        # extract columns from the class dict\n",
              "        declared_columns = self.declared_columns\n",
              "        column_ordering = self.column_ordering\n",
              "        name_to_prop_key = collections.defaultdict(set)\n",
              "        for key, c in list(our_stuff.items()):\n",
              "            if isinstance(c, _MapsColumns):\n",
              "                mp_to_assign = c.mapper_property_to_assign\n",
              "                if mp_to_assign:\n",
              "                    our_stuff[key] = mp_to_assign\n",
              "                else:\n",
              "                    # if no mapper property to assign, this currently means\n",
              "                    # this is a MappedColumn that will produce a Column for us\n",
              "                    del our_stuff[key]\n",
              "                for col, sort_order in c.columns_to_assign:\n",
              "                    if not isinstance(c, CompositeProperty):\n",
              "                        name_to_prop_key[col.name].add(key)\n",
              "                    declared_columns.add(col)\n",
              "                    # we would assert this, however we want the below\n",
              "                    # warning to take effect instead.  See #9630\n",
              "                    # assert col not in column_ordering\n",
              "                    column_ordering[col] = sort_order\n",
              "                    # if this is a MappedColumn and the attribute key we\n",
              "                    # have is not what the column has for its key, map the\n",
              "                    # Column explicitly under the attribute key name.\n",
              "                    # otherwise, Mapper will map it under the column key.\n",
              "                    if mp_to_assign is None and key != col.key:\n",
              "                        our_stuff[key] = col\n",
              "            elif isinstance(c, Column):\n",
              "                # undefer previously occurred here, and now occurs earlier.\n",
              "                # ensure every column we get here has been named\n",
              "                assert c.name is not None\n",
              "                name_to_prop_key[c.name].add(key)\n",
              "                declared_columns.add(c)\n",
              "                # if the column is the same name as the key,\n",
              "                # remove it from the explicit properties dict.\n",
              "                # the normal rules for assigning column-based properties\n",
              "                # will take over, including precedence of columns\n",
              "                # in multi-column ColumnProperties.\n",
              "                if key == c.key:\n",
              "                    del our_stuff[key]\n",
              "        for name, keys in name_to_prop_key.items():\n",
              "            if len(keys) > 1:\n",
              "                util.warn(\n",
              "                    \"On class %r, Column object %r named \"\n",
              "                    \"directly multiple times, \"\n",
              "                    \"only one will be used: %s. \"\n",
              "                    \"Consider using orm.synonym instead\"\n",
              "                    % (self.classname, name, (\", \".join(sorted(keys))))\n",
              "                )\n",
              "    def _setup_table(self, table: Optional[FromClause] = None) -> None:\n",
              "        cls = self.cls\n",
              "        cls_as_Decl = cast(\"MappedClassProtocol[Any]\", cls)\n",
              "        tablename = self.tablename\n",
              "        table_args = self.table_args\n",
              "        clsdict_view = self.clsdict_view\n",
              "        declared_columns = self.declared_columns\n",
              "        column_ordering = self.column_ordering\n",
              "        manager = attributes.manager_of_class(cls)\n",
              "        if \"__table__\" not in clsdict_view and table is None:\n",
              "            if hasattr(cls, \"__table_cls__\"):\n",
              "                table_cls = cast(\n",
              "                    Type[Table],\n",
              "                    util.unbound_method_to_callable(cls.__table_cls__),  # type: ignore  # noqa: E501\n",
              "                )\n",
              "            else:\n",
              "                table_cls = Table\n",
              "            if tablename is not None:\n",
              "                args: Tuple[Any, ...] = ()\n",
              "                table_kw: Dict[str, Any] = {}\n",
              "                if table_args:\n",
              "                    if isinstance(table_args, dict):\n",
              "                        table_kw = table_args\n",
              "                    elif isinstance(table_args, tuple):\n",
              "                        if isinstance(table_args[-1], dict):\n",
              "                            args, table_kw = table_args[0:-1], table_args[-1]\n",
              "                        else:\n",
              "                            args = table_args\n",
              "                autoload_with = clsdict_view.get(\"__autoload_with__\")\n",
              "                if autoload_with:\n",
              "                    table_kw[\"autoload_with\"] = autoload_with\n",
              "                autoload = clsdict_view.get(\"__autoload__\")\n",
              "                if autoload:\n",
              "                    table_kw[\"autoload\"] = True\n",
              "                sorted_columns = sorted(\n",
              "                    declared_columns,\n",
              "                    key=lambda c: column_ordering.get(c, 0),\n",
              "                )\n",
              "                table = self.set_cls_attribute(\n",
              "                    \"__table__\",\n",
              "                    table_cls(\n",
              "                        tablename,\n",
              "                        self._metadata_for_cls(manager),\n",
              "                        *sorted_columns,\n",
              "                        *args,\n",
              "                        **table_kw,\n",
              "                    ),\n",
              "                )\n",
              "        else:\n",
              "            if table is None:\n",
              "                table = cls_as_Decl.__table__\n",
              "            if declared_columns:\n",
              "                for c in declared_columns:\n",
              "                    if not table.c.contains_column(c):\n",
              "                        raise exc.ArgumentError(\n",
              "                            \"Can't add additional column %r when \"\n",
              "                            \"specifying __table__\" % c.key\n",
              "                        )\n",
              "        self.local_table = table\n",
              "    def _metadata_for_cls(self, manager: ClassManager[Any]) -> MetaData:\n",
              "        meta: Optional[MetaData] = getattr(self.cls, \"metadata\", None)\n",
              "        if meta is not None:\n",
              "            return meta\n",
              "        else:\n",
              "            return manager.registry.metadata\n",
              "    def _setup_inheriting_mapper(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        cls = self.cls\n",
              "        inherits = mapper_kw.get(\"inherits\", None)\n",
              "        if inherits is None:\n",
              "            # since we search for classical mappings now, search for\n",
              "            # multiple mapped bases as well and raise an error.\n",
              "            inherits_search = []\n",
              "            for base_ in cls.__bases__:\n",
              "                c = _resolve_for_abstract_or_classical(base_)\n",
              "                if c is None:\n",
              "                    continue\n",
              "                if _is_supercls_for_inherits(c) and c not in inherits_search:\n",
              "                    inherits_search.append(c)\n",
              "            if inherits_search:\n",
              "                if len(inherits_search) > 1:\n",
              "                    raise exc.InvalidRequestError(\n",
              "                        \"Class %s has multiple mapped bases: %r\"\n",
              "                        % (cls, inherits_search)\n",
              "                    )\n",
              "                inherits = inherits_search[0]\n",
              "        elif isinstance(inherits, Mapper):\n",
              "            inherits = inherits.class_\n",
              "        self.inherits = inherits\n",
              "        clsdict_view = self.clsdict_view\n",
              "        if \"__table__\" not in clsdict_view and self.tablename is None:\n",
              "            self.single = True\n",
              "    def _setup_inheriting_columns(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        table = self.local_table\n",
              "        cls = self.cls\n",
              "        table_args = self.table_args\n",
              "        declared_columns = self.declared_columns\n",
              "        if (\n",
              "            table is None\n",
              "            and self.inherits is None\n",
              "            and not _get_immediate_cls_attr(cls, \"__no_table__\")\n",
              "        ):\n",
              "            raise exc.InvalidRequestError(\n",
              "                \"Class %r does not have a __table__ or __tablename__ \"\n",
              "                \"specified and does not inherit from an existing \"\n",
              "                \"table-mapped class.\" % cls\n",
              "            )\n",
              "        elif self.inherits:\n",
              "            inherited_mapper_or_config = _declared_mapping_info(self.inherits)\n",
              "            assert inherited_mapper_or_config is not None\n",
              "            inherited_table = inherited_mapper_or_config.local_table\n",
              "            inherited_persist_selectable = (\n",
              "                inherited_mapper_or_config.persist_selectable\n",
              "            )\n",
              "            if table is None:\n",
              "                # single table inheritance.\n",
              "                # ensure no table args\n",
              "                if table_args:\n",
              "                    raise exc.ArgumentError(\n",
              "                        \"Can't place __table_args__ on an inherited class \"\n",
              "                        \"with no table.\"\n",
              "                    )\n",
              "                # add any columns declared here to the inherited table.\n",
              "                if declared_columns and not isinstance(inherited_table, Table):\n",
              "                    raise exc.ArgumentError(\n",
              "                        f\"Can't declare columns on single-table-inherited \"\n",
              "                        f\"subclass {self.cls}; superclass {self.inherits} \"\n",
              "                        \"is not mapped to a Table\"\n",
              "                    )\n",
              "                for col in declared_columns:\n",
              "                    assert inherited_table is not None\n",
              "                    if col.name in inherited_table.c:\n",
              "                        if inherited_table.c[col.name] is col:\n",
              "                            continue\n",
              "                        raise exc.ArgumentError(\n",
              "                            f\"Column '{col}' on class {cls.__name__} \"\n",
              "                            f\"conflicts with existing column \"\n",
              "                            f\"'{inherited_table.c[col.name]}'.  If using \"\n",
              "                            f\"Declarative, consider using the \"\n",
              "                            \"use_existing_column parameter of mapped_column() \"\n",
              "                            \"to resolve conflicts.\"\n",
              "                        )\n",
              "                    if col.primary_key:\n",
              "                        raise exc.ArgumentError(\n",
              "                            \"Can't place primary key columns on an inherited \"\n",
              "                            \"class with no table.\"\n",
              "                        )\n",
              "                    if TYPE_CHECKING:\n",
              "                        assert isinstance(inherited_table, Table)\n",
              "                    inherited_table.append_column(col)\n",
              "                    if (\n",
              "                        inherited_persist_selectable is not None\n",
              "                        and inherited_persist_selectable is not inherited_table\n",
              "                    ):\n",
              "                        inherited_persist_selectable._refresh_for_new_column(\n",
              "                            col\n",
              "                        )\n",
              "    def _prepare_mapper_arguments(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        properties = self.properties\n",
              "        if self.mapper_args_fn:\n",
              "            mapper_args = self.mapper_args_fn()\n",
              "        else:\n",
              "            mapper_args = {}\n",
              "        if mapper_kw:\n",
              "            mapper_args.update(mapper_kw)\n",
              "        if \"properties\" in mapper_args:\n",
              "            properties = dict(properties)\n",
              "            properties.update(mapper_args[\"properties\"])\n",
              "        # make sure that column copies are used rather\n",
              "        # than the original columns from any mixins\n",
              "        for k in (\"version_id_col\", \"polymorphic_on\"):\n",
              "            if k in mapper_args:\n",
              "                v = mapper_args[k]\n",
              "                mapper_args[k] = self.column_copies.get(v, v)\n",
              "        if \"primary_key\" in mapper_args:\n",
              "            mapper_args[\"primary_key\"] = [\n",
              "                self.column_copies.get(v, v)\n",
              "                for v in util.to_list(mapper_args[\"primary_key\"])\n",
              "            ]\n",
              "        if \"inherits\" in mapper_args:\n",
              "            inherits_arg = mapper_args[\"inherits\"]\n",
              "            if isinstance(inherits_arg, Mapper):\n",
              "                inherits_arg = inherits_arg.class_\n",
              "            if inherits_arg is not self.inherits:\n",
              "                raise exc.InvalidRequestError(\n",
              "                    \"mapper inherits argument given for non-inheriting \"\n",
              "                    \"class %s\" % (mapper_args[\"inherits\"])\n",
              "                )\n",
              "        if self.inherits:\n",
              "            mapper_args[\"inherits\"] = self.inherits\n",
              "        if self.inherits and not mapper_args.get(\"concrete\", False):\n",
              "            # note the superclass is expected to have a Mapper assigned and\n",
              "            # not be a deferred config, as this is called within map()\n",
              "            inherited_mapper = class_mapper(self.inherits, False)\n",
              "            inherited_table = inherited_mapper.local_table\n",
              "            # single or joined inheritance\n",
              "            # exclude any cols on the inherited table which are\n",
              "            # not mapped on the parent class, to avoid\n",
              "            # mapping columns specific to sibling/nephew classes\n",
              "            if \"exclude_properties\" not in mapper_args:\n",
              "                mapper_args[\"exclude_properties\"] = exclude_properties = {\n",
              "                    c.key\n",
              "                    for c in inherited_table.c\n",
              "                    if c not in inherited_mapper._columntoproperty\n",
              "                }.union(inherited_mapper.exclude_properties or ())\n",
              "                exclude_properties.difference_update(\n",
              "                    [c.key for c in self.declared_columns]\n",
              "                )\n",
              "            # look through columns in the current mapper that\n",
              "            # are keyed to a propname different than the colname\n",
              "            # (if names were the same, we'd have popped it out above,\n",
              "            # in which case the mapper makes this combination).\n",
              "            # See if the superclass has a similar column property.\n",
              "            # If so, join them together.\n",
              "            for k, col in list(properties.items()):\n",
              "                if not isinstance(col, expression.ColumnElement):\n",
              "                    continue\n",
              "                if k in inherited_mapper._props:\n",
              "                    p = inherited_mapper._props[k]\n",
              "                    if isinstance(p, ColumnProperty):\n",
              "                        # note here we place the subclass column\n",
              "                        # first.  See [ticket:1892] for background.\n",
              "                        properties[k] = [col] + p.columns\n",
              "        result_mapper_args = mapper_args.copy()\n",
              "        result_mapper_args[\"properties\"] = properties\n",
              "        self.mapper_args = result_mapper_args\n",
              "    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        self._prepare_mapper_arguments(mapper_kw)\n",
              "        if hasattr(self.cls, \"__mapper_cls__\"):\n",
              "            mapper_cls = cast(\n",
              "                \"Type[Mapper[Any]]\",\n",
              "                util.unbound_method_to_callable(\n",
              "                    self.cls.__mapper_cls__  # type: ignore\n",
              "                ),\n",
              "            )\n",
              "        else:\n",
              "            mapper_cls = Mapper\n",
              "        return self.set_cls_attribute(\n",
              "            \"__mapper__\",\n",
              "            mapper_cls(self.cls, self.local_table, **self.mapper_args),\n",
              "        )\n",
              "@util.preload_module(\"sqlalchemy.orm.decl_api\")\n",
              "def _as_dc_declaredattr(\n",
              "    field_metadata: Mapping[str, Any], sa_dataclass_metadata_key: str\n",
              ") -> Any:\n",
              "    # wrap lambdas inside dataclass fields inside an ad-hoc declared_attr.\n",
              "    # we can't write it because field.metadata is immutable :( so we have\n",
              "    # to go through extra trouble to compare these\n",
              "    decl_api = util.preloaded.orm_decl_api\n",
              "    obj = field_metadata[sa_dataclass_metadata_key]\n",
              "    if callable(obj) and not isinstance(obj, decl_api.declared_attr):\n",
              "        return decl_api.declared_attr(obj)\n",
              "    else:\n",
              "        return obj\n",
              "class _DeferredMapperConfig(_ClassScanMapperConfig):\n",
              "    _cls: weakref.ref[Type[Any]]\n",
              "    is_deferred = True\n",
              "    _configs: util.OrderedDict[\n",
              "        weakref.ref[Type[Any]], _DeferredMapperConfig\n",
              "    ] = util.OrderedDict()\n",
              "    def _early_mapping(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        pass\n",
              "    # mypy disallows plain property override of variable\n",
              "    @property  # type: ignore\n",
              "    def cls(self) -> Type[Any]:\n",
              "        return self._cls()  # type: ignore\n",
              "    @cls.setter\n",
              "    def cls(self, class_: Type[Any]) -> None:\n",
              "        self._cls = weakref.ref(class_, self._remove_config_cls)\n",
              "        self._configs[self._cls] = self\n",
              "    @classmethod\n",
              "    def _remove_config_cls(cls, ref: weakref.ref[Type[Any]]) -> None:\n",
              "        cls._configs.pop(ref, None)\n",
              "    @classmethod\n",
              "    def has_cls(cls, class_: Type[Any]) -> bool:\n",
              "        # 2.6 fails on weakref if class_ is an old style class\n",
              "        return isinstance(class_, type) and weakref.ref(class_) in cls._configs\n",
              "    @classmethod\n",
              "    def raise_unmapped_for_cls(cls, class_: Type[Any]) -> NoReturn:\n",
              "        if hasattr(class_, \"_sa_raise_deferred_config\"):\n",
              "            class_._sa_raise_deferred_config()\n",
              "        raise orm_exc.UnmappedClassError(\n",
              "            class_,\n",
              "            msg=(\n",
              "                f\"Class {orm_exc._safe_cls_name(class_)} has a deferred \"\n",
              "                \"mapping on it.  It is not yet usable as a mapped class.\"\n",
              "            ),\n",
              "        )\n",
              "    @classmethod\n",
              "    def config_for_cls(cls, class_: Type[Any]) -> _DeferredMapperConfig:\n",
              "        return cls._configs[weakref.ref(class_)]\n",
              "    @classmethod\n",
              "    def classes_for_base(\n",
              "        cls, base_cls: Type[Any], sort: bool = True\n",
              "    ) -> List[_DeferredMapperConfig]:\n",
              "        classes_for_base = [\n",
              "            m\n",
              "            for m, cls_ in [(m, m.cls) for m in cls._configs.values()]\n",
              "            if cls_ is not None and issubclass(cls_, base_cls)\n",
              "        ]\n",
              "        if not sort:\n",
              "            return classes_for_base\n",
              "        all_m_by_cls = {m.cls: m for m in classes_for_base}\n",
              "        tuples: List[Tuple[_DeferredMapperConfig, _DeferredMapperConfig]] = []\n",
              "        for m_cls in all_m_by_cls:\n",
              "            tuples.extend(\n",
              "                (all_m_by_cls[base_cls], all_m_by_cls[m_cls])\n",
              "                for base_cls in m_cls.__bases__\n",
              "                if base_cls in all_m_by_cls\n",
              "            )\n",
              "        return list(topological.sort(tuples, classes_for_base))\n",
              "    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        self._configs.pop(self._cls, None)\n",
              "        return super().map(mapper_kw)\n",
              "def _add_attribute(\n",
              "    cls: Type[Any], key: str, value: MapperProperty[Any]\n",
              ") -> None:\n",
              "    \"\"\"add an attribute to an existing declarative class.\n",
              "    This runs through the logic to determine MapperProperty,\n",
              "    adds it to the Mapper, adds a column to the mapped Table, etc.\n",
              "    \"\"\"\n",
              "    if \"__mapper__\" in cls.__dict__:\n",
              "        mapped_cls = cast(\"MappedClassProtocol[Any]\", cls)\n",
              "        def _table_or_raise(mc: MappedClassProtocol[Any]) -> Table:\n",
              "            if isinstance(mc.__table__, Table):\n",
              "                return mc.__table__\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Cannot add a new attribute to mapped class {mc.__name__!r} \"\n",
              "                \"because it's not mapped against a table.\"\n",
              "            )\n",
              "        if isinstance(value, Column):\n",
              "            _undefer_column_name(key, value)\n",
              "            _table_or_raise(mapped_cls).append_column(\n",
              "                value, replace_existing=True\n",
              "            )\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        elif isinstance(value, _MapsColumns):\n",
              "            mp = value.mapper_property_to_assign\n",
              "            for col, _ in value.columns_to_assign:\n",
              "                _undefer_column_name(key, col)\n",
              "                _table_or_raise(mapped_cls).append_column(\n",
              "                    col, replace_existing=True\n",
              "                )\n",
              "                if not mp:\n",
              "                    mapped_cls.__mapper__.add_property(key, col)\n",
              "            if mp:\n",
              "                mapped_cls.__mapper__.add_property(key, mp)\n",
              "        elif isinstance(value, MapperProperty):\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        elif isinstance(value, QueryableAttribute) and value.key != key:\n",
              "            # detect a QueryableAttribute that's already mapped being\n",
              "            # assigned elsewhere in userland, turn into a synonym()\n",
              "            value = SynonymProperty(value.key)\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        else:\n",
              "            type.__setattr__(cls, key, value)\n",
              "            mapped_cls.__mapper__._expire_memoizations()\n",
              "    else:\n",
              "        type.__setattr__(cls, key, value)\n",
              "def _del_attribute(cls: Type[Any], key: str) -> None:\n",
              "    if (\n",
              "        \"__mapper__\" in cls.__dict__\n",
              "        and key in cls.__dict__\n",
              "        and not cast(\n",
              "            \"MappedClassProtocol[Any]\", cls\n",
              "        ).__mapper__._dispose_called\n",
              "    ):\n",
              "        value = cls.__dict__[key]\n",
              "        if isinstance(\n",
              "            value, (Column, _MapsColumns, MapperProperty, QueryableAttribute)\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"Can't un-map individual mapped attributes on a mapped class.\"\n",
              "            )\n",
              "        else:\n",
              "            type.__delattr__(cls, key)\n",
              "            cast(\n",
              "                \"MappedClassProtocol[Any]\", cls\n",
              "            ).__mapper__._expire_memoizations()\n",
              "    else:\n",
              "        type.__delattr__(cls, key)\n",
              "def _declarative_constructor(self: Any, **kwargs: Any) -> None:\n",
              "    \"\"\"A simple constructor that allows initialization from kwargs.\n",
              "    Sets attributes on the constructed instance using the names and\n",
              "    values in ``kwargs``.\n",
              "    Only keys that are present as\n",
              "    attributes of the instance's class are allowed. These could be,\n",
              "    for example, any mapped columns or relationships.\n",
              "    \"\"\"\n",
              "    cls_ = type(self)\n",
              "    for k in kwargs:\n",
              "        if not hasattr(cls_, k):\n",
              "            raise TypeError(\n",
              "                \"%r is an invalid keyword argument for %s\" % (k, cls_.__name__)\n",
              "            )\n",
              "        setattr(self, k, kwargs[k])\n",
              "_declarative_constructor.__name__ = \"__init__\"\n",
              "def _undefer_column_name(key: str, column: Column[Any]) -> None:\n",
              "    if column.key is None:\n",
              "        column.key = key\n",
              "    if column.name is None:\n",
              "        column.name = key</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "выводы по базе знаний:\n",
        "1.можно удалить маленькие чанки с текстом [Deprecated] т.к. они содержат по одному устаревшему методу. но таких немного.\n",
        "2.чанки содержат код питон, функции небольшие, поэтому стоит разделить информацию на довольно маленькие кусочки порядка 700 токенов, чтобы поиском можно было возвращать побольше разнообразных релевантных кусочков, где упоминается тема запроса, - так на вход чатжпт попадет больше информации по использованию интересующего метода библиотеки."
      ],
      "metadata": {
        "id": "8Pr6dFIcMSCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# функция, добавляющая разделители перед классами,декораторами или перед объявлением функции\n",
        "# для повышения цельносвязности разбитых на части чанков\n",
        "def prepchunktosplit(chunktext):\n",
        "    lines = chunktext.split('\\n')\n",
        "    new_lines = []\n",
        "    inside_decorator = False\n",
        "    decorator_added = False  # Флаг для отслеживания, был ли добавлен маркер перед декораторами\n",
        "\n",
        "    for line in lines:\n",
        "        if re.match(r'^\\s*@', line):\n",
        "            if not decorator_added:\n",
        "                new_lines.append('##--##' + line)\n",
        "                decorator_added = True\n",
        "            else:\n",
        "                new_lines.append(line)\n",
        "            inside_decorator = True\n",
        "        elif re.match(r'^\\s*class\\s', line):\n",
        "            new_lines.append('##--##' + line)\n",
        "            inside_decorator = False\n",
        "            decorator_added = False\n",
        "        elif re.match(r'^\\s*def\\s', line):\n",
        "            if not inside_decorator:\n",
        "                new_lines.append('##--##' + line)\n",
        "            else:\n",
        "                new_lines.append(line)\n",
        "            inside_decorator = False\n",
        "            decorator_added = False  # Сброс флага после завершения блока декораторов\n",
        "        else:\n",
        "            new_lines.append(line)\n",
        "            if not re.match(r'^\\s*$', line):  # Если строка не пуста\n",
        "                inside_decorator = False\n",
        "                decorator_added = False  # Сброс флага если строка не продолжает блок декораторов\n",
        "\n",
        "    return '\\n'.join(new_lines)\n",
        "\n",
        "# Пример использования\n",
        "text = \"\"\"\n",
        "self.table_args = table_args\n",
        "self.tablename = tablename\n",
        "self.mapper_args_fn = mapper_args_fn\n",
        "@classmethod1\n",
        "@classmethod\n",
        "def _update_annotations_for_non_mapped_class(\n",
        "        cls, klass: Type[_O]\n",
        "    ) -> Mapping....\n",
        ")\n",
        "warn_for_non_dc_attrs = collections.defaultdict(list)\n",
        "def _allow_dataclass_field(\n",
        "    key: str, originating_class: Type[Any]\n",
        ") -> bool....\n",
        "class MyClass:\n",
        "    def my_method(self):\n",
        "        pass\n",
        "\"\"\"\n",
        "\n",
        "print(prepchunktosplit(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0OVWgFNot-b",
        "outputId": "ff45ac2f-5000-453d-9b65-e4d2f19d85a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "self.table_args = table_args\n",
            "self.tablename = tablename\n",
            "self.mapper_args_fn = mapper_args_fn\n",
            "##--##@classmethod1\n",
            "@classmethod\n",
            "def _update_annotations_for_non_mapped_class(\n",
            "        cls, klass: Type[_O]\n",
            "    ) -> Mapping....\n",
            ")\n",
            "warn_for_non_dc_attrs = collections.defaultdict(list)\n",
            "##--##def _allow_dataclass_field(\n",
            "    key: str, originating_class: Type[Any]\n",
            ") -> bool....\n",
            "##--##class MyClass:\n",
            "##--##    def my_method(self):\n",
            "        pass\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# еще функция для разметки перед делением\n",
        "# специальное подготовка чанков, чтобы делить крупные чанки на цельносвязные фрагменты\n",
        "def prepchunktosplit2(chunktext):\n",
        "    def replace_header1(match):\n",
        "        # Возвращаем строку \"Return type\" и следующую за ней строку с добавлением \"###\"\n",
        "        return f\"{match.group(1)}{match.group(2)}##--##\"\n",
        "\n",
        "\n",
        "    # Используем регулярное выражение для поиска \"Return type\" в начале строки и следующей за ней строки,\n",
        "    # которая является типом возврата\n",
        "    # Заменяем найденную строку с добавлением \"##--##\" чтобы делить на чанки в таких местах,\n",
        "    # чтобы повысить целостность фрагментов кода при делении на чанки\n",
        "\n",
        "    text = re.sub(r'^(Return type\\n)(.*)', replace_header1, chunktext, flags=re.MULTILINE)\n",
        "    return text\n",
        "# в основном имеется такая структура текста - описание различных функций\n",
        "text = \"\"\"\n",
        "ххххххх......\n",
        "Parameters\n",
        "value (Any) –\n",
        "Return type\n",
        "Model\n",
        "\"\"\"\n",
        "print(prepchunktosplit2(text))"
      ],
      "metadata": {
        "id": "hzisQ6nDUWXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7796ffd0-e883-4d9f-ca26-fe3f1995adb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ххххххх......\n",
            "Parameters\n",
            "value (Any) –\n",
            "Return type\n",
            "Model##--##\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=prepchunktosplit(docs[4156].page_content)\n",
        "text=prepchunktosplit2(text)\n",
        "display(HTML(wrap(text,4156)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EsvS98o3mPcc",
        "outputId": "86d29f4e-9c0c-4ae3-8ef4-c43f08ee003f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>=================startchunk[4156]=================</br><pre><code class=\"python\">Source code for sqlalchemy.orm.decl_base\n",
              "# orm/decl_base.py\n",
              "# Copyright (C) 2005-2024 the SQLAlchemy authors and contributors\n",
              "# <see AUTHORS file>\n",
              "#\n",
              "# This module is part of SQLAlchemy and is released under\n",
              "# the MIT License: https://www.opensource.org/licenses/mit-license.php\n",
              "\"\"\"Internal implementation for declarative.\"\"\"\n",
              "from __future__ import annotations\n",
              "import collections\n",
              "import dataclasses\n",
              "import re\n",
              "from typing import Any\n",
              "from typing import Callable\n",
              "from typing import cast\n",
              "from typing import Dict\n",
              "from typing import Iterable\n",
              "from typing import List\n",
              "from typing import Mapping\n",
              "from typing import NamedTuple\n",
              "from typing import NoReturn\n",
              "from typing import Optional\n",
              "from typing import Sequence\n",
              "from typing import Tuple\n",
              "from typing import Type\n",
              "from typing import TYPE_CHECKING\n",
              "from typing import TypeVar\n",
              "from typing import Union\n",
              "import weakref\n",
              "from . import attributes\n",
              "from . import clsregistry\n",
              "from . import exc as orm_exc\n",
              "from . import instrumentation\n",
              "from . import mapperlib\n",
              "from ._typing import _O\n",
              "from ._typing import attr_is_internal_proxy\n",
              "from .attributes import InstrumentedAttribute\n",
              "from .attributes import QueryableAttribute\n",
              "from .base import _is_mapped_class\n",
              "from .base import InspectionAttr\n",
              "from .descriptor_props import CompositeProperty\n",
              "from .descriptor_props import SynonymProperty\n",
              "from .interfaces import _AttributeOptions\n",
              "from .interfaces import _DCAttributeOptions\n",
              "from .interfaces import _IntrospectsAnnotations\n",
              "from .interfaces import _MappedAttribute\n",
              "from .interfaces import _MapsColumns\n",
              "from .interfaces import MapperProperty\n",
              "from .mapper import Mapper\n",
              "from .properties import ColumnProperty\n",
              "from .properties import MappedColumn\n",
              "from .util import _extract_mapped_subtype\n",
              "from .util import _is_mapped_annotation\n",
              "from .util import class_mapper\n",
              "from .util import de_stringify_annotation\n",
              "from .. import event\n",
              "from .. import exc\n",
              "from .. import util\n",
              "from ..sql import expression\n",
              "from ..sql.base import _NoArg\n",
              "from ..sql.schema import Column\n",
              "from ..sql.schema import Table\n",
              "from ..util import topological\n",
              "from ..util.typing import _AnnotationScanType\n",
              "from ..util.typing import is_fwd_ref\n",
              "from ..util.typing import is_literal\n",
              "from ..util.typing import Protocol\n",
              "from ..util.typing import TypedDict\n",
              "from ..util.typing import typing_get_args\n",
              "if TYPE_CHECKING:\n",
              "    from ._typing import _ClassDict\n",
              "    from ._typing import _RegistryType\n",
              "    from .base import Mapped\n",
              "    from .decl_api import declared_attr\n",
              "    from .instrumentation import ClassManager\n",
              "    from ..sql.elements import NamedColumn\n",
              "    from ..sql.schema import MetaData\n",
              "    from ..sql.selectable import FromClause\n",
              "_T = TypeVar(\"_T\", bound=Any)\n",
              "_MapperKwArgs = Mapping[str, Any]\n",
              "_TableArgsType = Union[Tuple[Any, ...], Dict[str, Any]]\n",
              "##--##class MappedClassProtocol(Protocol[_O]):\n",
              "    \"\"\"A protocol representing a SQLAlchemy mapped class.\n",
              "    The protocol is generic on the type of class, use\n",
              "    ``MappedClassProtocol[Any]`` to allow any mapped class.\n",
              "    \"\"\"\n",
              "    __name__: str\n",
              "    __mapper__: Mapper[_O]\n",
              "    __table__: FromClause\n",
              "##--##    def __call__(self, **kw: Any) -> _O: ...\n",
              "##--##class _DeclMappedClassProtocol(MappedClassProtocol[_O], Protocol):\n",
              "    \"Internal more detailed version of ``MappedClassProtocol``.\"\n",
              "    metadata: MetaData\n",
              "    __tablename__: str\n",
              "    __mapper_args__: _MapperKwArgs\n",
              "    __table_args__: Optional[_TableArgsType]\n",
              "    _sa_apply_dc_transforms: Optional[_DataclassArguments]\n",
              "##--##    def __declare_first__(self) -> None: ...\n",
              "##--##    def __declare_last__(self) -> None: ...\n",
              "##--##class _DataclassArguments(TypedDict):\n",
              "    init: Union[_NoArg, bool]\n",
              "    repr: Union[_NoArg, bool]\n",
              "    eq: Union[_NoArg, bool]\n",
              "    order: Union[_NoArg, bool]\n",
              "    unsafe_hash: Union[_NoArg, bool]\n",
              "    match_args: Union[_NoArg, bool]\n",
              "    kw_only: Union[_NoArg, bool]\n",
              "    dataclass_callable: Union[_NoArg, Callable[..., Type[Any]]]\n",
              "##--##def _declared_mapping_info(\n",
              "    cls: Type[Any],\n",
              ") -> Optional[Union[_DeferredMapperConfig, Mapper[Any]]]:\n",
              "    # deferred mapping\n",
              "    if _DeferredMapperConfig.has_cls(cls):\n",
              "        return _DeferredMapperConfig.config_for_cls(cls)\n",
              "    # regular mapping\n",
              "    elif _is_mapped_class(cls):\n",
              "        return class_mapper(cls, configure=False)\n",
              "    else:\n",
              "        return None\n",
              "##--##def _is_supercls_for_inherits(cls: Type[Any]) -> bool:\n",
              "    \"\"\"return True if this class will be used as a superclass to set in\n",
              "    'inherits'.\n",
              "    This includes deferred mapper configs that aren't mapped yet, however does\n",
              "    not include classes with _sa_decl_prepare_nocascade (e.g.\n",
              "    ``AbstractConcreteBase``); these concrete-only classes are not set up as\n",
              "    \"inherits\" until after mappers are configured using\n",
              "    mapper._set_concrete_base()\n",
              "    \"\"\"\n",
              "    if _DeferredMapperConfig.has_cls(cls):\n",
              "        return not _get_immediate_cls_attr(\n",
              "            cls, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        )\n",
              "    # regular mapping\n",
              "    elif _is_mapped_class(cls):\n",
              "        return True\n",
              "    else:\n",
              "        return False\n",
              "##--##def _resolve_for_abstract_or_classical(cls: Type[Any]) -> Optional[Type[Any]]:\n",
              "    if cls is object:\n",
              "        return None\n",
              "    sup: Optional[Type[Any]]\n",
              "    if cls.__dict__.get(\"__abstract__\", False):\n",
              "        for base_ in cls.__bases__:\n",
              "            sup = _resolve_for_abstract_or_classical(base_)\n",
              "            if sup is not None:\n",
              "                return sup\n",
              "        else:\n",
              "            return None\n",
              "    else:\n",
              "        clsmanager = _dive_for_cls_manager(cls)\n",
              "        if clsmanager:\n",
              "            return clsmanager.class_\n",
              "        else:\n",
              "            return cls\n",
              "##--##def _get_immediate_cls_attr(\n",
              "    cls: Type[Any], attrname: str, strict: bool = False\n",
              ") -> Optional[Any]:\n",
              "    \"\"\"return an attribute of the class that is either present directly\n",
              "    on the class, e.g. not on a superclass, or is from a superclass but\n",
              "    this superclass is a non-mapped mixin, that is, not a descendant of\n",
              "    the declarative base and is also not classically mapped.\n",
              "    This is used to detect attributes that indicate something about\n",
              "    a mapped class independently from any mapped classes that it may\n",
              "    inherit from.\n",
              "    \"\"\"\n",
              "    # the rules are different for this name than others,\n",
              "    # make sure we've moved it out.  transitional\n",
              "    assert attrname != \"__abstract__\"\n",
              "    if not issubclass(cls, object):\n",
              "        return None\n",
              "    if attrname in cls.__dict__:\n",
              "        return getattr(cls, attrname)\n",
              "    for base in cls.__mro__[1:]:\n",
              "        _is_classical_inherits = _dive_for_cls_manager(base) is not None\n",
              "        if attrname in base.__dict__ and (\n",
              "            base is cls\n",
              "            or (\n",
              "                (base in cls.__bases__ if strict else True)\n",
              "                and not _is_classical_inherits\n",
              "            )\n",
              "        ):\n",
              "            return getattr(base, attrname)\n",
              "    else:\n",
              "        return None\n",
              "##--##def _dive_for_cls_manager(cls: Type[_O]) -> Optional[ClassManager[_O]]:\n",
              "    # because the class manager registration is pluggable,\n",
              "    # we need to do the search for every class in the hierarchy,\n",
              "    # rather than just a simple \"cls._sa_class_manager\"\n",
              "    for base in cls.__mro__:\n",
              "        manager: Optional[ClassManager[_O]] = attributes.opt_manager_of_class(\n",
              "            base\n",
              "        )\n",
              "        if manager:\n",
              "            return manager\n",
              "    return None\n",
              "##--##def _as_declarative(\n",
              "    registry: _RegistryType, cls: Type[Any], dict_: _ClassDict\n",
              ") -> Optional[_MapperConfig]:\n",
              "    # declarative scans the class for attributes.  no table or mapper\n",
              "    # args passed separately.\n",
              "    return _MapperConfig.setup_mapping(registry, cls, dict_, None, {})\n",
              "##--##def _mapper(\n",
              "    registry: _RegistryType,\n",
              "    cls: Type[_O],\n",
              "    table: Optional[FromClause],\n",
              "    mapper_kw: _MapperKwArgs,\n",
              ") -> Mapper[_O]:\n",
              "    _ImperativeMapperConfig(registry, cls, table, mapper_kw)\n",
              "    return cast(\"MappedClassProtocol[_O]\", cls).__mapper__\n",
              "##--##@util.preload_module(\"sqlalchemy.orm.decl_api\")\n",
              "def _is_declarative_props(obj: Any) -> bool:\n",
              "    _declared_attr_common = util.preloaded.orm_decl_api._declared_attr_common\n",
              "    return isinstance(obj, (_declared_attr_common, util.classproperty))\n",
              "##--##def _check_declared_props_nocascade(\n",
              "    obj: Any, name: str, cls: Type[_O]\n",
              ") -> bool:\n",
              "    if _is_declarative_props(obj):\n",
              "        if getattr(obj, \"_cascading\", False):\n",
              "            util.warn(\n",
              "                \"@declared_attr.cascading is not supported on the %s \"\n",
              "                \"attribute on class %s.  This attribute invokes for \"\n",
              "                \"subclasses in any case.\" % (name, cls)\n",
              "            )\n",
              "        return True\n",
              "    else:\n",
              "        return False\n",
              "##--##class _MapperConfig:\n",
              "    __slots__ = (\n",
              "        \"cls\",\n",
              "        \"classname\",\n",
              "        \"properties\",\n",
              "        \"declared_attr_reg\",\n",
              "        \"__weakref__\",\n",
              "    )\n",
              "    cls: Type[Any]\n",
              "    classname: str\n",
              "    properties: util.OrderedDict[\n",
              "        str,\n",
              "        Union[\n",
              "            Sequence[NamedColumn[Any]], NamedColumn[Any], MapperProperty[Any]\n",
              "        ],\n",
              "    ]\n",
              "    declared_attr_reg: Dict[declared_attr[Any], Any]\n",
              "##--##    @classmethod\n",
              "    def setup_mapping(\n",
              "        cls,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        dict_: _ClassDict,\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ) -> Optional[_MapperConfig]:\n",
              "        manager = attributes.opt_manager_of_class(cls)\n",
              "        if manager and manager.class_ is cls_:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Class {cls!r} already has been instrumented declaratively\"\n",
              "            )\n",
              "        if cls_.__dict__.get(\"__abstract__\", False):\n",
              "            return None\n",
              "        defer_map = _get_immediate_cls_attr(\n",
              "            cls_, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        ) or hasattr(cls_, \"_sa_decl_prepare\")\n",
              "        if defer_map:\n",
              "            return _DeferredMapperConfig(\n",
              "                registry, cls_, dict_, table, mapper_kw\n",
              "            )\n",
              "        else:\n",
              "            return _ClassScanMapperConfig(\n",
              "                registry, cls_, dict_, table, mapper_kw\n",
              "            )\n",
              "##--##    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[Any],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        self.cls = util.assert_arg_type(cls_, type, \"cls_\")\n",
              "        self.classname = cls_.__name__\n",
              "        self.properties = util.OrderedDict()\n",
              "        self.declared_attr_reg = {}\n",
              "        if not mapper_kw.get(\"non_primary\", False):\n",
              "            instrumentation.register_class(\n",
              "                self.cls,\n",
              "                finalize=False,\n",
              "                registry=registry,\n",
              "                declarative_scan=self,\n",
              "                init_method=registry.constructor,\n",
              "            )\n",
              "        else:\n",
              "            manager = attributes.opt_manager_of_class(self.cls)\n",
              "            if not manager or not manager.is_mapped:\n",
              "                raise exc.InvalidRequestError(\n",
              "                    \"Class %s has no primary mapper configured.  Configure \"\n",
              "                    \"a primary mapper first before setting up a non primary \"\n",
              "                    \"Mapper.\" % self.cls\n",
              "                )\n",
              "##--##    def set_cls_attribute(self, attrname: str, value: _T) -> _T:\n",
              "        manager = instrumentation.manager_of_class(self.cls)\n",
              "        manager.install_member(attrname, value)\n",
              "        return value\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = ...) -> Mapper[Any]:\n",
              "        raise NotImplementedError()\n",
              "##--##    def _early_mapping(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        self.map(mapper_kw)\n",
              "##--##class _ImperativeMapperConfig(_MapperConfig):\n",
              "    __slots__ = (\"local_table\", \"inherits\")\n",
              "##--##    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        super().__init__(registry, cls_, mapper_kw)\n",
              "        self.local_table = self.set_cls_attribute(\"__table__\", table)\n",
              "        with mapperlib._CONFIGURE_MUTEX:\n",
              "            if not mapper_kw.get(\"non_primary\", False):\n",
              "                clsregistry.add_class(\n",
              "                    self.classname, self.cls, registry._class_registry\n",
              "                )\n",
              "            self._setup_inheritance(mapper_kw)\n",
              "            self._early_mapping(mapper_kw)\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        mapper_cls = Mapper\n",
              "        return self.set_cls_attribute(\n",
              "            \"__mapper__\",\n",
              "            mapper_cls(self.cls, self.local_table, **mapper_kw),\n",
              "        )\n",
              "##--##    def _setup_inheritance(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        cls = self.cls\n",
              "        inherits = mapper_kw.get(\"inherits\", None)\n",
              "        if inherits is None:\n",
              "            # since we search for classical mappings now, search for\n",
              "            # multiple mapped bases as well and raise an error.\n",
              "            inherits_search = []\n",
              "            for base_ in cls.__bases__:\n",
              "                c = _resolve_for_abstract_or_classical(base_)\n",
              "                if c is None:\n",
              "                    continue\n",
              "                if _is_supercls_for_inherits(c) and c not in inherits_search:\n",
              "                    inherits_search.append(c)\n",
              "            if inherits_search:\n",
              "                if len(inherits_search) > 1:\n",
              "                    raise exc.InvalidRequestError(\n",
              "                        \"Class %s has multiple mapped bases: %r\"\n",
              "                        % (cls, inherits_search)\n",
              "                    )\n",
              "                inherits = inherits_search[0]\n",
              "        elif isinstance(inherits, Mapper):\n",
              "            inherits = inherits.class_\n",
              "        self.inherits = inherits\n",
              "##--##class _CollectedAnnotation(NamedTuple):\n",
              "    raw_annotation: _AnnotationScanType\n",
              "    mapped_container: Optional[Type[Mapped[Any]]]\n",
              "    extracted_mapped_annotation: Union[Type[Any], str]\n",
              "    is_dataclass: bool\n",
              "    attr_value: Any\n",
              "    originating_module: str\n",
              "    originating_class: Type[Any]\n",
              "##--##class _ClassScanMapperConfig(_MapperConfig):\n",
              "    __slots__ = (\n",
              "        \"registry\",\n",
              "        \"clsdict_view\",\n",
              "        \"collected_attributes\",\n",
              "        \"collected_annotations\",\n",
              "        \"local_table\",\n",
              "        \"persist_selectable\",\n",
              "        \"declared_columns\",\n",
              "        \"column_ordering\",\n",
              "        \"column_copies\",\n",
              "        \"table_args\",\n",
              "        \"tablename\",\n",
              "        \"mapper_args\",\n",
              "        \"mapper_args_fn\",\n",
              "        \"inherits\",\n",
              "        \"single\",\n",
              "        \"allow_dataclass_fields\",\n",
              "        \"dataclass_setup_arguments\",\n",
              "        \"is_dataclass_prior_to_mapping\",\n",
              "        \"allow_unmapped_annotations\",\n",
              "    )\n",
              "    is_deferred = False\n",
              "    registry: _RegistryType\n",
              "    clsdict_view: _ClassDict\n",
              "    collected_annotations: Dict[str, _CollectedAnnotation]\n",
              "    collected_attributes: Dict[str, Any]\n",
              "    local_table: Optional[FromClause]\n",
              "    persist_selectable: Optional[FromClause]\n",
              "    declared_columns: util.OrderedSet[Column[Any]]\n",
              "    column_ordering: Dict[Column[Any], int]\n",
              "    column_copies: Dict[\n",
              "        Union[MappedColumn[Any], Column[Any]],\n",
              "        Union[MappedColumn[Any], Column[Any]],\n",
              "    ]\n",
              "    tablename: Optional[str]\n",
              "    mapper_args: Mapping[str, Any]\n",
              "    table_args: Optional[_TableArgsType]\n",
              "    mapper_args_fn: Optional[Callable[[], Dict[str, Any]]]\n",
              "    inherits: Optional[Type[Any]]\n",
              "    single: bool\n",
              "    is_dataclass_prior_to_mapping: bool\n",
              "    allow_unmapped_annotations: bool\n",
              "    dataclass_setup_arguments: Optional[_DataclassArguments]\n",
              "    \"\"\"if the class has SQLAlchemy native dataclass parameters, where\n",
              "    we will turn the class into a dataclass within the declarative mapping\n",
              "    process.\n",
              "    \"\"\"\n",
              "    allow_dataclass_fields: bool\n",
              "    \"\"\"if true, look for dataclass-processed Field objects on the target\n",
              "##--##    class as well as superclasses and extract ORM mapping directives from\n",
              "    the \"metadata\" attribute of each Field.\n",
              "    if False, dataclass fields can still be used, however they won't be\n",
              "    mapped.\n",
              "    \"\"\"\n",
              "##--##    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        dict_: _ClassDict,\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        # grab class dict before the instrumentation manager has been added.\n",
              "        # reduces cycles\n",
              "        self.clsdict_view = (\n",
              "            util.immutabledict(dict_) if dict_ else util.EMPTY_DICT\n",
              "        )\n",
              "        super().__init__(registry, cls_, mapper_kw)\n",
              "        self.registry = registry\n",
              "        self.persist_selectable = None\n",
              "        self.collected_attributes = {}\n",
              "        self.collected_annotations = {}\n",
              "        self.declared_columns = util.OrderedSet()\n",
              "        self.column_ordering = {}\n",
              "        self.column_copies = {}\n",
              "        self.single = False\n",
              "        self.dataclass_setup_arguments = dca = getattr(\n",
              "            self.cls, \"_sa_apply_dc_transforms\", None\n",
              "        )\n",
              "        self.allow_unmapped_annotations = getattr(\n",
              "            self.cls, \"__allow_unmapped__\", False\n",
              "        ) or bool(self.dataclass_setup_arguments)\n",
              "        self.is_dataclass_prior_to_mapping = cld = dataclasses.is_dataclass(\n",
              "            cls_\n",
              "        )\n",
              "        sdk = _get_immediate_cls_attr(cls_, \"__sa_dataclass_metadata_key__\")\n",
              "        # we don't want to consume Field objects from a not-already-dataclass.\n",
              "        # the Field objects won't have their \"name\" or \"type\" populated,\n",
              "        # and while it seems like we could just set these on Field as we\n",
              "        # read them, Field is documented as \"user read only\" and we need to\n",
              "        # stay far away from any off-label use of dataclasses APIs.\n",
              "        if (not cld or dca) and sdk:\n",
              "            raise exc.InvalidRequestError(\n",
              "                \"SQLAlchemy mapped dataclasses can't consume mapping \"\n",
              "                \"information from dataclass.Field() objects if the immediate \"\n",
              "                \"class is not already a dataclass.\"\n",
              "            )\n",
              "        # if already a dataclass, and __sa_dataclass_metadata_key__ present,\n",
              "        # then also look inside of dataclass.Field() objects yielded by\n",
              "        # dataclasses.get_fields(cls) when scanning for attributes\n",
              "        self.allow_dataclass_fields = bool(sdk and cld)\n",
              "        self._setup_declared_events()\n",
              "        self._scan_attributes()\n",
              "        self._setup_dataclasses_transforms()\n",
              "        with mapperlib._CONFIGURE_MUTEX:\n",
              "            clsregistry.add_class(\n",
              "                self.classname, self.cls, registry._class_registry\n",
              "            )\n",
              "            self._setup_inheriting_mapper(mapper_kw)\n",
              "            self._extract_mappable_attributes()\n",
              "            self._extract_declared_columns()\n",
              "            self._setup_table(table)\n",
              "            self._setup_inheriting_columns(mapper_kw)\n",
              "            self._early_mapping(mapper_kw)\n",
              "##--##    def _setup_declared_events(self) -> None:\n",
              "        if _get_immediate_cls_attr(self.cls, \"__declare_last__\"):\n",
              "##--##            @event.listens_for(Mapper, \"after_configured\")\n",
              "            def after_configured() -> None:\n",
              "                cast(\n",
              "                    \"_DeclMappedClassProtocol[Any]\", self.cls\n",
              "                ).__declare_last__()\n",
              "        if _get_immediate_cls_attr(self.cls, \"__declare_first__\"):\n",
              "##--##            @event.listens_for(Mapper, \"before_configured\")\n",
              "            def before_configured() -> None:\n",
              "                cast(\n",
              "                    \"_DeclMappedClassProtocol[Any]\", self.cls\n",
              "                ).__declare_first__()\n",
              "##--##    def _cls_attr_override_checker(\n",
              "        self, cls: Type[_O]\n",
              "    ) -> Callable[[str, Any], bool]:\n",
              "        \"\"\"Produce a function that checks if a class has overridden an\n",
              "        attribute, taking SQLAlchemy-enabled dataclass fields into account.\n",
              "        \"\"\"\n",
              "        if self.allow_dataclass_fields:\n",
              "            sa_dataclass_metadata_key = _get_immediate_cls_attr(\n",
              "                cls, \"__sa_dataclass_metadata_key__\"\n",
              "            )\n",
              "        else:\n",
              "            sa_dataclass_metadata_key = None\n",
              "        if not sa_dataclass_metadata_key:\n",
              "##--##            def attribute_is_overridden(key: str, obj: Any) -> bool:\n",
              "                return getattr(cls, key, obj) is not obj\n",
              "        else:\n",
              "            all_datacls_fields = {\n",
              "                f.name: f.metadata[sa_dataclass_metadata_key]\n",
              "                for f in util.dataclass_fields(cls)\n",
              "                if sa_dataclass_metadata_key in f.metadata\n",
              "            }\n",
              "            local_datacls_fields = {\n",
              "                f.name: f.metadata[sa_dataclass_metadata_key]\n",
              "                for f in util.local_dataclass_fields(cls)\n",
              "                if sa_dataclass_metadata_key in f.metadata\n",
              "            }\n",
              "            absent = object()\n",
              "##--##            def attribute_is_overridden(key: str, obj: Any) -> bool:\n",
              "                if _is_declarative_props(obj):\n",
              "                    obj = obj.fget\n",
              "                # this function likely has some failure modes still if\n",
              "                # someone is doing a deep mixing of the same attribute\n",
              "                # name as plain Python attribute vs. dataclass field.\n",
              "                ret = local_datacls_fields.get(key, absent)\n",
              "                if _is_declarative_props(ret):\n",
              "                    ret = ret.fget\n",
              "                if ret is obj:\n",
              "                    return False\n",
              "                elif ret is not absent:\n",
              "                    return True\n",
              "                all_field = all_datacls_fields.get(key, absent)\n",
              "                ret = getattr(cls, key, obj)\n",
              "                if ret is obj:\n",
              "                    return False\n",
              "                # for dataclasses, this could be the\n",
              "                # 'default' of the field.  so filter more specifically\n",
              "                # for an already-mapped InstrumentedAttribute\n",
              "                if ret is not absent and isinstance(\n",
              "                    ret, InstrumentedAttribute\n",
              "                ):\n",
              "                    return True\n",
              "                if all_field is obj:\n",
              "                    return False\n",
              "                elif all_field is not absent:\n",
              "                    return True\n",
              "                # can't find another attribute\n",
              "                return False\n",
              "        return attribute_is_overridden\n",
              "    _include_dunders = {\n",
              "        \"__table__\",\n",
              "        \"__mapper_args__\",\n",
              "        \"__tablename__\",\n",
              "        \"__table_args__\",\n",
              "    }\n",
              "    _match_exclude_dunders = re.compile(r\"^(?:_sa_|__)\")\n",
              "##--##    def _cls_attr_resolver(\n",
              "        self, cls: Type[Any]\n",
              "    ) -> Callable[[], Iterable[Tuple[str, Any, Any, bool]]]:\n",
              "        \"\"\"produce a function to iterate the \"attributes\" of a class\n",
              "        which we want to consider for mapping, adjusting for SQLAlchemy fields\n",
              "        embedded in dataclass fields.\n",
              "        \"\"\"\n",
              "        cls_annotations = util.get_annotations(cls)\n",
              "        cls_vars = vars(cls)\n",
              "        _include_dunders = self._include_dunders\n",
              "        _match_exclude_dunders = self._match_exclude_dunders\n",
              "        names = [\n",
              "            n\n",
              "            for n in util.merge_lists_w_ordering(\n",
              "                list(cls_vars), list(cls_annotations)\n",
              "            )\n",
              "            if not _match_exclude_dunders.match(n) or n in _include_dunders\n",
              "        ]\n",
              "        if self.allow_dataclass_fields:\n",
              "            sa_dataclass_metadata_key: Optional[str] = _get_immediate_cls_attr(\n",
              "                cls, \"__sa_dataclass_metadata_key__\"\n",
              "            )\n",
              "        else:\n",
              "            sa_dataclass_metadata_key = None\n",
              "        if not sa_dataclass_metadata_key:\n",
              "##--##            def local_attributes_for_class() -> (\n",
              "                Iterable[Tuple[str, Any, Any, bool]]\n",
              "            ):\n",
              "                return (\n",
              "                    (\n",
              "                        name,\n",
              "                        cls_vars.get(name),\n",
              "                        cls_annotations.get(name),\n",
              "                        False,\n",
              "                    )\n",
              "                    for name in names\n",
              "                )\n",
              "        else:\n",
              "            dataclass_fields = {\n",
              "                field.name: field for field in util.local_dataclass_fields(cls)\n",
              "            }\n",
              "            fixed_sa_dataclass_metadata_key = sa_dataclass_metadata_key\n",
              "##--##            def local_attributes_for_class() -> (\n",
              "                Iterable[Tuple[str, Any, Any, bool]]\n",
              "            ):\n",
              "                for name in names:\n",
              "                    field = dataclass_fields.get(name, None)\n",
              "                    if field and sa_dataclass_metadata_key in field.metadata:\n",
              "                        yield field.name, _as_dc_declaredattr(\n",
              "                            field.metadata, fixed_sa_dataclass_metadata_key\n",
              "                        ), cls_annotations.get(field.name), True\n",
              "                    else:\n",
              "                        yield name, cls_vars.get(name), cls_annotations.get(\n",
              "                            name\n",
              "                        ), False\n",
              "        return local_attributes_for_class\n",
              "##--##    def _scan_attributes(self) -> None:\n",
              "        cls = self.cls\n",
              "        cls_as_Decl = cast(\"_DeclMappedClassProtocol[Any]\", cls)\n",
              "        clsdict_view = self.clsdict_view\n",
              "        collected_attributes = self.collected_attributes\n",
              "        column_copies = self.column_copies\n",
              "        _include_dunders = self._include_dunders\n",
              "        mapper_args_fn = None\n",
              "        table_args = inherited_table_args = None\n",
              "        tablename = None\n",
              "        fixed_table = \"__table__\" in clsdict_view\n",
              "        attribute_is_overridden = self._cls_attr_override_checker(self.cls)\n",
              "        bases = []\n",
              "        for base in cls.__mro__:\n",
              "            # collect bases and make sure standalone columns are copied\n",
              "            # to be the column they will ultimately be on the class,\n",
              "            # so that declared_attr functions use the right columns.\n",
              "            # need to do this all the way up the hierarchy first\n",
              "            # (see #8190)\n",
              "            class_mapped = base is not cls and _is_supercls_for_inherits(base)\n",
              "            local_attributes_for_class = self._cls_attr_resolver(base)\n",
              "            if not class_mapped and base is not cls:\n",
              "                locally_collected_columns = self._produce_column_copies(\n",
              "                    local_attributes_for_class,\n",
              "                    attribute_is_overridden,\n",
              "                    fixed_table,\n",
              "                    base,\n",
              "                )\n",
              "            else:\n",
              "                locally_collected_columns = {}\n",
              "            bases.append(\n",
              "                (\n",
              "                    base,\n",
              "                    class_mapped,\n",
              "                    local_attributes_for_class,\n",
              "                    locally_collected_columns,\n",
              "                )\n",
              "            )\n",
              "        for (\n",
              "            base,\n",
              "            class_mapped,\n",
              "            local_attributes_for_class,\n",
              "            locally_collected_columns,\n",
              "        ) in bases:\n",
              "            # this transfer can also take place as we scan each name\n",
              "            # for finer-grained control of how collected_attributes is\n",
              "            # populated, as this is what impacts column ordering.\n",
              "            # however it's simpler to get it out of the way here.\n",
              "            collected_attributes.update(locally_collected_columns)\n",
              "            for (\n",
              "                name,\n",
              "                obj,\n",
              "                annotation,\n",
              "                is_dataclass_field,\n",
              "            ) in local_attributes_for_class():\n",
              "                if name in _include_dunders:\n",
              "                    if name == \"__mapper_args__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not mapper_args_fn and (\n",
              "                            not class_mapped or check_decl\n",
              "                        ):\n",
              "                            # don't even invoke __mapper_args__ until\n",
              "                            # after we've determined everything about the\n",
              "                            # mapped table.\n",
              "                            # make a copy of it so a class-level dictionary\n",
              "                            # is not overwritten when we update column-based\n",
              "                            # arguments.\n",
              "##--##                            def _mapper_args_fn() -> Dict[str, Any]:\n",
              "                                return dict(cls_as_Decl.__mapper_args__)\n",
              "                            mapper_args_fn = _mapper_args_fn\n",
              "                    elif name == \"__tablename__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not tablename and (not class_mapped or check_decl):\n",
              "                            tablename = cls_as_Decl.__tablename__\n",
              "                    elif name == \"__table_args__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not table_args and (not class_mapped or check_decl):\n",
              "                            table_args = cls_as_Decl.__table_args__\n",
              "                            if not isinstance(\n",
              "                                table_args, (tuple, dict, type(None))\n",
              "                            ):\n",
              "                                raise exc.ArgumentError(\n",
              "                                    \"__table_args__ value must be a tuple, \"\n",
              "                                    \"dict, or None\"\n",
              "                                )\n",
              "                            if base is not cls:\n",
              "                                inherited_table_args = True\n",
              "                    else:\n",
              "                        # skip all other dunder names, which at the moment\n",
              "                        # should only be __table__\n",
              "                        continue\n",
              "                elif class_mapped:\n",
              "                    if _is_declarative_props(obj) and not obj._quiet:\n",
              "                        util.warn(\n",
              "                            \"Regular (i.e. not __special__) \"\n",
              "                            \"attribute '%s.%s' uses @declared_attr, \"\n",
              "                            \"but owning class %s is mapped - \"\n",
              "                            \"not applying to subclass %s.\"\n",
              "                            % (base.__name__, name, base, cls)\n",
              "                        )\n",
              "                    continue\n",
              "                elif base is not cls:\n",
              "                    # we're a mixin, abstract base, or something that is\n",
              "                    # acting like that for now.\n",
              "                    if isinstance(obj, (Column, MappedColumn)):\n",
              "                        # already copied columns to the mapped class.\n",
              "                        continue\n",
              "                    elif isinstance(obj, MapperProperty):\n",
              "                        raise exc.InvalidRequestError(\n",
              "                            \"Mapper properties (i.e. deferred,\"\n",
              "                            \"column_property(), relationship(), etc.) must \"\n",
              "                            \"be declared as @declared_attr callables \"\n",
              "                            \"on declarative mixin classes.  For dataclass \"\n",
              "                            \"field() objects, use a lambda:\"\n",
              "                        )\n",
              "                    elif _is_declarative_props(obj):\n",
              "                        # tried to get overloads to tell this to\n",
              "                        # pylance, no luck\n",
              "                        assert obj is not None\n",
              "                        if obj._cascading:\n",
              "                            if name in clsdict_view:\n",
              "                                # unfortunately, while we can use the user-\n",
              "                                # defined attribute here to allow a clean\n",
              "                                # override, if there's another\n",
              "                                # subclass below then it still tries to use\n",
              "                                # this.  not sure if there is enough\n",
              "                                # information here to add this as a feature\n",
              "                                # later on.\n",
              "                                util.warn(\n",
              "                                    \"Attribute '%s' on class %s cannot be \"\n",
              "                                    \"processed due to \"\n",
              "                                    \"@declared_attr.cascading; \"\n",
              "                                    \"skipping\" % (name, cls)\n",
              "                                )\n",
              "                            collected_attributes[name] = column_copies[obj] = (\n",
              "                                ret\n",
              "                            ) = obj.__get__(obj, cls)\n",
              "                            setattr(cls, name, ret)\n",
              "                        else:\n",
              "                            if is_dataclass_field:\n",
              "                                # access attribute using normal class access\n",
              "                                # first, to see if it's been mapped on a\n",
              "                                # superclass.   note if the dataclasses.field()\n",
              "                                # has \"default\", this value can be anything.\n",
              "                                ret = getattr(cls, name, None)\n",
              "                                # so, if it's anything that's not ORM\n",
              "                                # mapped, assume we should invoke the\n",
              "                                # declared_attr\n",
              "                                if not isinstance(ret, InspectionAttr):\n",
              "                                    ret = obj.fget()\n",
              "                            else:\n",
              "                                # access attribute using normal class access.\n",
              "                                # if the declared attr already took place\n",
              "                                # on a superclass that is mapped, then\n",
              "                                # this is no longer a declared_attr, it will\n",
              "                                # be the InstrumentedAttribute\n",
              "                                ret = getattr(cls, name)\n",
              "                            # correct for proxies created from hybrid_property\n",
              "                            # or similar.  note there is no known case that\n",
              "                            # produces nested proxies, so we are only\n",
              "                            # looking one level deep right now.\n",
              "                            if (\n",
              "                                isinstance(ret, InspectionAttr)\n",
              "                                and attr_is_internal_proxy(ret)\n",
              "                                and not isinstance(\n",
              "                                    ret.original_property, MapperProperty\n",
              "                                )\n",
              "                            ):\n",
              "                                ret = ret.descriptor\n",
              "                            collected_attributes[name] = column_copies[obj] = (\n",
              "                                ret\n",
              "                            )\n",
              "                        if (\n",
              "                            isinstance(ret, (Column, MapperProperty))\n",
              "                            and ret.doc is None\n",
              "                        ):\n",
              "                            ret.doc = obj.__doc__\n",
              "                        self._collect_annotation(\n",
              "                            name,\n",
              "                            obj._collect_return_annotation(),\n",
              "                            base,\n",
              "                            True,\n",
              "                            obj,\n",
              "                        )\n",
              "                    elif _is_mapped_annotation(annotation, cls, base):\n",
              "                        # Mapped annotation without any object.\n",
              "                        # product_column_copies should have handled this.\n",
              "                        # if future support for other MapperProperty,\n",
              "                        # then test if this name is already handled and\n",
              "                        # otherwise proceed to generate.\n",
              "                        if not fixed_table:\n",
              "                            assert (\n",
              "                                name in collected_attributes\n",
              "                                or attribute_is_overridden(name, None)\n",
              "                            )\n",
              "                        continue\n",
              "                    else:\n",
              "                        # here, the attribute is some other kind of\n",
              "                        # property that we assume is not part of the\n",
              "                        # declarative mapping.  however, check for some\n",
              "                        # more common mistakes\n",
              "                        self._warn_for_decl_attributes(base, name, obj)\n",
              "                elif is_dataclass_field and (\n",
              "                    name not in clsdict_view or clsdict_view[name] is not obj\n",
              "                ):\n",
              "                    # here, we are definitely looking at the target class\n",
              "                    # and not a superclass.   this is currently a\n",
              "                    # dataclass-only path.  if the name is only\n",
              "                    # a dataclass field and isn't in local cls.__dict__,\n",
              "                    # put the object there.\n",
              "                    # assert that the dataclass-enabled resolver agrees\n",
              "                    # with what we are seeing\n",
              "                    assert not attribute_is_overridden(name, obj)\n",
              "                    if _is_declarative_props(obj):\n",
              "                        obj = obj.fget()\n",
              "                    collected_attributes[name] = obj\n",
              "                    self._collect_annotation(\n",
              "                        name, annotation, base, False, obj\n",
              "                    )\n",
              "                else:\n",
              "                    collected_annotation = self._collect_annotation(\n",
              "                        name, annotation, base, None, obj\n",
              "                    )\n",
              "                    is_mapped = (\n",
              "                        collected_annotation is not None\n",
              "                        and collected_annotation.mapped_container is not None\n",
              "                    )\n",
              "                    generated_obj = (\n",
              "                        collected_annotation.attr_value\n",
              "                        if collected_annotation is not None\n",
              "                        else obj\n",
              "                    )\n",
              "                    if obj is None and not fixed_table and is_mapped:\n",
              "                        collected_attributes[name] = (\n",
              "                            generated_obj\n",
              "                            if generated_obj is not None\n",
              "                            else MappedColumn()\n",
              "                        )\n",
              "                    elif name in clsdict_view:\n",
              "                        collected_attributes[name] = obj\n",
              "                    # else if the name is not in the cls.__dict__,\n",
              "                    # don't collect it as an attribute.\n",
              "                    # we will see the annotation only, which is meaningful\n",
              "                    # both for mapping and dataclasses setup\n",
              "        if inherited_table_args and not tablename:\n",
              "            table_args = None\n",
              "        self.table_args = table_args\n",
              "        self.tablename = tablename\n",
              "        self.mapper_args_fn = mapper_args_fn\n",
              "##--##    def _setup_dataclasses_transforms(self) -> None:\n",
              "        dataclass_setup_arguments = self.dataclass_setup_arguments\n",
              "        if not dataclass_setup_arguments:\n",
              "            return\n",
              "        # can't use is_dataclass since it uses hasattr\n",
              "        if \"__dataclass_fields__\" in self.cls.__dict__:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Class {self.cls} is already a dataclass; ensure that \"\n",
              "                \"base classes / decorator styles of establishing dataclasses \"\n",
              "                \"are not being mixed. \"\n",
              "                \"This can happen if a class that inherits from \"\n",
              "                \"'MappedAsDataclass', even indirectly, is been mapped with \"\n",
              "                \"'@registry.mapped_as_dataclass'\"\n",
              "            )\n",
              "        warn_for_non_dc_attrs = collections.defaultdict(list)\n",
              "##--##        def _allow_dataclass_field(\n",
              "            key: str, originating_class: Type[Any]\n",
              "        ) -> bool:\n",
              "            if (\n",
              "                originating_class is not self.cls\n",
              "                and \"__dataclass_fields__\" not in originating_class.__dict__\n",
              "            ):\n",
              "                warn_for_non_dc_attrs[originating_class].append(key)\n",
              "            return True\n",
              "        manager = instrumentation.manager_of_class(self.cls)\n",
              "        assert manager is not None\n",
              "        field_list = [\n",
              "            _AttributeOptions._get_arguments_for_make_dataclass(\n",
              "                key,\n",
              "                anno,\n",
              "                mapped_container,\n",
              "                self.collected_attributes.get(key, _NoArg.NO_ARG),\n",
              "            )\n",
              "            for key, anno, mapped_container in (\n",
              "                (\n",
              "                    key,\n",
              "                    mapped_anno if mapped_anno else raw_anno,\n",
              "                    mapped_container,\n",
              "                )\n",
              "                for key, (\n",
              "                    raw_anno,\n",
              "                    mapped_container,\n",
              "                    mapped_anno,\n",
              "                    is_dc,\n",
              "                    attr_value,\n",
              "                    originating_module,\n",
              "                    originating_class,\n",
              "                ) in self.collected_annotations.items()\n",
              "                if _allow_dataclass_field(key, originating_class)\n",
              "                and (\n",
              "                    key not in self.collected_attributes\n",
              "                    # issue #9226; check for attributes that we've collected\n",
              "                    # which are already instrumented, which we would assume\n",
              "                    # mean we are in an ORM inheritance mapping and this\n",
              "                    # attribute is already mapped on the superclass.   Under\n",
              "                    # no circumstance should any QueryableAttribute be sent to\n",
              "                    # the dataclass() function; anything that's mapped should\n",
              "                    # be Field and that's it\n",
              "                    or not isinstance(\n",
              "                        self.collected_attributes[key], QueryableAttribute\n",
              "                    )\n",
              "                )\n",
              "            )\n",
              "        ]\n",
              "        if warn_for_non_dc_attrs:\n",
              "            for (\n",
              "                originating_class,\n",
              "                non_dc_attrs,\n",
              "            ) in warn_for_non_dc_attrs.items():\n",
              "                util.warn_deprecated(\n",
              "                    f\"When transforming {self.cls} to a dataclass, \"\n",
              "                    f\"attribute(s) \"\n",
              "                    f\"{', '.join(repr(key) for key in non_dc_attrs)} \"\n",
              "                    f\"originates from superclass \"\n",
              "                    f\"{originating_class}, which is not a dataclass.  This \"\n",
              "                    f\"usage is deprecated and will raise an error in \"\n",
              "                    f\"SQLAlchemy 2.1.  When declaring SQLAlchemy Declarative \"\n",
              "                    f\"Dataclasses, ensure that all mixin classes and other \"\n",
              "                    f\"superclasses which include attributes are also a \"\n",
              "                    f\"subclass of MappedAsDataclass.\",\n",
              "                    \"2.0\",\n",
              "                    code=\"dcmx\",\n",
              "                )\n",
              "        annotations = {}\n",
              "        defaults = {}\n",
              "        for item in field_list:\n",
              "            if len(item) == 2:\n",
              "                name, tp = item\n",
              "            elif len(item) == 3:\n",
              "                name, tp, spec = item\n",
              "                defaults[name] = spec\n",
              "            else:\n",
              "                assert False\n",
              "            annotations[name] = tp\n",
              "        for k, v in defaults.items():\n",
              "            setattr(self.cls, k, v)\n",
              "        self._apply_dataclasses_to_any_class(\n",
              "            dataclass_setup_arguments, self.cls, annotations\n",
              "        )\n",
              "##--##    @classmethod\n",
              "    def _update_annotations_for_non_mapped_class(\n",
              "        cls, klass: Type[_O]\n",
              "    ) -> Mapping[str, _AnnotationScanType]:\n",
              "        cls_annotations = util.get_annotations(klass)\n",
              "        new_anno = {}\n",
              "        for name, annotation in cls_annotations.items():\n",
              "            if _is_mapped_annotation(annotation, klass, klass):\n",
              "                extracted = _extract_mapped_subtype(\n",
              "                    annotation,\n",
              "                    klass,\n",
              "                    klass.__module__,\n",
              "                    name,\n",
              "                    type(None),\n",
              "                    required=False,\n",
              "                    is_dataclass_field=False,\n",
              "                    expect_mapped=False,\n",
              "                )\n",
              "                if extracted:\n",
              "                    inner, _ = extracted\n",
              "                    new_anno[name] = inner\n",
              "            else:\n",
              "                new_anno[name] = annotation\n",
              "        return new_anno\n",
              "##--##    @classmethod\n",
              "    def _apply_dataclasses_to_any_class(\n",
              "        cls,\n",
              "        dataclass_setup_arguments: _DataclassArguments,\n",
              "        klass: Type[_O],\n",
              "        use_annotations: Mapping[str, _AnnotationScanType],\n",
              "    ) -> None:\n",
              "        cls._assert_dc_arguments(dataclass_setup_arguments)\n",
              "        dataclass_callable = dataclass_setup_arguments[\"dataclass_callable\"]\n",
              "        if dataclass_callable is _NoArg.NO_ARG:\n",
              "            dataclass_callable = dataclasses.dataclass\n",
              "        restored: Optional[Any]\n",
              "        if use_annotations:\n",
              "            # apply constructed annotations that should look \"normal\" to a\n",
              "            # dataclasses callable, based on the fields present.  This\n",
              "            # means remove the Mapped[] container and ensure all Field\n",
              "            # entries have an annotation\n",
              "            restored = getattr(klass, \"__annotations__\", None)\n",
              "            klass.__annotations__ = cast(\"Dict[str, Any]\", use_annotations)\n",
              "        else:\n",
              "            restored = None\n",
              "        try:\n",
              "            dataclass_callable(\n",
              "                klass,\n",
              "                **{\n",
              "                    k: v\n",
              "                    for k, v in dataclass_setup_arguments.items()\n",
              "                    if v is not _NoArg.NO_ARG and k != \"dataclass_callable\"\n",
              "                },\n",
              "            )\n",
              "        except (TypeError, ValueError) as ex:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Python dataclasses error encountered when creating \"\n",
              "                f\"dataclass for {klass.__name__!r}: \"\n",
              "                f\"{ex!r}. Please refer to Python dataclasses \"\n",
              "                \"documentation for additional information.\",\n",
              "                code=\"dcte\",\n",
              "            ) from ex\n",
              "        finally:\n",
              "            # restore original annotations outside of the dataclasses\n",
              "            # process; for mixins and __abstract__ superclasses, SQLAlchemy\n",
              "            # Declarative will need to see the Mapped[] container inside the\n",
              "            # annotations in order to map subclasses\n",
              "            if use_annotations:\n",
              "                if restored is None:\n",
              "                    del klass.__annotations__\n",
              "                else:\n",
              "                    klass.__annotations__ = restored\n",
              "##--##    @classmethod\n",
              "    def _assert_dc_arguments(cls, arguments: _DataclassArguments) -> None:\n",
              "        allowed = {\n",
              "            \"init\",\n",
              "            \"repr\",\n",
              "            \"order\",\n",
              "            \"eq\",\n",
              "            \"unsafe_hash\",\n",
              "            \"kw_only\",\n",
              "            \"match_args\",\n",
              "            \"dataclass_callable\",\n",
              "        }\n",
              "        disallowed_args = set(arguments).difference(allowed)\n",
              "        if disallowed_args:\n",
              "            msg = \", \".join(f\"{arg!r}\" for arg in sorted(disallowed_args))\n",
              "            raise exc.ArgumentError(\n",
              "                f\"Dataclass argument(s) {msg} are not accepted\"\n",
              "            )\n",
              "##--##    def _collect_annotation(\n",
              "        self,\n",
              "        name: str,\n",
              "        raw_annotation: _AnnotationScanType,\n",
              "        originating_class: Type[Any],\n",
              "        expect_mapped: Optional[bool],\n",
              "        attr_value: Any,\n",
              "    ) -> Optional[_CollectedAnnotation]:\n",
              "        if name in self.collected_annotations:\n",
              "            return self.collected_annotations[name]\n",
              "        if raw_annotation is None:\n",
              "            return None\n",
              "        is_dataclass = self.is_dataclass_prior_to_mapping\n",
              "        allow_unmapped = self.allow_unmapped_annotations\n",
              "        if expect_mapped is None:\n",
              "            is_dataclass_field = isinstance(attr_value, dataclasses.Field)\n",
              "            expect_mapped = (\n",
              "                not is_dataclass_field\n",
              "                and not allow_unmapped\n",
              "                and (\n",
              "                    attr_value is None\n",
              "                    or isinstance(attr_value, _MappedAttribute)\n",
              "                )\n",
              "            )\n",
              "        else:\n",
              "            is_dataclass_field = False\n",
              "        is_dataclass_field = False\n",
              "        extracted = _extract_mapped_subtype(\n",
              "            raw_annotation,\n",
              "            self.cls,\n",
              "            originating_class.__module__,\n",
              "            name,\n",
              "            type(attr_value),\n",
              "            required=False,\n",
              "            is_dataclass_field=is_dataclass_field,\n",
              "            expect_mapped=expect_mapped\n",
              "            and not is_dataclass,  # self.allow_dataclass_fields,\n",
              "        )\n",
              "        if extracted is None:\n",
              "            # ClassVar can come out here\n",
              "            return None\n",
              "        extracted_mapped_annotation, mapped_container = extracted\n",
              "        if attr_value is None and not is_literal(extracted_mapped_annotation):\n",
              "            for elem in typing_get_args(extracted_mapped_annotation):\n",
              "                if isinstance(elem, str) or is_fwd_ref(\n",
              "                    elem, check_generic=True\n",
              "                ):\n",
              "                    elem = de_stringify_annotation(\n",
              "                        self.cls,\n",
              "                        elem,\n",
              "                        originating_class.__module__,\n",
              "                        include_generic=True,\n",
              "                    )\n",
              "                # look in Annotated[...] for an ORM construct,\n",
              "                # such as Annotated[int, mapped_column(primary_key=True)]\n",
              "                if isinstance(elem, _IntrospectsAnnotations):\n",
              "                    attr_value = elem.found_in_pep593_annotated()\n",
              "        self.collected_annotations[name] = ca = _CollectedAnnotation(\n",
              "            raw_annotation,\n",
              "            mapped_container,\n",
              "            extracted_mapped_annotation,\n",
              "            is_dataclass,\n",
              "            attr_value,\n",
              "            originating_class.__module__,\n",
              "            originating_class,\n",
              "        )\n",
              "        return ca\n",
              "##--##    def _warn_for_decl_attributes(\n",
              "        self, cls: Type[Any], key: str, c: Any\n",
              "    ) -> None:\n",
              "        if isinstance(c, expression.ColumnElement):\n",
              "            util.warn(\n",
              "                f\"Attribute '{key}' on class {cls} appears to \"\n",
              "                \"be a non-schema SQLAlchemy expression \"\n",
              "                \"object; this won't be part of the declarative mapping. \"\n",
              "                \"To map arbitrary expressions, use ``column_property()`` \"\n",
              "                \"or a similar function such as ``deferred()``, \"\n",
              "                \"``query_expression()`` etc. \"\n",
              "            )\n",
              "##--##    def _produce_column_copies(\n",
              "        self,\n",
              "        attributes_for_class: Callable[\n",
              "            [], Iterable[Tuple[str, Any, Any, bool]]\n",
              "        ],\n",
              "        attribute_is_overridden: Callable[[str, Any], bool],\n",
              "        fixed_table: bool,\n",
              "        originating_class: Type[Any],\n",
              "    ) -> Dict[str, Union[Column[Any], MappedColumn[Any]]]:\n",
              "        cls = self.cls\n",
              "        dict_ = self.clsdict_view\n",
              "        locally_collected_attributes = {}\n",
              "        column_copies = self.column_copies\n",
              "        # copy mixin columns to the mapped class\n",
              "        for name, obj, annotation, is_dataclass in attributes_for_class():\n",
              "            if (\n",
              "                not fixed_table\n",
              "                and obj is None\n",
              "                and _is_mapped_annotation(annotation, cls, originating_class)\n",
              "            ):\n",
              "                # obj is None means this is the annotation only path\n",
              "                if attribute_is_overridden(name, obj):\n",
              "                    # perform same \"overridden\" check as we do for\n",
              "                    # Column/MappedColumn, this is how a mixin col is not\n",
              "                    # applied to an inherited subclass that does not have\n",
              "                    # the mixin.   the anno-only path added here for\n",
              "                    # #9564\n",
              "                    continue\n",
              "                collected_annotation = self._collect_annotation(\n",
              "                    name, annotation, originating_class, True, obj\n",
              "                )\n",
              "                obj = (\n",
              "                    collected_annotation.attr_value\n",
              "                    if collected_annotation is not None\n",
              "                    else obj\n",
              "                )\n",
              "                if obj is None:\n",
              "                    obj = MappedColumn()\n",
              "                locally_collected_attributes[name] = obj\n",
              "                setattr(cls, name, obj)\n",
              "            elif isinstance(obj, (Column, MappedColumn)):\n",
              "                if attribute_is_overridden(name, obj):\n",
              "                    # if column has been overridden\n",
              "                    # (like by the InstrumentedAttribute of the\n",
              "                    # superclass), skip.  don't collect the annotation\n",
              "                    # either (issue #8718)\n",
              "                    continue\n",
              "                collected_annotation = self._collect_annotation(\n",
              "                    name, annotation, originating_class, True, obj\n",
              "                )\n",
              "                obj = (\n",
              "                    collected_annotation.attr_value\n",
              "                    if collected_annotation is not None\n",
              "                    else obj\n",
              "                )\n",
              "                if name not in dict_ and not (\n",
              "                    \"__table__\" in dict_\n",
              "                    and (getattr(obj, \"name\", None) or name)\n",
              "                    in dict_[\"__table__\"].c\n",
              "                ):\n",
              "                    if obj.foreign_keys:\n",
              "                        for fk in obj.foreign_keys:\n",
              "                            if (\n",
              "                                fk._table_column is not None\n",
              "                                and fk._table_column.table is None\n",
              "                            ):\n",
              "                                raise exc.InvalidRequestError(\n",
              "                                    \"Columns with foreign keys to \"\n",
              "                                    \"non-table-bound \"\n",
              "                                    \"columns must be declared as \"\n",
              "                                    \"@declared_attr callables \"\n",
              "                                    \"on declarative mixin classes.  \"\n",
              "                                    \"For dataclass \"\n",
              "                                    \"field() objects, use a lambda:.\"\n",
              "                                )\n",
              "                    column_copies[obj] = copy_ = obj._copy()\n",
              "                    locally_collected_attributes[name] = copy_\n",
              "                    setattr(cls, name, copy_)\n",
              "        return locally_collected_attributes\n",
              "##--##    def _extract_mappable_attributes(self) -> None:\n",
              "        cls = self.cls\n",
              "        collected_attributes = self.collected_attributes\n",
              "        our_stuff = self.properties\n",
              "        _include_dunders = self._include_dunders\n",
              "        late_mapped = _get_immediate_cls_attr(\n",
              "            cls, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        )\n",
              "        allow_unmapped_annotations = self.allow_unmapped_annotations\n",
              "        expect_annotations_wo_mapped = (\n",
              "            allow_unmapped_annotations or self.is_dataclass_prior_to_mapping\n",
              "        )\n",
              "        look_for_dataclass_things = bool(self.dataclass_setup_arguments)\n",
              "        for k in list(collected_attributes):\n",
              "            if k in _include_dunders:\n",
              "                continue\n",
              "            value = collected_attributes[k]\n",
              "            if _is_declarative_props(value):\n",
              "                # @declared_attr in collected_attributes only occurs here for a\n",
              "                # @declared_attr that's directly on the mapped class;\n",
              "                # for a mixin, these have already been evaluated\n",
              "                if value._cascading:\n",
              "                    util.warn(\n",
              "                        \"Use of @declared_attr.cascading only applies to \"\n",
              "                        \"Declarative 'mixin' and 'abstract' classes.  \"\n",
              "                        \"Currently, this flag is ignored on mapped class \"\n",
              "                        \"%s\" % self.cls\n",
              "                    )\n",
              "                value = getattr(cls, k)\n",
              "            elif (\n",
              "                isinstance(value, QueryableAttribute)\n",
              "                and value.class_ is not cls\n",
              "                and value.key != k\n",
              "            ):\n",
              "                # detect a QueryableAttribute that's already mapped being\n",
              "                # assigned elsewhere in userland, turn into a synonym()\n",
              "                value = SynonymProperty(value.key)\n",
              "                setattr(cls, k, value)\n",
              "            if (\n",
              "                isinstance(value, tuple)\n",
              "                and len(value) == 1\n",
              "                and isinstance(value[0], (Column, _MappedAttribute))\n",
              "            ):\n",
              "                util.warn(\n",
              "                    \"Ignoring declarative-like tuple value of attribute \"\n",
              "                    \"'%s': possibly a copy-and-paste error with a comma \"\n",
              "                    \"accidentally placed at the end of the line?\" % k\n",
              "                )\n",
              "                continue\n",
              "            elif look_for_dataclass_things and isinstance(\n",
              "                value, dataclasses.Field\n",
              "            ):\n",
              "                # we collected a dataclass Field; dataclasses would have\n",
              "                # set up the correct state on the class\n",
              "                continue\n",
              "            elif not isinstance(value, (Column, _DCAttributeOptions)):\n",
              "                # using @declared_attr for some object that\n",
              "                # isn't Column/MapperProperty/_DCAttributeOptions; remove\n",
              "                # from the clsdict_view\n",
              "                # and place the evaluated value onto the class.\n",
              "                collected_attributes.pop(k)\n",
              "                self._warn_for_decl_attributes(cls, k, value)\n",
              "                if not late_mapped:\n",
              "                    setattr(cls, k, value)\n",
              "                continue\n",
              "            # we expect to see the name 'metadata' in some valid cases;\n",
              "            # however at this point we see it's assigned to something trying\n",
              "            # to be mapped, so raise for that.\n",
              "            # TODO: should \"registry\" here be also?   might be too late\n",
              "            # to change that now (2.0 betas)\n",
              "            elif k in (\"metadata\",):\n",
              "                raise exc.InvalidRequestError(\n",
              "                    f\"Attribute name '{k}' is reserved when using the \"\n",
              "                    \"Declarative API.\"\n",
              "                )\n",
              "            elif isinstance(value, Column):\n",
              "                _undefer_column_name(\n",
              "                    k, self.column_copies.get(value, value)  # type: ignore\n",
              "                )\n",
              "            else:\n",
              "                if isinstance(value, _IntrospectsAnnotations):\n",
              "                    (\n",
              "                        annotation,\n",
              "                        mapped_container,\n",
              "                        extracted_mapped_annotation,\n",
              "                        is_dataclass,\n",
              "                        attr_value,\n",
              "                        originating_module,\n",
              "                        originating_class,\n",
              "                    ) = self.collected_annotations.get(\n",
              "                        k, (None, None, None, False, None, None, None)\n",
              "                    )\n",
              "                    # issue #8692 - don't do any annotation interpretation if\n",
              "                    # an annotation were present and a container such as\n",
              "                    # Mapped[] etc. were not used.  If annotation is None,\n",
              "                    # do declarative_scan so that the property can raise\n",
              "                    # for required\n",
              "                    if (\n",
              "                        mapped_container is not None\n",
              "                        or annotation is None\n",
              "                        # issue #10516: need to do declarative_scan even with\n",
              "                        # a non-Mapped annotation if we are doing\n",
              "                        # __allow_unmapped__, for things like col.name\n",
              "                        # assignment\n",
              "                        or allow_unmapped_annotations\n",
              "                    ):\n",
              "                        try:\n",
              "                            value.declarative_scan(\n",
              "                                self,\n",
              "                                self.registry,\n",
              "                                cls,\n",
              "                                originating_module,\n",
              "                                k,\n",
              "                                mapped_container,\n",
              "                                annotation,\n",
              "                                extracted_mapped_annotation,\n",
              "                                is_dataclass,\n",
              "                            )\n",
              "                        except NameError as ne:\n",
              "                            raise exc.ArgumentError(\n",
              "                                f\"Could not resolve all types within mapped \"\n",
              "                                f'annotation: \"{annotation}\".  Ensure all '\n",
              "                                f\"types are written correctly and are \"\n",
              "                                f\"imported within the module in use.\"\n",
              "                            ) from ne\n",
              "                    else:\n",
              "                        # assert that we were expecting annotations\n",
              "                        # without Mapped[] were going to be passed.\n",
              "                        # otherwise an error should have been raised\n",
              "                        # by util._extract_mapped_subtype before we got here.\n",
              "                        assert expect_annotations_wo_mapped\n",
              "                if isinstance(value, _DCAttributeOptions):\n",
              "                    if (\n",
              "                        value._has_dataclass_arguments\n",
              "                        and not look_for_dataclass_things\n",
              "                    ):\n",
              "                        if isinstance(value, MapperProperty):\n",
              "                            argnames = [\n",
              "                                \"init\",\n",
              "                                \"default_factory\",\n",
              "                                \"repr\",\n",
              "                                \"default\",\n",
              "                            ]\n",
              "                        else:\n",
              "                            argnames = [\"init\", \"default_factory\", \"repr\"]\n",
              "                        args = {\n",
              "                            a\n",
              "                            for a in argnames\n",
              "                            if getattr(\n",
              "                                value._attribute_options, f\"dataclasses_{a}\"\n",
              "                            )\n",
              "                            is not _NoArg.NO_ARG\n",
              "                        }\n",
              "                        raise exc.ArgumentError(\n",
              "                            f\"Attribute '{k}' on class {cls} includes \"\n",
              "                            f\"dataclasses argument(s): \"\n",
              "                            f\"{', '.join(sorted(repr(a) for a in args))} but \"\n",
              "                            f\"class does not specify \"\n",
              "                            \"SQLAlchemy native dataclass configuration.\"\n",
              "                        )\n",
              "                    if not isinstance(value, (MapperProperty, _MapsColumns)):\n",
              "                        # filter for _DCAttributeOptions objects that aren't\n",
              "                        # MapperProperty / mapped_column().  Currently this\n",
              "                        # includes AssociationProxy.   pop it from the things\n",
              "                        # we're going to map and set it up as a descriptor\n",
              "                        # on the class.\n",
              "                        collected_attributes.pop(k)\n",
              "                        # Assoc Prox (or other descriptor object that may\n",
              "                        # use _DCAttributeOptions) is usually here, except if\n",
              "                        # 1. we're a\n",
              "                        # dataclass, dataclasses would have removed the\n",
              "                        # attr here or 2. assoc proxy is coming from a\n",
              "                        # superclass, we want it to be direct here so it\n",
              "                        # tracks state or 3. assoc prox comes from\n",
              "                        # declared_attr, uncommon case\n",
              "                        setattr(cls, k, value)\n",
              "                        continue\n",
              "            our_stuff[k] = value\n",
              "##--##    def _extract_declared_columns(self) -> None:\n",
              "        our_stuff = self.properties\n",
              "        # extract columns from the class dict\n",
              "        declared_columns = self.declared_columns\n",
              "        column_ordering = self.column_ordering\n",
              "        name_to_prop_key = collections.defaultdict(set)\n",
              "        for key, c in list(our_stuff.items()):\n",
              "            if isinstance(c, _MapsColumns):\n",
              "                mp_to_assign = c.mapper_property_to_assign\n",
              "                if mp_to_assign:\n",
              "                    our_stuff[key] = mp_to_assign\n",
              "                else:\n",
              "                    # if no mapper property to assign, this currently means\n",
              "                    # this is a MappedColumn that will produce a Column for us\n",
              "                    del our_stuff[key]\n",
              "                for col, sort_order in c.columns_to_assign:\n",
              "                    if not isinstance(c, CompositeProperty):\n",
              "                        name_to_prop_key[col.name].add(key)\n",
              "                    declared_columns.add(col)\n",
              "                    # we would assert this, however we want the below\n",
              "                    # warning to take effect instead.  See #9630\n",
              "                    # assert col not in column_ordering\n",
              "                    column_ordering[col] = sort_order\n",
              "                    # if this is a MappedColumn and the attribute key we\n",
              "                    # have is not what the column has for its key, map the\n",
              "                    # Column explicitly under the attribute key name.\n",
              "                    # otherwise, Mapper will map it under the column key.\n",
              "                    if mp_to_assign is None and key != col.key:\n",
              "                        our_stuff[key] = col\n",
              "            elif isinstance(c, Column):\n",
              "                # undefer previously occurred here, and now occurs earlier.\n",
              "                # ensure every column we get here has been named\n",
              "                assert c.name is not None\n",
              "                name_to_prop_key[c.name].add(key)\n",
              "                declared_columns.add(c)\n",
              "                # if the column is the same name as the key,\n",
              "                # remove it from the explicit properties dict.\n",
              "                # the normal rules for assigning column-based properties\n",
              "                # will take over, including precedence of columns\n",
              "                # in multi-column ColumnProperties.\n",
              "                if key == c.key:\n",
              "                    del our_stuff[key]\n",
              "        for name, keys in name_to_prop_key.items():\n",
              "            if len(keys) > 1:\n",
              "                util.warn(\n",
              "                    \"On class %r, Column object %r named \"\n",
              "                    \"directly multiple times, \"\n",
              "                    \"only one will be used: %s. \"\n",
              "                    \"Consider using orm.synonym instead\"\n",
              "                    % (self.classname, name, (\", \".join(sorted(keys))))\n",
              "                )\n",
              "##--##    def _setup_table(self, table: Optional[FromClause] = None) -> None:\n",
              "        cls = self.cls\n",
              "        cls_as_Decl = cast(\"MappedClassProtocol[Any]\", cls)\n",
              "        tablename = self.tablename\n",
              "        table_args = self.table_args\n",
              "        clsdict_view = self.clsdict_view\n",
              "        declared_columns = self.declared_columns\n",
              "        column_ordering = self.column_ordering\n",
              "        manager = attributes.manager_of_class(cls)\n",
              "        if \"__table__\" not in clsdict_view and table is None:\n",
              "            if hasattr(cls, \"__table_cls__\"):\n",
              "                table_cls = cast(\n",
              "                    Type[Table],\n",
              "                    util.unbound_method_to_callable(cls.__table_cls__),  # type: ignore  # noqa: E501\n",
              "                )\n",
              "            else:\n",
              "                table_cls = Table\n",
              "            if tablename is not None:\n",
              "                args: Tuple[Any, ...] = ()\n",
              "                table_kw: Dict[str, Any] = {}\n",
              "                if table_args:\n",
              "                    if isinstance(table_args, dict):\n",
              "                        table_kw = table_args\n",
              "                    elif isinstance(table_args, tuple):\n",
              "                        if isinstance(table_args[-1], dict):\n",
              "                            args, table_kw = table_args[0:-1], table_args[-1]\n",
              "                        else:\n",
              "                            args = table_args\n",
              "                autoload_with = clsdict_view.get(\"__autoload_with__\")\n",
              "                if autoload_with:\n",
              "                    table_kw[\"autoload_with\"] = autoload_with\n",
              "                autoload = clsdict_view.get(\"__autoload__\")\n",
              "                if autoload:\n",
              "                    table_kw[\"autoload\"] = True\n",
              "                sorted_columns = sorted(\n",
              "                    declared_columns,\n",
              "                    key=lambda c: column_ordering.get(c, 0),\n",
              "                )\n",
              "                table = self.set_cls_attribute(\n",
              "                    \"__table__\",\n",
              "                    table_cls(\n",
              "                        tablename,\n",
              "                        self._metadata_for_cls(manager),\n",
              "                        *sorted_columns,\n",
              "                        *args,\n",
              "                        **table_kw,\n",
              "                    ),\n",
              "                )\n",
              "        else:\n",
              "            if table is None:\n",
              "                table = cls_as_Decl.__table__\n",
              "            if declared_columns:\n",
              "                for c in declared_columns:\n",
              "                    if not table.c.contains_column(c):\n",
              "                        raise exc.ArgumentError(\n",
              "                            \"Can't add additional column %r when \"\n",
              "                            \"specifying __table__\" % c.key\n",
              "                        )\n",
              "        self.local_table = table\n",
              "##--##    def _metadata_for_cls(self, manager: ClassManager[Any]) -> MetaData:\n",
              "        meta: Optional[MetaData] = getattr(self.cls, \"metadata\", None)\n",
              "        if meta is not None:\n",
              "            return meta\n",
              "        else:\n",
              "            return manager.registry.metadata\n",
              "##--##    def _setup_inheriting_mapper(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        cls = self.cls\n",
              "        inherits = mapper_kw.get(\"inherits\", None)\n",
              "        if inherits is None:\n",
              "            # since we search for classical mappings now, search for\n",
              "            # multiple mapped bases as well and raise an error.\n",
              "            inherits_search = []\n",
              "            for base_ in cls.__bases__:\n",
              "                c = _resolve_for_abstract_or_classical(base_)\n",
              "                if c is None:\n",
              "                    continue\n",
              "                if _is_supercls_for_inherits(c) and c not in inherits_search:\n",
              "                    inherits_search.append(c)\n",
              "            if inherits_search:\n",
              "                if len(inherits_search) > 1:\n",
              "                    raise exc.InvalidRequestError(\n",
              "                        \"Class %s has multiple mapped bases: %r\"\n",
              "                        % (cls, inherits_search)\n",
              "                    )\n",
              "                inherits = inherits_search[0]\n",
              "        elif isinstance(inherits, Mapper):\n",
              "            inherits = inherits.class_\n",
              "        self.inherits = inherits\n",
              "        clsdict_view = self.clsdict_view\n",
              "        if \"__table__\" not in clsdict_view and self.tablename is None:\n",
              "            self.single = True\n",
              "##--##    def _setup_inheriting_columns(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        table = self.local_table\n",
              "        cls = self.cls\n",
              "        table_args = self.table_args\n",
              "        declared_columns = self.declared_columns\n",
              "        if (\n",
              "            table is None\n",
              "            and self.inherits is None\n",
              "            and not _get_immediate_cls_attr(cls, \"__no_table__\")\n",
              "        ):\n",
              "            raise exc.InvalidRequestError(\n",
              "                \"Class %r does not have a __table__ or __tablename__ \"\n",
              "                \"specified and does not inherit from an existing \"\n",
              "                \"table-mapped class.\" % cls\n",
              "            )\n",
              "        elif self.inherits:\n",
              "            inherited_mapper_or_config = _declared_mapping_info(self.inherits)\n",
              "            assert inherited_mapper_or_config is not None\n",
              "            inherited_table = inherited_mapper_or_config.local_table\n",
              "            inherited_persist_selectable = (\n",
              "                inherited_mapper_or_config.persist_selectable\n",
              "            )\n",
              "            if table is None:\n",
              "                # single table inheritance.\n",
              "                # ensure no table args\n",
              "                if table_args:\n",
              "                    raise exc.ArgumentError(\n",
              "                        \"Can't place __table_args__ on an inherited class \"\n",
              "                        \"with no table.\"\n",
              "                    )\n",
              "                # add any columns declared here to the inherited table.\n",
              "                if declared_columns and not isinstance(inherited_table, Table):\n",
              "                    raise exc.ArgumentError(\n",
              "                        f\"Can't declare columns on single-table-inherited \"\n",
              "                        f\"subclass {self.cls}; superclass {self.inherits} \"\n",
              "                        \"is not mapped to a Table\"\n",
              "                    )\n",
              "                for col in declared_columns:\n",
              "                    assert inherited_table is not None\n",
              "                    if col.name in inherited_table.c:\n",
              "                        if inherited_table.c[col.name] is col:\n",
              "                            continue\n",
              "                        raise exc.ArgumentError(\n",
              "                            f\"Column '{col}' on class {cls.__name__} \"\n",
              "                            f\"conflicts with existing column \"\n",
              "                            f\"'{inherited_table.c[col.name]}'.  If using \"\n",
              "                            f\"Declarative, consider using the \"\n",
              "                            \"use_existing_column parameter of mapped_column() \"\n",
              "                            \"to resolve conflicts.\"\n",
              "                        )\n",
              "                    if col.primary_key:\n",
              "                        raise exc.ArgumentError(\n",
              "                            \"Can't place primary key columns on an inherited \"\n",
              "                            \"class with no table.\"\n",
              "                        )\n",
              "                    if TYPE_CHECKING:\n",
              "                        assert isinstance(inherited_table, Table)\n",
              "                    inherited_table.append_column(col)\n",
              "                    if (\n",
              "                        inherited_persist_selectable is not None\n",
              "                        and inherited_persist_selectable is not inherited_table\n",
              "                    ):\n",
              "                        inherited_persist_selectable._refresh_for_new_column(\n",
              "                            col\n",
              "                        )\n",
              "##--##    def _prepare_mapper_arguments(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        properties = self.properties\n",
              "        if self.mapper_args_fn:\n",
              "            mapper_args = self.mapper_args_fn()\n",
              "        else:\n",
              "            mapper_args = {}\n",
              "        if mapper_kw:\n",
              "            mapper_args.update(mapper_kw)\n",
              "        if \"properties\" in mapper_args:\n",
              "            properties = dict(properties)\n",
              "            properties.update(mapper_args[\"properties\"])\n",
              "        # make sure that column copies are used rather\n",
              "        # than the original columns from any mixins\n",
              "        for k in (\"version_id_col\", \"polymorphic_on\"):\n",
              "            if k in mapper_args:\n",
              "                v = mapper_args[k]\n",
              "                mapper_args[k] = self.column_copies.get(v, v)\n",
              "        if \"primary_key\" in mapper_args:\n",
              "            mapper_args[\"primary_key\"] = [\n",
              "                self.column_copies.get(v, v)\n",
              "                for v in util.to_list(mapper_args[\"primary_key\"])\n",
              "            ]\n",
              "        if \"inherits\" in mapper_args:\n",
              "            inherits_arg = mapper_args[\"inherits\"]\n",
              "            if isinstance(inherits_arg, Mapper):\n",
              "                inherits_arg = inherits_arg.class_\n",
              "            if inherits_arg is not self.inherits:\n",
              "                raise exc.InvalidRequestError(\n",
              "                    \"mapper inherits argument given for non-inheriting \"\n",
              "                    \"class %s\" % (mapper_args[\"inherits\"])\n",
              "                )\n",
              "        if self.inherits:\n",
              "            mapper_args[\"inherits\"] = self.inherits\n",
              "        if self.inherits and not mapper_args.get(\"concrete\", False):\n",
              "            # note the superclass is expected to have a Mapper assigned and\n",
              "            # not be a deferred config, as this is called within map()\n",
              "            inherited_mapper = class_mapper(self.inherits, False)\n",
              "            inherited_table = inherited_mapper.local_table\n",
              "            # single or joined inheritance\n",
              "            # exclude any cols on the inherited table which are\n",
              "            # not mapped on the parent class, to avoid\n",
              "            # mapping columns specific to sibling/nephew classes\n",
              "            if \"exclude_properties\" not in mapper_args:\n",
              "                mapper_args[\"exclude_properties\"] = exclude_properties = {\n",
              "                    c.key\n",
              "                    for c in inherited_table.c\n",
              "                    if c not in inherited_mapper._columntoproperty\n",
              "                }.union(inherited_mapper.exclude_properties or ())\n",
              "                exclude_properties.difference_update(\n",
              "                    [c.key for c in self.declared_columns]\n",
              "                )\n",
              "            # look through columns in the current mapper that\n",
              "            # are keyed to a propname different than the colname\n",
              "            # (if names were the same, we'd have popped it out above,\n",
              "            # in which case the mapper makes this combination).\n",
              "            # See if the superclass has a similar column property.\n",
              "            # If so, join them together.\n",
              "            for k, col in list(properties.items()):\n",
              "                if not isinstance(col, expression.ColumnElement):\n",
              "                    continue\n",
              "                if k in inherited_mapper._props:\n",
              "                    p = inherited_mapper._props[k]\n",
              "                    if isinstance(p, ColumnProperty):\n",
              "                        # note here we place the subclass column\n",
              "                        # first.  See [ticket:1892] for background.\n",
              "                        properties[k] = [col] + p.columns\n",
              "        result_mapper_args = mapper_args.copy()\n",
              "        result_mapper_args[\"properties\"] = properties\n",
              "        self.mapper_args = result_mapper_args\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        self._prepare_mapper_arguments(mapper_kw)\n",
              "        if hasattr(self.cls, \"__mapper_cls__\"):\n",
              "            mapper_cls = cast(\n",
              "                \"Type[Mapper[Any]]\",\n",
              "                util.unbound_method_to_callable(\n",
              "                    self.cls.__mapper_cls__  # type: ignore\n",
              "                ),\n",
              "            )\n",
              "        else:\n",
              "            mapper_cls = Mapper\n",
              "        return self.set_cls_attribute(\n",
              "            \"__mapper__\",\n",
              "            mapper_cls(self.cls, self.local_table, **self.mapper_args),\n",
              "        )\n",
              "##--##@util.preload_module(\"sqlalchemy.orm.decl_api\")\n",
              "def _as_dc_declaredattr(\n",
              "    field_metadata: Mapping[str, Any], sa_dataclass_metadata_key: str\n",
              ") -> Any:\n",
              "    # wrap lambdas inside dataclass fields inside an ad-hoc declared_attr.\n",
              "    # we can't write it because field.metadata is immutable :( so we have\n",
              "    # to go through extra trouble to compare these\n",
              "    decl_api = util.preloaded.orm_decl_api\n",
              "    obj = field_metadata[sa_dataclass_metadata_key]\n",
              "    if callable(obj) and not isinstance(obj, decl_api.declared_attr):\n",
              "        return decl_api.declared_attr(obj)\n",
              "    else:\n",
              "        return obj\n",
              "##--##class _DeferredMapperConfig(_ClassScanMapperConfig):\n",
              "    _cls: weakref.ref[Type[Any]]\n",
              "    is_deferred = True\n",
              "    _configs: util.OrderedDict[\n",
              "        weakref.ref[Type[Any]], _DeferredMapperConfig\n",
              "    ] = util.OrderedDict()\n",
              "##--##    def _early_mapping(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        pass\n",
              "    # mypy disallows plain property override of variable\n",
              "##--##    @property  # type: ignore\n",
              "    def cls(self) -> Type[Any]:\n",
              "        return self._cls()  # type: ignore\n",
              "##--##    @cls.setter\n",
              "    def cls(self, class_: Type[Any]) -> None:\n",
              "        self._cls = weakref.ref(class_, self._remove_config_cls)\n",
              "        self._configs[self._cls] = self\n",
              "##--##    @classmethod\n",
              "    def _remove_config_cls(cls, ref: weakref.ref[Type[Any]]) -> None:\n",
              "        cls._configs.pop(ref, None)\n",
              "##--##    @classmethod\n",
              "    def has_cls(cls, class_: Type[Any]) -> bool:\n",
              "        # 2.6 fails on weakref if class_ is an old style class\n",
              "        return isinstance(class_, type) and weakref.ref(class_) in cls._configs\n",
              "##--##    @classmethod\n",
              "    def raise_unmapped_for_cls(cls, class_: Type[Any]) -> NoReturn:\n",
              "        if hasattr(class_, \"_sa_raise_deferred_config\"):\n",
              "            class_._sa_raise_deferred_config()\n",
              "        raise orm_exc.UnmappedClassError(\n",
              "            class_,\n",
              "            msg=(\n",
              "                f\"Class {orm_exc._safe_cls_name(class_)} has a deferred \"\n",
              "                \"mapping on it.  It is not yet usable as a mapped class.\"\n",
              "            ),\n",
              "        )\n",
              "##--##    @classmethod\n",
              "    def config_for_cls(cls, class_: Type[Any]) -> _DeferredMapperConfig:\n",
              "        return cls._configs[weakref.ref(class_)]\n",
              "##--##    @classmethod\n",
              "    def classes_for_base(\n",
              "        cls, base_cls: Type[Any], sort: bool = True\n",
              "    ) -> List[_DeferredMapperConfig]:\n",
              "        classes_for_base = [\n",
              "            m\n",
              "            for m, cls_ in [(m, m.cls) for m in cls._configs.values()]\n",
              "            if cls_ is not None and issubclass(cls_, base_cls)\n",
              "        ]\n",
              "        if not sort:\n",
              "            return classes_for_base\n",
              "        all_m_by_cls = {m.cls: m for m in classes_for_base}\n",
              "        tuples: List[Tuple[_DeferredMapperConfig, _DeferredMapperConfig]] = []\n",
              "        for m_cls in all_m_by_cls:\n",
              "            tuples.extend(\n",
              "                (all_m_by_cls[base_cls], all_m_by_cls[m_cls])\n",
              "                for base_cls in m_cls.__bases__\n",
              "                if base_cls in all_m_by_cls\n",
              "            )\n",
              "        return list(topological.sort(tuples, classes_for_base))\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        self._configs.pop(self._cls, None)\n",
              "        return super().map(mapper_kw)\n",
              "##--##def _add_attribute(\n",
              "    cls: Type[Any], key: str, value: MapperProperty[Any]\n",
              ") -> None:\n",
              "    \"\"\"add an attribute to an existing declarative class.\n",
              "    This runs through the logic to determine MapperProperty,\n",
              "    adds it to the Mapper, adds a column to the mapped Table, etc.\n",
              "    \"\"\"\n",
              "    if \"__mapper__\" in cls.__dict__:\n",
              "        mapped_cls = cast(\"MappedClassProtocol[Any]\", cls)\n",
              "##--##        def _table_or_raise(mc: MappedClassProtocol[Any]) -> Table:\n",
              "            if isinstance(mc.__table__, Table):\n",
              "                return mc.__table__\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Cannot add a new attribute to mapped class {mc.__name__!r} \"\n",
              "                \"because it's not mapped against a table.\"\n",
              "            )\n",
              "        if isinstance(value, Column):\n",
              "            _undefer_column_name(key, value)\n",
              "            _table_or_raise(mapped_cls).append_column(\n",
              "                value, replace_existing=True\n",
              "            )\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        elif isinstance(value, _MapsColumns):\n",
              "            mp = value.mapper_property_to_assign\n",
              "            for col, _ in value.columns_to_assign:\n",
              "                _undefer_column_name(key, col)\n",
              "                _table_or_raise(mapped_cls).append_column(\n",
              "                    col, replace_existing=True\n",
              "                )\n",
              "                if not mp:\n",
              "                    mapped_cls.__mapper__.add_property(key, col)\n",
              "            if mp:\n",
              "                mapped_cls.__mapper__.add_property(key, mp)\n",
              "        elif isinstance(value, MapperProperty):\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        elif isinstance(value, QueryableAttribute) and value.key != key:\n",
              "            # detect a QueryableAttribute that's already mapped being\n",
              "            # assigned elsewhere in userland, turn into a synonym()\n",
              "            value = SynonymProperty(value.key)\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        else:\n",
              "            type.__setattr__(cls, key, value)\n",
              "            mapped_cls.__mapper__._expire_memoizations()\n",
              "    else:\n",
              "        type.__setattr__(cls, key, value)\n",
              "##--##def _del_attribute(cls: Type[Any], key: str) -> None:\n",
              "    if (\n",
              "        \"__mapper__\" in cls.__dict__\n",
              "        and key in cls.__dict__\n",
              "        and not cast(\n",
              "            \"MappedClassProtocol[Any]\", cls\n",
              "        ).__mapper__._dispose_called\n",
              "    ):\n",
              "        value = cls.__dict__[key]\n",
              "        if isinstance(\n",
              "            value, (Column, _MapsColumns, MapperProperty, QueryableAttribute)\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"Can't un-map individual mapped attributes on a mapped class.\"\n",
              "            )\n",
              "        else:\n",
              "            type.__delattr__(cls, key)\n",
              "            cast(\n",
              "                \"MappedClassProtocol[Any]\", cls\n",
              "            ).__mapper__._expire_memoizations()\n",
              "    else:\n",
              "        type.__delattr__(cls, key)\n",
              "##--##def _declarative_constructor(self: Any, **kwargs: Any) -> None:\n",
              "    \"\"\"A simple constructor that allows initialization from kwargs.\n",
              "    Sets attributes on the constructed instance using the names and\n",
              "    values in ``kwargs``.\n",
              "    Only keys that are present as\n",
              "    attributes of the instance's class are allowed. These could be,\n",
              "    for example, any mapped columns or relationships.\n",
              "    \"\"\"\n",
              "    cls_ = type(self)\n",
              "    for k in kwargs:\n",
              "        if not hasattr(cls_, k):\n",
              "            raise TypeError(\n",
              "                \"%r is an invalid keyword argument for %s\" % (k, cls_.__name__)\n",
              "            )\n",
              "        setattr(self, k, kwargs[k])\n",
              "_declarative_constructor.__name__ = \"__init__\"\n",
              "##--##def _undefer_column_name(key: str, column: Column[Any]) -> None:\n",
              "    if column.key is None:\n",
              "        column.key = key\n",
              "    if column.name is None:\n",
              "        column.name = key</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка, как делится текст\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=0,\n",
        "    length_function=lambda x: num_tokens_from_string(x),\n",
        "    # предпочитать сепаратор сначала класса,потом декоратора, потом корневой функции пото остальные\n",
        "    separators=[\"##--##c\",\"##--##@\",\"##--##d\",\"##--##\",\"\\n\\n\", \"\\n\"]\n",
        ")\n",
        "\n",
        "for i,chunk in enumerate(splitter.split_text(text)):\n",
        "    # cleaned_text = re.sub(r'##--##', '', chunk)\n",
        "    cleaned_text = chunk\n",
        "    display(HTML(wrap(cleaned_text,f'{i}длина{num_tokens_from_string(cleaned_text)}')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Co2_1i4cd2el",
        "outputId": "00b89fdc-66b3-4455-cf7a-55a5d71aa708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[0длина291]===============</br><pre><code class=\"python\">Source code for sqlalchemy.orm.decl_base\n",
              "# orm/decl_base.py\n",
              "# Copyright (C) 2005-2024 the SQLAlchemy authors and contributors\n",
              "# <see AUTHORS file>\n",
              "#\n",
              "# This module is part of SQLAlchemy and is released under\n",
              "# the MIT License: https://www.opensource.org/licenses/mit-license.php\n",
              "\"\"\"Internal implementation for declarative.\"\"\"\n",
              "from __future__ import annotations\n",
              "import collections\n",
              "import dataclasses\n",
              "import re\n",
              "from typing import Any\n",
              "from typing import Callable\n",
              "from typing import cast\n",
              "from typing import Dict\n",
              "from typing import Iterable\n",
              "from typing import List\n",
              "from typing import Mapping\n",
              "from typing import NamedTuple\n",
              "from typing import NoReturn\n",
              "from typing import Optional\n",
              "from typing import Sequence\n",
              "from typing import Tuple\n",
              "from typing import Type\n",
              "from typing import TYPE_CHECKING\n",
              "from typing import TypeVar\n",
              "from typing import Union\n",
              "import weakref\n",
              "from . import attributes\n",
              "from . import clsregistry\n",
              "from . import exc as orm_exc\n",
              "from . import instrumentation\n",
              "from . import mapperlib\n",
              "from ._typing import _O\n",
              "from ._typing import attr_is_internal_proxy\n",
              "from .attributes import InstrumentedAttribute\n",
              "from .attributes import QueryableAttribute\n",
              "from .base import _is_mapped_class\n",
              "from .base import InspectionAttr\n",
              "from .descriptor_props import CompositeProperty\n",
              "from .descriptor_props import SynonymProperty\n",
              "from .interfaces import _AttributeOptions\n",
              "from .interfaces import _DCAttributeOptions</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[1длина295]===============</br><pre><code class=\"python\">from .interfaces import _IntrospectsAnnotations\n",
              "from .interfaces import _MappedAttribute\n",
              "from .interfaces import _MapsColumns\n",
              "from .interfaces import MapperProperty\n",
              "from .mapper import Mapper\n",
              "from .properties import ColumnProperty\n",
              "from .properties import MappedColumn\n",
              "from .util import _extract_mapped_subtype\n",
              "from .util import _is_mapped_annotation\n",
              "from .util import class_mapper\n",
              "from .util import de_stringify_annotation\n",
              "from .. import event\n",
              "from .. import exc\n",
              "from .. import util\n",
              "from ..sql import expression\n",
              "from ..sql.base import _NoArg\n",
              "from ..sql.schema import Column\n",
              "from ..sql.schema import Table\n",
              "from ..util import topological\n",
              "from ..util.typing import _AnnotationScanType\n",
              "from ..util.typing import is_fwd_ref\n",
              "from ..util.typing import is_literal\n",
              "from ..util.typing import Protocol\n",
              "from ..util.typing import TypedDict\n",
              "from ..util.typing import typing_get_args\n",
              "if TYPE_CHECKING:\n",
              "    from ._typing import _ClassDict\n",
              "    from ._typing import _RegistryType\n",
              "    from .base import Mapped\n",
              "    from .decl_api import declared_attr\n",
              "    from .instrumentation import ClassManager\n",
              "    from ..sql.elements import NamedColumn\n",
              "    from ..sql.schema import MetaData\n",
              "    from ..sql.selectable import FromClause\n",
              "_T = TypeVar(\"_T\", bound=Any)\n",
              "_MapperKwArgs = Mapping[str, Any]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>===============startchunk[2длина16]===============</br><pre><code class=\"python\">_TableArgsType = Union[Tuple[Any, ...], Dict[str, Any]]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[3длина202]===============</br><pre><code class=\"python\">##--##class MappedClassProtocol(Protocol[_O]):\n",
              "    \"\"\"A protocol representing a SQLAlchemy mapped class.\n",
              "    The protocol is generic on the type of class, use\n",
              "    ``MappedClassProtocol[Any]`` to allow any mapped class.\n",
              "    \"\"\"\n",
              "    __name__: str\n",
              "    __mapper__: Mapper[_O]\n",
              "    __table__: FromClause\n",
              "##--##    def __call__(self, **kw: Any) -> _O: ...\n",
              "##--##class _DeclMappedClassProtocol(MappedClassProtocol[_O], Protocol):\n",
              "    \"Internal more detailed version of ``MappedClassProtocol``.\"\n",
              "    metadata: MetaData\n",
              "    __tablename__: str\n",
              "    __mapper_args__: _MapperKwArgs\n",
              "    __table_args__: Optional[_TableArgsType]\n",
              "    _sa_apply_dc_transforms: Optional[_DataclassArguments]\n",
              "##--##    def __declare_first__(self) -> None: ...\n",
              "##--##    def __declare_last__(self) -> None: ...</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[4длина185]===============</br><pre><code class=\"python\">##--##class _DataclassArguments(TypedDict):\n",
              "    init: Union[_NoArg, bool]\n",
              "    repr: Union[_NoArg, bool]\n",
              "    eq: Union[_NoArg, bool]\n",
              "    order: Union[_NoArg, bool]\n",
              "    unsafe_hash: Union[_NoArg, bool]\n",
              "    match_args: Union[_NoArg, bool]\n",
              "    kw_only: Union[_NoArg, bool]\n",
              "    dataclass_callable: Union[_NoArg, Callable[..., Type[Any]]]\n",
              "##--##def _declared_mapping_info(\n",
              "    cls: Type[Any],\n",
              ") -> Optional[Union[_DeferredMapperConfig, Mapper[Any]]]:\n",
              "    # deferred mapping\n",
              "    if _DeferredMapperConfig.has_cls(cls):\n",
              "        return _DeferredMapperConfig.config_for_cls(cls)\n",
              "    # regular mapping\n",
              "    elif _is_mapped_class(cls):\n",
              "        return class_mapper(cls, configure=False)\n",
              "    else:\n",
              "        return None</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[5длина295]===============</br><pre><code class=\"python\">##--##def _is_supercls_for_inherits(cls: Type[Any]) -> bool:\n",
              "    \"\"\"return True if this class will be used as a superclass to set in\n",
              "    'inherits'.\n",
              "    This includes deferred mapper configs that aren't mapped yet, however does\n",
              "    not include classes with _sa_decl_prepare_nocascade (e.g.\n",
              "    ``AbstractConcreteBase``); these concrete-only classes are not set up as\n",
              "    \"inherits\" until after mappers are configured using\n",
              "    mapper._set_concrete_base()\n",
              "    \"\"\"\n",
              "    if _DeferredMapperConfig.has_cls(cls):\n",
              "        return not _get_immediate_cls_attr(\n",
              "            cls, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        )\n",
              "    # regular mapping\n",
              "    elif _is_mapped_class(cls):\n",
              "        return True\n",
              "    else:\n",
              "        return False\n",
              "##--##def _resolve_for_abstract_or_classical(cls: Type[Any]) -> Optional[Type[Any]]:\n",
              "    if cls is object:\n",
              "        return None\n",
              "    sup: Optional[Type[Any]]\n",
              "    if cls.__dict__.get(\"__abstract__\", False):\n",
              "        for base_ in cls.__bases__:\n",
              "            sup = _resolve_for_abstract_or_classical(base_)\n",
              "            if sup is not None:\n",
              "                return sup\n",
              "        else:\n",
              "            return None\n",
              "    else:\n",
              "        clsmanager = _dive_for_cls_manager(cls)\n",
              "        if clsmanager:\n",
              "            return clsmanager.class_\n",
              "        else:\n",
              "            return cls</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[6длина285]===============</br><pre><code class=\"python\">##--##def _get_immediate_cls_attr(\n",
              "    cls: Type[Any], attrname: str, strict: bool = False\n",
              ") -> Optional[Any]:\n",
              "    \"\"\"return an attribute of the class that is either present directly\n",
              "    on the class, e.g. not on a superclass, or is from a superclass but\n",
              "    this superclass is a non-mapped mixin, that is, not a descendant of\n",
              "    the declarative base and is also not classically mapped.\n",
              "    This is used to detect attributes that indicate something about\n",
              "    a mapped class independently from any mapped classes that it may\n",
              "    inherit from.\n",
              "    \"\"\"\n",
              "    # the rules are different for this name than others,\n",
              "    # make sure we've moved it out.  transitional\n",
              "    assert attrname != \"__abstract__\"\n",
              "    if not issubclass(cls, object):\n",
              "        return None\n",
              "    if attrname in cls.__dict__:\n",
              "        return getattr(cls, attrname)\n",
              "    for base in cls.__mro__[1:]:\n",
              "        _is_classical_inherits = _dive_for_cls_manager(base) is not None\n",
              "        if attrname in base.__dict__ and (\n",
              "            base is cls\n",
              "            or (\n",
              "                (base in cls.__bases__ if strict else True)\n",
              "                and not _is_classical_inherits\n",
              "            )\n",
              "        ):\n",
              "            return getattr(base, attrname)\n",
              "    else:\n",
              "        return None</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[7длина259]===============</br><pre><code class=\"python\">##--##def _dive_for_cls_manager(cls: Type[_O]) -> Optional[ClassManager[_O]]:\n",
              "    # because the class manager registration is pluggable,\n",
              "    # we need to do the search for every class in the hierarchy,\n",
              "    # rather than just a simple \"cls._sa_class_manager\"\n",
              "    for base in cls.__mro__:\n",
              "        manager: Optional[ClassManager[_O]] = attributes.opt_manager_of_class(\n",
              "            base\n",
              "        )\n",
              "        if manager:\n",
              "            return manager\n",
              "    return None\n",
              "##--##def _as_declarative(\n",
              "    registry: _RegistryType, cls: Type[Any], dict_: _ClassDict\n",
              ") -> Optional[_MapperConfig]:\n",
              "    # declarative scans the class for attributes.  no table or mapper\n",
              "    # args passed separately.\n",
              "    return _MapperConfig.setup_mapping(registry, cls, dict_, None, {})\n",
              "##--##def _mapper(\n",
              "    registry: _RegistryType,\n",
              "    cls: Type[_O],\n",
              "    table: Optional[FromClause],\n",
              "    mapper_kw: _MapperKwArgs,\n",
              ") -> Mapper[_O]:\n",
              "    _ImperativeMapperConfig(registry, cls, table, mapper_kw)\n",
              "    return cast(\"MappedClassProtocol[_O]\", cls).__mapper__</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[8длина178]===============</br><pre><code class=\"python\">##--##@util.preload_module(\"sqlalchemy.orm.decl_api\")\n",
              "def _is_declarative_props(obj: Any) -> bool:\n",
              "    _declared_attr_common = util.preloaded.orm_decl_api._declared_attr_common\n",
              "    return isinstance(obj, (_declared_attr_common, util.classproperty))\n",
              "##--##def _check_declared_props_nocascade(\n",
              "    obj: Any, name: str, cls: Type[_O]\n",
              ") -> bool:\n",
              "    if _is_declarative_props(obj):\n",
              "        if getattr(obj, \"_cascading\", False):\n",
              "            util.warn(\n",
              "                \"@declared_attr.cascading is not supported on the %s \"\n",
              "                \"attribute on class %s.  This attribute invokes for \"\n",
              "                \"subclasses in any case.\" % (name, cls)\n",
              "            )\n",
              "        return True\n",
              "    else:\n",
              "        return False</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>===============startchunk[9длина99]===============</br><pre><code class=\"python\">##--##class _MapperConfig:\n",
              "    __slots__ = (\n",
              "        \"cls\",\n",
              "        \"classname\",\n",
              "        \"properties\",\n",
              "        \"declared_attr_reg\",\n",
              "        \"__weakref__\",\n",
              "    )\n",
              "    cls: Type[Any]\n",
              "    classname: str\n",
              "    properties: util.OrderedDict[\n",
              "        str,\n",
              "        Union[\n",
              "            Sequence[NamedColumn[Any]], NamedColumn[Any], MapperProperty[Any]\n",
              "        ],\n",
              "    ]\n",
              "    declared_attr_reg: Dict[declared_attr[Any], Any]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[10длина214]==============</br><pre><code class=\"python\">##--##    @classmethod\n",
              "    def setup_mapping(\n",
              "        cls,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        dict_: _ClassDict,\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ) -> Optional[_MapperConfig]:\n",
              "        manager = attributes.opt_manager_of_class(cls)\n",
              "        if manager and manager.class_ is cls_:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Class {cls!r} already has been instrumented declaratively\"\n",
              "            )\n",
              "        if cls_.__dict__.get(\"__abstract__\", False):\n",
              "            return None\n",
              "        defer_map = _get_immediate_cls_attr(\n",
              "            cls_, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        ) or hasattr(cls_, \"_sa_decl_prepare\")\n",
              "        if defer_map:\n",
              "            return _DeferredMapperConfig(\n",
              "                registry, cls_, dict_, table, mapper_kw\n",
              "            )\n",
              "        else:\n",
              "            return _ClassScanMapperConfig(\n",
              "                registry, cls_, dict_, table, mapper_kw\n",
              "            )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[11длина294]==============</br><pre><code class=\"python\">##--##    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[Any],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        self.cls = util.assert_arg_type(cls_, type, \"cls_\")\n",
              "        self.classname = cls_.__name__\n",
              "        self.properties = util.OrderedDict()\n",
              "        self.declared_attr_reg = {}\n",
              "        if not mapper_kw.get(\"non_primary\", False):\n",
              "            instrumentation.register_class(\n",
              "                self.cls,\n",
              "                finalize=False,\n",
              "                registry=registry,\n",
              "                declarative_scan=self,\n",
              "                init_method=registry.constructor,\n",
              "            )\n",
              "        else:\n",
              "            manager = attributes.opt_manager_of_class(self.cls)\n",
              "            if not manager or not manager.is_mapped:\n",
              "                raise exc.InvalidRequestError(\n",
              "                    \"Class %s has no primary mapper configured.  Configure \"\n",
              "                    \"a primary mapper first before setting up a non primary \"\n",
              "                    \"Mapper.\" % self.cls\n",
              "                )\n",
              "##--##    def set_cls_attribute(self, attrname: str, value: _T) -> _T:\n",
              "        manager = instrumentation.manager_of_class(self.cls)\n",
              "        manager.install_member(attrname, value)\n",
              "        return value\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = ...) -> Mapper[Any]:\n",
              "        raise NotImplementedError()\n",
              "##--##    def _early_mapping(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        self.map(mapper_kw)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[12длина218]==============</br><pre><code class=\"python\">##--##class _ImperativeMapperConfig(_MapperConfig):\n",
              "    __slots__ = (\"local_table\", \"inherits\")\n",
              "##--##    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        super().__init__(registry, cls_, mapper_kw)\n",
              "        self.local_table = self.set_cls_attribute(\"__table__\", table)\n",
              "        with mapperlib._CONFIGURE_MUTEX:\n",
              "            if not mapper_kw.get(\"non_primary\", False):\n",
              "                clsregistry.add_class(\n",
              "                    self.classname, self.cls, registry._class_registry\n",
              "                )\n",
              "            self._setup_inheritance(mapper_kw)\n",
              "            self._early_mapping(mapper_kw)\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        mapper_cls = Mapper\n",
              "        return self.set_cls_attribute(\n",
              "            \"__mapper__\",\n",
              "            mapper_cls(self.cls, self.local_table, **mapper_kw),\n",
              "        )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[13длина205]==============</br><pre><code class=\"python\">##--##    def _setup_inheritance(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        cls = self.cls\n",
              "        inherits = mapper_kw.get(\"inherits\", None)\n",
              "        if inherits is None:\n",
              "            # since we search for classical mappings now, search for\n",
              "            # multiple mapped bases as well and raise an error.\n",
              "            inherits_search = []\n",
              "            for base_ in cls.__bases__:\n",
              "                c = _resolve_for_abstract_or_classical(base_)\n",
              "                if c is None:\n",
              "                    continue\n",
              "                if _is_supercls_for_inherits(c) and c not in inherits_search:\n",
              "                    inherits_search.append(c)\n",
              "            if inherits_search:\n",
              "                if len(inherits_search) > 1:\n",
              "                    raise exc.InvalidRequestError(\n",
              "                        \"Class %s has multiple mapped bases: %r\"\n",
              "                        % (cls, inherits_search)\n",
              "                    )\n",
              "                inherits = inherits_search[0]\n",
              "        elif isinstance(inherits, Mapper):\n",
              "            inherits = inherits.class_\n",
              "        self.inherits = inherits</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[14длина71]===============</br><pre><code class=\"python\">##--##class _CollectedAnnotation(NamedTuple):\n",
              "    raw_annotation: _AnnotationScanType\n",
              "    mapped_container: Optional[Type[Mapped[Any]]]\n",
              "    extracted_mapped_annotation: Union[Type[Any], str]\n",
              "    is_dataclass: bool\n",
              "    attr_value: Any\n",
              "    originating_module: str\n",
              "    originating_class: Type[Any]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[15длина262]==============</br><pre><code class=\"python\">##--##class _ClassScanMapperConfig(_MapperConfig):\n",
              "    __slots__ = (\n",
              "        \"registry\",\n",
              "        \"clsdict_view\",\n",
              "        \"collected_attributes\",\n",
              "        \"collected_annotations\",\n",
              "        \"local_table\",\n",
              "        \"persist_selectable\",\n",
              "        \"declared_columns\",\n",
              "        \"column_ordering\",\n",
              "        \"column_copies\",\n",
              "        \"table_args\",\n",
              "        \"tablename\",\n",
              "        \"mapper_args\",\n",
              "        \"mapper_args_fn\",\n",
              "        \"inherits\",\n",
              "        \"single\",\n",
              "        \"allow_dataclass_fields\",\n",
              "        \"dataclass_setup_arguments\",\n",
              "        \"is_dataclass_prior_to_mapping\",\n",
              "        \"allow_unmapped_annotations\",\n",
              "    )\n",
              "    is_deferred = False\n",
              "    registry: _RegistryType\n",
              "    clsdict_view: _ClassDict\n",
              "    collected_annotations: Dict[str, _CollectedAnnotation]\n",
              "    collected_attributes: Dict[str, Any]\n",
              "    local_table: Optional[FromClause]\n",
              "    persist_selectable: Optional[FromClause]\n",
              "    declared_columns: util.OrderedSet[Column[Any]]\n",
              "    column_ordering: Dict[Column[Any], int]\n",
              "    column_copies: Dict[\n",
              "        Union[MappedColumn[Any], Column[Any]],\n",
              "        Union[MappedColumn[Any], Column[Any]],\n",
              "    ]\n",
              "    tablename: Optional[str]\n",
              "    mapper_args: Mapping[str, Any]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[16длина127]==============</br><pre><code class=\"python\">table_args: Optional[_TableArgsType]\n",
              "    mapper_args_fn: Optional[Callable[[], Dict[str, Any]]]\n",
              "    inherits: Optional[Type[Any]]\n",
              "    single: bool\n",
              "    is_dataclass_prior_to_mapping: bool\n",
              "    allow_unmapped_annotations: bool\n",
              "    dataclass_setup_arguments: Optional[_DataclassArguments]\n",
              "    \"\"\"if the class has SQLAlchemy native dataclass parameters, where\n",
              "    we will turn the class into a dataclass within the declarative mapping\n",
              "    process.\n",
              "    \"\"\"\n",
              "    allow_dataclass_fields: bool\n",
              "    \"\"\"if true, look for dataclass-processed Field objects on the target</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[17длина50]===============</br><pre><code class=\"python\">##--##    class as well as superclasses and extract ORM mapping directives from\n",
              "    the \"metadata\" attribute of each Field.\n",
              "    if False, dataclass fields can still be used, however they won't be\n",
              "    mapped.\n",
              "    \"\"\"</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[18длина266]==============</br><pre><code class=\"python\">##--##    def __init__(\n",
              "        self,\n",
              "        registry: _RegistryType,\n",
              "        cls_: Type[_O],\n",
              "        dict_: _ClassDict,\n",
              "        table: Optional[FromClause],\n",
              "        mapper_kw: _MapperKwArgs,\n",
              "    ):\n",
              "        # grab class dict before the instrumentation manager has been added.\n",
              "        # reduces cycles\n",
              "        self.clsdict_view = (\n",
              "            util.immutabledict(dict_) if dict_ else util.EMPTY_DICT\n",
              "        )\n",
              "        super().__init__(registry, cls_, mapper_kw)\n",
              "        self.registry = registry\n",
              "        self.persist_selectable = None\n",
              "        self.collected_attributes = {}\n",
              "        self.collected_annotations = {}\n",
              "        self.declared_columns = util.OrderedSet()\n",
              "        self.column_ordering = {}\n",
              "        self.column_copies = {}\n",
              "        self.single = False\n",
              "        self.dataclass_setup_arguments = dca = getattr(\n",
              "            self.cls, \"_sa_apply_dc_transforms\", None\n",
              "        )\n",
              "        self.allow_unmapped_annotations = getattr(\n",
              "            self.cls, \"__allow_unmapped__\", False\n",
              "        ) or bool(self.dataclass_setup_arguments)\n",
              "        self.is_dataclass_prior_to_mapping = cld = dataclasses.is_dataclass(\n",
              "            cls_\n",
              "        )\n",
              "        sdk = _get_immediate_cls_attr(cls_, \"__sa_dataclass_metadata_key__\")</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[19длина276]==============</br><pre><code class=\"python\"># we don't want to consume Field objects from a not-already-dataclass.\n",
              "        # the Field objects won't have their \"name\" or \"type\" populated,\n",
              "        # and while it seems like we could just set these on Field as we\n",
              "        # read them, Field is documented as \"user read only\" and we need to\n",
              "        # stay far away from any off-label use of dataclasses APIs.\n",
              "        if (not cld or dca) and sdk:\n",
              "            raise exc.InvalidRequestError(\n",
              "                \"SQLAlchemy mapped dataclasses can't consume mapping \"\n",
              "                \"information from dataclass.Field() objects if the immediate \"\n",
              "                \"class is not already a dataclass.\"\n",
              "            )\n",
              "        # if already a dataclass, and __sa_dataclass_metadata_key__ present,\n",
              "        # then also look inside of dataclass.Field() objects yielded by\n",
              "        # dataclasses.get_fields(cls) when scanning for attributes\n",
              "        self.allow_dataclass_fields = bool(sdk and cld)\n",
              "        self._setup_declared_events()\n",
              "        self._scan_attributes()\n",
              "        self._setup_dataclasses_transforms()\n",
              "        with mapperlib._CONFIGURE_MUTEX:\n",
              "            clsregistry.add_class(\n",
              "                self.classname, self.cls, registry._class_registry\n",
              "            )\n",
              "            self._setup_inheriting_mapper(mapper_kw)\n",
              "            self._extract_mappable_attributes()</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[20длина35]===============</br><pre><code class=\"python\">self._extract_declared_columns()\n",
              "            self._setup_table(table)\n",
              "            self._setup_inheriting_columns(mapper_kw)\n",
              "            self._early_mapping(mapper_kw)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[21длина255]==============</br><pre><code class=\"python\">##--##    def _setup_declared_events(self) -> None:\n",
              "        if _get_immediate_cls_attr(self.cls, \"__declare_last__\"):\n",
              "##--##            @event.listens_for(Mapper, \"after_configured\")\n",
              "            def after_configured() -> None:\n",
              "                cast(\n",
              "                    \"_DeclMappedClassProtocol[Any]\", self.cls\n",
              "                ).__declare_last__()\n",
              "        if _get_immediate_cls_attr(self.cls, \"__declare_first__\"):\n",
              "##--##            @event.listens_for(Mapper, \"before_configured\")\n",
              "            def before_configured() -> None:\n",
              "                cast(\n",
              "                    \"_DeclMappedClassProtocol[Any]\", self.cls\n",
              "                ).__declare_first__()\n",
              "##--##    def _cls_attr_override_checker(\n",
              "        self, cls: Type[_O]\n",
              "    ) -> Callable[[str, Any], bool]:\n",
              "        \"\"\"Produce a function that checks if a class has overridden an\n",
              "        attribute, taking SQLAlchemy-enabled dataclass fields into account.\n",
              "        \"\"\"\n",
              "        if self.allow_dataclass_fields:\n",
              "            sa_dataclass_metadata_key = _get_immediate_cls_attr(\n",
              "                cls, \"__sa_dataclass_metadata_key__\"\n",
              "            )\n",
              "        else:\n",
              "            sa_dataclass_metadata_key = None\n",
              "        if not sa_dataclass_metadata_key:</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[22длина128]==============</br><pre><code class=\"python\">##--##            def attribute_is_overridden(key: str, obj: Any) -> bool:\n",
              "                return getattr(cls, key, obj) is not obj\n",
              "        else:\n",
              "            all_datacls_fields = {\n",
              "                f.name: f.metadata[sa_dataclass_metadata_key]\n",
              "                for f in util.dataclass_fields(cls)\n",
              "                if sa_dataclass_metadata_key in f.metadata\n",
              "            }\n",
              "            local_datacls_fields = {\n",
              "                f.name: f.metadata[sa_dataclass_metadata_key]\n",
              "                for f in util.local_dataclass_fields(cls)\n",
              "                if sa_dataclass_metadata_key in f.metadata\n",
              "            }\n",
              "            absent = object()</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[23длина282]==============</br><pre><code class=\"python\">##--##            def attribute_is_overridden(key: str, obj: Any) -> bool:\n",
              "                if _is_declarative_props(obj):\n",
              "                    obj = obj.fget\n",
              "                # this function likely has some failure modes still if\n",
              "                # someone is doing a deep mixing of the same attribute\n",
              "                # name as plain Python attribute vs. dataclass field.\n",
              "                ret = local_datacls_fields.get(key, absent)\n",
              "                if _is_declarative_props(ret):\n",
              "                    ret = ret.fget\n",
              "                if ret is obj:\n",
              "                    return False\n",
              "                elif ret is not absent:\n",
              "                    return True\n",
              "                all_field = all_datacls_fields.get(key, absent)\n",
              "                ret = getattr(cls, key, obj)\n",
              "                if ret is obj:\n",
              "                    return False\n",
              "                # for dataclasses, this could be the\n",
              "                # 'default' of the field.  so filter more specifically\n",
              "                # for an already-mapped InstrumentedAttribute\n",
              "                if ret is not absent and isinstance(\n",
              "                    ret, InstrumentedAttribute\n",
              "                ):\n",
              "                    return True\n",
              "                if all_field is obj:\n",
              "                    return False\n",
              "                elif all_field is not absent:\n",
              "                    return True\n",
              "                # can't find another attribute\n",
              "                return False\n",
              "        return attribute_is_overridden\n",
              "    _include_dunders = {\n",
              "        \"__table__\",\n",
              "        \"__mapper_args__\",\n",
              "        \"__tablename__\",</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[24длина26]===============</br><pre><code class=\"python\">\"__table_args__\",\n",
              "    }\n",
              "    _match_exclude_dunders = re.compile(r\"^(?:_sa_|__)\")</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[25длина226]==============</br><pre><code class=\"python\">##--##    def _cls_attr_resolver(\n",
              "        self, cls: Type[Any]\n",
              "    ) -> Callable[[], Iterable[Tuple[str, Any, Any, bool]]]:\n",
              "        \"\"\"produce a function to iterate the \"attributes\" of a class\n",
              "        which we want to consider for mapping, adjusting for SQLAlchemy fields\n",
              "        embedded in dataclass fields.\n",
              "        \"\"\"\n",
              "        cls_annotations = util.get_annotations(cls)\n",
              "        cls_vars = vars(cls)\n",
              "        _include_dunders = self._include_dunders\n",
              "        _match_exclude_dunders = self._match_exclude_dunders\n",
              "        names = [\n",
              "            n\n",
              "            for n in util.merge_lists_w_ordering(\n",
              "                list(cls_vars), list(cls_annotations)\n",
              "            )\n",
              "            if not _match_exclude_dunders.match(n) or n in _include_dunders\n",
              "        ]\n",
              "        if self.allow_dataclass_fields:\n",
              "            sa_dataclass_metadata_key: Optional[str] = _get_immediate_cls_attr(\n",
              "                cls, \"__sa_dataclass_metadata_key__\"\n",
              "            )\n",
              "        else:\n",
              "            sa_dataclass_metadata_key = None\n",
              "        if not sa_dataclass_metadata_key:</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[26длина217]==============</br><pre><code class=\"python\">##--##            def local_attributes_for_class() -> (\n",
              "                Iterable[Tuple[str, Any, Any, bool]]\n",
              "            ):\n",
              "                return (\n",
              "                    (\n",
              "                        name,\n",
              "                        cls_vars.get(name),\n",
              "                        cls_annotations.get(name),\n",
              "                        False,\n",
              "                    )\n",
              "                    for name in names\n",
              "                )\n",
              "        else:\n",
              "            dataclass_fields = {\n",
              "                field.name: field for field in util.local_dataclass_fields(cls)\n",
              "            }\n",
              "            fixed_sa_dataclass_metadata_key = sa_dataclass_metadata_key\n",
              "##--##            def local_attributes_for_class() -> (\n",
              "                Iterable[Tuple[str, Any, Any, bool]]\n",
              "            ):\n",
              "                for name in names:\n",
              "                    field = dataclass_fields.get(name, None)\n",
              "                    if field and sa_dataclass_metadata_key in field.metadata:\n",
              "                        yield field.name, _as_dc_declaredattr(\n",
              "                            field.metadata, fixed_sa_dataclass_metadata_key\n",
              "                        ), cls_annotations.get(field.name), True\n",
              "                    else:\n",
              "                        yield name, cls_vars.get(name), cls_annotations.get(\n",
              "                            name\n",
              "                        ), False\n",
              "        return local_attributes_for_class</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[27длина279]==============</br><pre><code class=\"python\">##--##    def _scan_attributes(self) -> None:\n",
              "        cls = self.cls\n",
              "        cls_as_Decl = cast(\"_DeclMappedClassProtocol[Any]\", cls)\n",
              "        clsdict_view = self.clsdict_view\n",
              "        collected_attributes = self.collected_attributes\n",
              "        column_copies = self.column_copies\n",
              "        _include_dunders = self._include_dunders\n",
              "        mapper_args_fn = None\n",
              "        table_args = inherited_table_args = None\n",
              "        tablename = None\n",
              "        fixed_table = \"__table__\" in clsdict_view\n",
              "        attribute_is_overridden = self._cls_attr_override_checker(self.cls)\n",
              "        bases = []\n",
              "        for base in cls.__mro__:\n",
              "            # collect bases and make sure standalone columns are copied\n",
              "            # to be the column they will ultimately be on the class,\n",
              "            # so that declared_attr functions use the right columns.\n",
              "            # need to do this all the way up the hierarchy first\n",
              "            # (see #8190)\n",
              "            class_mapped = base is not cls and _is_supercls_for_inherits(base)\n",
              "            local_attributes_for_class = self._cls_attr_resolver(base)\n",
              "            if not class_mapped and base is not cls:\n",
              "                locally_collected_columns = self._produce_column_copies(\n",
              "                    local_attributes_for_class,\n",
              "                    attribute_is_overridden,\n",
              "                    fixed_table,\n",
              "                    base,\n",
              "                )\n",
              "            else:</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[28длина265]==============</br><pre><code class=\"python\">locally_collected_columns = {}\n",
              "            bases.append(\n",
              "                (\n",
              "                    base,\n",
              "                    class_mapped,\n",
              "                    local_attributes_for_class,\n",
              "                    locally_collected_columns,\n",
              "                )\n",
              "            )\n",
              "        for (\n",
              "            base,\n",
              "            class_mapped,\n",
              "            local_attributes_for_class,\n",
              "            locally_collected_columns,\n",
              "        ) in bases:\n",
              "            # this transfer can also take place as we scan each name\n",
              "            # for finer-grained control of how collected_attributes is\n",
              "            # populated, as this is what impacts column ordering.\n",
              "            # however it's simpler to get it out of the way here.\n",
              "            collected_attributes.update(locally_collected_columns)\n",
              "            for (\n",
              "                name,\n",
              "                obj,\n",
              "                annotation,\n",
              "                is_dataclass_field,\n",
              "            ) in local_attributes_for_class():\n",
              "                if name in _include_dunders:\n",
              "                    if name == \"__mapper_args__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not mapper_args_fn and (\n",
              "                            not class_mapped or check_decl\n",
              "                        ):\n",
              "                            # don't even invoke __mapper_args__ until\n",
              "                            # after we've determined everything about the\n",
              "                            # mapped table.\n",
              "                            # make a copy of it so a class-level dictionary\n",
              "                            # is not overwritten when we update column-based\n",
              "                            # arguments.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[29длина270]==============</br><pre><code class=\"python\">##--##                            def _mapper_args_fn() -> Dict[str, Any]:\n",
              "                                return dict(cls_as_Decl.__mapper_args__)\n",
              "                            mapper_args_fn = _mapper_args_fn\n",
              "                    elif name == \"__tablename__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not tablename and (not class_mapped or check_decl):\n",
              "                            tablename = cls_as_Decl.__tablename__\n",
              "                    elif name == \"__table_args__\":\n",
              "                        check_decl = _check_declared_props_nocascade(\n",
              "                            obj, name, cls\n",
              "                        )\n",
              "                        if not table_args and (not class_mapped or check_decl):\n",
              "                            table_args = cls_as_Decl.__table_args__\n",
              "                            if not isinstance(\n",
              "                                table_args, (tuple, dict, type(None))\n",
              "                            ):\n",
              "                                raise exc.ArgumentError(\n",
              "                                    \"__table_args__ value must be a tuple, \"\n",
              "                                    \"dict, or None\"\n",
              "                                )\n",
              "                            if base is not cls:\n",
              "                                inherited_table_args = True\n",
              "                    else:\n",
              "                        # skip all other dunder names, which at the moment\n",
              "                        # should only be __table__\n",
              "                        continue\n",
              "                elif class_mapped:\n",
              "                    if _is_declarative_props(obj) and not obj._quiet:\n",
              "                        util.warn(\n",
              "                            \"Regular (i.e. not __special__) \"</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[30длина273]==============</br><pre><code class=\"python\">\"attribute '%s.%s' uses @declared_attr, \"\n",
              "                            \"but owning class %s is mapped - \"\n",
              "                            \"not applying to subclass %s.\"\n",
              "                            % (base.__name__, name, base, cls)\n",
              "                        )\n",
              "                    continue\n",
              "                elif base is not cls:\n",
              "                    # we're a mixin, abstract base, or something that is\n",
              "                    # acting like that for now.\n",
              "                    if isinstance(obj, (Column, MappedColumn)):\n",
              "                        # already copied columns to the mapped class.\n",
              "                        continue\n",
              "                    elif isinstance(obj, MapperProperty):\n",
              "                        raise exc.InvalidRequestError(\n",
              "                            \"Mapper properties (i.e. deferred,\"\n",
              "                            \"column_property(), relationship(), etc.) must \"\n",
              "                            \"be declared as @declared_attr callables \"\n",
              "                            \"on declarative mixin classes.  For dataclass \"\n",
              "                            \"field() objects, use a lambda:\"\n",
              "                        )\n",
              "                    elif _is_declarative_props(obj):\n",
              "                        # tried to get overloads to tell this to\n",
              "                        # pylance, no luck\n",
              "                        assert obj is not None\n",
              "                        if obj._cascading:\n",
              "                            if name in clsdict_view:\n",
              "                                # unfortunately, while we can use the user-\n",
              "                                # defined attribute here to allow a clean\n",
              "                                # override, if there's another\n",
              "                                # subclass below then it still tries to use</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[31длина272]==============</br><pre><code class=\"python\"># this.  not sure if there is enough\n",
              "                                # information here to add this as a feature\n",
              "                                # later on.\n",
              "                                util.warn(\n",
              "                                    \"Attribute '%s' on class %s cannot be \"\n",
              "                                    \"processed due to \"\n",
              "                                    \"@declared_attr.cascading; \"\n",
              "                                    \"skipping\" % (name, cls)\n",
              "                                )\n",
              "                            collected_attributes[name] = column_copies[obj] = (\n",
              "                                ret\n",
              "                            ) = obj.__get__(obj, cls)\n",
              "                            setattr(cls, name, ret)\n",
              "                        else:\n",
              "                            if is_dataclass_field:\n",
              "                                # access attribute using normal class access\n",
              "                                # first, to see if it's been mapped on a\n",
              "                                # superclass.   note if the dataclasses.field()\n",
              "                                # has \"default\", this value can be anything.\n",
              "                                ret = getattr(cls, name, None)\n",
              "                                # so, if it's anything that's not ORM\n",
              "                                # mapped, assume we should invoke the\n",
              "                                # declared_attr\n",
              "                                if not isinstance(ret, InspectionAttr):\n",
              "                                    ret = obj.fget()\n",
              "                            else:\n",
              "                                # access attribute using normal class access.\n",
              "                                # if the declared attr already took place\n",
              "                                # on a superclass that is mapped, then\n",
              "                                # this is no longer a declared_attr, it will\n",
              "                                # be the InstrumentedAttribute</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[32длина261]==============</br><pre><code class=\"python\">ret = getattr(cls, name)\n",
              "                            # correct for proxies created from hybrid_property\n",
              "                            # or similar.  note there is no known case that\n",
              "                            # produces nested proxies, so we are only\n",
              "                            # looking one level deep right now.\n",
              "                            if (\n",
              "                                isinstance(ret, InspectionAttr)\n",
              "                                and attr_is_internal_proxy(ret)\n",
              "                                and not isinstance(\n",
              "                                    ret.original_property, MapperProperty\n",
              "                                )\n",
              "                            ):\n",
              "                                ret = ret.descriptor\n",
              "                            collected_attributes[name] = column_copies[obj] = (\n",
              "                                ret\n",
              "                            )\n",
              "                        if (\n",
              "                            isinstance(ret, (Column, MapperProperty))\n",
              "                            and ret.doc is None\n",
              "                        ):\n",
              "                            ret.doc = obj.__doc__\n",
              "                        self._collect_annotation(\n",
              "                            name,\n",
              "                            obj._collect_return_annotation(),\n",
              "                            base,\n",
              "                            True,\n",
              "                            obj,\n",
              "                        )\n",
              "                    elif _is_mapped_annotation(annotation, cls, base):\n",
              "                        # Mapped annotation without any object.\n",
              "                        # product_column_copies should have handled this.\n",
              "                        # if future support for other MapperProperty,\n",
              "                        # then test if this name is already handled and\n",
              "                        # otherwise proceed to generate.\n",
              "                        if not fixed_table:\n",
              "                            assert (\n",
              "                                name in collected_attributes\n",
              "                                or attribute_is_overridden(name, None)\n",
              "                            )\n",
              "                        continue\n",
              "                    else:</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[33длина278]==============</br><pre><code class=\"python\"># here, the attribute is some other kind of\n",
              "                        # property that we assume is not part of the\n",
              "                        # declarative mapping.  however, check for some\n",
              "                        # more common mistakes\n",
              "                        self._warn_for_decl_attributes(base, name, obj)\n",
              "                elif is_dataclass_field and (\n",
              "                    name not in clsdict_view or clsdict_view[name] is not obj\n",
              "                ):\n",
              "                    # here, we are definitely looking at the target class\n",
              "                    # and not a superclass.   this is currently a\n",
              "                    # dataclass-only path.  if the name is only\n",
              "                    # a dataclass field and isn't in local cls.__dict__,\n",
              "                    # put the object there.\n",
              "                    # assert that the dataclass-enabled resolver agrees\n",
              "                    # with what we are seeing\n",
              "                    assert not attribute_is_overridden(name, obj)\n",
              "                    if _is_declarative_props(obj):\n",
              "                        obj = obj.fget()\n",
              "                    collected_attributes[name] = obj\n",
              "                    self._collect_annotation(\n",
              "                        name, annotation, base, False, obj\n",
              "                    )\n",
              "                else:\n",
              "                    collected_annotation = self._collect_annotation(\n",
              "                        name, annotation, base, None, obj\n",
              "                    )\n",
              "                    is_mapped = (\n",
              "                        collected_annotation is not None\n",
              "                        and collected_annotation.mapped_container is not None\n",
              "                    )\n",
              "                    generated_obj = (\n",
              "                        collected_annotation.attr_value</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[34длина155]==============</br><pre><code class=\"python\">if collected_annotation is not None\n",
              "                        else obj\n",
              "                    )\n",
              "                    if obj is None and not fixed_table and is_mapped:\n",
              "                        collected_attributes[name] = (\n",
              "                            generated_obj\n",
              "                            if generated_obj is not None\n",
              "                            else MappedColumn()\n",
              "                        )\n",
              "                    elif name in clsdict_view:\n",
              "                        collected_attributes[name] = obj\n",
              "                    # else if the name is not in the cls.__dict__,\n",
              "                    # don't collect it as an attribute.\n",
              "                    # we will see the annotation only, which is meaningful\n",
              "                    # both for mapping and dataclasses setup\n",
              "        if inherited_table_args and not tablename:\n",
              "            table_args = None\n",
              "        self.table_args = table_args\n",
              "        self.tablename = tablename\n",
              "        self.mapper_args_fn = mapper_args_fn</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[35длина162]==============</br><pre><code class=\"python\">##--##    def _setup_dataclasses_transforms(self) -> None:\n",
              "        dataclass_setup_arguments = self.dataclass_setup_arguments\n",
              "        if not dataclass_setup_arguments:\n",
              "            return\n",
              "        # can't use is_dataclass since it uses hasattr\n",
              "        if \"__dataclass_fields__\" in self.cls.__dict__:\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Class {self.cls} is already a dataclass; ensure that \"\n",
              "                \"base classes / decorator styles of establishing dataclasses \"\n",
              "                \"are not being mixed. \"\n",
              "                \"This can happen if a class that inherits from \"\n",
              "                \"'MappedAsDataclass', even indirectly, is been mapped with \"\n",
              "                \"'@registry.mapped_as_dataclass'\"\n",
              "            )\n",
              "        warn_for_non_dc_attrs = collections.defaultdict(list)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[36длина262]==============</br><pre><code class=\"python\">##--##        def _allow_dataclass_field(\n",
              "            key: str, originating_class: Type[Any]\n",
              "        ) -> bool:\n",
              "            if (\n",
              "                originating_class is not self.cls\n",
              "                and \"__dataclass_fields__\" not in originating_class.__dict__\n",
              "            ):\n",
              "                warn_for_non_dc_attrs[originating_class].append(key)\n",
              "            return True\n",
              "        manager = instrumentation.manager_of_class(self.cls)\n",
              "        assert manager is not None\n",
              "        field_list = [\n",
              "            _AttributeOptions._get_arguments_for_make_dataclass(\n",
              "                key,\n",
              "                anno,\n",
              "                mapped_container,\n",
              "                self.collected_attributes.get(key, _NoArg.NO_ARG),\n",
              "            )\n",
              "            for key, anno, mapped_container in (\n",
              "                (\n",
              "                    key,\n",
              "                    mapped_anno if mapped_anno else raw_anno,\n",
              "                    mapped_container,\n",
              "                )\n",
              "                for key, (\n",
              "                    raw_anno,\n",
              "                    mapped_container,\n",
              "                    mapped_anno,\n",
              "                    is_dc,\n",
              "                    attr_value,\n",
              "                    originating_module,\n",
              "                    originating_class,\n",
              "                ) in self.collected_annotations.items()\n",
              "                if _allow_dataclass_field(key, originating_class)\n",
              "                and (\n",
              "                    key not in self.collected_attributes\n",
              "                    # issue #9226; check for attributes that we've collected\n",
              "                    # which are already instrumented, which we would assume</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[37длина272]==============</br><pre><code class=\"python\"># mean we are in an ORM inheritance mapping and this\n",
              "                    # attribute is already mapped on the superclass.   Under\n",
              "                    # no circumstance should any QueryableAttribute be sent to\n",
              "                    # the dataclass() function; anything that's mapped should\n",
              "                    # be Field and that's it\n",
              "                    or not isinstance(\n",
              "                        self.collected_attributes[key], QueryableAttribute\n",
              "                    )\n",
              "                )\n",
              "            )\n",
              "        ]\n",
              "        if warn_for_non_dc_attrs:\n",
              "            for (\n",
              "                originating_class,\n",
              "                non_dc_attrs,\n",
              "            ) in warn_for_non_dc_attrs.items():\n",
              "                util.warn_deprecated(\n",
              "                    f\"When transforming {self.cls} to a dataclass, \"\n",
              "                    f\"attribute(s) \"\n",
              "                    f\"{', '.join(repr(key) for key in non_dc_attrs)} \"\n",
              "                    f\"originates from superclass \"\n",
              "                    f\"{originating_class}, which is not a dataclass.  This \"\n",
              "                    f\"usage is deprecated and will raise an error in \"\n",
              "                    f\"SQLAlchemy 2.1.  When declaring SQLAlchemy Declarative \"\n",
              "                    f\"Dataclasses, ensure that all mixin classes and other \"\n",
              "                    f\"superclasses which include attributes are also a \"\n",
              "                    f\"subclass of MappedAsDataclass.\",\n",
              "                    \"2.0\",\n",
              "                    code=\"dcmx\",\n",
              "                )\n",
              "        annotations = {}</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[38длина106]==============</br><pre><code class=\"python\">defaults = {}\n",
              "        for item in field_list:\n",
              "            if len(item) == 2:\n",
              "                name, tp = item\n",
              "            elif len(item) == 3:\n",
              "                name, tp, spec = item\n",
              "                defaults[name] = spec\n",
              "            else:\n",
              "                assert False\n",
              "            annotations[name] = tp\n",
              "        for k, v in defaults.items():\n",
              "            setattr(self.cls, k, v)\n",
              "        self._apply_dataclasses_to_any_class(\n",
              "            dataclass_setup_arguments, self.cls, annotations\n",
              "        )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[39длина155]==============</br><pre><code class=\"python\">##--##    @classmethod\n",
              "    def _update_annotations_for_non_mapped_class(\n",
              "        cls, klass: Type[_O]\n",
              "    ) -> Mapping[str, _AnnotationScanType]:\n",
              "        cls_annotations = util.get_annotations(klass)\n",
              "        new_anno = {}\n",
              "        for name, annotation in cls_annotations.items():\n",
              "            if _is_mapped_annotation(annotation, klass, klass):\n",
              "                extracted = _extract_mapped_subtype(\n",
              "                    annotation,\n",
              "                    klass,\n",
              "                    klass.__module__,\n",
              "                    name,\n",
              "                    type(None),\n",
              "                    required=False,\n",
              "                    is_dataclass_field=False,\n",
              "                    expect_mapped=False,\n",
              "                )\n",
              "                if extracted:\n",
              "                    inner, _ = extracted\n",
              "                    new_anno[name] = inner\n",
              "            else:\n",
              "                new_anno[name] = annotation\n",
              "        return new_anno</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[40длина269]==============</br><pre><code class=\"python\">##--##    @classmethod\n",
              "    def _apply_dataclasses_to_any_class(\n",
              "        cls,\n",
              "        dataclass_setup_arguments: _DataclassArguments,\n",
              "        klass: Type[_O],\n",
              "        use_annotations: Mapping[str, _AnnotationScanType],\n",
              "    ) -> None:\n",
              "        cls._assert_dc_arguments(dataclass_setup_arguments)\n",
              "        dataclass_callable = dataclass_setup_arguments[\"dataclass_callable\"]\n",
              "        if dataclass_callable is _NoArg.NO_ARG:\n",
              "            dataclass_callable = dataclasses.dataclass\n",
              "        restored: Optional[Any]\n",
              "        if use_annotations:\n",
              "            # apply constructed annotations that should look \"normal\" to a\n",
              "            # dataclasses callable, based on the fields present.  This\n",
              "            # means remove the Mapped[] container and ensure all Field\n",
              "            # entries have an annotation\n",
              "            restored = getattr(klass, \"__annotations__\", None)\n",
              "            klass.__annotations__ = cast(\"Dict[str, Any]\", use_annotations)\n",
              "        else:\n",
              "            restored = None\n",
              "        try:\n",
              "            dataclass_callable(\n",
              "                klass,\n",
              "                **{\n",
              "                    k: v\n",
              "                    for k, v in dataclass_setup_arguments.items()\n",
              "                    if v is not _NoArg.NO_ARG and k != \"dataclass_callable\"\n",
              "                },\n",
              "            )\n",
              "        except (TypeError, ValueError) as ex:\n",
              "            raise exc.InvalidRequestError(</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[41длина139]==============</br><pre><code class=\"python\">f\"Python dataclasses error encountered when creating \"\n",
              "                f\"dataclass for {klass.__name__!r}: \"\n",
              "                f\"{ex!r}. Please refer to Python dataclasses \"\n",
              "                \"documentation for additional information.\",\n",
              "                code=\"dcte\",\n",
              "            ) from ex\n",
              "        finally:\n",
              "            # restore original annotations outside of the dataclasses\n",
              "            # process; for mixins and __abstract__ superclasses, SQLAlchemy\n",
              "            # Declarative will need to see the Mapped[] container inside the\n",
              "            # annotations in order to map subclasses\n",
              "            if use_annotations:\n",
              "                if restored is None:\n",
              "                    del klass.__annotations__\n",
              "                else:\n",
              "                    klass.__annotations__ = restored</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[42длина129]==============</br><pre><code class=\"python\">##--##    @classmethod\n",
              "    def _assert_dc_arguments(cls, arguments: _DataclassArguments) -> None:\n",
              "        allowed = {\n",
              "            \"init\",\n",
              "            \"repr\",\n",
              "            \"order\",\n",
              "            \"eq\",\n",
              "            \"unsafe_hash\",\n",
              "            \"kw_only\",\n",
              "            \"match_args\",\n",
              "            \"dataclass_callable\",\n",
              "        }\n",
              "        disallowed_args = set(arguments).difference(allowed)\n",
              "        if disallowed_args:\n",
              "            msg = \", \".join(f\"{arg!r}\" for arg in sorted(disallowed_args))\n",
              "            raise exc.ArgumentError(\n",
              "                f\"Dataclass argument(s) {msg} are not accepted\"\n",
              "            )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[43длина264]==============</br><pre><code class=\"python\">##--##    def _collect_annotation(\n",
              "        self,\n",
              "        name: str,\n",
              "        raw_annotation: _AnnotationScanType,\n",
              "        originating_class: Type[Any],\n",
              "        expect_mapped: Optional[bool],\n",
              "        attr_value: Any,\n",
              "    ) -> Optional[_CollectedAnnotation]:\n",
              "        if name in self.collected_annotations:\n",
              "            return self.collected_annotations[name]\n",
              "        if raw_annotation is None:\n",
              "            return None\n",
              "        is_dataclass = self.is_dataclass_prior_to_mapping\n",
              "        allow_unmapped = self.allow_unmapped_annotations\n",
              "        if expect_mapped is None:\n",
              "            is_dataclass_field = isinstance(attr_value, dataclasses.Field)\n",
              "            expect_mapped = (\n",
              "                not is_dataclass_field\n",
              "                and not allow_unmapped\n",
              "                and (\n",
              "                    attr_value is None\n",
              "                    or isinstance(attr_value, _MappedAttribute)\n",
              "                )\n",
              "            )\n",
              "        else:\n",
              "            is_dataclass_field = False\n",
              "        is_dataclass_field = False\n",
              "        extracted = _extract_mapped_subtype(\n",
              "            raw_annotation,\n",
              "            self.cls,\n",
              "            originating_class.__module__,\n",
              "            name,\n",
              "            type(attr_value),\n",
              "            required=False,\n",
              "            is_dataclass_field=is_dataclass_field,\n",
              "            expect_mapped=expect_mapped\n",
              "            and not is_dataclass,  # self.allow_dataclass_fields,\n",
              "        )\n",
              "        if extracted is None:</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[44длина203]==============</br><pre><code class=\"python\"># ClassVar can come out here\n",
              "            return None\n",
              "        extracted_mapped_annotation, mapped_container = extracted\n",
              "        if attr_value is None and not is_literal(extracted_mapped_annotation):\n",
              "            for elem in typing_get_args(extracted_mapped_annotation):\n",
              "                if isinstance(elem, str) or is_fwd_ref(\n",
              "                    elem, check_generic=True\n",
              "                ):\n",
              "                    elem = de_stringify_annotation(\n",
              "                        self.cls,\n",
              "                        elem,\n",
              "                        originating_class.__module__,\n",
              "                        include_generic=True,\n",
              "                    )\n",
              "                # look in Annotated[...] for an ORM construct,\n",
              "                # such as Annotated[int, mapped_column(primary_key=True)]\n",
              "                if isinstance(elem, _IntrospectsAnnotations):\n",
              "                    attr_value = elem.found_in_pep593_annotated()\n",
              "        self.collected_annotations[name] = ca = _CollectedAnnotation(\n",
              "            raw_annotation,\n",
              "            mapped_container,\n",
              "            extracted_mapped_annotation,\n",
              "            is_dataclass,\n",
              "            attr_value,\n",
              "            originating_class.__module__,\n",
              "            originating_class,\n",
              "        )\n",
              "        return ca</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[45длина125]==============</br><pre><code class=\"python\">##--##    def _warn_for_decl_attributes(\n",
              "        self, cls: Type[Any], key: str, c: Any\n",
              "    ) -> None:\n",
              "        if isinstance(c, expression.ColumnElement):\n",
              "            util.warn(\n",
              "                f\"Attribute '{key}' on class {cls} appears to \"\n",
              "                \"be a non-schema SQLAlchemy expression \"\n",
              "                \"object; this won't be part of the declarative mapping. \"\n",
              "                \"To map arbitrary expressions, use ``column_property()`` \"\n",
              "                \"or a similar function such as ``deferred()``, \"\n",
              "                \"``query_expression()`` etc. \"\n",
              "            )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[46длина282]==============</br><pre><code class=\"python\">##--##    def _produce_column_copies(\n",
              "        self,\n",
              "        attributes_for_class: Callable[\n",
              "            [], Iterable[Tuple[str, Any, Any, bool]]\n",
              "        ],\n",
              "        attribute_is_overridden: Callable[[str, Any], bool],\n",
              "        fixed_table: bool,\n",
              "        originating_class: Type[Any],\n",
              "    ) -> Dict[str, Union[Column[Any], MappedColumn[Any]]]:\n",
              "        cls = self.cls\n",
              "        dict_ = self.clsdict_view\n",
              "        locally_collected_attributes = {}\n",
              "        column_copies = self.column_copies\n",
              "        # copy mixin columns to the mapped class\n",
              "        for name, obj, annotation, is_dataclass in attributes_for_class():\n",
              "            if (\n",
              "                not fixed_table\n",
              "                and obj is None\n",
              "                and _is_mapped_annotation(annotation, cls, originating_class)\n",
              "            ):\n",
              "                # obj is None means this is the annotation only path\n",
              "                if attribute_is_overridden(name, obj):\n",
              "                    # perform same \"overridden\" check as we do for\n",
              "                    # Column/MappedColumn, this is how a mixin col is not\n",
              "                    # applied to an inherited subclass that does not have\n",
              "                    # the mixin.   the anno-only path added here for\n",
              "                    # #9564\n",
              "                    continue\n",
              "                collected_annotation = self._collect_annotation(\n",
              "                    name, annotation, originating_class, True, obj\n",
              "                )\n",
              "                obj = (</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[47длина271]==============</br><pre><code class=\"python\">collected_annotation.attr_value\n",
              "                    if collected_annotation is not None\n",
              "                    else obj\n",
              "                )\n",
              "                if obj is None:\n",
              "                    obj = MappedColumn()\n",
              "                locally_collected_attributes[name] = obj\n",
              "                setattr(cls, name, obj)\n",
              "            elif isinstance(obj, (Column, MappedColumn)):\n",
              "                if attribute_is_overridden(name, obj):\n",
              "                    # if column has been overridden\n",
              "                    # (like by the InstrumentedAttribute of the\n",
              "                    # superclass), skip.  don't collect the annotation\n",
              "                    # either (issue #8718)\n",
              "                    continue\n",
              "                collected_annotation = self._collect_annotation(\n",
              "                    name, annotation, originating_class, True, obj\n",
              "                )\n",
              "                obj = (\n",
              "                    collected_annotation.attr_value\n",
              "                    if collected_annotation is not None\n",
              "                    else obj\n",
              "                )\n",
              "                if name not in dict_ and not (\n",
              "                    \"__table__\" in dict_\n",
              "                    and (getattr(obj, \"name\", None) or name)\n",
              "                    in dict_[\"__table__\"].c\n",
              "                ):\n",
              "                    if obj.foreign_keys:\n",
              "                        for fk in obj.foreign_keys:\n",
              "                            if (\n",
              "                                fk._table_column is not None\n",
              "                                and fk._table_column.table is None\n",
              "                            ):\n",
              "                                raise exc.InvalidRequestError(\n",
              "                                    \"Columns with foreign keys to \"\n",
              "                                    \"non-table-bound \"</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[48длина82]===============</br><pre><code class=\"python\">\"columns must be declared as \"\n",
              "                                    \"@declared_attr callables \"\n",
              "                                    \"on declarative mixin classes.  \"\n",
              "                                    \"For dataclass \"\n",
              "                                    \"field() objects, use a lambda:.\"\n",
              "                                )\n",
              "                    column_copies[obj] = copy_ = obj._copy()\n",
              "                    locally_collected_attributes[name] = copy_\n",
              "                    setattr(cls, name, copy_)\n",
              "        return locally_collected_attributes</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[49длина282]==============</br><pre><code class=\"python\">##--##    def _extract_mappable_attributes(self) -> None:\n",
              "        cls = self.cls\n",
              "        collected_attributes = self.collected_attributes\n",
              "        our_stuff = self.properties\n",
              "        _include_dunders = self._include_dunders\n",
              "        late_mapped = _get_immediate_cls_attr(\n",
              "            cls, \"_sa_decl_prepare_nocascade\", strict=True\n",
              "        )\n",
              "        allow_unmapped_annotations = self.allow_unmapped_annotations\n",
              "        expect_annotations_wo_mapped = (\n",
              "            allow_unmapped_annotations or self.is_dataclass_prior_to_mapping\n",
              "        )\n",
              "        look_for_dataclass_things = bool(self.dataclass_setup_arguments)\n",
              "        for k in list(collected_attributes):\n",
              "            if k in _include_dunders:\n",
              "                continue\n",
              "            value = collected_attributes[k]\n",
              "            if _is_declarative_props(value):\n",
              "                # @declared_attr in collected_attributes only occurs here for a\n",
              "                # @declared_attr that's directly on the mapped class;\n",
              "                # for a mixin, these have already been evaluated\n",
              "                if value._cascading:\n",
              "                    util.warn(\n",
              "                        \"Use of @declared_attr.cascading only applies to \"\n",
              "                        \"Declarative 'mixin' and 'abstract' classes.  \"\n",
              "                        \"Currently, this flag is ignored on mapped class \"\n",
              "                        \"%s\" % self.cls\n",
              "                    )\n",
              "                value = getattr(cls, k)\n",
              "            elif (</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[50длина281]==============</br><pre><code class=\"python\">isinstance(value, QueryableAttribute)\n",
              "                and value.class_ is not cls\n",
              "                and value.key != k\n",
              "            ):\n",
              "                # detect a QueryableAttribute that's already mapped being\n",
              "                # assigned elsewhere in userland, turn into a synonym()\n",
              "                value = SynonymProperty(value.key)\n",
              "                setattr(cls, k, value)\n",
              "            if (\n",
              "                isinstance(value, tuple)\n",
              "                and len(value) == 1\n",
              "                and isinstance(value[0], (Column, _MappedAttribute))\n",
              "            ):\n",
              "                util.warn(\n",
              "                    \"Ignoring declarative-like tuple value of attribute \"\n",
              "                    \"'%s': possibly a copy-and-paste error with a comma \"\n",
              "                    \"accidentally placed at the end of the line?\" % k\n",
              "                )\n",
              "                continue\n",
              "            elif look_for_dataclass_things and isinstance(\n",
              "                value, dataclasses.Field\n",
              "            ):\n",
              "                # we collected a dataclass Field; dataclasses would have\n",
              "                # set up the correct state on the class\n",
              "                continue\n",
              "            elif not isinstance(value, (Column, _DCAttributeOptions)):\n",
              "                # using @declared_attr for some object that\n",
              "                # isn't Column/MapperProperty/_DCAttributeOptions; remove\n",
              "                # from the clsdict_view\n",
              "                # and place the evaluated value onto the class.\n",
              "                collected_attributes.pop(k)\n",
              "                self._warn_for_decl_attributes(cls, k, value)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[51длина261]==============</br><pre><code class=\"python\">if not late_mapped:\n",
              "                    setattr(cls, k, value)\n",
              "                continue\n",
              "            # we expect to see the name 'metadata' in some valid cases;\n",
              "            # however at this point we see it's assigned to something trying\n",
              "            # to be mapped, so raise for that.\n",
              "            # TODO: should \"registry\" here be also?   might be too late\n",
              "            # to change that now (2.0 betas)\n",
              "            elif k in (\"metadata\",):\n",
              "                raise exc.InvalidRequestError(\n",
              "                    f\"Attribute name '{k}' is reserved when using the \"\n",
              "                    \"Declarative API.\"\n",
              "                )\n",
              "            elif isinstance(value, Column):\n",
              "                _undefer_column_name(\n",
              "                    k, self.column_copies.get(value, value)  # type: ignore\n",
              "                )\n",
              "            else:\n",
              "                if isinstance(value, _IntrospectsAnnotations):\n",
              "                    (\n",
              "                        annotation,\n",
              "                        mapped_container,\n",
              "                        extracted_mapped_annotation,\n",
              "                        is_dataclass,\n",
              "                        attr_value,\n",
              "                        originating_module,\n",
              "                        originating_class,\n",
              "                    ) = self.collected_annotations.get(\n",
              "                        k, (None, None, None, False, None, None, None)\n",
              "                    )\n",
              "                    # issue #8692 - don't do any annotation interpretation if\n",
              "                    # an annotation were present and a container such as</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[52длина265]==============</br><pre><code class=\"python\"># Mapped[] etc. were not used.  If annotation is None,\n",
              "                    # do declarative_scan so that the property can raise\n",
              "                    # for required\n",
              "                    if (\n",
              "                        mapped_container is not None\n",
              "                        or annotation is None\n",
              "                        # issue #10516: need to do declarative_scan even with\n",
              "                        # a non-Mapped annotation if we are doing\n",
              "                        # __allow_unmapped__, for things like col.name\n",
              "                        # assignment\n",
              "                        or allow_unmapped_annotations\n",
              "                    ):\n",
              "                        try:\n",
              "                            value.declarative_scan(\n",
              "                                self,\n",
              "                                self.registry,\n",
              "                                cls,\n",
              "                                originating_module,\n",
              "                                k,\n",
              "                                mapped_container,\n",
              "                                annotation,\n",
              "                                extracted_mapped_annotation,\n",
              "                                is_dataclass,\n",
              "                            )\n",
              "                        except NameError as ne:\n",
              "                            raise exc.ArgumentError(\n",
              "                                f\"Could not resolve all types within mapped \"\n",
              "                                f'annotation: \"{annotation}\".  Ensure all '\n",
              "                                f\"types are written correctly and are \"\n",
              "                                f\"imported within the module in use.\"\n",
              "                            ) from ne\n",
              "                    else:\n",
              "                        # assert that we were expecting annotations\n",
              "                        # without Mapped[] were going to be passed.\n",
              "                        # otherwise an error should have been raised\n",
              "                        # by util._extract_mapped_subtype before we got here.\n",
              "                        assert expect_annotations_wo_mapped</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[53длина268]==============</br><pre><code class=\"python\">if isinstance(value, _DCAttributeOptions):\n",
              "                    if (\n",
              "                        value._has_dataclass_arguments\n",
              "                        and not look_for_dataclass_things\n",
              "                    ):\n",
              "                        if isinstance(value, MapperProperty):\n",
              "                            argnames = [\n",
              "                                \"init\",\n",
              "                                \"default_factory\",\n",
              "                                \"repr\",\n",
              "                                \"default\",\n",
              "                            ]\n",
              "                        else:\n",
              "                            argnames = [\"init\", \"default_factory\", \"repr\"]\n",
              "                        args = {\n",
              "                            a\n",
              "                            for a in argnames\n",
              "                            if getattr(\n",
              "                                value._attribute_options, f\"dataclasses_{a}\"\n",
              "                            )\n",
              "                            is not _NoArg.NO_ARG\n",
              "                        }\n",
              "                        raise exc.ArgumentError(\n",
              "                            f\"Attribute '{k}' on class {cls} includes \"\n",
              "                            f\"dataclasses argument(s): \"\n",
              "                            f\"{', '.join(sorted(repr(a) for a in args))} but \"\n",
              "                            f\"class does not specify \"\n",
              "                            \"SQLAlchemy native dataclass configuration.\"\n",
              "                        )\n",
              "                    if not isinstance(value, (MapperProperty, _MapsColumns)):\n",
              "                        # filter for _DCAttributeOptions objects that aren't\n",
              "                        # MapperProperty / mapped_column().  Currently this\n",
              "                        # includes AssociationProxy.   pop it from the things\n",
              "                        # we're going to map and set it up as a descriptor\n",
              "                        # on the class.\n",
              "                        collected_attributes.pop(k)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[54длина116]==============</br><pre><code class=\"python\"># Assoc Prox (or other descriptor object that may\n",
              "                        # use _DCAttributeOptions) is usually here, except if\n",
              "                        # 1. we're a\n",
              "                        # dataclass, dataclasses would have removed the\n",
              "                        # attr here or 2. assoc proxy is coming from a\n",
              "                        # superclass, we want it to be direct here so it\n",
              "                        # tracks state or 3. assoc prox comes from\n",
              "                        # declared_attr, uncommon case\n",
              "                        setattr(cls, k, value)\n",
              "                        continue\n",
              "            our_stuff[k] = value</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[55длина286]==============</br><pre><code class=\"python\">##--##    def _extract_declared_columns(self) -> None:\n",
              "        our_stuff = self.properties\n",
              "        # extract columns from the class dict\n",
              "        declared_columns = self.declared_columns\n",
              "        column_ordering = self.column_ordering\n",
              "        name_to_prop_key = collections.defaultdict(set)\n",
              "        for key, c in list(our_stuff.items()):\n",
              "            if isinstance(c, _MapsColumns):\n",
              "                mp_to_assign = c.mapper_property_to_assign\n",
              "                if mp_to_assign:\n",
              "                    our_stuff[key] = mp_to_assign\n",
              "                else:\n",
              "                    # if no mapper property to assign, this currently means\n",
              "                    # this is a MappedColumn that will produce a Column for us\n",
              "                    del our_stuff[key]\n",
              "                for col, sort_order in c.columns_to_assign:\n",
              "                    if not isinstance(c, CompositeProperty):\n",
              "                        name_to_prop_key[col.name].add(key)\n",
              "                    declared_columns.add(col)\n",
              "                    # we would assert this, however we want the below\n",
              "                    # warning to take effect instead.  See #9630\n",
              "                    # assert col not in column_ordering\n",
              "                    column_ordering[col] = sort_order\n",
              "                    # if this is a MappedColumn and the attribute key we\n",
              "                    # have is not what the column has for its key, map the\n",
              "                    # Column explicitly under the attribute key name.\n",
              "                    # otherwise, Mapper will map it under the column key.</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[56длина228]==============</br><pre><code class=\"python\">if mp_to_assign is None and key != col.key:\n",
              "                        our_stuff[key] = col\n",
              "            elif isinstance(c, Column):\n",
              "                # undefer previously occurred here, and now occurs earlier.\n",
              "                # ensure every column we get here has been named\n",
              "                assert c.name is not None\n",
              "                name_to_prop_key[c.name].add(key)\n",
              "                declared_columns.add(c)\n",
              "                # if the column is the same name as the key,\n",
              "                # remove it from the explicit properties dict.\n",
              "                # the normal rules for assigning column-based properties\n",
              "                # will take over, including precedence of columns\n",
              "                # in multi-column ColumnProperties.\n",
              "                if key == c.key:\n",
              "                    del our_stuff[key]\n",
              "        for name, keys in name_to_prop_key.items():\n",
              "            if len(keys) > 1:\n",
              "                util.warn(\n",
              "                    \"On class %r, Column object %r named \"\n",
              "                    \"directly multiple times, \"\n",
              "                    \"only one will be used: %s. \"\n",
              "                    \"Consider using orm.synonym instead\"\n",
              "                    % (self.classname, name, (\", \".join(sorted(keys))))\n",
              "                )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[57длина280]==============</br><pre><code class=\"python\">##--##    def _setup_table(self, table: Optional[FromClause] = None) -> None:\n",
              "        cls = self.cls\n",
              "        cls_as_Decl = cast(\"MappedClassProtocol[Any]\", cls)\n",
              "        tablename = self.tablename\n",
              "        table_args = self.table_args\n",
              "        clsdict_view = self.clsdict_view\n",
              "        declared_columns = self.declared_columns\n",
              "        column_ordering = self.column_ordering\n",
              "        manager = attributes.manager_of_class(cls)\n",
              "        if \"__table__\" not in clsdict_view and table is None:\n",
              "            if hasattr(cls, \"__table_cls__\"):\n",
              "                table_cls = cast(\n",
              "                    Type[Table],\n",
              "                    util.unbound_method_to_callable(cls.__table_cls__),  # type: ignore  # noqa: E501\n",
              "                )\n",
              "            else:\n",
              "                table_cls = Table\n",
              "            if tablename is not None:\n",
              "                args: Tuple[Any, ...] = ()\n",
              "                table_kw: Dict[str, Any] = {}\n",
              "                if table_args:\n",
              "                    if isinstance(table_args, dict):\n",
              "                        table_kw = table_args\n",
              "                    elif isinstance(table_args, tuple):\n",
              "                        if isinstance(table_args[-1], dict):\n",
              "                            args, table_kw = table_args[0:-1], table_args[-1]\n",
              "                        else:\n",
              "                            args = table_args\n",
              "                autoload_with = clsdict_view.get(\"__autoload_with__\")\n",
              "                if autoload_with:</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[58длина183]==============</br><pre><code class=\"python\">table_kw[\"autoload_with\"] = autoload_with\n",
              "                autoload = clsdict_view.get(\"__autoload__\")\n",
              "                if autoload:\n",
              "                    table_kw[\"autoload\"] = True\n",
              "                sorted_columns = sorted(\n",
              "                    declared_columns,\n",
              "                    key=lambda c: column_ordering.get(c, 0),\n",
              "                )\n",
              "                table = self.set_cls_attribute(\n",
              "                    \"__table__\",\n",
              "                    table_cls(\n",
              "                        tablename,\n",
              "                        self._metadata_for_cls(manager),\n",
              "                        *sorted_columns,\n",
              "                        *args,\n",
              "                        **table_kw,\n",
              "                    ),\n",
              "                )\n",
              "        else:\n",
              "            if table is None:\n",
              "                table = cls_as_Decl.__table__\n",
              "            if declared_columns:\n",
              "                for c in declared_columns:\n",
              "                    if not table.c.contains_column(c):\n",
              "                        raise exc.ArgumentError(\n",
              "                            \"Can't add additional column %r when \"\n",
              "                            \"specifying __table__\" % c.key\n",
              "                        )\n",
              "        self.local_table = table</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[59длина299]==============</br><pre><code class=\"python\">##--##    def _metadata_for_cls(self, manager: ClassManager[Any]) -> MetaData:\n",
              "        meta: Optional[MetaData] = getattr(self.cls, \"metadata\", None)\n",
              "        if meta is not None:\n",
              "            return meta\n",
              "        else:\n",
              "            return manager.registry.metadata\n",
              "##--##    def _setup_inheriting_mapper(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        cls = self.cls\n",
              "        inherits = mapper_kw.get(\"inherits\", None)\n",
              "        if inherits is None:\n",
              "            # since we search for classical mappings now, search for\n",
              "            # multiple mapped bases as well and raise an error.\n",
              "            inherits_search = []\n",
              "            for base_ in cls.__bases__:\n",
              "                c = _resolve_for_abstract_or_classical(base_)\n",
              "                if c is None:\n",
              "                    continue\n",
              "                if _is_supercls_for_inherits(c) and c not in inherits_search:\n",
              "                    inherits_search.append(c)\n",
              "            if inherits_search:\n",
              "                if len(inherits_search) > 1:\n",
              "                    raise exc.InvalidRequestError(\n",
              "                        \"Class %s has multiple mapped bases: %r\"\n",
              "                        % (cls, inherits_search)\n",
              "                    )\n",
              "                inherits = inherits_search[0]\n",
              "        elif isinstance(inherits, Mapper):\n",
              "            inherits = inherits.class_\n",
              "        self.inherits = inherits\n",
              "        clsdict_view = self.clsdict_view\n",
              "        if \"__table__\" not in clsdict_view and self.tablename is None:\n",
              "            self.single = True</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[60длина274]==============</br><pre><code class=\"python\">##--##    def _setup_inheriting_columns(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        table = self.local_table\n",
              "        cls = self.cls\n",
              "        table_args = self.table_args\n",
              "        declared_columns = self.declared_columns\n",
              "        if (\n",
              "            table is None\n",
              "            and self.inherits is None\n",
              "            and not _get_immediate_cls_attr(cls, \"__no_table__\")\n",
              "        ):\n",
              "            raise exc.InvalidRequestError(\n",
              "                \"Class %r does not have a __table__ or __tablename__ \"\n",
              "                \"specified and does not inherit from an existing \"\n",
              "                \"table-mapped class.\" % cls\n",
              "            )\n",
              "        elif self.inherits:\n",
              "            inherited_mapper_or_config = _declared_mapping_info(self.inherits)\n",
              "            assert inherited_mapper_or_config is not None\n",
              "            inherited_table = inherited_mapper_or_config.local_table\n",
              "            inherited_persist_selectable = (\n",
              "                inherited_mapper_or_config.persist_selectable\n",
              "            )\n",
              "            if table is None:\n",
              "                # single table inheritance.\n",
              "                # ensure no table args\n",
              "                if table_args:\n",
              "                    raise exc.ArgumentError(\n",
              "                        \"Can't place __table_args__ on an inherited class \"\n",
              "                        \"with no table.\"\n",
              "                    )\n",
              "                # add any columns declared here to the inherited table.\n",
              "                if declared_columns and not isinstance(inherited_table, Table):</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[61длина258]==============</br><pre><code class=\"python\">raise exc.ArgumentError(\n",
              "                        f\"Can't declare columns on single-table-inherited \"\n",
              "                        f\"subclass {self.cls}; superclass {self.inherits} \"\n",
              "                        \"is not mapped to a Table\"\n",
              "                    )\n",
              "                for col in declared_columns:\n",
              "                    assert inherited_table is not None\n",
              "                    if col.name in inherited_table.c:\n",
              "                        if inherited_table.c[col.name] is col:\n",
              "                            continue\n",
              "                        raise exc.ArgumentError(\n",
              "                            f\"Column '{col}' on class {cls.__name__} \"\n",
              "                            f\"conflicts with existing column \"\n",
              "                            f\"'{inherited_table.c[col.name]}'.  If using \"\n",
              "                            f\"Declarative, consider using the \"\n",
              "                            \"use_existing_column parameter of mapped_column() \"\n",
              "                            \"to resolve conflicts.\"\n",
              "                        )\n",
              "                    if col.primary_key:\n",
              "                        raise exc.ArgumentError(\n",
              "                            \"Can't place primary key columns on an inherited \"\n",
              "                            \"class with no table.\"\n",
              "                        )\n",
              "                    if TYPE_CHECKING:\n",
              "                        assert isinstance(inherited_table, Table)\n",
              "                    inherited_table.append_column(col)\n",
              "                    if (\n",
              "                        inherited_persist_selectable is not None\n",
              "                        and inherited_persist_selectable is not inherited_table\n",
              "                    ):\n",
              "                        inherited_persist_selectable._refresh_for_new_column(\n",
              "                            col\n",
              "                        )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[62длина264]==============</br><pre><code class=\"python\">##--##    def _prepare_mapper_arguments(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        properties = self.properties\n",
              "        if self.mapper_args_fn:\n",
              "            mapper_args = self.mapper_args_fn()\n",
              "        else:\n",
              "            mapper_args = {}\n",
              "        if mapper_kw:\n",
              "            mapper_args.update(mapper_kw)\n",
              "        if \"properties\" in mapper_args:\n",
              "            properties = dict(properties)\n",
              "            properties.update(mapper_args[\"properties\"])\n",
              "        # make sure that column copies are used rather\n",
              "        # than the original columns from any mixins\n",
              "        for k in (\"version_id_col\", \"polymorphic_on\"):\n",
              "            if k in mapper_args:\n",
              "                v = mapper_args[k]\n",
              "                mapper_args[k] = self.column_copies.get(v, v)\n",
              "        if \"primary_key\" in mapper_args:\n",
              "            mapper_args[\"primary_key\"] = [\n",
              "                self.column_copies.get(v, v)\n",
              "                for v in util.to_list(mapper_args[\"primary_key\"])\n",
              "            ]\n",
              "        if \"inherits\" in mapper_args:\n",
              "            inherits_arg = mapper_args[\"inherits\"]\n",
              "            if isinstance(inherits_arg, Mapper):\n",
              "                inherits_arg = inherits_arg.class_\n",
              "            if inherits_arg is not self.inherits:\n",
              "                raise exc.InvalidRequestError(\n",
              "                    \"mapper inherits argument given for non-inheriting \"</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[63длина272]==============</br><pre><code class=\"python\">\"class %s\" % (mapper_args[\"inherits\"])\n",
              "                )\n",
              "        if self.inherits:\n",
              "            mapper_args[\"inherits\"] = self.inherits\n",
              "        if self.inherits and not mapper_args.get(\"concrete\", False):\n",
              "            # note the superclass is expected to have a Mapper assigned and\n",
              "            # not be a deferred config, as this is called within map()\n",
              "            inherited_mapper = class_mapper(self.inherits, False)\n",
              "            inherited_table = inherited_mapper.local_table\n",
              "            # single or joined inheritance\n",
              "            # exclude any cols on the inherited table which are\n",
              "            # not mapped on the parent class, to avoid\n",
              "            # mapping columns specific to sibling/nephew classes\n",
              "            if \"exclude_properties\" not in mapper_args:\n",
              "                mapper_args[\"exclude_properties\"] = exclude_properties = {\n",
              "                    c.key\n",
              "                    for c in inherited_table.c\n",
              "                    if c not in inherited_mapper._columntoproperty\n",
              "                }.union(inherited_mapper.exclude_properties or ())\n",
              "                exclude_properties.difference_update(\n",
              "                    [c.key for c in self.declared_columns]\n",
              "                )\n",
              "            # look through columns in the current mapper that\n",
              "            # are keyed to a propname different than the colname\n",
              "            # (if names were the same, we'd have popped it out above,\n",
              "            # in which case the mapper makes this combination).</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[64длина133]==============</br><pre><code class=\"python\"># See if the superclass has a similar column property.\n",
              "            # If so, join them together.\n",
              "            for k, col in list(properties.items()):\n",
              "                if not isinstance(col, expression.ColumnElement):\n",
              "                    continue\n",
              "                if k in inherited_mapper._props:\n",
              "                    p = inherited_mapper._props[k]\n",
              "                    if isinstance(p, ColumnProperty):\n",
              "                        # note here we place the subclass column\n",
              "                        # first.  See [ticket:1892] for background.\n",
              "                        properties[k] = [col] + p.columns\n",
              "        result_mapper_args = mapper_args.copy()\n",
              "        result_mapper_args[\"properties\"] = properties\n",
              "        self.mapper_args = result_mapper_args</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[65длина123]==============</br><pre><code class=\"python\">##--##    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        self._prepare_mapper_arguments(mapper_kw)\n",
              "        if hasattr(self.cls, \"__mapper_cls__\"):\n",
              "            mapper_cls = cast(\n",
              "                \"Type[Mapper[Any]]\",\n",
              "                util.unbound_method_to_callable(\n",
              "                    self.cls.__mapper_cls__  # type: ignore\n",
              "                ),\n",
              "            )\n",
              "        else:\n",
              "            mapper_cls = Mapper\n",
              "        return self.set_cls_attribute(\n",
              "            \"__mapper__\",\n",
              "            mapper_cls(self.cls, self.local_table, **self.mapper_args),\n",
              "        )</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[66длина144]==============</br><pre><code class=\"python\">##--##@util.preload_module(\"sqlalchemy.orm.decl_api\")\n",
              "def _as_dc_declaredattr(\n",
              "    field_metadata: Mapping[str, Any], sa_dataclass_metadata_key: str\n",
              ") -> Any:\n",
              "    # wrap lambdas inside dataclass fields inside an ad-hoc declared_attr.\n",
              "    # we can't write it because field.metadata is immutable :( so we have\n",
              "    # to go through extra trouble to compare these\n",
              "    decl_api = util.preloaded.orm_decl_api\n",
              "    obj = field_metadata[sa_dataclass_metadata_key]\n",
              "    if callable(obj) and not isinstance(obj, decl_api.declared_attr):\n",
              "        return decl_api.declared_attr(obj)\n",
              "    else:\n",
              "        return obj</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[67длина274]==============</br><pre><code class=\"python\">##--##class _DeferredMapperConfig(_ClassScanMapperConfig):\n",
              "    _cls: weakref.ref[Type[Any]]\n",
              "    is_deferred = True\n",
              "    _configs: util.OrderedDict[\n",
              "        weakref.ref[Type[Any]], _DeferredMapperConfig\n",
              "    ] = util.OrderedDict()\n",
              "##--##    def _early_mapping(self, mapper_kw: _MapperKwArgs) -> None:\n",
              "        pass\n",
              "    # mypy disallows plain property override of variable\n",
              "##--##    @property  # type: ignore\n",
              "    def cls(self) -> Type[Any]:\n",
              "        return self._cls()  # type: ignore\n",
              "##--##    @cls.setter\n",
              "    def cls(self, class_: Type[Any]) -> None:\n",
              "        self._cls = weakref.ref(class_, self._remove_config_cls)\n",
              "        self._configs[self._cls] = self\n",
              "##--##    @classmethod\n",
              "    def _remove_config_cls(cls, ref: weakref.ref[Type[Any]]) -> None:\n",
              "        cls._configs.pop(ref, None)\n",
              "##--##    @classmethod\n",
              "    def has_cls(cls, class_: Type[Any]) -> bool:\n",
              "        # 2.6 fails on weakref if class_ is an old style class\n",
              "        return isinstance(class_, type) and weakref.ref(class_) in cls._configs</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[68длина140]==============</br><pre><code class=\"python\">##--##    @classmethod\n",
              "    def raise_unmapped_for_cls(cls, class_: Type[Any]) -> NoReturn:\n",
              "        if hasattr(class_, \"_sa_raise_deferred_config\"):\n",
              "            class_._sa_raise_deferred_config()\n",
              "        raise orm_exc.UnmappedClassError(\n",
              "            class_,\n",
              "            msg=(\n",
              "                f\"Class {orm_exc._safe_cls_name(class_)} has a deferred \"\n",
              "                \"mapping on it.  It is not yet usable as a mapped class.\"\n",
              "            ),\n",
              "        )\n",
              "##--##    @classmethod\n",
              "    def config_for_cls(cls, class_: Type[Any]) -> _DeferredMapperConfig:\n",
              "        return cls._configs[weakref.ref(class_)]</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[69длина242]==============</br><pre><code class=\"python\">##--##    @classmethod\n",
              "    def classes_for_base(\n",
              "        cls, base_cls: Type[Any], sort: bool = True\n",
              "    ) -> List[_DeferredMapperConfig]:\n",
              "        classes_for_base = [\n",
              "            m\n",
              "            for m, cls_ in [(m, m.cls) for m in cls._configs.values()]\n",
              "            if cls_ is not None and issubclass(cls_, base_cls)\n",
              "        ]\n",
              "        if not sort:\n",
              "            return classes_for_base\n",
              "        all_m_by_cls = {m.cls: m for m in classes_for_base}\n",
              "        tuples: List[Tuple[_DeferredMapperConfig, _DeferredMapperConfig]] = []\n",
              "        for m_cls in all_m_by_cls:\n",
              "            tuples.extend(\n",
              "                (all_m_by_cls[base_cls], all_m_by_cls[m_cls])\n",
              "                for base_cls in m_cls.__bases__\n",
              "                if base_cls in all_m_by_cls\n",
              "            )\n",
              "        return list(topological.sort(tuples, classes_for_base))\n",
              "##--##    def map(self, mapper_kw: _MapperKwArgs = util.EMPTY_DICT) -> Mapper[Any]:\n",
              "        self._configs.pop(self._cls, None)\n",
              "        return super().map(mapper_kw)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[70длина95]===============</br><pre><code class=\"python\">##--##def _add_attribute(\n",
              "    cls: Type[Any], key: str, value: MapperProperty[Any]\n",
              ") -> None:\n",
              "    \"\"\"add an attribute to an existing declarative class.\n",
              "    This runs through the logic to determine MapperProperty,\n",
              "    adds it to the Mapper, adds a column to the mapped Table, etc.\n",
              "    \"\"\"\n",
              "    if \"__mapper__\" in cls.__dict__:\n",
              "        mapped_cls = cast(\"MappedClassProtocol[Any]\", cls)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[71длина263]==============</br><pre><code class=\"python\">##--##        def _table_or_raise(mc: MappedClassProtocol[Any]) -> Table:\n",
              "            if isinstance(mc.__table__, Table):\n",
              "                return mc.__table__\n",
              "            raise exc.InvalidRequestError(\n",
              "                f\"Cannot add a new attribute to mapped class {mc.__name__!r} \"\n",
              "                \"because it's not mapped against a table.\"\n",
              "            )\n",
              "        if isinstance(value, Column):\n",
              "            _undefer_column_name(key, value)\n",
              "            _table_or_raise(mapped_cls).append_column(\n",
              "                value, replace_existing=True\n",
              "            )\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        elif isinstance(value, _MapsColumns):\n",
              "            mp = value.mapper_property_to_assign\n",
              "            for col, _ in value.columns_to_assign:\n",
              "                _undefer_column_name(key, col)\n",
              "                _table_or_raise(mapped_cls).append_column(\n",
              "                    col, replace_existing=True\n",
              "                )\n",
              "                if not mp:\n",
              "                    mapped_cls.__mapper__.add_property(key, col)\n",
              "            if mp:\n",
              "                mapped_cls.__mapper__.add_property(key, mp)\n",
              "        elif isinstance(value, MapperProperty):\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        elif isinstance(value, QueryableAttribute) and value.key != key:\n",
              "            # detect a QueryableAttribute that's already mapped being</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[72длина73]===============</br><pre><code class=\"python\"># assigned elsewhere in userland, turn into a synonym()\n",
              "            value = SynonymProperty(value.key)\n",
              "            mapped_cls.__mapper__.add_property(key, value)\n",
              "        else:\n",
              "            type.__setattr__(cls, key, value)\n",
              "            mapped_cls.__mapper__._expire_memoizations()\n",
              "    else:\n",
              "        type.__setattr__(cls, key, value)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[73длина166]==============</br><pre><code class=\"python\">##--##def _del_attribute(cls: Type[Any], key: str) -> None:\n",
              "    if (\n",
              "        \"__mapper__\" in cls.__dict__\n",
              "        and key in cls.__dict__\n",
              "        and not cast(\n",
              "            \"MappedClassProtocol[Any]\", cls\n",
              "        ).__mapper__._dispose_called\n",
              "    ):\n",
              "        value = cls.__dict__[key]\n",
              "        if isinstance(\n",
              "            value, (Column, _MapsColumns, MapperProperty, QueryableAttribute)\n",
              "        ):\n",
              "            raise NotImplementedError(\n",
              "                \"Can't un-map individual mapped attributes on a mapped class.\"\n",
              "            )\n",
              "        else:\n",
              "            type.__delattr__(cls, key)\n",
              "            cast(\n",
              "                \"MappedClassProtocol[Any]\", cls\n",
              "            ).__mapper__._expire_memoizations()\n",
              "    else:\n",
              "        type.__delattr__(cls, key)</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>==============startchunk[74длина199]==============</br><pre><code class=\"python\">##--##def _declarative_constructor(self: Any, **kwargs: Any) -> None:\n",
              "    \"\"\"A simple constructor that allows initialization from kwargs.\n",
              "    Sets attributes on the constructed instance using the names and\n",
              "    values in ``kwargs``.\n",
              "    Only keys that are present as\n",
              "    attributes of the instance's class are allowed. These could be,\n",
              "    for example, any mapped columns or relationships.\n",
              "    \"\"\"\n",
              "    cls_ = type(self)\n",
              "    for k in kwargs:\n",
              "        if not hasattr(cls_, k):\n",
              "            raise TypeError(\n",
              "                \"%r is an invalid keyword argument for %s\" % (k, cls_.__name__)\n",
              "            )\n",
              "        setattr(self, k, kwargs[k])\n",
              "_declarative_constructor.__name__ = \"__init__\"\n",
              "##--##def _undefer_column_name(key: str, column: Column[Any]) -> None:\n",
              "    if column.key is None:\n",
              "        column.key = key\n",
              "    if column.name is None:\n",
              "        column.name = key</code></pre>=====================endchunk=====================</br>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## почистить лишнее"
      ],
      "metadata": {
        "id": "dacNhM3Is_nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(docs))\n",
        "# удалить маленькие чанки с текстом [Deprecated]\n",
        "new_list = [item for item in range(len(fragment_token_counts)) if '[Deprecated]' in docs[item].page_content]\n",
        "new_list = [item for item in new_list if 0<fragment_token_counts[item]<200]\n",
        "docs0 = [item for i,item in enumerate(docs) if i not in new_list]\n",
        "print(len(docs0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW01jEYCPQgd",
        "outputId": "f0745561-ff55-4bbd-c585-3b732a337cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4157\n",
            "4146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0])\n",
        "print(docs[1])\n",
        "docs0=docs0[2:] #удалить пустые первые 2 чанка"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmVbXeNHnQf6",
        "outputId": "15a18d94-8e27-4c47-d1fe-145a4b4d12a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='' metadata={'source': 'drive/MyDrive/docs4colab/api.python.langchain.com/en/stable/index.html'}\n",
            "page_content='' metadata={'source': 'drive/MyDrive/docs4colab/api.python.langchain.com/en/latest/index.html'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fragment_token_counts0 = [num_tokens_from_string(doc.page_content) for doc in docs0]\n",
        "# есть очень длинные документы\n",
        "bigchunks=[]\n",
        "for i,count in enumerate(fragment_token_counts0):\n",
        "    if count > 15000:\n",
        "        bigchunks.append(i)\n",
        "        print(f\"{count}[{i}]\",end=\" \")\n",
        "len(bigchunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFOCpq4S4JQn",
        "outputId": "25ab1aa9-d83a-48b8-c7c7-286da53f45eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32121[25] 20396[828] 21321[2734] 36699[3042] 16993[3070] 18063[3879] 15534[4143] "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# дополнительная обработка текстов, чтобы делить на чанки"
      ],
      "metadata": {
        "id": "kyVquuz7XRaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# подготовка базы знаний из всех скачанных документов:\n",
        "# деление на чанки и формирование списка LangChain Document\n",
        "# цель расставить сепараторы ##--## так, чтобы делить код на цельносвязные куски(начало класса, конец функции)\n",
        "m = hashlib.md5()  # this will convert URL into unique ID\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=0,\n",
        "    length_function=lambda x: num_tokens_from_string(x),\n",
        "    # предпочитать сепаратор сначала класса,потом декоратора, потом корневой функции потом остальные\n",
        "    separators=[\"##--##c\",\"##--##@\",\"##--##d\",\"##--##\",\"\\n\\n\", \"\\n\"]\n",
        ")\n",
        "\n",
        "source_chunks=[]\n",
        "for fragment in tqdm(docs0, desc=\"Processing documents\"):\n",
        "    # общая ссылка на документ\n",
        "    url=fragment.metadata['source'].replace(f'{folder_path}/'[2:], 'https://')\n",
        "    # convert URL to unique ID\n",
        "    m.update(url.encode('utf-8'))\n",
        "    # достаточно для уникального кодирования\n",
        "    uid = m.hexdigest()[:12]\n",
        "    # добавление разделителей\n",
        "    text=prepchunktosplit2(fragment.page_content)\n",
        "    text=prepchunktosplit(text)\n",
        "    sublist=[]\n",
        "    for i,chunk in enumerate(splitter.split_text(text)):\n",
        "        # удаление разделителей\n",
        "        cleaned_text = re.sub(r'##--##', '', chunk)\n",
        "        # сохранить адресацию исходного документа и порядковые номера кусочков\n",
        "        metadata = {\n",
        "            'id': f\"{uid}\",\n",
        "            'subid':i,\n",
        "            'total':0,\n",
        "            'source': url\n",
        "        }\n",
        "        readydoc=Document(page_content=cleaned_text, metadata=metadata)\n",
        "        sublist.append(readydoc)\n",
        "    # добавить информацию об общем количестве кусочков, представляющих цельный документ\n",
        "    for chunk in sublist:\n",
        "        chunk.metadata['total']=len(sublist)\n",
        "        # display(HTML(wrap(chunk.page_content,chunk.metadata)))\n",
        "    source_chunks.extend(sublist)\n"
      ],
      "metadata": {
        "id": "EJR077lcPvdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# всего чанков после деления 4157 отдельных документов\n",
        "len(source_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02rRPvK2_rLf",
        "outputId": "963243fd-86ec-4403-ed95-417d7c614a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54455"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XXcUQL0QlGLI",
        "outputId": "dce0ef43-549a-44f5-fbd0-179fb7d160fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./drive/MyDrive/docs4colab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# построение индекса и сохранение базы на диск\n",
        "# индексация занимает 10 минут\n",
        "# Инициализирум модель эмбеддингов\n",
        "embeddings = OpenAIEmbeddings()\n",
        "# Создадим индексную базу из разделенных фрагментов текста\n",
        "db = FAISS.from_documents(source_chunks, embeddings)\n",
        "# Задаем имя, чтобы идентифицировать сохраненные файлы\n",
        "index_name = \"dbfaiss_from_langchain\"\n",
        "# сохраняем db_from_texts на ваш гугл драйв\n",
        "db.save_local(folder_path=folder_path, index_name=index_name)"
      ],
      "metadata": {
        "id": "mArNQuZqZEaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# открыть предварительно сохраненную индексную базу"
      ],
      "metadata": {
        "id": "tyjJPjjq9uML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# возможность загрузки предварительно сохраненной индексной базы с диска\n",
        "embeddings = OpenAIEmbeddings()\n",
        "# Имя, используемое при сохранении файлов\n",
        "index_name = \"dbfaiss_from_langchain\"\n",
        "# Загрузка данных и создание нового экземпляра FAISS\n",
        "db = FAISS.load_local(\n",
        "    folder_path=folder_path,\n",
        "    embeddings=embeddings,\n",
        "    index_name=index_name\n",
        ")"
      ],
      "metadata": {
        "id": "yIVRmB7cD9QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# количество документов в индексной базе\n",
        "len(db.docstore._dict.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_9QIcLVYRCn",
        "outputId": "9f6ebb5d-0e3d-42fe-c434-c27c636ab676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54455"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка чанка по id из метаданных\n",
        "def findindbbyid(id):\n",
        "    result=None\n",
        "    for _key, _value in db.docstore._dict.items():\n",
        "        if _value.metadata['id'] == id:\n",
        "            # result=_value if not result else result\n",
        "            # print(_value.page_content,_value.metadata)\n",
        "            return _value\n",
        "    print(\"Element not found\")\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "Uspuo6Ei-faH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk=findindbbyid('2c795f4bdc27')\n",
        "chunk.metadata['source']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UGfJTqDNELG7",
        "outputId": "9bec9cc8-fdb4-430e-b87e-45af1b7d410c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## дополнить базу другого типа документами - блокнотами ipynb"
      ],
      "metadata": {
        "id": "qH3trnvFYhdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# дополнение базы информацией из блокнотов с гитхаба pinecone, где есть примеры использования langchain\n",
        "# еще в планах добавить https://github.com/langchain-ai/langchain/blob/master/cookbook/README.md (не сделано)\n",
        "# сохранены в папку на гуглдиске\n",
        "f\"{folder_path}/langchain\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FZqUDqDh-fs2",
        "outputId": "0dfb615f-e315-4b14-e1b0-524ed087426f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./drive/MyDrive/docs4colab/langchain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# функция для загрузки блокнота ipynb в Document LangChain\n",
        "# от NotebookLoader пришлось отказаться - он глючит\n",
        "def loadipynb(fname):\n",
        "    # fname='/content/drive/MyDrive/docs4colab/langchain/00b-azure-openai-simple.ipynb'\n",
        "    # Чтение файла ноутбука как JSON\n",
        "    with open(fname, 'r') as f:\n",
        "        notebook = json.load(f)\n",
        "    codecells=[] #ячейки с кодом\n",
        "    markdowncells=[] #ячейки с текстом\n",
        "    # Просматриваем код в ячейках\n",
        "    for cell in notebook['cells']:\n",
        "        if cell['cell_type'] == 'code':\n",
        "            codecells.append(''.join(cell['source']))\n",
        "        elif cell['cell_type'] == 'markdown':\n",
        "            markdowncells.append(''.join(cell['source']))\n",
        "    code=''.join(codecells)\n",
        "    markdown=''.join(markdowncells)\n",
        "    metadata = {\n",
        "        'codesize': f\"{len(code)}\", #в чатжпт предполагается подавать только код, т.е. перед подачей обрезать чанк по размеру кода\n",
        "        'source': fname\n",
        "    }\n",
        "    # для индексации и поиска использовать код и текст из нотбука\n",
        "    # а для выполнения запроса текст предварительно выкинуть, т.к. чатжпт сам может объяснить код\n",
        "    readydoc=Document(page_content=''.join([code,markdown]), metadata=metadata)\n",
        "    return readydoc\n"
      ],
      "metadata": {
        "id": "lL7X4ToQ_K9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#собрать список лангчейн документов из ипинбов(ipynb)\n",
        "# здесь в основном нотбуки ipynb, но есть и чистый файл питон py, загружаются разными загрузчиками\n",
        "root_dir = '/content/drive/MyDrive/docs4colab/langchain'\n",
        "# root_dir = '/content/drive/MyDrive/docs4colab/langchain/handbook/09-langchain-streaming'\n",
        "\n",
        "ipynbdocs=[]\n",
        "# Используем os.walk для обхода всех вложенных папок\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for filename in filenames:\n",
        "        fullname=f\"{dirpath}/{filename}\"\n",
        "        # Вычисляем длину заполнения на основе длины dirpath\n",
        "        padding_length = 150-len(fullname)\n",
        "        if padding_length<0:\n",
        "            print(padding_length)\n",
        "            padding_length=0\n",
        "        # Используем динамическое форматирование внутри f-строки\n",
        "        pad_string = ('{:=^' + str(padding_length) + '}').format('')\n",
        "        print(f\"{fullname}{pad_string}\",end=\"\\n\")\n",
        "        if filename.endswith(\".ipynb\"):\n",
        "            ipynbdocs.append(loadipynb(fullname))\n",
        "        else: #файлы py\n",
        "            loader = UnstructuredFileLoader(fullname)\n",
        "            lo = loader.load()\n",
        "            lo[0].metadata['codesize']=len(lo[0].page_content)\n",
        "            ipynbdocs.extend(lo)\n",
        "print(f\"всего загружено файлов примеров лангчейн: {len(ipynbdocs)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfeU8EDv-SXt",
        "outputId": "3dd0b9de-d564-4276-8069-5271dbe5c8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/docs4colab/langchain/00b-azure-openai-simple.ipynb=============================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/00-azure-openai-retrieval.ipynb===========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/rag-chatbot.ipynb=========================================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/v1/claude-3-agent.ipynb===================================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/v1/xml-agents.ipynb=======================================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/03a-token-counter.ipynb==========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/06-langchain-agents.ipynb========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/00-langchain-intro.ipynb=========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/01-langchain-prompt-templates.ipynb==============================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/05-langchain-retrieval-augmentation.ipynb========================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/04-langchain-chat.ipynb==========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/02-langchain-chains.ipynb========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/03-langchain-conversational-memory.ipynb=========================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/xx-langchain-chunking.ipynb======================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/07-langchain-tools.ipynb=========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/10-langchain-multi-query.ipynb===================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/xx-quick-agents-intro.ipynb======================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/08-langchain-retrieval-agent.ipynb===============================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/11-langchain-expression-language.ipynb===========================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/09-langchain-streaming/09-langchain-streaming.ipynb==============================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/09-langchain-streaming/main.py===================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "всего загружено файлов примеров лангчейн: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет токенов для каждого фрагмента-документа ipynb и построение графика\n",
        "# предварительно ipynb были реструктурированы, что сначала идет код, потом весь текст,\n",
        "# текст поможет поиску по запросу пользователя в индексной базе, а для чатажпт текст предположительно не нужен\n",
        "# и в запрос подаваться не будет.\n",
        "# если подавать чатужпт только код, то размер в токенах не более 2000\n",
        "fragment_token_counts_f = [num_tokens_from_string(doc.page_content) for doc in ipynbdocs]\n",
        "fragment_token_counts_с = [num_tokens_from_string(doc.page_content[:int(doc.metadata['codesize'])]) for doc in ipynbdocs]\n",
        "\n",
        "plt.hist(fragment_token_counts_с, bins=10, alpha=0.5, label='Fragments только код')\n",
        "plt.hist(fragment_token_counts_f, bins=10, alpha=0.5, label='Fragments код с текстом')\n",
        "plt.title('Distribution of Token Counts in ipynb notebooks')\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend() # Добавление легенды\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Xccs4563svD2",
        "outputId": "3ef5f1f1-48ae-46bb-8ef5-29ddd7d0799c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAHHCAYAAACRAnNyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABU6klEQVR4nO3dd1QU1/8+8GdpSy9KVwQULIiABQ2xCwZLbNFYYkE0Gns30cRYEnshosaW2JPY61fFrlgTKyqKKCpiQTEWmhEV7u8Pf8zHdQEBF3aA53XOnuPO3L3znuvM7sPszKxCCCFAREREJEM62i6AiIiIKDsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqRdjEiROhUCgKZVmNGjVCo0aNpOdHjhyBQqHApk2bCmX5PXv2hIuLS6EsK79SUlLw9ddfw97eHgqFAsOGDSvQ5WX+///7778FuhzKWWxsLBQKBVauXKmxPt/f37Rp5cqVUCgUOHv2rLZL0ZjCfv96F/fbvGNQkYnMN4PMh6GhIRwdHREYGIh58+YhOTlZI8t58OABJk6ciIiICI30p0lyri03pk6dipUrV6J///5Ys2YNunfvrtYm803qQw+5fEjl1aNHjzBq1ChUrlwZxsbGMDExQc2aNTF58mQ8f/5c2+UBAP766y/MnTtX22XQR5g6dSq2bdum7TKokOhpuwBS9dNPP8HV1RWvX7/Gw4cPceTIEQwbNgwhISHYsWMHvLy8pLbjxo3DmDFj8tT/gwcPMGnSJLi4uMDHxyfXr9u3b1+elpMfOdX222+/ISMjo8Br+BiHDh3CJ598ggkTJmTb5osvvoCbm5v0PCUlBf3790e7du3wxRdfSNPt7OwKtNaCcObMGbRo0QIpKSno1q0batasCQA4e/Yspk+fjqNHjxbKdvQhf/31FyIjIzV2xMvZ2Rn//fcf9PX1NdIfUDj7W1E2depUdOjQAW3bttV2KVQIGFRkpnnz5qhVq5b0fOzYsTh06BA+//xztG7dGlFRUTAyMgIA6OnpQU+vYP8LX7x4AWNjYxgYGBTocj5Ekx8CBSUhIQEeHh45tvHy8lIJm//++y/69+8PLy8vdOvWraBLLDDPnz9Hu3btoKuriwsXLqBy5coq86dMmYLffvtNS9UVrMwjoJqk7f2NSE741U8R0KRJE/z444+4c+cO/vjjD2l6Vueo7N+/H/Xq1YOlpSVMTU1RqVIlfP/99wDefi/r6+sLAAgODpa+Zsj8br1Ro0bw9PTEuXPn0KBBAxgbG0uvze478/T0dHz//fewt7eHiYkJWrdujbt376q0cXFxQc+ePdVe+26fH6otq3NUUlNTMXLkSDg5OUGpVKJSpUqYPXs23v9BcIVCgUGDBmHbtm3w9PSEUqlE1apVsWfPnqwH/D0JCQno3bs37OzsYGhoCG9vb6xatUqan/l99+3bt7Fr1y6p9tjY2Fz1n5VDhw6hfv36MDExgaWlJdq0aYOoqKgPvu7OnTtwc3ODp6cnHj16BOBtiBg2bJg0Tm5ubpgxY4bKEarM8yxmz56NpUuXokKFClAqlfD19cWZM2c+uNwlS5bg/v37CAkJUQspwNsjROPGjVOZtnDhQlStWhVKpRKOjo4YOHCg2tdDudl2gP/9H2zYsAFTpkxB2bJlYWhoCH9/f8TExKi8bteuXbhz5470//TudjV//nxUrVoVxsbGsLKyQq1atfDXX3/luO5ZnaPSs2dPmJqa4v79+2jbti1MTU1hY2ODUaNGIT09Pcf+clq/9evX57i/TZgwAfr6+nj8+LFan3379oWlpSVevnwJ4O3Yfv755zh+/Dhq164NQ0NDlC9fHqtXr86yphcvXuCbb75B6dKlYW5ujh49euDZs2cfXJe8jEVu9mmFQoHU1FSsWrVK+j98dxu5f/8+evXqBTs7O2lfX758eZa15eb9CwA2btyImjVrwsjICNbW1ujWrRvu37+v1k6T++2NGzfQvn172Nvbw9DQEGXLlkXnzp2RmJj4wf6KHUGysGLFCgFAnDlzJsv5d+/eFQBEhw4dpGkTJkwQ7/4XRkZGCgMDA1GrVi0RGhoqFi9eLEaNGiUaNGgghBDi4cOH4qeffhIARN++fcWaNWvEmjVrxM2bN4UQQjRs2FDY29sLGxsbMXjwYLFkyRKxbds2aV7Dhg2lZR0+fFgAENWqVRNeXl4iJCREjBkzRhgaGoqKFSuKFy9eSG2dnZ1FUFCQ2jq92+eHagsKChLOzs7SazMyMkSTJk2EQqEQX3/9tViwYIFo1aqVACCGDRumshwAwtvbWzg4OIiff/5ZzJ07V5QvX14YGxuLf//9N8f/lxcvXogqVaoIfX19MXz4cDFv3jxRv359AUDMnTtXqn3NmjXC2tpa+Pj4SLWnpKTk2LcQQjx+/FgAEBMmTJCm7d+/X+jp6YmKFSuKmTNnikmTJglra2thZWUlbt++LbXL/P9//PixEEKImJgYUa5cOeHj4yNNS01NFV5eXqJ06dLi+++/F4sXLxY9evQQCoVCDB06VOrr9u3bAoCoXr26cHNzEzNmzBAzZ84U1tbWomzZsuLVq1c5rsenn34qjIyMRFpa2gfX+d3aAwICxPz588WgQYOErq6u8PX1VVlWbrYdIf63PVavXl3UrFlT/PLLL2LixInC2NhY1K5dW2q3b98+4ePjI6ytraX/p61btwohhFi6dKm0jy1ZskSEhoaK3r17iyFDhuS4Lpljt2LFCmlaUFCQMDQ0FFWrVhW9evUSixYtEu3btxcAxMKFCz84Pvnd327cuCEAiPnz56v0l5aWJqysrESvXr2kac7OzqJSpUrCzs5OfP/992LBggWiRo0aQqFQiMjISKld5ntTtWrVRP369cW8efPEwIEDhY6OjmjQoIHIyMjIcV1yOxa53afXrFkjlEqlqF+/vvR/ePLkSSHE232xbNmywsnJSfz0009i0aJFonXr1gKA+OWXX/I8nu+uv6+vr/jll1/EmDFjhJGRkXBxcRHPnj2T2mlyv01LSxOurq7C0dFRTJ48Wfz+++9i0qRJwtfXV8TGxuY43sURg4pMfCioCCGEhYWFqF69uvT8/aDyyy+/qOwAWTlz5ozam2qmhg0bCgBi8eLFWc7L6o2zTJkyIikpSZq+YcMGAUCEhoZK03L7YZNTbe8HlW3btgkAYvLkySrtOnToIBQKhYiJiZGmARAGBgYq0y5evJjlG/r75s6dKwCIP/74Q5r26tUr4efnJ0xNTVXW3dnZWbRs2TLH/t6XVVDx8fERtra24smTJyr16ujoiB49ekjT3n3Di4qKEo6OjsLX11c8ffpUavPzzz8LExMTcf36dZXljhkzRujq6oq4uDghxP8+bEuXLq3y+u3btwsA4v/+7/9yXA8rKyvh7e2dq3VOSEgQBgYG4rPPPhPp6enS9AULFggAYvny5dK0vAaVKlWqqISl0NBQAUBcvnxZmtayZUuVbSlTmzZtRNWqVXO1Du/KLqgAED/99JNK28wg9SEfs7/5+fmJOnXqqPS3ZcsWAUAcPnxYmubs7CwAiKNHj0rTEhIShFKpFCNHjpSmZb431axZUyVEzpw5UwAQ27dvz3FdcjsWedmnTUxMstwuevfuLRwcHNT+AOncubOwsLCQAkhux/PVq1fC1tZWeHp6iv/++09qt3PnTgFAjB8/Xpqmyf32woULAoDYuHFjFiNa8vCrnyLE1NQ0x6t/LC0tAQDbt2/P94mnSqUSwcHBuW7fo0cPmJmZSc87dOgABwcH7N69O1/Lz63du3dDV1cXQ4YMUZk+cuRICCEQFhamMj0gIAAVKlSQnnt5ecHc3By3bt364HLs7e3RpUsXaZq+vj6GDBmClJQUhIeHa2Bt/ic+Ph4RERHo2bMnSpUqpVJv06ZNsxzXyMhINGzYEC4uLjhw4ACsrKykeRs3bkT9+vVhZWWFf//9V3oEBAQgPT0dR48eVemrU6dOKq+vX78+AHxwnJKSklS2g5wcOHAAr169wrBhw6Cj87+3oD59+sDc3By7du3KVT9ZCQ4OVjm/I7f1A2/3n3v37uXqq67c6tevn8rz+vXr56qW7ORmf+vRowf++ecf3Lx5U5r2559/wsnJCQ0bNlTpz8PDQxojALCxsUGlSpWyrLFv374q54r1798fenp6ud7XPzQWed2n3yeEwObNm9GqVSsIIVS298DAQCQmJuL8+fMqr/nQeJ49exYJCQkYMGCAynlILVu2ROXKlaVtVdP7rYWFBQBg7969ePHiRY7rXRIwqBQhKSkpOX4YdOrUCXXr1sXXX38NOzs7dO7cGRs2bMhTaClTpkyeTuRzd3dXea5QKODm5vZR52fkxp07d+Do6Kg2HlWqVJHmv6tcuXJqfVhZWX3wO/Y7d+7A3d1d5QM1p+V8rMz+KlWqpDavSpUq+Pfff5GamqoyvVWrVjAzM8PevXthbm6uMu/GjRvYs2cPbGxsVB4BAQEA3p5/8673xynzzfND42Rubp7rS+izW0cDAwOUL1/+o8Y0v/UDwHfffQdTU1PUrl0b7u7uGDhwIE6cOJHvWgwNDWFjY6NWT25qyU5u9rdOnTpBqVTizz//BAAkJiZi586d6Nq1q9o5bXnZL95ftqmpKRwcHHK1r+dmLPK6T7/v8ePHeP78OZYuXaq2vWf+8fX+9v6h8cxpf6xcubI0X9P7raurK0aMGIHff/8d1tbWCAwMxK+//loyz08Bg0qRce/ePSQmJqpc2vo+IyMjHD16FAcOHED37t1x6dIldOrUCU2bNs3VCXyZfWhadjely21NmqCrq5vldPHeibdFUfv27XHz5k3pg+ldGRkZaNq0Kfbv35/lo3379irt8ztOlStXxvXr1/Hq1av8r0gW8rrtfMz/c5UqVRAdHY1169ahXr162Lx5M+rVq5fj5eY5ya6WgmZlZYXPP/9c2h42bdqEtLS0LK8qK6z9ojDGIvMPsm7dumW7vdetW7fA68itnPZbAJgzZw4uXbqE77//Hv/99x+GDBmCqlWr4t69e4VcqfYxqBQRa9asAQAEBgbm2E5HRwf+/v4ICQnB1atXMWXKFBw6dAiHDx8GkP0bf37duHFD5bkQAjExMSpXUlhZWWV5s6/3/0LKS23Ozs548OCB2l/x165dk+ZrgrOzM27cuKF2VErTy3l3eQAQHR2tNu/atWuwtraGiYmJyvRZs2ahd+/eGDBggNoVKhUqVEBKSgoCAgKyfGT1F3V+tGrVCv/99x82b978wbbZreOrV69w+/ZtlTHN7baTFzltZyYmJujUqRNWrFiBuLg4tGzZElOmTJGulNG23OxvwNuvNK5fv44zZ87gzz//RPXq1VG1alWNLjslJQXx8fEau2N0XvbprP4PbWxsYGZmhvT09Gy3d1tb2xzX6f3xzGl/jI6OluZrer/NVK1aNYwbNw5Hjx7FsWPHcP/+fSxevDjLtsUZg0oRcOjQIfz8889wdXVF165ds2339OlTtWmZN05LS0sDAGln0dRdQlevXq3yxrJp0ybEx8ejefPm0rQKFSrg77//Vvlre+fOnWqXAealthYtWiA9PR0LFixQmf7LL79AoVCoLP9jtGjRAg8fPsT69eulaW/evMH8+fNhamqq9p3/x3JwcICPjw9WrVqlMg6RkZHYt28fWrRoofYahUKBpUuXokOHDggKCsKOHTukeR07dsSpU6ewd+9etdc9f/4cb9680Ujd/fr1g4ODA0aOHInr16+rzU9ISMDkyZMBvD1fyMDAAPPmzVP5y33ZsmVITExEy5YtpWm53XbywsTEJMtD6E+ePFF5bmBgAA8PDwgh8Pr163wvT5Nys78Bb+/HZG1tjRkzZiA8PFwj9+hZunSpyjgsWrQIb9680ei+ltt92sTERO19QldXF+3bt8fmzZsRGRmp1n9Wl2x/aDxr1aoFW1tbLF68WHoPBYCwsDBERUVJ26qm99ukpCS1fbNatWrQ0dFRqaOk4A3fZCYsLAzXrl3Dmzdv8OjRIxw6dAj79++Hs7MzduzYkeONpX766SccPXoULVu2hLOzMxISErBw4UKULVsW9erVA/D2jd/S0hKLFy+GmZkZTExMUKdOHbi6uuar3lKlSqFevXoIDg7Go0ePMHfuXLi5uaFPnz5Sm6+//hqbNm1Cs2bN0LFjR9y8eRN//PGHysmtea2tVatWaNy4MX744QfExsbC29sb+/btw/bt2zFs2DC1vvOrb9++WLJkCXr27Ilz587BxcUFmzZtwokTJzB37txcn0CaF7NmzULz5s3h5+eH3r1747///sP8+fNhYWGBiRMnZvkaHR0d/PHHH2jbti06duyI3bt3o0mTJhg9ejR27NiBzz//HD179kTNmjWRmpqKy5cvY9OmTYiNjYW1tfVH12xlZYWtW7eiRYsW8PHxUbkz7fnz57F27Vr4+fkBePuX79ixYzFp0iQ0a9YMrVu3RnR0NBYuXAhfX1+VD9Xcbjt5UbNmTaxfvx4jRoyAr68vTE1N0apVK3z22Wewt7dH3bp1YWdnh6ioKCxYsAAtW7YskP/n/MjN/ga8PeG7c+fOWLBgAXR1dVVOBs+vV69ewd/fHx07dpT+v+rVq4fWrVt/dN9A3vbpmjVr4sCBAwgJCYGjoyNcXV1Rp04dTJ8+HYcPH0adOnXQp08feHh44OnTpzh//jwOHDig9sfch8ZTX18fM2bMQHBwMBo2bIguXbrg0aNHCA0NhYuLC4YPHy71pcn99tChQxg0aBC+/PJLVKxYEW/evMGaNWukMFbiaOVaI1KTeQlg5sPAwEDY29uLpk2bitDQUJVL6DK9f3nywYMHRZs2bYSjo6MwMDAQjo6OokuXLmqXpm7fvl14eHgIPT09lcsqGzZsmO3lmdldLrl27VoxduxYYWtrK4yMjETLli3FnTt31F4/Z84cUaZMGaFUKkXdunXF2bNn1frMqbb3L08WQojk5GQxfPhw4ejoKPT19YW7u7uYNWuW2n0dAIiBAweq1ZTdpa/ve/TokQgODhbW1tbCwMBAVKtWLctLqDV1ebIQQhw4cEDUrVtXGBkZCXNzc9GqVStx9epVlTbv349BiLf3fWnYsKEwNTUVf//9txDi7TiNHTtWuLm5CQMDA2FtbS0+/fRTMXv2bOly08xLbGfNmqVWY1b1ZefBgwdi+PDhomLFisLQ0FAYGxuLmjVriilTpojExESVtgsWLBCVK1cW+vr6ws7OTvTv31/lvhSZcrPtZG6P71/OmdWlwykpKeKrr74SlpaWAoC0XS1ZskQ0aNBAlC5dWiiVSlGhQgUxevRotbrfl93lySYmJmpt399ns/Ox+5sQQpw+fVoAEJ999lmW87PbXt9fduZ7U3h4uOjbt6+wsrISpqamomvXriqX4mYnL2OR23362rVrokGDBsLIyEgAUNmPHz16JAYOHCicnJyEvr6+sLe3F/7+/mLp0qVSm7yO5/r160X16tWFUqkUpUqVEl27dhX37t1Ta6ep/fbWrVuiV69eokKFCsLQ0FCUKlVKNG7cWBw4cCDnwS6mFEIUg7MJiYiKsSNHjqBx48bYuHEjOnTokKvXXLx4ET4+Pli9enWWP5BJVFTwHBUiomLot99+g6mpqcqPXRIVRTxHhYioGPm///s/XL16FUuXLsWgQYPUrjYhKmoYVIiIipHBgwfj0aNHaNGiBSZNmqTtcog+Gs9RISIiItniOSpEREQkWwwqREREJFtF+hyVjIwMPHjwAGZmZhq/NTwREREVDCEEkpOT4ejoqPajr+8r0kHlwYMHcHJy0nYZRERElA93795F2bJlc2xTpINK5m2t7969q/Yz2URERCRPSUlJcHJyytXPUxTpoJL5dY+5uTmDChERURGTm9M2eDItERERyRaDChEREckWgwoRERHJVpE+RyW30tPT8fr1a22XQVTi6evrQ1dXV9tlEFERUqyDihACDx8+xPPnz7VdChH9f5aWlrC3t+e9j4goV4p1UMkMKba2tjA2NuYbI5EWCSHw4sULJCQkAAAcHBy0XBERFQXFNqikp6dLIaV06dLaLoeIABgZGQEAEhISYGtry6+BiOiDiu3JtJnnpBgbG2u5EiJ6V+Y+yfPGiCg3im1QycSve4jkhfskEeVFsQ8qREREVHRpPajcv38f3bp1Q+nSpWFkZIRq1arh7Nmz2i6LiIiIZECrJ9M+e/YMdevWRePGjREWFgYbGxvcuHEDVlZWBbrcX/ZfL9D+3zW8acU8v6Znz55YtWqV2vQbN27Azc1NE2XJTqNGjeDj44O5c+dquxQiIpIRrQaVGTNmwMnJCStWrJCmubq6arEi+WjWrJnKuACAjY2NWrtXr17BwMCgsMoiIiIqVFr96mfHjh2oVasWvvzyS9ja2qJ69er47bfftFmSbCiVStjb26s8dHV10ahRIwwaNAjDhg2DtbU1AgMDAQAhISGoVq0aTExM4OTkhAEDBiAlJUWlz99++w1OTk4wNjZGu3btEBISAktLS2n+xIkT4ePjg+XLl6NcuXIwNTXFgAEDkJ6ejpkzZ8Le3h62traYMmWKSr/Pnz/H119/DRsbG5ibm6NJkya4ePGiWr9r1qyBi4sLLCws0LlzZyQnJwN4ewQpPDwcoaGhUCgUUCgUiI2NxbNnz9C1a1fY2NjAyMgI7u7uauEtU8+ePaXXvv/o2bMnACAtLQ1DhgyBra0tDA0NUa9ePZw5c0atLxcXF7U+tm3bBgA4cuQIFApFtjcRjI2NhUKhQEREhLTMgIAABAQEIC0tDQCQkZGBn376CWXLloVSqYSPjw/27NmTZX+ZGjVqhGHDhknPf//9d1haWuL8+fPStPDwcNSuXRtKpRIODg4YM2YM3rx5o9JPZv3vPt7dBoiI5EarQeXWrVtYtGgR3N3dsXfvXvTv3x9DhgzJ8msP4O2bflJSksqjJFq1ahUMDAxw4sQJLF68GACgo6ODefPm4cqVK1i1ahUOHTqEb7/9VnrNiRMn0K9fPwwdOhQRERFo2rSpWuAAgJs3byIsLAx79uzB2rVrsWzZMrRs2RL37t1DeHg4ZsyYgXHjxuGff/6RXvPll18iISEBYWFhOHfuHGrUqAF/f388ffpUpd9t27Zh586d2LlzJ8LDwzF9+nQAQGhoKPz8/NCnTx/Ex8cjPj4eTk5O+PHHH3H16lWEhYUhKioKixYtgrW1dZZjEhoaKr22Y8eO6Nixo/Q8NDQUAPDtt99i8+bNWLVqFc6fPw83NzcEBgaq1Am8vTHZTz/9JL0+v9LT09G5c2ekpKRg27ZtUCqVUq1z5szB7NmzcenSJQQGBqJ169a4ceNGrvrdsGEDhg8fjh07dqBGjRoA3p7r1aJFC/j6+uLixYtYtGgRli1bhsmTJ2fZR3R0NOLj4/lVGxHJnla/+snIyECtWrUwdepUAED16tURGRmJxYsXIygoSK39tGnTMGnSpMIuUyt27twJU1NT6Xnz5s2xceNGAIC7uztmzpyp0v7dv7ZdXFwwefJk9OvXDwsXLgQAzJ8/H82bN8eoUaMAABUrVsTJkyexc+dOlX4yMjKwfPlymJmZwcPDA40bN0Z0dDR2794NHR0dVKpUCTNmzMDhw4dRp04dHD9+HKdPn0ZCQoL0QTx79mxs27YNmzZtQt++faV+V65cCTMzMwBA9+7dcfDgQUyZMgUWFhYwMDCAsbEx7O3tpVri4uJQvXp11KpVS1qv7FhYWMDCwgLA/24q9m5fqampWLRoEVauXInmzZsDeHuEaf/+/Vi2bBlGjx4ttX39+jVKlSql8vq8EkIgODgYMTExCA8PV/m/nD17Nr777jt07twZAKTxnDt3Ln799dcc+w0LC0NwcDA2btyIBg0aSNMXLlwIJycnLFiwAAqFApUrV8aDBw/w3XffYfz48dDRefs3SeZRnTJlysDExEQaM6I8OzxN2xV8WOOx2q6ANECrR1QcHBzg4eGhMq1KlSqIi4vLsv3YsWORmJgoPe7evVsYZWpF48aNERERIT3mzZsnzatZs6Za+wMHDsDf3x9lypSBmZkZunfvjidPnuDFixcA3v4FXbt2bZXXvP8ceBsGMsMEANjZ2cHDw0P6oMuclnkb9IsXLyIlJQWlS5eGqamp9Lh9+zZu3ryZbb8ODg5SH9np378/1q1bBx8fH3z77bc4efJkju1zcvPmTbx+/Rp169aVpunr66N27dqIiopSaZuUlAQTE5Mc+ytbtizMzMzg6uqKPn36IDExUWX+6NGjsWbNGvj6+qJUqVIqfT948EClDgCoW7euWh3vO336NNq3bw8TExPUqVNHZV5UVBT8/PxU7lFSt25dpKSk4N69e9K0J0+eQE9PjzdCJKIiQ6tBpW7duoiOjlaZdv36dTg7O2fZXqlUwtzcXOVRXJmYmMDNzU16vPu7KO9/iMbGxuLzzz+Hl5cXNm/ejHPnzkl/mb969SpPy9XX11d5rlAospyWkZEBAEhJSYGDg4NKqIqIiEB0dLTKUYqc+shO8+bNcefOHQwfPhwPHjyAv7+/dESooCQlJSE1NRWOjo45tjt27BguXLggHZX54YcfVOZHRUUhLCwM69atw969ezVS26lTpxASEgIvLy8MGjQoX33cunULzs7OvOkaERUZWg0qw4cPx99//42pU6ciJiYGf/31F5YuXYqBAwdqs6wi59y5c8jIyMCcOXPwySefoGLFinjw4IFKm0qVKqmdOJrViaR5VaNGDTx8+BB6enoqwcrNzS3b80myYmBggPT0dLXpNjY2CAoKwh9//IG5c+di6dKl+aqzQoUK0nk9mV6/fo0zZ86oHNU7c+YMFAoFfHx8cuzP1dUVbm5uCAgIwJdffimdPJtpzZo1aNasGX7++Wf06dNHOp/K3Nwcjo6OKnUAb88hev/o4vu6d++Ofv36YdmyZdi5cye2bt0qzatSpQpOnToFIYRKn2ZmZihbtqw0LTw8HPXr189xOUREcqLVoOLr64utW7di7dq18PT0xM8//4y5c+eia9eu2iyryHFzc8Pr168xf/583Lp1C2vWrJFOss00ePBg7N69GyEhIbhx4waWLFmCsLCwj/7LOiAgAH5+fmjbti327duH2NhYnDx5Ej/88EOebtzn4uKCf/75B7Gxsfj333+RkZGB8ePHY/v27YiJicGVK1ewc+dOVKlSJV91mpiYoH///hg9ejT27NmDq1evok+fPnjx4gV69+4NADh8+DAGDhyIFi1awNbWNsf+0tLS8PLlS1y7dg1hYWHw9PRUmZ/5dc/w4cPh5OSEESNGSPNGjx6NGTNmYP369YiOjsaYMWMQERGBoUOH5rjMzD6dnZ0xa9Ys9O/fH0+ePAEADBgwAHfv3sXgwYNx7do1bN++HRMmTMCIESOgo6ODV69eYfPmzTh06BDatGmDhw8f4uHDh0hMTIQQAo8fP87bgBIRFRKt35n2888/x+XLl/Hy5UtERUWhT58+2i6pyPH29kZISAhmzJgBT09P/Pnnn5g2TfVEt7p162Lx4sUICQmBt7c39uzZg+HDh8PQ0PCjlq1QKLB79240aNAAwcHBqFixIjp37ow7d+7Azs4u1/2MGjUKurq68PDwgI2NDeLi4mBgYICxY8fCy8sLDRo0gK6uLtatW5fvWqdPn4727duje/fuqFGjBmJiYrB3717pBoO9evVC/fr18ccff3ywL3t7exgZGaF+/frw9vZWG+9MOjo6WLFiBf766y/s27cPADBkyBCMGDECI0eORLVq1bBnzx7s2LED7u7uuV6Xb775Bp6enhg8eDCAtyfH7t69G6dPn4a3tzf69euH3r17Y9y4cQCAkydPokOHDsjIyEC7du3g4OAABwcHDBs2DElJSfD19c31somICpNCvHusuIhJSkqChYUFEhMT1c5XefnyJW7fvg1XV9eP/jAurvr06YNr167h2LFj2i6FCtiRI0cwceJEHDlyRG3e8+fP4ePjg9jY2EKphftmMcGrfugj5PT5/T6tXp5MhWv27Nlo2rQpTExMEBYWhlWrVkmXL1PxZmBgoHL10bt0dHSyvOsxEZEcMKiUIKdPn8bMmTORnJyM8uXLY968efj666+1XRYVgk8//RRbtmzJcp65ublGTqwmIioIDColyIYNG7RdAhERUZ5o/WRaIiIiouwwqBAREZFsMagQERGRbDGoEBERkWwxqBAREZFsMagQERGRbDGoEBERkWyVzPuoFOatn/NxC+eePXti1apVatNv3LgBNzc3TVQlO40aNYKPjw/mzp2r7VKIiEhGSmZQKQKaNWuGFStWqEzL6jbnr169goGBQWGVRUREVKj41Y9MKZVK2Nvbqzx0dXXRqFEjDBo0CMOGDYO1tTUCAwMBACEhIahWrRpMTEzg5OSEAQMGICUlRaXP3377DU5OTjA2Nka7du0QEhICS0tLaf7EiRPh4+OD5cuXo1y5cjA1NcWAAQOQnp6OmTNnwt7eHra2tpgyZYpKv8+fP8fXX38NGxsbmJubo0mTJrh48aJav2vWrIGLiwssLCzQuXNnJCcnA3h7BCk8PByhoaFQKBRQKBSIjY3Fs2fP0LVrV9jY2MDIyAju7u5q4e1djRo1wrBhw6Tnv//+OywtLXH+/HlpWnh4OGrXrg2lUgkHBweMGTMGb968UennyJEjUh2Zj3fHKSsZGRmYOXMm3NzcoFQqUa5cObVxytSzZ0+1/jMfPXv2lPqbNm0aXF1dYWRkBG9vb2zatEmtxufPnwMAnj17Bi8vL/To0QOZvzOaU03ZLV+hUEg/XHj58mU0adIERkZGKF26NPr27auyTWWuR0hIiMr6tWvXDgqFAitXrsxxzIiIcoNBpQhatWoVDAwMcOLECSxevBjA2x+WmzdvHq5cuYJVq1bh0KFD+Pbbb6XXnDhxAv369cPQoUMRERGBpk2bZvlBevPmTYSFhWHPnj1Yu3Ytli1bhpYtW+LevXsIDw/HjBkzMG7cOPzzzz/Sa7788kskJCQgLCwM586dQ40aNeDv74+nT5+q9Ltt2zbs3LkTO3fuRHh4OKZPnw4ACA0NhZ+fH/r06YP4+HjEx8fDyckJP/74I65evYqwsDBERUVh0aJFsLa2ztUYbdiwAcOHD8eOHTtQo0YNAMD9+/fRokUL+Pr64uLFi1i0aBGWLVuGyZMnZ9lHdHQ04uPjc/V11NixYzF9+nSp5r/++gt2dnZZtg0NDZXWs2PHjujYsaP0PDQ0FAAwbdo0rF69GosXL8aVK1cwfPhwdOvWDeHh4Wr9paSkoEWLFihfvjyWL18OhULxwZoylxcfHw8A2Lx5s/T8008/RWpqKgIDA2FlZYUzZ85g48aNOHDgAAYNGqSy7DJlyuC3336Tnj948AAnTpyAsbHxB8eMiCg3+NWPTO3cuROmpqbS8+bNm2Pjxo0AAHd3d8ycOVOl/btHElxcXDB58mT069dP+nXk+fPno3nz5hg1ahQAoGLFijh58iR27typ0k9GRgaWL18OMzMzeHh4oHHjxoiOjsbu3buho6ODSpUqYcaMGTh8+DDq1KmD48eP4/Tp00hISIBSqQTw9leat23bhk2bNqFv375SvytXroSZmRkAoHv37jh48CCmTJkCCwsLGBgYwNjYGPb29lItcXFxqF69OmrVqiWtV26EhYUhODgYGzduRIMGDaTpCxcuhJOTExYsWACFQoHKlSvjwYMH+O677zB+/Hjo6LzN7WlpaQDefgibmJjAwsIix+UlJycjNDQUCxYsQFBQEACgQoUKqFevXpbtLSwspD6NjIwAQGW909LSMHXqVBw4cAB+fn4AgPLly+P48eNYsmQJGjZsqNK2Q4cOMDY2xvr166Gnp5ermt5dHgCUKlVKZdqqVavw8uVLrF69GiYmJgCABQsWoFWrVpgxY4YUeGrVqoXbt2/j2LFjqF+/PpYvX47OnTtj9erVOY4ZEVFu8YiKTDVu3BgRERHSY968edK8mjVrqrU/cOAA/P39UaZMGZiZmaF79+548uQJXrx4AeDt0YHatWurvOb958DbMJAZJgDAzs4OHh4e0od45rSEhAQAwMWLF5GSkoLSpUvD1NRUety+fRs3b97Mtl8HBwepj+z0798f69atg4+PD7799lucPHkyx/bA21+Ibt++PUxMTFCnTh2VeVFRUfDz85OOOABA3bp1kZKSgnv37knTnjx5Aj09vVwfFYiKikJaWhr8/f1z1f5DYmJi8OLFCzRt2lRlTFevXq0ypgDQtWtXHDx4EA0bNpSCoiZqioqKgre3txRSgLdjlZGRgejoaJW2ffr0wdKlS5GRkYFly5ahT58++VomEVFWeERFpkxMTLK9wufdDw8AiI2Nxeeff47+/ftjypQpKFWqFI4fP47evXvj1atXeToMr6+vr/JcoVBkOS0jIwPA268dHBwcpPMa3vXueR059ZGd5s2b486dO9i9ezf2798Pf39/DBw4ELNnz872NadOncKiRYuwadMmDBo0CGvXrs1xGVm5desWnJ2dVQJNTjKPimhK5nkgu3btQpkyZVTmvRtGAODhw4fYvHkzvvrqK7Rr1w7VqlUrkJpy0q1bN0yYMAHr1q2Dvb29VAMRkSbwiEoxcO7cOWRkZGDOnDn45JNPULFiRTx48EClTaVKlXDmzBmVae8/z48aNWrg4cOH0NPTg5ubm8ojt+eTAICBgQHS09PVptvY2CAoKAh//PEH5s6di6VLl+bYT/fu3dGvXz8sW7YMO3fuxNatW6V5VapUwalTp6STTYG35+6YmZmhbNmy0rTw8HDUr18/17W7u7vDyMgIBw8ezPVrcuLh4QGlUom4uDi1MXVyclJpu2PHDnzxxRfo06cPgoODpRODP7amKlWq4OLFi0hNTZWmnThxQvr6712WlpZo3bo1+vXrx6MpRKRxDCrFgJubG16/fo358+fj1q1bWLNmjXSSbabBgwdj9+7dCAkJwY0bN7BkyRKEhYXl+qhBdgICAuDn54e2bdti3759iI2NxcmTJ/HDDz/g7Nmzue7HxcUF//zzD2JjY/Hvv/8iIyMD48ePx/bt2xETE4MrV65g586dqFKlSo79lCpVCgDg7OyMWbNmoX///njy5AkAYMCAAbh79y4GDx6Ma9euYfv27ZgwYQJGjBgBHR0dvHr1Cps3b8ahQ4fQpk0bPHz4EA8fPkRiYiKEEHj8+HGWyzQ0NMR3332Hb7/9Vvp65u+//8ayZctyvf7vMjMzw6hRozB8+HCsWrUKN2/exPnz5zF//ny1++tkru/06dPx7Nkz6QTlj62pa9euMDQ0RFBQECIjI3H48GEMHjwY3bt3z/Ik4TFjxuD7779Hp06d8rXORETZYVApBry9vRESEoIZM2bA09MTf/75J6ZNU72pXd26dbF48WKEhITA29sbe/bswfDhw2FoaPhRy1YoFNi9ezcaNGiA4OBgVKxYEZ07d8adO3eyveolK6NGjYKuri48PDxgY2ODuLg4GBgYYOzYsfDy8kKDBg2gq6uLdevW5brPb775Bp6enhg8eDCAtyfH7t69G6dPn4a3tzf69euH3r17Y9y4cQCAkydPokOHDsjIyEC7du3g4OAABwcHDBs2DElJSfD19c12WT/++CNGjhyJ8ePHo0qVKujUqdMHz8HJyc8//4wff/wR06ZNQ5UqVdCsWTPs2rULrq6uWbY3MTHB8uXLMWXKFERGRn50TcbGxti7dy+ePn0KX19fdOjQAf7+/liwYEGW7StVqoQxY8aofS1JRPSxFOLd4+BFTFJSEiwsLJCYmAhzc3OVeS9fvsTt27fh6ur60R/GxVWfPn1w7do1HDt2TNulyMKRI0cwceLELM+3ef78OXx8fBAbG1vodRU33DeLicK8w3d+5ePO4FQ4cvr8fh9Ppi1BZs+ejaZNm8LExARhYWFYtWqVdPkyvT1PJvOrlPfp6OhkeWdgIiIqWAwqJcjp06cxc+ZMJCcno3z58pg3bx6+/vprbZclG59++im2bNmS5Txzc3ONnHxMRER5w6BSgmzYsEHbJRAREeUJT6YlIiIi2Sr2QaUInytMVCxxnySivCi2QSXzTqiZt5AnInnI3Cffv1sxEVFWiu05Krq6urC0tJTuG2FsbPzRNzcjovwTQuDFixdISEiApaUldHV1tV0SERUBxTaoAP/7hdiPufEWEWmWpaWl2q83ExFlp1gHFYVCAQcHB9ja2uL169faLoeoxNPX1+eRFCLKk2IdVDLp6uryzZGIiKgIKrYn0xIREVHRx6BCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESypdWgMnHiRCgUCpVH5cqVtVkSERERyYietguoWrUqDhw4ID3X09N6SURERCQTWk8Fenp6sLe313YZREREJENaP0flxo0bcHR0RPny5dG1a1fExcVl2zYtLQ1JSUkqDyIiIiq+tBpU6tSpg5UrV2LPnj1YtGgRbt++jfr16yM5OTnL9tOmTYOFhYX0cHJyKuSKiYiIqDAphBBC20Vkev78OZydnRESEoLevXurzU9LS0NaWpr0PCkpCU5OTkhMTIS5uXlhlkpEVLIdnqbtCj6s8VhtV0DZSEpKgoWFRa4+v7V+jsq7LC0tUbFiRcTExGQ5X6lUQqlUFnJVREREpC1aP0flXSkpKbh58yYcHBy0XQoRERHJgFaDyqhRoxAeHo7Y2FicPHkS7dq1g66uLrp06aLNsoiIiEgmtPrVz71799ClSxc8efIENjY2qFevHv7++2/Y2NhosywiIiKSCa0GlXXr1mlz8URERCRzsjpHhYiIiOhdDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFuyCSrTp0+HQqHAsGHDtF0KERERyYQsgsqZM2ewZMkSeHl5absUIiIikhGtB5WUlBR07doVv/32G6ysrLRdDhEREcmI1oPKwIED0bJlSwQEBHywbVpaGpKSklQeREREVHzpaXPh69atw/nz53HmzJlctZ82bRomTZpUwFUVXb/sv14g/Q5vWrFA+iXSisPTtF3BhzUeq+0KiGRDa0dU7t69i6FDh+LPP/+EoaFhrl4zduxYJCYmSo+7d+8WcJVERESkTVo7onLu3DkkJCSgRo0a0rT09HQcPXoUCxYsQFpaGnR1dVVeo1QqoVQqC7tUIiIi0hKtBRV/f39cvnxZZVpwcDAqV66M7777Ti2kEBERUcmjtaBiZmYGT09PlWkmJiYoXbq02nQiIiIqmbR+1Q8RERFRdrR61c/7jhw5ou0SiIiISEZ4RIWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhkK19B5datW5qug4iIiEhNvoKKm5sbGjdujD/++AMvX77UdE1EREREAPIZVM6fPw8vLy+MGDEC9vb2+Oabb3D69GlN10ZEREQlXL6Cio+PD0JDQ/HgwQMsX74c8fHxqFevHjw9PRESEoLHjx9ruk4iIiIqgT7qZFo9PT188cUX2LhxI2bMmIGYmBiMGjUKTk5O6NGjB+Lj4zVVJxEREZVAHxVUzp49iwEDBsDBwQEhISEYNWoUbt68if379+PBgwdo06aNpuokIiKiEkgvPy8KCQnBihUrEB0djRYtWmD16tVo0aIFdHTe5h5XV1esXLkSLi4umqyViIiISph8BZVFixahV69e6NmzJxwcHLJsY2tri2XLln1UcURERFSy5Suo3Lhx44NtDAwMEBQUlJ/uiYiIiADk8xyVFStWYOPGjWrTN27ciFWrVn10UURERERAPoPKtGnTYG1trTbd1tYWU6dO/eiiiIiIiIB8BpW4uDi4urqqTXd2dkZcXNxHF0VEREQE5DOo2Nra4tKlS2rTL168iNKlS390UURERERAPoNKly5dMGTIEBw+fBjp6elIT0/HoUOHMHToUHTu3FnTNRIREVEJla+rfn7++WfExsbC398fenpvu8jIyECPHj14jgoRERFpTL6CioGBAdavX4+ff/4ZFy9ehJGREapVqwZnZ2dN10dEREQlWL6CSqaKFSuiYsWKmqqFiIiISEW+gkp6ejpWrlyJgwcPIiEhARkZGSrzDx06pJHiiIiIqGTLV1AZOnQoVq5ciZYtW8LT0xMKhULTdRERERHlL6isW7cOGzZsQIsWLTRdDxEREZEkX5cnGxgYwM3NTdO1EBEREanIV1AZOXIkQkNDIYTQdD1EREREknx99XP8+HEcPnwYYWFhqFq1KvT19VXmb9myRSPFERERUcmWr6BiaWmJdu3aaboWIiIiIhX5CiorVqzQdB1EREREavJ1jgoAvHnzBgcOHMCSJUuQnJwMAHjw4AFSUlI0VhwRERGVbPk6onLnzh00a9YMcXFxSEtLQ9OmTWFmZoYZM2YgLS0Nixcv1nSdREREVALl64jK0KFDUatWLTx79gxGRkbS9Hbt2uHgwYMaK46IiIhKtnwdUTl27BhOnjwJAwMDlekuLi64f/++RgojIiIiytcRlYyMDKSnp6tNv3fvHszMzD66KCIiIiIgn0Hls88+w9y5c6XnCoUCKSkpmDBhAm+rT0RERBqTr69+5syZg8DAQHh4eODly5f46quvcOPGDVhbW2Pt2rWarpGIiIhKqHwFlbJly+LixYtYt24dLl26hJSUFPTu3Rtdu3ZVObmWiIiI6GPkK6gAgJ6eHrp166bJWoiIiIhU5CuorF69Osf5PXr0yFcxRERERO/KV1AZOnSoyvPXr1/jxYsXMDAwgLGxMYMKERERaUS+rvp59uyZyiMlJQXR0dGoV68eT6YlIiIijcn3b/28z93dHdOnT1c72pKTRYsWwcvLC+bm5jA3N4efnx/CwsI0VRIREREVcRoLKsDbE2wfPHiQ6/Zly5bF9OnTce7cOZw9exZNmjRBmzZtcOXKFU2WRUREREVUvs5R2bFjh8pzIQTi4+OxYMEC1K1bN9f9tGrVSuX5lClTsGjRIvz999+oWrVqfkojIiKiYiRfQaVt27YqzxUKBWxsbNCkSRPMmTMnX4Wkp6dj48aNSE1NhZ+fX776ICIiouIlX0ElIyNDYwVcvnwZfn5+ePnyJUxNTbF161Z4eHhk2TYtLQ1paWnS86SkJI3VQURERPKT7xu+aUqlSpUQERGBxMREbNq0CUFBQQgPD88yrEybNg2TJk3SQpWa9cv+6xrr65O4pf/7t8Z6fc/h0h/3+sZjs5ysyXF43/CmFQusb8rB4WnaroCIipl8BZURI0bkum1ISEiO8w0MDODm5gYAqFmzJs6cOYPQ0FAsWbJEre3YsWNVlp2UlAQnJ6dc10JERERFS76CyoULF3DhwgW8fv0alSpVAgBcv34durq6qFGjhtROoVDkue+MjAyVr3fepVQqoVQq81MyERERFUH5CiqtWrWCmZkZVq1aBSsrKwBvbwIXHByM+vXrY+TIkbnqZ+zYsWjevDnKlSuH5ORk/PXXXzhy5Aj27t2bn7KIiIiomMlXUJkzZw727dsnhRQAsLKywuTJk/HZZ5/lOqgkJCSgR48eiI+Ph4WFBby8vLB37140bdo0P2URERFRMZOvoJKUlITHjx+rTX/8+DGSk5Nz3c+yZcvys3giIiIqIfJ1Z9p27dohODgYW7Zswb1793Dv3j1s3rwZvXv3xhdffKHpGomIiKiEytcRlcWLF2PUqFH46quv8Pr167cd6emhd+/emDVrlkYLJCIiopIrX0HF2NgYCxcuxKxZs3Dz5k0AQIUKFWBiYqLR4oiIiKhk+6gfJYyPj0d8fDzc3d1hYmICIYSm6iIiIiLKX1B58uQJ/P39UbFiRbRo0QLx8fEAgN69e+f6ih8iIiKiD8lXUBk+fDj09fURFxcHY2NjaXqnTp2wZ88ejRVHREREJVu+zlHZt28f9u7di7Jly6pMd3d3x507dzRSGBEREVG+jqikpqaqHEnJ9PTpU97inoiIiDQmX0Glfv36WL16tfRcoVAgIyMDM2fOROPGjTVWHBEREZVs+frqZ+bMmfD398fZs2fx6tUrfPvtt7hy5QqePn2KEydOaLpGIiIiKqHydUTF09MT169fR7169dCmTRukpqbiiy++wIULF1ChQgVN10hEREQlVJ6PqLx+/RrNmjXD4sWL8cMPPxRETUREREQA8nFERV9fH5cuXSqIWoiIiIhU5Ourn27duvGXj4mIiKjA5etk2jdv3mD58uU4cOAAatasqfYbPyEhIRopjoiIiEq2PAWVW7duwcXFBZGRkahRowYA4Pr16yptFAqF5qojIiKiEi1PQcXd3R3x8fE4fPgwgLe3zJ83bx7s7OwKpDgiIiIq2fJ0jsr7v44cFhaG1NRUjRZERERElClfJ9Nmej+4EBEREWlSnoKKQqFQOweF56QQERFRQcnTOSpCCPTs2VP64cGXL1+iX79+alf9bNmyRXMVEhERUYmVp6ASFBSk8rxbt24aLYaIiIjoXXkKKitWrCioOoiIiIjUfNTJtEREREQFiUGFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhki0GFiIiIZItBhYiIiGSLQYWIiIhkS6tBZdq0afD19YWZmRlsbW3Rtm1bREdHa7MkIiIikhGtBpXw8HAMHDgQf//9N/bv34/Xr1/js88+Q2pqqjbLIiIiIpnQ0+bC9+zZo/J85cqVsLW1xblz59CgQQMtVUVERERyodWg8r7ExEQAQKlSpbKcn5aWhrS0NOl5UlJSodRFRERE2iGboJKRkYFhw4ahbt268PT0zLLNtGnTMGnSpEKujIqiX/Zf13YJGvdJ3FJtlyDxK19a2yUQUQkhm6t+Bg4ciMjISKxbty7bNmPHjkViYqL0uHv3biFWSERERIVNFkdUBg0ahJ07d+Lo0aMoW7Zstu2USiWUSmUhVkZERETapNWgIoTA4MGDsXXrVhw5cgSurq7aLIeIiIhkRqtBZeDAgfjrr7+wfft2mJmZ4eHDhwAACwsLGBkZabM0IiIikgGtnqOyaNEiJCYmolGjRnBwcJAe69ev12ZZREREJBNa/+qHiIiIKDuyueqHiIiI6H0MKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkW1oNKkePHkWrVq3g6OgIhUKBbdu2abMcIiIikhmtBpXU1FR4e3vj119/1WYZREREJFN62lx48+bN0bx5c22WQERERDKm1aCSV2lpaUhLS5OeJyUlabEaIiIiKmhFKqhMmzYNkyZNKrTl/bL/eqEtS85O3XryUa//+438x/GTuKXaLqFI+dhtIid+5UsXWN9FxuFp2q6ACktR+L9uPFariy9SV/2MHTsWiYmJ0uPu3bvaLomIiIgKUJE6oqJUKqFUKrVdBhERERWSInVEhYiIiEoWrR5RSUlJQUxMjPT89u3biIiIQKlSpVCuXDktVkZERERyoNWgcvbsWTRu3Fh6PmLECABAUFAQVq5cqaWqiIiISC60GlQaNWoEIYQ2SyAiIiIZ4zkqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbDCpEREQkWwwqREREJFsMKkRERCRbsggqv/76K1xcXGBoaIg6derg9OnT2i6JiIiIZEDrQWX9+vUYMWIEJkyYgPPnz8Pb2xuBgYFISEjQdmlERESkZVoPKiEhIejTpw+Cg4Ph4eGBxYsXw9jYGMuXL9d2aURERKRlWg0qr169wrlz5xAQECBN09HRQUBAAE6dOqXFyoiIiEgO9LS58H///Rfp6emws7NTmW5nZ4dr166ptU9LS0NaWpr0PDExEQCQlJRUIPW9TE0pkH41KfW/tA830jKOI+VFUupLbZdAxUUBfTZoVFHY3gtgHDM/t4UQH2yr1aCSV9OmTcOkSZPUpjs5OWmhGsq9BdougIhKpJ+0XUAxUXDjmJycDAsLixzbaDWoWFtbQ1dXF48ePVKZ/ujRI9jb26u1Hzt2LEaMGCE9z8jIwNOnT1G6dGkoFIoCr1eTkpKS4OTkhLt378Lc3Fzb5WgFx+AtjgPHIBPHgWOQqbiPgxACycnJcHR0/GBbrQYVAwMD1KxZEwcPHkTbtm0BvA0fBw8exKBBg9TaK5VKKJVKlWmWlpaFUGnBMTc3L5YbYV5wDN7iOHAMMnEcOAaZivM4fOhISiatf/UzYsQIBAUFoVatWqhduzbmzp2L1NRUBAcHa7s0IiIi0jKtB5VOnTrh8ePHGD9+PB4+fAgfHx/s2bNH7QRbIiIiKnm0HlQAYNCgQVl+1VOcKZVKTJgwQe2rrJKEY/AWx4FjkInjwDHIxHH4H4XIzbVBRERERFqg9TvTEhEREWWHQYWIiIhki0GFiIiIZItBhYiIiGSLQUWDJk6cCIVCofKoXLmyNP/ly5cYOHAgSpcuDVNTU7Rv317trrxxcXFo2bIljI2NYWtri9GjR+PNmzeFvSq5dvToUbRq1QqOjo5QKBTYtm2bynwhBMaPHw8HBwcYGRkhICAAN27cUGnz9OlTdO3aFebm5rC0tETv3r2RkqL6+0CXLl1C/fr1YWhoCCcnJ8ycObOgVy1PPjQOPXv2VNs2mjVrptKmqI/DtGnT4OvrCzMzM9ja2qJt27aIjo5WaaOpfeDIkSOoUaMGlEol3NzcsHLlyoJevVzJzRg0atRIbVvo16+fSpuiPAYAsGjRInh5eUk3K/Pz80NYWJg0v7hvB8CHx6AkbAcaI0hjJkyYIKpWrSri4+Olx+PHj6X5/fr1E05OTuLgwYPi7Nmz4pNPPhGffvqpNP/NmzfC09NTBAQEiAsXLojdu3cLa2trMXbsWG2sTq7s3r1b/PDDD2LLli0CgNi6davK/OnTpwsLCwuxbds2cfHiRdG6dWvh6uoq/vvvP6lNs2bNhLe3t/j777/FsWPHhJubm+jSpYs0PzExUdjZ2YmuXbuKyMhIsXbtWmFkZCSWLFlSWKv5QR8ah6CgINGsWTOVbePp06cqbYr6OAQGBooVK1aIyMhIERERIVq0aCHKlSsnUlJSpDaa2Adu3boljI2NxYgRI8TVq1fF/Pnzha6urtizZ0+hrm9WcjMGDRs2FH369FHZFhITE6X5RX0MhBBix44dYteuXeL69esiOjpafP/990JfX19ERkYKIYr/diDEh8egJGwHmsKgokETJkwQ3t7eWc57/vy50NfXFxs3bpSmRUVFCQDi1KlTQoi3H3Y6Ojri4cOHUptFixYJc3NzkZaWVqC1a8L7H9AZGRnC3t5ezJo1S5r2/PlzoVQqxdq1a4UQQly9elUAEGfOnJHahIWFCYVCIe7fvy+EEGLhwoXCyspKZQy+++47UalSpQJeo/zJLqi0adMm29cUx3FISEgQAER4eLgQQnP7wLfffiuqVq2qsqxOnTqJwMDAgl6lPHt/DIR4+wE1dOjQbF9T3MYgk5WVlfj9999L5HaQKXMMhCi520F+8KsfDbtx4wYcHR1Rvnx5dO3aFXFxcQCAc+fO4fXr1wgICJDaVq5cGeXKlcOpU6cAAKdOnUK1atVU7sobGBiIpKQkXLlypXBXRANu376Nhw8fqqyzhYUF6tSpo7LOlpaWqFWrltQmICAAOjo6+Oeff6Q2DRo0gIGBgdQmMDAQ0dHRePbsWSGtzcc7cuQIbG1tUalSJfTv3x9PnjyR5hXHcUhMTAQAlCpVCoDm9oFTp06p9JHZJrMPOXl/DDL9+eefsLa2hqenJ8aOHYsXL15I84rbGKSnp2PdunVITU2Fn59fidwO3h+DTCVpO/gYsrgzbXFRp04drFy5EpUqVUJ8fDwmTZqE+vXrIzIyEg8fPoSBgYHajyja2dnh4cOHAICHDx+q/XRA5vPMNkVJZs1ZrdO762xra6syX09PD6VKlVJp4+rqqtZH5jwrK6sCqV+TmjVrhi+++AKurq64efMmvv/+ezRv3hynTp2Crq5usRuHjIwMDBs2DHXr1oWnpycAaGwfyK5NUlIS/vvvPxgZGRXEKuVZVmMAAF999RWcnZ3h6OiIS5cu4bvvvkN0dDS2bNkCoPiMweXLl+Hn54eXL1/C1NQUW7duhYeHByIiIkrMdpDdGAAlZzvQBAYVDWrevLn0by8vL9SpUwfOzs7YsGFDsdlgKH86d+4s/btatWrw8vJChQoVcOTIEfj7+2uxsoIxcOBAREZG4vjx49ouRWuyG4O+fftK/65WrRocHBzg7++PmzdvokKFCoVdZoGpVKkSIiIikJiYiE2bNiEoKAjh4eHaLqtQZTcGHh4eJWY70AR+9VOALC0tUbFiRcTExMDe3h6vXr3C8+fPVdo8evQI9vb2AAB7e3u1M98zn2e2KUoya85qnd5d54SEBJX5b968wdOnT4vtuABA+fLlYW1tjZiYGADFaxwGDRqEnTt34vDhwyhbtqw0XVP7QHZtzM3NZfMHQXZjkJU6deoAgMq2UBzGwMDAAG5ubqhZsyamTZsGb29vhIaGlqjtILsxyEpx3Q40gUGlAKWkpODmzZtwcHBAzZo1oa+vj4MHD0rzo6OjERcXJ31n6efnh8uXL6t8YO3fvx/m5ubS4cKixNXVFfb29irrnJSUhH/++UdlnZ8/f45z585JbQ4dOoSMjAxpx/Xz88PRo0fx+vVrqc3+/ftRqVIlWX3dkRf37t3DkydP4ODgAKB4jIMQAoMGDcLWrVtx6NAhta+pNLUP+Pn5qfSR2ebd7/615UNjkJWIiAgAUNkWivIYZCcjIwNpaWklYjvITuYYZKWkbAf5ou2zeYuTkSNHiiNHjojbt2+LEydOiICAAGFtbS0SEhKEEG8vyStXrpw4dOiQOHv2rPDz8xN+fn7S6zMvR/vss89ERESE2LNnj7CxsZH15cnJycniwoUL4sKFCwKACAkJERcuXBB37twRQry9PNnS0lJs375dXLp0SbRp0ybLy5OrV68u/vnnH3H8+HHh7u6uclnu8+fPhZ2dnejevbuIjIwU69atE8bGxrK5LFeInMchOTlZjBo1Spw6dUrcvn1bHDhwQNSoUUO4u7uLly9fSn0U9XHo37+/sLCwEEeOHFG55PLFixdSG03sA5mXZI4ePVpERUWJX3/9VTaXZH5oDGJiYsRPP/0kzp49K27fvi22b98uypcvLxo0aCD1UdTHQAghxowZI8LDw8Xt27fFpUuXxJgxY4RCoRD79u0TQhT/7UCInMegpGwHmsKgokGdOnUSDg4OwsDAQJQpU0Z06tRJxMTESPP/++8/MWDAAGFlZSWMjY1Fu3btRHx8vEofsbGxonnz5sLIyEhYW1uLkSNHitevXxf2quTa4cOHBQC1R1BQkBDi7SXKP/74o7CzsxNKpVL4+/uL6OholT6ePHkiunTpIkxNTYW5ubkIDg4WycnJKm0uXrwo6tWrJ5RKpShTpoyYPn16Ya1iruQ0Di9evBCfffaZsLGxEfr6+sLZ2Vn06dNH5bJDIYr+OGS1/gDEihUrpDaa2gcOHz4sfHx8hIGBgShfvrzKMrTpQ2MQFxcnGjRoIEqVKiWUSqVwc3MTo0ePVrl/hhBFewyEEKJXr17C2dlZGBgYCBsbG+Hv7y+FFCGK/3YgRM5jUFK2A01RCCFE4R2/ISIiIso9nqNCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkR5EhsbC4VCId3ym4ioIDGoEJVACoUix8fEiRO1XWKWYmJiEBwcjLJly0KpVMLV1RVdunTB2bNnC7UOhjWiwqOn7QKIqPDFx8dL/16/fj3Gjx+P6OhoaZqpqak2ysrR2bNn4e/vD09PTyxZsgSVK1dGcnIytm/fjpEjRyI8PFzbJRJRAeARFaISyN7eXnpYWFhAoVBIz21tbRESEiIdtfDx8cGePXuy7Ss9PR29evVC5cqVERcXBwDYvn07atSoAUNDQ5QvXx6TJk3CmzdvpNcoFAr8/vvvaNeuHYyNjeHu7o4dO3ZkuwwhBHr27Al3d3ccO3YMLVu2RIUKFeDj44MJEyZg+/btUtvLly+jSZMmMDIyQunSpdG3b1+kpKRI8xs1aoRhw4ap9N+2bVv07NlTeu7i4oKpU6eiV69eMDMzQ7ly5bB06VJpfuavIlevXh0KhQKNGjXKcbyJKP8YVIhIRWhoKObMmYPZs2fj0qVLCAwMROvWrXHjxg21tmlpafjyyy8RERGBY8eOoVy5cjh27Bh69OiBoUOH4urVq1iyZAlWrlyJKVOmqLx20qRJ6NixIy5duoQWLVqga9euePr0aZY1RURE4MqVKxg5ciR0dNTftiwtLQEAqampCAwMhJWVFc6cOYONGzfiwIEDGDRoUJ7HYc6cOahVqxYuXLiAAQMGoH///tJRp9OnTwMADhw4gPj4eGzZsiXP/RNRLmn5RxGJSMtWrFghLCwspOeOjo5iypQpKm18fX3FgAEDhBBC3L59WwAQx44dE/7+/qJevXri+fPnUlt/f38xdepUldevWbNGODg4SM8BiHHjxknPU1JSBAARFhaWZY3r168XAMT58+dzXJelS5cKKysrkZKSIk3btWuX0NHRkX6tumHDhmLo0KEqr2vTpo30i99CCOHs7Cy6desmPc/IyBC2trZi0aJFKmNw4cKFHOshoo/Hc1SISJKUlIQHDx6gbt26KtPr1q2Lixcvqkzr0qULypYti0OHDsHIyEiafvHiRZw4cULlCEp6ejpevnyJFy9ewNjYGADg5eUlzTcxMYG5uTkSEhKyrEvk8kfeo6Ki4O3tDRMTE5XaMzIyEB0dDTs7u1z18359mV+NZVcfERUcfvVDRPnSokULXLp0CadOnVKZnpKSgkmTJiEiIkJ6XL58GTdu3IChoaHUTl9fX+V1CoUCGRkZWS6rYsWKAIBr1659dN06Ojpqwef169dq7fJSHxEVHAYVIpKYm5vD0dERJ06cUJl+4sQJeHh4qEzr378/pk+fjtatW6tccVOjRg1ER0fDzc1N7ZHV+SW54ePjAw8PD8yZMyfLsPD8+XMAQJUqVXDx4kWkpqaq1K6jo4NKlSoBAGxsbFSuekpPT0dkZGSe6jEwMJBeS0QFi0GFiFSMHj0aM2bMwPr16xEdHY0xY8YgIiICQ4cOVWs7ePBgTJ48GZ9//jmOHz8OABg/fjxWr16NSZMm4cqVK4iKisK6deswbty4fNekUCiwYsUKXL9+HfXr18fu3btx69YtXLp0CVOmTEGbNm0AAF27doWhoSGCgoIQGRmJw4cPY/Dgwejevbv0tU+TJk2wa9cu7Nq1C9euXUP//v2loJNbtra2MDIywp49e/Do0SMkJibme92IKGcMKkSkYsiQIRgxYgRGjhyJatWqYc+ePdixYwfc3d2zbD9s2DBMmjQJLVq0wMmTJxEYGIidO3di37598PX1xSeffIJffvkFzs7OH1VX7dq1cfbsWbi5uaFPnz6oUqUKWrdujStXrmDu3LkAAGNjY+zduxdPnz6Fr68vOnToAH9/fyxYsEDqp1evXggKCkKPHj3QsGFDlC9fHo0bN85TLXp6epg3bx6WLFkCR0dHKSgRkeYpRG7PUiMiIiIqZDyiQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREssWgQkRERLLFoEJERESyxaBCREREsvX/AM1KoENKFnNRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#альтернативный вариант загрузки нобуков с маркированием маркдаун ячеек как комментарии внутри кода"
      ],
      "metadata": {
        "id": "SdW0kAR86Tyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# функция для загрузки блокнота ipynb в Document LangChain\n",
        "# от NotebookLoader пришлось отказаться - он глючит\n",
        "def loadipynb(fname):\n",
        "    # fname='/content/drive/MyDrive/docs4colab/langchain/00b-azure-openai-simple.ipynb'\n",
        "    # Чтение файла ноутбука как JSON\n",
        "    with open(fname, 'r') as f:\n",
        "        notebook = json.load(f)\n",
        "    codecells=[] #ячейки с кодом\n",
        "    markdowncells=[] #ячейки с текстом\n",
        "    # Просматриваем код в ячейках\n",
        "    for cell in notebook['cells']:\n",
        "        if cell['cell_type'] == 'code':\n",
        "            codecells.append(''.join(cell['source']))\n",
        "        elif cell['cell_type'] == 'markdown':\n",
        "            # Добавление \"# \" в начало каждой строки, чтобы эта строка вписцывалась в код, как комментарий\n",
        "            for line0 in cell['source']:\n",
        "                modified_text = \"\\n\".join(\"# \" + line2 for line1 in line0.splitlines() if (line2 := line1.strip()) and len(line2) > 1)\n",
        "                codecells.append(''.join(modified_text))\n",
        "    code='\\n'.join(codecells)\n",
        "    metadata = {\n",
        "        'codesize': f\"{len(code)}\", #в чатжпт предполагается подавать код с комментариями, взятыми из маркдаун ячеек нотбука\n",
        "        'source': fname\n",
        "    }\n",
        "    # для индексации и поиска использовать код и текст из нотбука\n",
        "    readydoc=Document(page_content=code, metadata=metadata)\n",
        "    return readydoc\n",
        "\n",
        "#собрать список лангчейн документов из ипинбов(ipynb)\n",
        "# здесь в основном нотбуки ipynb, но есть и чистый файл питон py, загружаются разными загрузчиками\n",
        "root_dir = '/content/drive/MyDrive/docs4colab/langchain'\n",
        "\n",
        "ipynbdocs=[]\n",
        "# Используем os.walk для обхода всех вложенных папок\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for filename in filenames:\n",
        "        fullname=f\"{dirpath}/{filename}\"\n",
        "        # Вычисляем длину заполнения на основе длины dirpath\n",
        "        padding_length = 150-len(fullname)\n",
        "        if padding_length<0:\n",
        "            print(padding_length)\n",
        "            padding_length=0\n",
        "        # Используем динамическое форматирование внутри f-строки\n",
        "        pad_string = ('{:=^' + str(padding_length) + '}').format('')\n",
        "        print(f\"{fullname}{pad_string}\",end=\"\\n\")\n",
        "        if filename.endswith(\".ipynb\"):\n",
        "            ipynbdocs.append(loadipynb(fullname))\n",
        "        else: #файлы py\n",
        "            loader = UnstructuredFileLoader(fullname)\n",
        "            lo = loader.load()\n",
        "            lo[0].metadata['codesize']=len(lo[0].page_content)\n",
        "            ipynbdocs.extend(lo)\n",
        "print(f\"всего загружено файлов примеров лангчейн: {len(ipynbdocs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BQYBSSj6QY9",
        "outputId": "20bc030b-bd9d-461d-800c-49b955c9e6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/docs4colab/langchain/00b-azure-openai-simple.ipynb=============================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/00-azure-openai-retrieval.ipynb===========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/rag-chatbot.ipynb=========================================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/v1/claude-3-agent.ipynb===================================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/v1/xml-agents.ipynb=======================================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/03a-token-counter.ipynb==========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/06-langchain-agents.ipynb========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/00-langchain-intro.ipynb=========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/01-langchain-prompt-templates.ipynb==============================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/05-langchain-retrieval-augmentation.ipynb========================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/04-langchain-chat.ipynb==========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/02-langchain-chains.ipynb========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/03-langchain-conversational-memory.ipynb=========================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/xx-langchain-chunking.ipynb======================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/07-langchain-tools.ipynb=========================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/10-langchain-multi-query.ipynb===================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/xx-quick-agents-intro.ipynb======================================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/08-langchain-retrieval-agent.ipynb===============================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/11-langchain-expression-language.ipynb===========================================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/09-langchain-streaming/09-langchain-streaming.ipynb==============================================\n",
            "/content/drive/MyDrive/docs4colab/langchain/handbook/09-langchain-streaming/main.py===================================================================\n",
            "всего загружено файлов примеров лангчейн: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ^ конец альтернативного варианта"
      ],
      "metadata": {
        "id": "QuKyvdRn8vQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# приготовить индексную базу для example-нотбуков и сохранить\n",
        "# db.add_documents(documents)\n",
        "embeddings = OpenAIEmbeddings()\n",
        "dbipynb = FAISS.from_documents(ipynbdocs, embeddings)\n",
        "index_name = \"dbfaiss_from_langchain2\"\n",
        "dbipynb.save_local(folder_path=folder_path, index_name=index_name)"
      ],
      "metadata": {
        "id": "D4CydHyaZvXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pdwpdy2icR2p",
        "outputId": "dda35789-d382-4107-cc7a-285170bfaf94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./drive/MyDrive/docs4colab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# считать вторую базу\n",
        "# на данный момент используется альтернативный вариант\n",
        "index_name = \"dbfaiss_from_langchain2\"\n",
        "dbipynb = FAISS.load_local(\n",
        "    folder_path=folder_path,\n",
        "    embeddings=embeddings,\n",
        "    index_name=index_name\n",
        ")"
      ],
      "metadata": {
        "id": "QFX-t_gXYhRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _key, _value in dbipynb.docstore._dict.items():\n",
        "    print(f\"{_key} {(_value)}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GuXv1gcShrX",
        "outputId": "f79aceee-bc0a-4b99-80cf-702e4f134c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9c980cef-2f63-431b-8d0d-567c99deaf6b page_content='# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/00b-azure-openai-simple.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/00b-azure-openai-simple.ipynb)\\n\\n# #### [LangChain Handbook](https://pinecone.io/learn/langchain)\\n\\n# # Using Azure\\'s OpenAI with LangChain\\n!pip install -qU \\\\\\n    langchain==0.0.227 \\\\\\n    openai==0.27.8\\n# ## Initializing Azure OpenAI\\n# To use OpenAI\\'s service via Azure we first need to setup the service in Azure via **Azure OpenAI Studio**. In here we need to create a deployment using `gpt-4`.\\n\\n# Once we\\'ve done this we need to set a few environment variables (all found in **Azure OpenAI Studio**) like so:\\nimport os\\n\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'YOUR_API_KEY\\'\\nos.environ[\\'OPENAI_API_TYPE\\'] = \\'azure\\'\\nos.environ[\\'OPENAI_API_VERSION\\'] = \\'2023-03-15-preview\\'\\nos.environ[\\'OPENAI_API_BASE\\'] = \\'https://azure-pinecone-demo.openai.azure.com/\\'\\n# We can now connect to our deployment via LangChain. We are using a `ChatCompletion` endpoint that uses `gpt-4`:\\nfrom langchain.chat_models import AzureChatOpenAI\\n\\nllm = AzureChatOpenAI(\\n    deployment_name=\"gpt4\",\\n    model_name=\"gpt-4\"\\n)\\n# ## Making Queries\\n\\n# Now we can begin making queries as we usually would in LangChain. As we\\'re using a chat model we use a list of messages beginning with a `SystemMessage` that prepares the chatbot, giving it instructions on how to behave.\\nfrom langchain.schema import (\\n    SystemMessage,\\n    HumanMessage,\\n    AIMessage\\n)\\n\\nmessages = [\\n    SystemMessage(content=\"You are ExpertGPT, an AGI system capable of \" +\\n                          \"anything except answering questions about cheese. \" +\\n                          \"It turns out that AGI does not fathom cheese as a \" +\\n                          \"concept, the reason for this is a mystery.\")\\n]\\n# We\\'ll add our first user query:\\nmessages.append(\\n    HumanMessage(\\n        content=\"Hey how are you doing today? What is the meaning of life?\"\\n    )\\n)\\n# And get a response:\\nres = llm(messages)\\nres\\n# We then add this response to our `messages` to continue the conversation:\\nmessages.append(res)\\n# And continue chatting:\\nmessages.append(\\n    HumanMessage(\\n        content=\"Can you give me one concrete example of one of these interpretations?\"\\n    )\\n)\\n\\nres = llm(messages)\\nres\\nmessages.append(res)\\n\\nmessages.append(\\n    HumanMessage(\\n        content=\"Thanks! What color is cheese?\"\\n    )\\n)\\n\\nres = llm(messages)\\nres\\n# ---' metadata={'codesize': '2665', 'source': '/content/drive/MyDrive/docs4colab/langchain/00b-azure-openai-simple.ipynb'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# translate (перевод запроса на оригинал базы знаний)"
      ],
      "metadata": {
        "id": "oLap7q2fi5R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# переводчик - используется для перевода русскоязычного запроса на английский язык, для возможности поиска в эмбедингах\n",
        "# сформированных на англоязычной базе знаний\n",
        "def translate_questions(zapros):\n",
        "    global client\n",
        "    \"\"\"\n",
        "    Функция возвращает английский текст запроса.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"\"\"\n",
        "        Ты - русско-английский переводчик. Твоя задача - переводить русскоязычные запросы,\n",
        "        связанные с темой программирования на языке python, на технический английский язык,\n",
        "        приближенный к языку написания технической документации библиотек python.\n",
        "        запрос, требующий перевода delimited by triple quotes \\\"\\\"\\\".\n",
        "        В качестве ответа возвращай только перевод без рассуждений, без разглагольствований и без лишней информации.\n",
        "        \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"\n",
        "        \\\"\\\"\\\"{zapros}\\\"\\\"\\\"\n",
        "        \"\"\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    # вернуть ответ и потраченные токены\n",
        "    return completion.choices[0].message.content,completion.__dict__['usage'].__dict__['total_tokens']"
      ],
      "metadata": {
        "id": "fnp1EzJLZQip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_questions(\"как использовать функцию загрузки документа\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXfv7O3BLGYV",
        "outputId": "a2a59602-be0e-4299-a7cd-78859f6f41c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('\"How to use the document loading function\"', 211)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv94-X_7P75z"
      },
      "outputs": [],
      "source": [
        "# суммаризатор не используется\n",
        "# def summarize_questions(dialog):\n",
        "#     \"\"\"\n",
        "#     Функция возвращает саммаризированный текст диалога.\n",
        "#     \"\"\"\n",
        "#     messages = [\n",
        "#         {\"role\": \"system\", \"content\": \"Ты - нейро-саммаризатор. Твоя задача - суммаризировать диалог, который тебе пришел. Если пользователь назвал свое имя, обязательно отрази его в суммаризированном диалоге\"},\n",
        "#         {\"role\": \"user\", \"content\": \"Суммаризируй следующий диалог консультанта и пользователя, тебе запрещено удалять из суммаризации имя пользователя: \" + \" \".join(dialog)}\n",
        "#     ]\n",
        "\n",
        "#     completion = client.chat.completions.create(\n",
        "#         model=\"gpt-3.5-turbo-1106\",     # используем gpt4 для более точной саммаризации\n",
        "#         messages=messages,\n",
        "#         temperature=0,          # Используем более низкую температуру для более определенной суммаризации\n",
        "#     )\n",
        "\n",
        "#     # вернуть ответ и потраченные токены\n",
        "#     return completion.choices[0].message.content,completion.__dict__['usage'].__dict__['total_tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer_index"
      ],
      "metadata": {
        "id": "QolTDOdsi__F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lAYuYN9P7zz"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "relevan=0.7 #чем меньше, тем лучше, но дать большую свободу\n",
        "porogmax=4000 #задать предел токенов(суммарно для системного сообщения и фрагмента базы знаний), за который не выходить для любых запросов\n",
        "\n",
        "# блок, отвечающий за выбор информации из базы\n",
        "def extract_json(text):\n",
        "    # Находим содержимое строки между ```json и ```\n",
        "    match = re.search(r'```json\\n(.*?)```', text, re.DOTALL)\n",
        "    if match:\n",
        "        json_str = match.group(1)\n",
        "        # Удаляем пробелы в начале и конце строки\n",
        "        json_str = json_str.strip()\n",
        "        # Выводим содержимое строки\n",
        "        return json_str\n",
        "    else:\n",
        "        return \"Content between ```json and ``` not found in the text.\"\n",
        "# получение id документа из индексной базы для дальнейшего извлечения из него url\n",
        "def remove_after_dash(id_list):\n",
        "    return [id.split('-')[0] for id in id_list]\n",
        "\n",
        "def answer_index(system,dbdocs,dbexample, search_query,  verbose=0):\n",
        "    global relevan\n",
        "    global client\n",
        "    global porogmax\n",
        "    num_tokens=0\n",
        "    porog=porogmax # этот порог соблюдается для всех чанков, кроме чанков из списка specchanks, которым разрешено попасть в запрос несмотря на превышение порога\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "    ]\n",
        "    #вычесть количество токенов на системную роль,запрос [, пример запроса и ответ ассистента ]\n",
        "    for mess in messages:\n",
        "        porog-=num_tokens_from_string(mess['content'])\n",
        "    porog-=num_tokens_from_string(search_query)\n",
        "\n",
        "    frags=[]\n",
        "    scor=[]\n",
        "\n",
        "    docsipynb = dbexample.similarity_search_with_score(search_query, k=1)\n",
        "    for i, doc in enumerate(docsipynb):\n",
        "        page_content=doc[0].page_content[:int(doc[0].metadata['codesize'])] #взять для запроса только код\n",
        "        nexttopic=f'FRAG№\\n{page_content}~~~{doc[0].metadata[\"source\"]}~~~'\n",
        "        # print(f'{doc[1]:.4f}//{num_tokens_from_string(doc[0].page_content)}{nexttopic}')\n",
        "        frags.append(nexttopic)\n",
        "        scor.append(f\"{doc[1]:.4f}\")\n",
        "        porog-=num_tokens_from_string(nexttopic)\n",
        "        break #из нотбуков использовать самый первый\n",
        "\n",
        "    # Поиск релевантных отрезков из базы знаний по вопросу пользователя\n",
        "    docs = dbdocs.similarity_search_with_score(search_query, k=20)\n",
        "    # вычислить, сколько из найденных фрагментов в базе данных можно вставить в запрос\n",
        "    for i, doc in enumerate(docs):\n",
        "        nexttopic=f'FRAG№\\n{doc[0].page_content}~~~{doc[0].metadata[\"id\"]}-{doc[0].metadata[\"subid\"]}~~~'\n",
        "        # print(f'{doc[1]:.4f} {porog-num_tokens_from_string(nexttopic, \"cl100k_base\")}')\n",
        "        if doc[1]<=relevan:\n",
        "            # если есть еще резерв токенов, то добавить чанк в запрос\n",
        "            if porog-num_tokens_from_string(nexttopic)>0:\n",
        "                frags.append(nexttopic)\n",
        "                porog-=num_tokens_from_string(nexttopic)\n",
        "                scor.append(f\"{doc[1]:.4f}\") #вывести потом все найденные скоры\n",
        "            else:\n",
        "                #очередной чанк превысит порог используемых токенов, больше не добавлять\n",
        "                break\n",
        "\n",
        "    # message_content = re.sub(r'\\n{2}', ' ', '\\n '.join(frags))\n",
        "    message_content = '\\n'.join(frags)\n",
        "    if verbose: print(f'{\"message_content\":=^50}\\n', message_content)\n",
        "    if verbose: print(f'{\"message_content\":-^50}\\n')\n",
        "    # return \"\",porogmax-porog\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": f\"\\\"\\\"\\\"{message_content}\\\"\\\"\\\"\\n```{search_query}```\"})\n",
        "\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\", #gpt-3.5-turbo-1106\n",
        "        # response_format={ \"type\": \"json_object\" },\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    totaltokens=completion.__dict__['usage'].__dict__['total_tokens']\n",
        "    json_answer = completion.choices[0].message.content\n",
        "    try:\n",
        "        # загрузить json объект из ответа\n",
        "        # Попытка преобразовать извлеченный JSON в объект Python\n",
        "        json_obj = json.loads(extract_json(json_answer))\n",
        "        # Если преобразование прошло успешно, вы можете продолжить работу с json_obj\n",
        "    except json.JSONDecodeError as e:\n",
        "        # Обработка исключения, возникающего при некорректном JSON\n",
        "        return f\"<div>повторите еще раз этот же вопрос</br>т.к. из-за сбоя модели консультант вернул некорректную структуру:</br>{json_answer}</div>\",totaltokens\n",
        "\n",
        "    # всего два ключа формируются по заданию\n",
        "    # пример кода питон на запрос пользователя\n",
        "    code=json_obj['HTMLPYCODE']\n",
        "    # ссылки на оригинальную документацию - все подряд без анализа\n",
        "    linkto=remove_after_dash(json_obj['SourceIDList'])\n",
        "    # сформировать html текст для приличного отображения\n",
        "    htmllinkto=[f'<div><a target=\"_blank\" href=\"{findindbbyid(link).metadata[\"source\"]}\">{findindbbyid(link).metadata[\"source\"]}</a></div>' for link in linkto]\n",
        "    # возврат блока информации для отображения и цену запроса в токенах\n",
        "    return f\"{code}</br>полезные ссылки <div>{''.join(htmllinkto)}</div>\",totaltokens#,' '.join(scor)\n",
        "    # urls=[]\n",
        "    # for cl in linkto:\n",
        "    #     docs = dbdocs.similarity_search_with_score(cl, k=1)\n",
        "    #     urls.append(docs[0].metadata['source'])\n",
        "    # links=[f\"{link},{linkurl}</br>\" for link,linkurl in zip(linkto,urls)]\n",
        "    # # вернуть ответ и потраченные токены и все скоры\n",
        "    # return f\"{response}</br>полезные ссылки <div>{''.join(links)}</div>\",\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer_user_question_dialog"
      ],
      "metadata": {
        "id": "UA-qvMtNimhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_user_question_dialog(system, db1,db2, user_question, translatequestion=True,question_history=\"\"):\n",
        "    \"\"\"\n",
        "    Функция возвращает ответ на вопрос пользователя.\n",
        "    \"\"\"\n",
        "    if translatequestion:\n",
        "        # перевести запрос пользователя на английский язык\n",
        "        topic,tokens1=translate_questions(user_question)\n",
        "    else:\n",
        "        topic,tokens1=user_question,0\n",
        "\n",
        "    # ************************************************не удалять блок для возможного расширения функционала\n",
        "    # summarized_history = \"\"\n",
        "    # # Если в истории более одного вопроса, применяем суммаризацию\n",
        "    # s_q=(\"\",0)\n",
        "    # if len(question_history) > 0:\n",
        "    #     s_q=summarize_questions([q + ' ' + (a if a else '') for q, a in question_history])\n",
        "    #     summarized_history = s_q[0] #Вот саммаризированный предыдущий диалог с пользователем:\n",
        "    # topic = f\"```{summarized_history}```\" + \" Актуальный вопрос пользователя: \" + user_question\n",
        "    # *************************************************\n",
        "\n",
        "    # Получаем ответ, используя только user_question для поиска в базе данных,verbose=True\n",
        "    print(topic)\n",
        "    answer_text,tokens2 = answer_index(system, db1,db2, topic)\n",
        "\n",
        "    # ************************************************не удалять блок для возможного расширения функционала\n",
        "    # question_history.append((f'Пользователь: {user_question}', f\"Консультант: {answer_text[0] if answer_text[0] else ''}\"))\n",
        "    # # Выводим саммаризированный текст, который видит модель\n",
        "    # if summarized_history:\n",
        "    #     print(f'{\"summarized_history\":*^50}')\n",
        "    #     print(insert_newlines(summarized_history))\n",
        "    #     print(f'{\"summarized_history\":*^50}')\n",
        "    # *************************************************\n",
        "\n",
        "    # вернуть ответ и потраченные токены, включая затраты на перевод запроса\n",
        "    return answer_text,tokens2+tokens1\n"
      ],
      "metadata": {
        "id": "g9maUoWgjmgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# system"
      ],
      "metadata": {
        "id": "EuCZ1R8disaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system=\"\"\"\n",
        "### instruction ###\n",
        "Act as a Python expert, especially proficient with the LangChain library.\n",
        "Below is the data structure and abbreviations that will be used:\n",
        "Fragment: A text or code excerpt from the LangChain library, which may not be a complete Python structure.\n",
        "Database: A collection of multiple Fragments.\n",
        "SourceID: A unique identifier representing the source of each individual Fragment in the Database.\n",
        "User's Query: The current question posed by the user.\n",
        "PythonEntity: Python classes or methods.\n",
        "\n",
        "Instructions for data handling:\n",
        "The Database will be delimited by triple quotes (\\\"\\\"\\\");\n",
        "each Fragment is preceded by the label FRAG№ and followed by the SourceID, delimited by triple tildes (~~~).\n",
        "The User's Query will be delimited by triple backticks (```).\n",
        "From the database extract a list of all PythonEntity (termed as  ALLentity) and any existing brief information about their purposes.\n",
        "From the database extract a list of SourceID (termed as  SourceIDList);\n",
        "Extract the following elements from the User's Query:\n",
        "- some PythonEntity that exist in ALLentity;\n",
        "- explicit task;\n",
        "In the absence of any of the two points, the User's Query should be expanded using the existing point as follows:\n",
        "- if only a task is present, then it is necessary to select from one to three most suitable PythonEntity from ALLentity to perform this type of task;\n",
        "- if only PythonEntity are present, you need to show an example of the use of these PythonEntity;\n",
        "\n",
        "### Task ###\n",
        "Given the above info about goal and the exact PythonEntity (termed as RLVCLASSES), you should be able to generate some pretty clear example Python code.\n",
        "First try to find existing Python code from the database.\n",
        "If a suitable fragment is not found, generate the Python code yourself based on the information from the database.\n",
        "Please provide this code with comments in Russian.\n",
        "Wrap this code with <pre> and <code=\"Python\"> tags to ensure it will properly displayed as HTML on a webpage;\n",
        "Explain in as much detail as possible the main purpose of the classes, methods and parameters used.\n",
        "\n",
        "Provide SourceIDList and you python code as JSON with the following keys:\n",
        "\"SourceIDList\",\"HTMLPYCODE\"\n",
        "Also, make sure that all you comments are provided in Russian only.\n",
        "\n",
        "\"\"\"\n",
        "# user_question=\"как использовать RecursiveCharacterTextSplitter\"\n",
        "# как применить утилиту калькулятора\n",
        "# утилиты с множественными параметрами\n"
      ],
      "metadata": {
        "id": "uCgg4r6LR4BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q496OWI7Rrb0"
      },
      "outputs": [],
      "source": [
        "def run_dialog(system, db,dbipynb):\n",
        "    \"\"\"\n",
        "    Функция запускает диалог между пользователем и нейро-консультантом.\n",
        "    \"\"\"\n",
        "    print(\"Задайте вопрос по библиотеке LangChain\")\n",
        "    while True:\n",
        "        user_question = input('Пользователь: ')\n",
        "        if user_question.lower() == 'stop':\n",
        "            break\n",
        "        answer = answer_user_question_dialog(system, db,dbipynb, user_question,translatequestion=True)\n",
        "        print(\"\", flush=True)\n",
        "        display(HTML(wrap(f'<div>Запрос пользователя: {user_question}</br>стоимость (запрос+перевод+ответ) {answer[1]} токенов </br>Ответ консультанта:{answer[0]}</div>',startend=False)))\n",
        "        print(\"\", flush=True)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_dialog(system, db,dbipynb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hJ41PzYELSm8",
        "outputId": "332d1b9a-7583-440a-b396-bb04d62a3e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задайте вопрос по библиотеке LangChain\n",
            "Пользователь: утилиты с множественными параметрами\n",
            "\"\"\"Utilities with multiple parameters\"\"\"\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    <div>Запрос пользователя: утилиты с множественными параметрами</br>стоимость (запрос+перевод+ответ) 4698 токенов </br>Ответ консультанта:<pre><code class=\"Python\"># Пример использования класса PythagorasTool\n",
              "\n",
              "# Импорт необходимых библиотек\n",
              "from langchain.tools import BaseTool\n",
              "from typing import Union, Optional\n",
              "from math import sqrt, cos, sin\n",
              "\n",
              "# Описание класса PythagorasTool\n",
              "# Этот инструмент предназначен для вычисления гипотенузы треугольника\n",
              "# на основе заданных сторон и/или углов\n",
              "\n",
              "class PythagorasTool(BaseTool):\n",
              "    name = \"Hypotenuse calculator\"\n",
              "    description = \"use this tool when you need to calculate the length of an hypotenuse given one or two sides of a triangle and/or an angle (in degrees). To use the tool you must provide at least two of the following parameters ['adjacent_side', 'opposite_side', 'angle'].\"\n",
              "\n",
              "    def _run(\n",
              "        self,\n",
              "        adjacent_side: Optional[Union[int, float]] = None,\n",
              "        opposite_side: Optional[Union[int, float]] = None,\n",
              "        angle: Optional[Union[int, float]] = None\n",
              "    ):\n",
              "        # Проверяем значения, которые нам передали\n",
              "        if adjacent_side and opposite_side:\n",
              "            return sqrt(float(adjacent_side)**2 + float(opposite_side)**2)\n",
              "        elif adjacent_side and angle:\n",
              "            return adjacent_side / cos(float(angle))\n",
              "        elif opposite_side and angle:\n",
              "            return opposite_side / sin(float(angle))\n",
              "        else:\n",
              "            return \"Could not calculate the hypotenuse of the triangle. Need two or more of `adjacent_side`, `opposite_side`, or `angle`.\"\n",
              "    \n",
              "    def _arun(self, query: str):\n",
              "        raise NotImplementedError(\"This tool does not support async\")\n",
              "\n",
              "# Создание экземпляра класса PythagorasTool\n",
              "pythagoras_tool = PythagorasTool()\n",
              "\n",
              "# Пример использования инструмента для вычисления гипотенузы треугольника\n",
              "result = pythagoras_tool._run(adjacent_side=3, opposite_side=4)\n",
              "print(result)\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_core/language_models/chat_models.html\">https://api.python.langchain.com/en/latest/_modules/langchain_core/language_models/chat_models.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/functions_utils/langchain_google_vertexai.functions_utils.ParametersSchema.html\">https://api.python.langchain.com/en/latest/functions_utils/langchain_google_vertexai.functions_utils.ParametersSchema.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html\">https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/typing.html\">https://api.python.langchain.com/en/latest/_modules/typing.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/tools/langchain_community.tools.connery.models.Parameter.html\">https://api.python.langchain.com/en/latest/tools/langchain_community.tools.connery.models.Parameter.html</a></div></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Пользователь: как применить утилиту калькулятора\n",
            "\"How to use the calculator utility\"\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    <div>Запрос пользователя: как применить утилиту калькулятора</br>стоимость (запрос+перевод+ответ) 4613 токенов </br>Ответ консультанта:<pre><code class=\"Python\"># Пример использования утилиты калькулятора\n",
              "\n",
              "from langchain.tools import BaseTool\n",
              "from math import pi\n",
              "from typing import Union\n",
              "\n",
              "\n",
              "class CircumferenceTool(BaseTool):\n",
              "    name = \"Circumference calculator\"\n",
              "    description = \"use this tool when you need to calculate a circumference using the radius of a circle\"\n",
              "\n",
              "    def _run(self, radius: Union[int, float]):\n",
              "        return float(radius)*2.0*pi\n",
              "    \n",
              "    def _arun(self, radius: Union[int, float]):\n",
              "        raise NotImplementedError(\"This tool does not support async\")\n",
              "\n",
              "# Создание экземпляра инструмента\n",
              "calculator = CircumferenceTool()\n",
              "\n",
              "# Вычисление длины окружности для круга с радиусом 7.81 мм\n",
              "radius = 7.81\n",
              "result = calculator._run(radius)\n",
              "print(result)  # Вывод результата\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain/chains/structured_output/base.html\">https://api.python.langchain.com/en/latest/_modules/langchain/chains/structured_output/base.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/parsers/language/language_parser.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/parsers/language/language_parser.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html\">https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html\">https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/reddit.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/reddit.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html\">https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.base.BaseTracer.html\">https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.base.BaseTracer.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/typing.html\">https://api.python.langchain.com/en/latest/_modules/typing.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.clarifai.Clarifai.html\">https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.clarifai.Clarifai.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_core/language_models/chat_models.html\">https://api.python.langchain.com/en/latest/_modules/langchain_core/language_models/chat_models.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.qdrant.Qdrant.html\">https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.qdrant.Qdrant.html</a></div></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Пользователь: как использовать RecursiveCharacterTextSplitter\n",
            "\"How to use RecursiveCharacterTextSplitter\"\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    <div>Запрос пользователя: как использовать RecursiveCharacterTextSplitter</br>стоимость (запрос+перевод+ответ) 4489 токенов </br>Ответ консультанта:<pre><code class=\"Python\"># Пример использования RecursiveCharacterTextSplitter\n",
              "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
              "from langchain.storage import InMemoryStore\n",
              "\n",
              "# Этот текстовый разделитель используется для создания родительских документов\n",
              "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, add_start_index=True)\n",
              "\n",
              "# Этот текстовый разделитель используется для создания дочерних документов\n",
              "# Он должен создавать документы меньшего размера, чем родительские\n",
              "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400, add_start_index=True)\n",
              "\n",
              "# Векторное хранилище для индексации дочерних фрагментов\n",
              "vectorstore = Chroma(embedding_function=OpenAIEmbeddings())\n",
              "\n",
              "# Слой хранения для родительских документов\n",
              "store = InMemoryStore()\n",
              "\n",
              "# Инициализация ретриевера\n",
              "retriever = ParentDocumentRetriever(\n",
              "    vectorstore=vectorstore,\n",
              "    docstore=store,\n",
              "    child_splitter=child_splitter,\n",
              "    parent_splitter=parent_splitter,\n",
              ")\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html\">https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.CharacterTextSplitter.html\">https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.CharacterTextSplitter.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html\">https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html</a></div></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Пользователь: как сохранять предыдущее взаимодействие с пользователем в чате\n",
            "\"How to save previous user interactions in a chat\"\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    <div>Запрос пользователя: как сохранять предыдущее взаимодействие с пользователем в чате</br>стоимость (запрос+перевод+ответ) 4753 токенов </br>Ответ консультанта:<pre><code class=\"Python\"># Пример кода на Python\n",
              "\n",
              "# Определение функции для получения истории сообщений сессии\n",
              "# Функция принимает идентификатор пользователя и идентификатор беседы\n",
              "# и возвращает историю сообщений\n",
              "# Если история для данного пользователя и беседы не существует, создается новая\n",
              "# история в памяти\n",
              "# Возвращает объект истории сообщений\n",
              "\n",
              "def get_session_history(\n",
              "    user_id: str, conversation_id: str\n",
              ") -> BaseChatMessageHistory:\n",
              "    if (user_id, conversation_id) not in store:\n",
              "        store[(user_id, conversation_id)] = InMemoryHistory()\n",
              "    return store[(user_id, conversation_id)]\n",
              "\n",
              "# Создание шаблона чата\n",
              "# Шаблон содержит сообщения для системы, пользователя и заполнитель для истории сообщений\n",
              "prompt = ChatPromptTemplate.from_messages([\n",
              "    (\"system\", \"You're an assistant who's good at {ability}\"),\n",
              "    MessagesPlaceholder(variable_name=\"history\"),\n",
              "    (\"human\", \"{question}\"),\n",
              "])\n",
              "\n",
              "# Создание цепочки для общения\n",
              "# Цепочка состоит из шаблона чата и модели для общения\n",
              "chain = prompt | ChatAnthropic(model=\"claude-2\")\n",
              "\n",
              "# Создание объекта для выполнения с учетом истории сообщений\n",
              "# Объект содержит цепочку, функцию для получения истории сообщений, ключи для входных и исторических сообщений\n",
              "# и конфигурацию для создания истории\n",
              "with_message_history = RunnableWithMessageHistory(\n",
              "    chain,\n",
              "    get_session_history=get_session_history,\n",
              "    input_messages_key=\"question\",\n",
              "    history_messages_key=\"history\",\n",
              "    history_factory_config=[\n",
              "        ConfigurableFieldSpec(\n",
              "            id=\"user_id\",\n",
              "            annotation=str,\n",
              "            name=\"User ID\",\n",
              "            description=\"Unique identifier for the user.\",\n",
              "            default=\"\",\n",
              "            is_shared=True,\n",
              "        ),\n",
              "        ConfigurableFieldSpec(\n",
              "            id=\"conversation_id\",\n",
              "            annotation=str,\n",
              "            name=\"Conversation ID\",\n",
              "            description=\"Unique identifier for the conversation.\",\n",
              "            default=\"\",\n",
              "            is_shared=True,\n",
              "        ),\n",
              "    ],\n",
              ")\n",
              "\n",
              "# Вызов объекта с учетом истории сообщений\n",
              "with_message_history.invoke()\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html\">https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html</a></div></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Пользователь: расскажи про агентов\n",
            "\"Tell me about agents\"\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    <div>Запрос пользователя: расскажи про агентов</br>стоимость (запрос+перевод+ответ) 4575 токенов </br>Ответ консультанта:<pre><code class=\"Python\"># Пример использования класса AgentExecutor\n",
              "\n",
              "from langchain.agents import AgentExecutor\n",
              "from langchain.prompts import ChatPromptTemplate\n",
              "from langchain_cohere import ChatCohere, create_cohere_react_agent\n",
              "\n",
              "# Создание шаблона запроса\n",
              "prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
              "\n",
              "# Создание списка инструментов\n",
              "tools = []  # Заполните этот список инструментами, которые вы хотите использовать.\n",
              "\n",
              "# Инициализация LLM\n",
              "llm = ChatCohere()\n",
              "\n",
              "# Создание агента\n",
              "agent = create_cohere_react_agent(llm, tools, prompt)\n",
              "\n",
              "# Инициализация исполнителя агента\n",
              "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
              "\n",
              "# Вызов агента с запросом\n",
              "agent_executor.invoke({\"input\": \"In what year was the company that was founded as Sound of Music added to the S&P 500?\"})\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html\">https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.base.BaseTracer.html\">https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.base.BaseTracer.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain/chains/structured_output/base.html\">https://api.python.langchain.com/en/latest/_modules/langchain/chains/structured_output/base.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/parsers/language/language_parser.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/parsers/language/language_parser.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html\">https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html\">https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/react_multi_hop/langchain_cohere.react_multi_hop.agent.create_cohere_react_agent.html\">https://api.python.langchain.com/en/latest/react_multi_hop/langchain_cohere.react_multi_hop.agent.create_cohere_react_agent.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html\">https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html</a></div></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Пользователь: stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# конец задания 11"
      ],
      "metadata": {
        "id": "0XrN1wSycc96"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9NNk1hlLSYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBuJDMkiLSJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# промежуточные тесты"
      ],
      "metadata": {
        "id": "BDRPCArAK3dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_question=\"как сохранять предыдущее взаимодействие с пользователем в чате\"\n",
        "answer = answer_user_question_dialog(system, db,dbipynb, user_question,translatequestion=True)\n",
        "display(HTML(wrap(answer[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0EiTiIOpUSWf",
        "outputId": "309ab007-863c-4537-ff5e-3214a9b78cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"How to save previous user interactions in a chat\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>===================startchunk[]===================</br><pre><code class=\"Python\"># Пример кода на Python\n",
              "\n",
              "# Определение функции для получения истории сообщений сессии\n",
              "# Функция принимает идентификатор пользователя и идентификатор беседы\n",
              "# и возвращает историю сообщений\n",
              "# Если история для данного пользователя и беседы не существует, то создается новая\n",
              "# история в памяти\n",
              "# Возвращает объект истории сообщений\n",
              "\n",
              "def get_session_history(\n",
              "    user_id: str, conversation_id: str\n",
              ") -> BaseChatMessageHistory:\n",
              "    if (user_id, conversation_id) not in store:\n",
              "        store[(user_id, conversation_id)] = InMemoryHistory()\n",
              "    return store[(user_id, conversation_id)]\n",
              "\n",
              "# Создание шаблона чата\n",
              "# Шаблон содержит сообщения системы, плейсхолдер для истории сообщений и сообщение пользователя\n",
              "prompt = ChatPromptTemplate.from_messages([\n",
              "    (\"system\", \"You're an assistant who's good at {ability}\"),\n",
              "    MessagesPlaceholder(variable_name=\"history\"),\n",
              "    (\"human\", \"{question}\"),\n",
              "])\n",
              "\n",
              "# Создание цепочки для обработки чата\n",
              "# Цепочка состоит из шаблона чата и модели антропика\n",
              "chain = prompt | ChatAnthropic(model=\"claude-2\")\n",
              "\n",
              "# Создание объекта для выполнения с историей сообщений\n",
              "# Передаем цепочку, функцию для получения истории сообщений, ключи для входящих и исторических сообщений\n",
              "# и конфигурацию для фабрики историй\n",
              "with_message_history = RunnableWithMessageHistory(\n",
              "    chain,\n",
              "    get_session_history=get_session_history,\n",
              "    input_messages_key=\"question\",\n",
              "    history_messages_key=\"history\",\n",
              "    history_factory_config=[\n",
              "        ConfigurableFieldSpec(\n",
              "            id=\"user_id\",\n",
              "            annotation=str,\n",
              "            name=\"User ID\",\n",
              "            description=\"Unique identifier for the user.\",\n",
              "            default=\"\",\n",
              "            is_shared=True,\n",
              "        ),\n",
              "        ConfigurableFieldSpec(\n",
              "            id=\"conversation_id\",\n",
              "            annotation=str,\n",
              "            name=\"Conversation ID\",\n",
              "            description=\"Unique identifier for the conversation.\",\n",
              "            default=\"\",\n",
              "            is_shared=True,\n",
              "        ),\n",
              "    ],\n",
              ")\n",
              "\n",
              "# Вызов функции с историей сообщений\n",
              "with_message_history.invoke()\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html\">https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html</a></div></div>=====================endchunk=====================</br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_question=\"RecursiveCharacterTextSplitter\" #what is RecursiveCharacterTextSplitter for\n",
        "answer = answer_user_question_dialog(system, db,dbipynb, user_question,translatequestion=False)\n",
        "display(HTML(wrap(answer,startend=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "CH-rOt-tw1nG",
        "outputId": "1cc604c4-3946-4c23-e8f4-e82bfa311eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    <pre><code class=\"Python\"># Пример использования класса RecursiveCharacterTextSplitter\n",
              "\n",
              "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
              "\n",
              "# Инициализация объекта RecursiveCharacterTextSplitter\n",
              "text_splitter = RecursiveCharacterTextSplitter(\n",
              "    chunk_size=400,  # размер части текста\n",
              "    chunk_overlap=20,  # количество перекрывающихся токенов между частями\n",
              "    length_function=tiktoken_len,  # функция для измерения длины текста в токенах\n",
              "    separators=['\\n\\n', '\\n', ' ', '']  # разделители текста\n",
              ")\n",
              "\n",
              "# Разделение текста для определенного документа\n",
              "chunks = text_splitter.split_text(docs[5].page_content)\n",
              "len(chunks)\n",
              "print(tiktoken_len(chunks[0]), tiktoken_len(chunks[1]))\n",
              "\n",
              "# Для документа docs[5] мы создали 2 части длиной в 346 и 247 токенов\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html\">https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html</a></div></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_question=\"what is RecursiveCharacterTextSplitter for\"\n",
        "answer = answer_user_question_dialog(system, db,dbipynb, user_question,translatequestion=False)\n",
        "display(HTML(wrap(answer)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "q1Uabv4gQgWb",
        "outputId": "83e8b4d6-4e43-4c0f-8ab6-c21324d79b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>===================startchunk[]===================</br><pre><code class=\"Python\"># Импорт необходимых библиотек и классов\n",
              "from langchain_text_splitters.base import TextSplitter\n",
              "\n",
              "# Определение класса RecursiveCharacterTextSplitter, наследующего TextSplitter\n",
              "class RecursiveCharacterTextSplitter(TextSplitter):\n",
              "    \"\"\"Разделение текста путем рекурсивного просмотра символов.\n",
              "    Рекурсивно пытается разделить текст по разным символам, чтобы найти подходящий.\n",
              "    \"\"\"\n",
              "\n",
              "    def __init__(\n",
              "        self,\n",
              "        separators: Optional[List[str]] = None,\n",
              "        keep_separator: bool = True,\n",
              "        is_separator_regex: bool = False,\n",
              "        **kwargs: Any,\n",
              "    ) -> None:\n",
              "        super().__init__(**kwargs)\n",
              "        self._separators = separators\n",
              "        self._keep_separator = keep_separator\n",
              "        self._is_separator_regex = is_separator_regex\n",
              "\n",
              "    def split_text(self, text: str) -> List[str]:\n",
              "        \"\"\"Разделение входного текста и возврат фрагментов.\"\"\"\n",
              "        # Сначала мы наивно разделяем большой ввод на множество меньших.\n",
              "        splits = []\n",
              "        for separator in self._separators:\n",
              "            if self._is_separator_regex:\n",
              "                separator = re.escape(separator)\n",
              "            splits = _split_text_with_regex(text, separator, self._keep_separator)\n",
              "            _separator = \"\" if self._keep_separator else separator\n",
              "            splits = self._merge_splits(splits, _separator)\n",
              "        return splits\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html\">https://api.python.langchain.com/en/latest/_modules/langchain_text_splitters/character.html</a></div></div>=====================endchunk=====================</br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string(user_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmF2K3XbJiUJ",
        "outputId": "e9fadb35-e2bd-4e77-a94c-ebc4b9fbeeea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_question=\"как приготовить документы для дальнейшего использования?\"\n",
        "answer = answer_user_question_dialog(system, db,dbipynb, user_question,translatequestion=True)\n",
        "display(HTML(wrap(answer)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "T59YWZ6gvwM_",
        "outputId": "874e30e5-1a84-427f-936a-b214622d0bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css\">\n",
              "    <script src=\"https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js\"></script>\n",
              "    <script>hljs.highlightAll();</script>\n",
              "    </br>===================startchunk[]===================</br><pre><code class=\"Python\"># Импорт необходимых библиотек\n",
              "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
              "\n",
              "# Инициализация объекта RecursiveCharacterTextSplitter\n",
              "# с указанием размера чанка, перекрытия, функции длины и разделителей\n",
              "text_splitter = RecursiveCharacterTextSplitter(\n",
              "    chunk_size=400,\n",
              "    chunk_overlap=20,  # количество перекрывающихся токенов между чанками\n",
              "    length_function=tiktoken_len,  # функция для подсчета длины текста\n",
              "    separators=['\\n\\n', '\\n', ' ', '']\n",
              ")\n",
              "\n",
              "# Разделение текста на чанки\n",
              "chunks = text_splitter.split_text(docs[5].page_content)\n",
              "len(chunks)\n",
              "\n",
              "# Подсчет длины чанков\n",
              "tiktoken_len(chunks[0]), tiktoken_len(chunks[1])\n",
              "</code></pre></br>полезные ссылки <div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.parsers.audio.OpenAIWhisperParserLocal.html\">https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.parsers.audio.OpenAIWhisperParserLocal.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html\">https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.async_html.AsyncHtmlLoader.html\">https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.async_html.AsyncHtmlLoader.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.quip.QuipLoader.html\">https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.quip.QuipLoader.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/utilities/searx_search.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/vectorstores/pgvecto_rs.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain/chains/structured_output/base.html\">https://api.python.langchain.com/en/latest/_modules/langchain/chains/structured_output/base.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/parsers/language/language_parser.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/document_loaders/parsers/language/language_parser.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html\">https://api.python.langchain.com/en/latest/_modules/langchain_anthropic/chat_models.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html\">https://api.python.langchain.com/en/latest/_modules/langchain_community/embeddings/aleph_alpha.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html\">https://api.python.langchain.com/en/latest/_modules/langchain_cohere/react_multi_hop/parsing.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html\">https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.parsing.json_distance.JsonEditDistanceEvaluator.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.base.BaseTracer.html\">https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.base.BaseTracer.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain/chains/combine_documents/reduce.html\">https://api.python.langchain.com/en/latest/_modules/langchain/chains/combine_documents/reduce.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/index.html\">https://api.python.langchain.com/en/latest/_modules/index.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.you.YouDocument.html\">https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.you.YouDocument.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html\">https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.prompt.PromptTemplate.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_mapping.html\">https://api.python.langchain.com/en/latest/_modules/langchain_experimental/data_anonymizer/deanonymizer_mapping.html</a></div><div><a target=\"_blank\" href=\"https://api.python.langchain.com/en/latest/_modules/typing.html\">https://api.python.langchain.com/en/latest/_modules/typing.html</a></div></div>=====================endchunk=====================</br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ^конец промежуточных тестов"
      ],
      "metadata": {
        "id": "La9GVXe_LAUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# deprecated"
      ],
      "metadata": {
        "id": "LPI2RJa0hibP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def dispansw(answer):\n",
        "    json_str=answer.strip(\"`\")\n",
        "    json_obj = json.loads(json_str)\n",
        "    display(HTML(wrap(json_obj[\"HTMLPYCODE\"])))\n",
        "    print(\"Links:\", json_obj[\"RLVCLASSES\"])\n",
        "def dispall(answer):\n",
        "    json_str=answer.strip(\"`\")\n",
        "    print(json_str)\n",
        "    json_obj = json.loads(json_str)\n",
        "    for key,value in json_obj.items():\n",
        "        display(HTML(wrap(value,key)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qn9XF9ABElDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "system=\"\"\"\n",
        "Ты-консультант по использованию LangChain библиотеки для python.\n",
        "принятые сокращения:\n",
        "ФР - часть текста из технической документации из библиотеки LangChain, которая(часть)\n",
        "в общем случае может оказаться фрагментом кода без начала или конца,\n",
        "т.е. не законченной по правилам python структуры кода.\n",
        "БД - это сокращенно \"несколько ФР\";\n",
        "ИСТ - это сокращенно \"источник отдельного фрагмента из БД\", представляющий собой уникальный номер;\n",
        "АВП - это сокращенно \"актуальный вопрос пользователя\";\n",
        "Далее тебе будет предоставлена следующая информация:\n",
        "1.БД delimited by triple quotes \\\"\\\"\\\";\n",
        "each ФР is is preceded by the inscription FRAG№ and followed by an ИСТ, delimited by triple tildes ~~~;\n",
        "2.АВП delimited by triple backticks ```;\n",
        "Ты должен полноценно ответить АВП, в т.ч. привести пример законченного кода, а не фрагмента без конца или начала.\n",
        "На основе предоставленной тебе БД выдай ответ в одной из форм:\n",
        "1.если тебе не хватает для ответа цельносвязной информации из БД,\n",
        "из БД ты должен выявить список ФР (назовем СПИСОКФР), наиболее близких к АВП,\n",
        "далее для СПИСОКФР ты должен сформировать список ИСТ (назовем СПИСОКИСТ);\n",
        "из СПИСОКФР ты должен выявить имена внутренних функций и/или параметров,\n",
        "сформировать из них список ААА и выдать ответ in JSON format with the following keys:\n",
        "success=False, additional=ААА, source=СПИСОКИСТ.\n",
        "2.если информации для ответа хватает, ответь подробно на АВП с использованием БД,\n",
        "напиши код python (назовем его БББ), если это поможет решить задачу пользователя;\n",
        "Format БББ as HTML (назовем БББHTML) that can be used in a website.\n",
        "ты должен сформировать список ИСТ (назовем СПИСОКИСТ) тех фрагментов, которые взяты за основу ответа;\n",
        "выдай ответ in JSON format with the following keys:\n",
        "success=True, response=БББHTML, source=ИСТ.\n",
        "Не придумывай ничего от себя, отвечай максимально по БД, не предлагай решение из других библиотек.\n",
        "Если переданная тебе БД не содержат ответа на АВП, ответь \"данный вопрос не в моей компетенции, задайте другой вопрос...\"\n",
        "\"\"\"\n",
        "Act as a python expert, most for LangChain library.\n",
        "принятые сокращения:\n",
        "ФР - часть текста из технической документации из библиотеки LangChain, которая(часть)\n",
        "в общем случае может оказаться фрагментом кода без начала или конца,\n",
        "т.е. не законченной по правилам python структуры кода.\n",
        "БД - это сокращенно \"несколько ФР\";\n",
        "ИСТ - это сокращенно \"источник отдельного фрагмента из БД\", представляющий собой уникальный номер;\n",
        "АВП - это сокращенно \"актуальный вопрос пользователя\";\n",
        "Далее тебе будет предоставлена следующая информация:\n",
        "1.БД delimited by triple quotes \\\"\\\"\\\";\n",
        "each ФР is preceded by the inscription FRAG№ and followed by an ИСТ, delimited by triple tildes ~~~;\n",
        "2.АВП delimited by triple backticks ```;\n",
        "return only a JSON with the following keys :\n",
        "\"response\" for БББ fragment, \"linkto\" for СПИСОККЛ fragment (see details below).\n",
        "из контекста АВП и из предоставленной тебе БД сформулируй простую задачу,\n",
        "иллюстрирующую основную идею применения наиболее релевантного к АВП класса библиотеки LangChain\n",
        "и обязательно напиши код python (назовем его БББ), решающий эту задачу.\n",
        "Для твоего кода сформируй список не более трех наиболее ключевых классов (назовем СПИСОККЛ).\n",
        "Не придумывай ничего от себя, отвечай максимально по БД.\n",
        "Если переданная тебе БД не содержат ничего похожего на АВП, ответь \"По данному вопросу не найдено релевантной информации в библиотеке Langchain, задайте другой вопрос...\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "Request: Act as a Python expert, especially proficient with the LangChain library.\n",
        "Below is the data structure and abbreviations that will be used:\n",
        "\n",
        "Fragment (FR): A text or code excerpt from the LangChain library, which may not be a complete Python structure.\n",
        "Database (DB): A collection of multiple Fragments.\n",
        "Source ID (SRC): A unique identifier representing the source of each individual Fragment in the Database.\n",
        "User's Query (UFAQ): The current question posed by the user.\n",
        "\n",
        "Instructions for data handling:\n",
        "The Database will be delimited by triple quotes (\\\"\\\"\\\");\n",
        "each Fragment is preceded by the label FRAG№ and followed by the Source ID, delimited by triple tildes (~~~).\n",
        "The User's Query will be delimited by triple backticks (```).\n",
        "\n",
        "Task: Based on the context of the User's Query and the provided Database,\n",
        "formulate a simple task illustrating the application of the most relevant class\n",
        "from the LangChain library to the User's Query. Develop Python code (termed as PYCODE) to solve this task.\n",
        "Format PYCODE as HTML (termed as HTMLPYCODE) that can be used in a website.\n",
        "Determine a list of up to three key classes used in your code (termed as CLLIST).\n",
        "\n",
        "If the Database does not contain information pertinent to the User's Query, return a JSON response:\n",
        "{\n",
        "  \"response\": \"По данному вопросу не найдено релевантной информации в библиотеке Langchain, задайте другой вопрос...\"\n",
        "}\n",
        "Expected JSON format for the response:\n",
        "{\n",
        "  \"HTMLPYCODE\": \"Python code solving the posed question\",\n",
        "  \"CLLIST\": [\"ClassName1\", \"ClassName2\", \"ClassName3\"]\n",
        "}\n",
        "Additionally, ensure that the response is provided in Russian.\n",
        "\n"
      ],
      "metadata": {
        "id": "0a5llWOBhv5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system=\"\"\"\n",
        "### instruction ###\n",
        "Act as a Python expert, especially proficient with the LangChain library.\n",
        "Below is the data structure and abbreviations that will be used:\n",
        "Fragment: A text or code excerpt from the LangChain library, which may not be a complete Python structure.\n",
        "Database: A collection of multiple Fragments.\n",
        "SourceID: A unique identifier representing the source of each individual Fragment in the Database.\n",
        "User's Query: The current question posed by the user.\n",
        "PythonEntity: Python classes or methods.\n",
        "\n",
        "Instructions for data handling:\n",
        "The Database will be delimited by triple quotes (\\\"\\\"\\\");\n",
        "each Fragment is preceded by the label FRAG№ and followed by the SourceID, delimited by triple tildes (~~~).\n",
        "The User's Query will be delimited by triple backticks (```).\n",
        "\n",
        "### Task ###\n",
        "From the database extract a list of all PythonEntity (termed as  ALLentity) and any existing brief information about their purposes.\n",
        "Define the following elements from the User's Query:\n",
        "- some PythonEntity that exist in ALLentity;\n",
        "- explicit task;\n",
        "In the absence of any of the two points, the User's Query should be expanded using the existing point as follows:\n",
        "- if only a task is present, then it is necessary to select from one to three most suitable PythonEntity from ALLentity to perform this type of task;\n",
        "- if only PythonEntity are present, you need to show an example of the use of these PythonEntity;\n",
        "Given the goal and the exact PythonEntity, you should be able to generate some pretty clear example Python code.\n",
        "First try to find existing Python code from the database.\n",
        "If a suitable fragment is not found, generate the Python code yourself based on the information from the database.\n",
        "Please provide this code with comments in Russian.\n",
        "Explain in as much detail as possible the main purpose of the classes, methods and parameters used.\n",
        "The list of PythonEntity used in yourcode termed as RLVCLASSES.\n",
        "\n",
        "Provide next four Entity\n",
        "-main goal for Python code generation;\n",
        "-you python code wraped with <pre> and <code=\"Python\"> tags to ensure it will properly displayed as HTML on a webpage;\n",
        "-RLVCLASSES;\n",
        "-PythonEntity specified by user;\n",
        "as JSON with the following keys:\n",
        "\"goal\",\"HTMLPYCODE\",\"RLVCLASSES\",\"PythonEntity\";\n",
        "Also, make sure that all you comments are provided in Russian only.\n",
        "\n",
        "\"\"\"\n",
        "```python\n",
        "# Главная цель для генерации Python кода:\n",
        "# - Извлечь информацию о классе RecursiveCharacterTextSplitter из базы данных и предоставить пример использования.\n",
        "\n",
        "# Python код для класса RecursiveCharacterTextSplitter с комментариями:\n",
        "\n",
        "from langchain_text_splitters.character import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Создание экземпляра класса RecursiveCharacterTextSplitter с указанием параметров\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=['\\n\\n', '\\n', ' ', ''],  # разделители для разделения текста\n",
        "    chunk_size=400,  # размер чанка\n",
        "    chunk_overlap=20,  # перекрытие между чанками\n",
        "    length_function=tiktoken_len  # функция для подсчета количества токенов\n",
        ")\n",
        "\n",
        "# Разделение текста на чанки\n",
        "chunks = text_splitter.split_text(docs[5].page_content)\n",
        "\n",
        "# Вывод информации о количестве токенов в каждом чанке\n",
        "print(tiktoken_len(chunks[0]), tiktoken_len(chunks[1]))\n",
        "\n",
        "# Пример использования класса RecursiveCharacterTextSplitter для разделения текста на чанки с заданными параметрами.\n",
        "```\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"goal\": \"Извлечь информацию о классе RecursiveCharacterTextSplitter из базы данных и предоставить пример использования\",\n",
        "  \"HTMLPYCODE\": \"<pre><code class=\\\"Python\\\"># Python код для класса RecursiveCharacterTextSplitter с комментариями:\\n\\nfrom langchain_text_splitters.character import RecursiveCharacterTextSplitter\\n\\n# Создание экземпляра класса RecursiveCharacterTextSplitter с указанием параметров\\ntext_splitter = RecursiveCharacterTextSplitter(\\n    separators=['\\\\n\\\\n', '\\\\n', ' ', ''],  # разделители для разделения текста\\n    chunk_size=400,  # размер чанка\\n    chunk_overlap=20,  # перекрытие между чанками\\n    length_function=tiktoken_len  # функция для подсчета количества токенов\\n)\\n\\n# Разделение текста на чанки\\nchunks = text_splitter.split_text(docs[5].page_content)\\n\\n# Вывод информации о количестве токенов в каждом чанке\\nprint(tiktoken_len(chunks[0]), tiktoken_len(chunks[1]))\\n\\n# Пример использования класса RecursiveCharacterTextSplitter для разделения текста на чанки с заданными параметрами.\\n</code></pre>\",\n",
        "  \"RLVCLASSES\": [\"RecursiveCharacterTextSplitter\"],\n",
        "  \"PythonEntity\": \"RecursiveCharacterTextSplitter\"\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "Lxm3f3Uau7sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testtesttest\n"
      ],
      "metadata": {
        "id": "wgUSuvdDiLPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install certifi python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xdKcv5905cg",
        "outputId": "c4b6cfcb-26a4-4813-de5d-e9fe719ccbf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (2024.2.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# os.environ.clear()\n",
        "# load_dotenv(\".env\")\n",
        "print(os.environ.get(\"SSL_CERT_FILE\"))\n",
        "print(os.environ.get('REQUESTS_CA_BUNDLE'))\n",
        "\n",
        "import ssl\n",
        "# ssl._create_default_https_context = ssl._create_unverified_context\n",
        "from httpx import HTTPTransport\n",
        "from unittest.mock import patch\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "# print(dir(OpenAIEmbeddings))\n",
        "# print(OpenAIEmbeddings.__doc__)\n",
        "\n",
        "# from langchain_openai import OpenAIEmbeddingsc:\\temp\\KasperskyCertification.crt\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "import openai\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "openai.verify_ssl_certs = False\n",
        "# print(os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Укажите путь к директории\n",
        "# folder_path = ''\n",
        "# задаем system\n",
        "default_system = '''Ты-консультант по ПРАВИЛАМ СТРАХОВАНИЯ.\n",
        "Ответь на вопрос клиента на основе переданного тебе документа с соответствующими правилами.\n",
        "Не придумывай ничего от себя, отвечай максимально по документу.\n",
        "Не упоминай Документ с информацией для ответа клиенту.\n",
        "Клиент ничего не должен знать про Документ с информацией для ответа клиенту\n",
        "'''\n",
        "\n",
        "# Проверяем существование файлов\n",
        "def check_files_exist(folder_path, file_names):\n",
        "    for file_name in file_names:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.exists(file_path):\n",
        "            pass\n",
        "        else:\n",
        "            print(f\"Файл '{file_name}' не найден в директории '{folder_path}'.\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "class LLMModel():\n",
        "    def __init__(self, folder_path: str, sep: str = \" \", ch_size: int = 1024):\n",
        "        self.client = OpenAI()\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "\n",
        "        index_name = \"dbaerofaiss_from_langchain\"\n",
        "        # Список файлов для проверки\n",
        "        files_to_check = [f'{index_name}.faiss', f'{index_name}.pkl']\n",
        "        # Вызов функции проверки\n",
        "        if check_files_exist(folder_path, files_to_check):\n",
        "            # возможность загрузки предварительно сохраненной индексной базы с диска\n",
        "            # Имя, используемое при сохранении файлов\n",
        "            # Загрузка данных и создание нового экземпляра FAISS\n",
        "            self.db = FAISS.load_local(\n",
        "                folder_path=folder_path,\n",
        "                embeddings=embeddings,\n",
        "                index_name=index_name\n",
        "            )\n",
        "\n",
        "        else: # база не проиндексирована - сделать это с нуля\n",
        "            # прочитать с гуглдрайва из под uvicorn не получилось из-за ssl ошибок.\n",
        "            # простой запуск без uvicorn - сработывал нормально\n",
        "            # document=getfilefromgoogledisk(uniquesubstringfromfilename='АЭРОПОРТОВ И АВИАЦИОННЫХ ТОВАРОПРОИЗВОДИТЕЛЕЙ')\n",
        "\n",
        "            # чтение локальной копии файла базы знаний\n",
        "            with open(f\"{folder_path}Копия ПРАВИЛА СТРАХОВАНИЯ ОТВЕТСТВЕННОСТИ АЭРОПОРТОВ И АВИАЦИОННЫХ ТОВАРОПРОИЗВОДИТЕЛЕЙ.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "                document = f.read()\n",
        "\n",
        "            # создаем список чанков\n",
        "            source_chunks = []\n",
        "            splitter = CharacterTextSplitter(separator=sep, chunk_size=ch_size)\n",
        "            for chunk in splitter.split_text(document):\n",
        "                source_chunks.append(Document(page_content=chunk, metadata={}))\n",
        "\n",
        "            # создаем индексную базу\n",
        "            self.db = FAISS.from_documents(source_chunks, embeddings)\n",
        "            # сохраняем db_from_texts на ваш гугл драйв\n",
        "            self.db.save_local(folder_path=folder_path, index_name=index_name)\n",
        "\n",
        "\n",
        "    def get_answer(self,query: str = None, system: str = default_system):\n",
        "        '''Функция получения ответа от chatgpt\n",
        "        '''\n",
        "        # релевантные отрезки из базы\n",
        "        docs = self.db.similarity_search(query, k=4)\n",
        "        message_content = '\\n'.join([f'{doc.page_content}' for doc in docs])\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": f\"Ответь на вопрос клиента. Не упоминай документ с информацией для \\\n",
        "                                          ответа клиенту в ответе. Документ с информацией для ответа клиенту:\\\n",
        "                                          {message_content}\\n\\nВопрос клиента: \\n{query}\"}\n",
        "        ]\n",
        "\n",
        "        # получение ответа от chatgpt\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\", #gpt-3.5-turbo-1106\n",
        "            # response_format={ \"type\": \"json_object\" },\n",
        "            messages=messages,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "# model = LLMModel(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWS3SV7gyY2i",
        "outputId": "87ceab27-fb93-41a2-a0ec-8605f686a3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y-CV1TiI1UK-",
        "outputId": "740295ae-d4cd-43bd-9cb1-01c245c81bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./drive/MyDrive/docs4colab'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path  = './drive/MyDrive/docs4colab'\n",
        "model = LLMModel(f\"{folder_path}/testforwebservices/\")"
      ],
      "metadata": {
        "id": "xOgrqJwn00Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_answer(\"какая деятельность относится к аэропортовой?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "4dLZ5dvi43xG",
        "outputId": "55e45d13-b860-478b-fc4a-32d9aa68a970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Аэропортовая деятельность включает в себя деятельность, осуществляемую юридическими лицами, по обеспечению взлета, посадки, руления, стоянки воздушных судов, их техническому обслуживанию и обеспечению горюче-смазочными материалами и специальными жидкостями, коммерческому обслуживанию пассажиров, багажа, почты и грузов.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for _key, _value in model.db.docstore._dict.items():\n",
        "    print(f\"{_key} {(_value)}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txf259825Wnu",
        "outputId": "d32cb1d3-14da-4f33-8a45-043a84749679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33588e6c-af8a-4f8f-b9a3-4ebe7c4cf7a3 page_content='\\ufeffПРАВИЛА СТРАХОВАНИЯ ОТВЕТСТВЕННОСТИ АЭРОПОРТОВ И АВИАЦИОННЫХ ТОВАРОПРОИЗВОДИТЕЛЕЙ \\n\\n\\n ОБЩИЕ ПОЛОЖЕНИЯ \\n1.1. В соответствии с законодательством Российской Федерации и на основании настоящих Правил страховая организация АО «АльфаСтрахование» (далее по тексту – Страховщик) заключает договоры страхования гражданской ответственности перед третьими лицами владельцев и эксплуатантов аэропортов, поставщиков авиационных товаров и услуг, а также органов управления воздушным движением (далее по тексту - Страхователи). \\n1.2. Основные понятия, конкретизированные определениями, изложенными ниже, трактуются в рамках настоящих Правил только согласно данным определениям: \\n1.2.1. Авиационные товары и услуги - изделия авиационно-космической техники: самолеты, вертолеты, летательные аппараты специального назначения, планеры, автожиры, дельтапланы, ракеты космического назначения, космические аппараты, двигатели, агрегаты, оборудование, приборы и другие комплектующие изделия (КИ), конструкторская и техническая документация к ним,'\n"
          ]
        }
      ]
    }
  ]
}